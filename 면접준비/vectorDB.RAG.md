# AI 면접 프로젝트: Vector DB(pgvector) 기술 정리 및 면접 가이드

본 문서는 면접 준비를 위해 프로젝트 내 Vector DB의 활용 현황을 체계적으로 정리한 자료입니다.

---

## 1. 개요 (Overview)

* **기술 스택**: PostgreSQL + **`pgvector`** 확장 프로그램
* **선택 이유**:
  * **통합 관리**: 관계형 데이터(지원자 정보, 면접 로그)와 벡터 데이터(임베딩)를 하나의 DB에서 관리하여 데이터 정합성 유지.
  * **비용 효율**: Pinecone, Milvus 등 별도의 벡터 전용 DB 서버를 운영하지 않아 인프라 복잡도와 비용 절감.
  * **표준화**: SQL을 사용하여 벡터 검색과 일반 필터링(예: 특정 지원자의 이력서만 검색)을 동시에 수행 가능.

---

## 2. 주요 활용 모듈 및 목적

### ① RAG (Retrieval-Augmented Generation) - 이력서 기반 질문 생성

* **관련 모듈**: `ai-worker/tasks/chunking.py`, `ai-worker/tasks/rag_retrieval.py`, `ai-worker/tasks/question_generator.py`
* **기능**:
  * **임베딩 생성**: 면접 시작 전, 이력서 본문을 조각(Chunk) 내어 벡터로 변환 후 전용 테이블(`resume_embeddings`)에 저장.
  * **실시간 검색(Retrieve)**: 질문을 생성할 때, 현재 면접 단계의 주제(예: 직무 경험, 문제 해결)와 가장 관련성 높은 이력서 구절을 벡터 검색으로 추출.
  * **문맥 보강(Augment)**: 추출된 구절을 LLM의 프롬프트에 '참고 정보'로 넣어 질문의 정확도를 높임.
* **학습용 팁**: "네, 이 방식은 **RAG 아키텍처**가 맞습니다. LLM이 이력서 내용을 외우고 있지 않아도, DB에서 필요한 정보를 실시간으로 찾아와서(Retrieve) 답변을 보강(Augment)하여 생성(Generation)하기 때문입니다."

### ② 질문 시나리오별 RAG 적용 현황

현재 우리 프로젝트의 시나리오에서 어떤 문항이 RAG를 사용하는지 구분하는 것이 중요합니다.

| 분류                   | 해당하는 단계 (Order)         | RAG 사용 여부                | 이유                                                                                                                      |
| :--------------------- | :---------------------------- | :--------------------------- | :------------------------------------------------------------------------------------------------------------------------ |
| **템플릿 질문**  | 1, 2, 3, 5, 7, 9, 11번        | **X (매핑 방식)**      | 이력서에서 추출된 '정형 데이터'(회사명, 직무명, 프로젝트명)를 템플릿에 직접 꽂아 넣음.                                    |
| **AI 생성 질문** | 13, 14번 등 (나머지 AI 문항)  | **O (RAG 사용)**       | 특정 주제(예: 성장 가능성)에 대해 이력서에서 근거 문장을 찾아 질문을 구성할 때 `rag_retrieval.py`를 호출함.             |
| **AI 꼬리질문**  | 4, 6, 8, 10, 12번 (Follow-up) | **X (대화 맥락 사용)** | **환각(Hallucination) 방지**를 위해 이력서 검색보다는 현재 지원자가 방금 한 '답변' 내용에만 집중하여 질문을 생성함. |

### ③ 답변(Transcript) 데이터 처리 방식

* **현재 방식**: 지원자의 답변은 STT를 통해 텍스트로 변환되어 `transcripts` 테이블에 **Plain Text**로 저장됩니다.
* **임베딩 여부**: 현재 면접 과정에서 **지원자의 답변을 실시간으로 청킹하거나 벡터 DB에 넣지는 않습니다.**
* **이유**: 답변은 실시간 평가(`evaluator.py`)와 꼬리질문 생성을 위한 '문맥'으로 즉시 사용될 뿐, 다른 지원자와 유사도를 비교하거나 재검색할 필요가 현재는 없기 때문입니다. (단, 우수 답변 은행 등 향후 확장성을 위해 `AnswerBank` 테이블 구조는 설계되어 있습니다.)

---

## 3. 데이터 파이프라인 (Data Pipeline)

1. **전처리 (Pre-processing)**: `chunking.py`에서 문장을 500~1000자 내외로 분할.
2. **임베딩 (Embedding)**: `sentence-transformers` 또는 고성능 오픈소스 임베딩 모델(예: BGE-M3)을 사용하여 1024차원의 밀집 벡터(Dense Vector) 생성.
3. **저장 (Storage)**: PostgreSQL의 `vector(1024)` 타입을 사용하는 `embedding` 컬럼에 저장.
4. **검색 (Retrieval)**: 코사인 유사도 연산자(`<=>`)를 사용하여 유사도가 높은 상위 K개의 데이터를 검색.

---

## 4. 예상 질문 및 모범 답안 (Interview Q&A)

### Q: 꼬리질문(Follow-up) 생성 시 왜 RAG를 쓰지 않고 대화 맥락만 쓰나요?

> **A**: "꼬리질문의 핵심은 지원자의 '방금 전 답변'에 대한 진위 파악과 심층 검증입니다. 이때 이력서 내용을 다시 검색하면, AI가 지원자의 현재 답변과 이력서 내용을 혼동하여 말하지도 않은 내용을 질문하는 **'환각 현상'**이 발생할 수 있습니다. 따라서 꼬리질문은 철저히 이전 답변 문맥에만 강력하게 고정(Grounding)되도록 설계했습니다."

### Q: 이력서 청킹(Chunking) 시 어떤 단위로 쪼개나요?

> **A**: "단순히 글자 수로만 자르는 것이 아니라, 이력서의 섹션(경력, 자격증, 프로젝트 등)의 의미적 경계를 고려하여 쪼갭니다. 이를 통해 벡터 검색 시 하나의 주제가 온전히 담긴 구절이 검색되도록 관리하고 있습니다."

---

## 5. 핵심 코드 위치

* `ai-worker/tasks/resume_embedding.py`: 면접 전 이력서를 벡터화하여 DB에 넣는 핵심 워커.
* `ai-worker/tasks/rag_retrieval.py`: 질문 생성 시 필요한 구절을 찾아주는 엔진.
* `ai-worker/tasks/question_generator.py`: 검색된 컨텍스트를 조합하여 최종 질문을 만드는 로직 (223번 라인 등에서 꼬리질문 시 RAG 제외 로직 확인 가능).
