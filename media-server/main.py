import os
import sys

# [ë¡œê·¸] ì„œë²„ ì‹œì‘ ì¦‰ì‹œ ì¶œë ¥ (ë²„í¼ë§ ë°©ì§€ìš© flush=True)
print("ğŸš€ [ë¯¸ë””ì–´ ì„œë²„] ëª¨ë“ˆ ì´ˆê¸°í™” ì‹œì‘ ì¤‘...", flush=True)

import asyncio
import json
import logging

import base64
import time
import cv2
from typing import Dict, Set
from fastapi import FastAPI, Request, WebSocket, WebSocketDisconnect
from aiortc import RTCPeerConnection, RTCSessionDescription, MediaStreamTrack, RTCConfiguration, RTCIceServer
from aiortc.contrib.media import MediaRelay
from celery import Celery
import av
from vision_analyzer import VisionAnalyzer  # [NEW] MediaPipe Vision Analyzer
import io  # [NEW] ì˜¤ë””ì˜¤ ë²„í¼ë§ìš©

# [Global Monkey Patch] Force UDP Port Range for Docker NAT Traversal
# aiortc/aioiceëŠ” ê¸°ë³¸ì ìœ¼ë¡œ random port(0)ë¥¼ ì‚¬ìš©í•˜ë¯€ë¡œ, ì´ë¥¼ Dockerê°€ ë§¤í•‘í•œ 50000-50050 ë²”ìœ„ë¡œ ê°•ì œí•¨
import socket
import random

original_socket_bind = socket.socket.bind

def restricted_socket_bind(self, address):
    # UDP ì†Œì¼“ì´ê³ , í¬íŠ¸ê°€ 0(ëœë¤)ì¼ ê²½ìš°ì—ë§Œ ê°œì…
    if self.type == socket.SOCK_DGRAM and address[1] == 0:
        min_port = 50000
        max_port = 50050
        # ë²”ìœ„ ë‚´ì—ì„œ ëœë¤ í¬íŠ¸ ì‹œë„ (ìµœëŒ€ 50ë²ˆ)
        for _ in range(100):
            try:
                port = random.randint(min_port, max_port)
                new_address = (address[0], port)
                original_socket_bind(self, new_address)
                print(f"âœ… [MonkeyPatch] UDP Port Bound: {port}", flush=True)
                return
            except OSError:
                continue
        # ì‹¤íŒ¨ ì‹œ ì›ë˜ëŒ€ë¡œ 0ìœ¼ë¡œ ì‹œë„ (ì–´ì°¨í”¼ ì•ˆ ë˜ê² ì§€ë§Œ)
        print("âš ï¸ [MonkeyPatch] UDP Port binding failed in range 50000-50050", flush=True)
        return original_socket_bind(self, address)
    
    # TCPê±°ë‚˜ íŠ¹ì • í¬íŠ¸ê°€ ì§€ì •ëœ ê²½ìš°ëŠ” ê·¸ëŒ€ë¡œ í†µê³¼
    return original_socket_bind(self, address)

socket.socket.bind = restricted_socket_bind
print("ğŸ’ [ë¯¸ë””ì–´ ì„œë²„] Global Socket Monkey Patch Applied: UDP Ports 50000-50050", flush=True)

# 1. ë¡œê¹… ì„¤ì •
# [í•„ìˆ˜] WebRTC ë””ë²„ê¹… ë¡œê·¸ (ì—°ê²° ë¬¸ì œ í•´ê²°ìš©)
# ë„ˆë¬´ ì‹œë„ëŸ¬ìš°ë©´ WARNINGìœ¼ë¡œ ë³€ê²½
logging.basicConfig(level=logging.INFO) # ì „ì²´ ë ˆë²¨ì€ INFOë¡œ ìœ ì§€
logger = logging.getLogger("Media-Server")

# aiortc ë° aioice ë¡œê·¸ ë ˆë²¨ ì¡°ì • (ì—°ê²° ì„±ê³µí–ˆìœ¼ë¯€ë¡œ ì‹œë„ëŸ¬ìš´ ë¡œê·¸ ìˆ¨ê¹€)
logging.getLogger("aiortc").setLevel(logging.WARNING)
logging.getLogger("aioice").setLevel(logging.WARNING)
logging.getLogger("av").setLevel(logging.WARNING) # av ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¡œê·¸ë„ ìˆ¨ê¹€

app = FastAPI()

# CORS ì„¤ì •
from fastapi.middleware.cors import CORSMiddleware
app.add_middleware(
    CORSMiddleware,
    allow_origins=[
        "http://localhost:3000", 
        "http://127.0.0.1:3000",
        "http://localhost:5173",  # Vite ê°œë°œ ì„œë²„
        "http://127.0.0.1:5173"
    ],
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

relay = MediaRelay()

# ë¹„ì „ ë¶„ì„ê¸° ì „ì—­ ë³€ìˆ˜
analyzer_instance = None

def get_analyzer():
    global analyzer_instance
    if analyzer_instance is None:
        print("ğŸš€ [ë¯¸ë””ì–´ ì„œë²„] ë¶„ì„ ì—”ì§„(VisionAnalyzer) ì²« ì ‘ê·¼ - ì´ˆê¸°í™” ì¤‘ (ì§€ì—° ë¡œë”©)...", flush=True)
        analyzer_instance = VisionAnalyzer()
    return analyzer_instance

async def background_init_analyzer():
    """ì„œë²„ ì‹œì‘ ì‹œ ë°±ê·¸ë¼ìš´ë“œ ìŠ¤ë ˆë“œì—ì„œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë”© (Non-blocking)"""
    global analyzer_instance
    try:
        print("ğŸš€ [ë¯¸ë””ì–´ ì„œë²„] ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì‹œì‘...", flush=True)
        # ë¸”ë¡œí‚¹ ì˜¤í¼ë ˆì´ì…˜ì„ ë³„ë„ ìŠ¤ë ˆë“œì—ì„œ ì‹¤í–‰
        loop = asyncio.get_event_loop()
        analyzer_instance = await loop.run_in_executor(None, VisionAnalyzer)
        print("âœ… [ë¯¸ë””ì–´ ì„œë²„] ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ì—”ì§„ ì´ˆê¸°í™” ì™„ë£Œ!", flush=True)
    except Exception as e:
        print(f"âŒ [ë¯¸ë””ì–´ ì„œë²„] ë°±ê·¸ë¼ìš´ë“œ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}", flush=True)

# 2. Celery ì„¤ì •
redis_url = os.getenv("REDIS_URL", "redis://redis:6379/0")
celery_app = Celery("ai_worker", broker=redis_url, backend=redis_url)
celery_app.conf.update(
    broker_connection_retry_on_startup=True,
    redis_backend_health_check_interval=30,  # ì—°ê²° ì•ˆì •ì„± í™•ë³´
)

# 3. ì—°ê²° ê´€ë¦¬ (ì„¸ì…˜ë³„ WebSocket ë° PeerConnection ì €ì¥)
active_websockets: Dict[str, WebSocket] = {}
active_pcs: Dict[str, RTCPeerConnection] = {}
active_video_tracks: Dict[str, 'VideoAnalysisTrack'] = {}
active_analysis_tasks: Dict[str, asyncio.Task] = {}
ws_locks: Dict[str, asyncio.Lock] = {} # [ì¶”ê°€] ì›¹ì†Œì¼“ ë™ì‹œ ì „ì†¡ ë°©ì§€ìš© ë½

async def send_to_websocket(session_id: str, data: dict):
    """WebSocketìœ¼ë¡œ ë°ì´í„° ì „ì†¡ (Lockì„ ì‚¬ìš©í•˜ì—¬ ë™ì‹œ ì „ì†¡ ì¶©ëŒ ë°©ì§€)"""
    ws = active_websockets.get(session_id)
    if not ws:
        return
    
    # ì„¸ì…˜ë³„ ë½ ê°€ì ¸ì˜¤ê¸°
    if session_id not in ws_locks:
        ws_locks[session_id] = asyncio.Lock()
    
    async with ws_locks[session_id]:
        try:
            await ws.send_json(data)
        except Exception as e:
            logger.error(f"[{session_id}] WebSocket ì „ì†¡ ì‹¤íŒ¨: {e}")
    """ë¹„ë””ì˜¤ í”„ë ˆì„ì„ ì¶”ì¶œí•˜ì—¬ ai-workerì— ê°ì • ë¶„ì„ì„ ìš”ì²­í•˜ëŠ” íŠ¸ë™"""
    kind = "video"

    def __init__(self, track, session_id):
        super().__init__()
        self.track = track
        self.session_id = session_id
        
        # [ë°ì´í„° ëˆ„ì ìš©] ì§€ì—° ë¡œë”© í˜¸ì¶œ
        self.analyzer = get_analyzer()
        self.session_started_at = time.time()
        self.total_frames = 0
        
        # ì§ˆë¬¸ë³„ ë°ì´í„° (ì „ì²´ í•©ì‚°ì„ ìœ„í•´ ë¦¬ìŠ¤íŠ¸ë¡œ ê´€ë¦¬)
        self.questions_history = [] 
        self.current_q_index = 0
        self.current_q_data = self._get_empty_q_data()
        
        # [ì‹ ê·œ] ì „ì²´ ë©´ì ‘ í†µí•© ë°ì´í„° ë²„ì¼“ (ëª¨ë“  í”„ë ˆì„ ëˆ„ì )
        self.session_all_data = self._get_empty_q_data()
        
        # ì‹¤ì‹œê°„ ë¡œê·¸ ì¿¨íƒ€ì„
        self.last_log_time = 0
        self.last_tracking_time = 0
        
        # [DEBUG] ìƒì„± ì™„ë£Œ ë¡œê·¸
        print(f"âœ… [{session_id}] VideoAnalysisTrack ì´ˆê¸°í™” ì™„ë£Œ (Analyzer: {self.analyzer is not None})", flush=True)

    def _get_empty_q_data(self):
        """ìƒˆ ì§ˆë¬¸ì„ ìœ„í•œ ë¹ˆ ë°ì´í„° êµ¬ì¡° ìƒì„±"""
        return {
            "smile_scores": [],
            "anxiety_scores": [],
            "gaze_center_frames": 0,
            "posture_stable_frames": 0,
            "total_frames": 0,
            "start_time": time.time()
        }

    def switch_question(self, new_index):
        """ì§ˆë¬¸ì´ ë°”ë€” ë•Œ í˜¸ì¶œ (from WebSocket)"""
        # [ë³€ê²½] ì¤‘ê°„ ë¦¬í¬íŠ¸ ì¶œë ¥ì€ ìƒëµí•˜ê³  ë°ì´í„°ë§Œ ë°±ì—…
        if self.current_q_data["total_frames"] > 0:
            self.questions_history.append(self.current_q_data)
        
        self.current_q_index = new_index
        self.current_q_data = self._get_empty_q_data()
        print(f"â¡ï¸ [{self.session_id}] {new_index}ë²ˆ ì§ˆë¬¸ìœ¼ë¡œ ì „í™˜ë¨ (ì—°ì† ì¶”ì  ì¤‘...)", flush=True)

    def _calculate_scores(self, q_list):
        """ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸(ë˜ëŠ” ë‹¨ì¼ ì§ˆë¬¸)ë¡œë¶€í„° POC ê°€ì¤‘ì¹˜ ê¸°ë°˜ ì ìˆ˜ ê³„ì‚°"""
        if not q_list: return None
        if isinstance(q_list, dict): q_list = [q_list]
        
        total_frames = sum(q["total_frames"] for q in q_list)
        if total_frames == 0: return None

        all_smiles = []
        all_anxiety = []
        total_gaze_center = 0
        total_posture_stable = 0
        
        for q in q_list:
            all_smiles.extend(q["smile_scores"])
            all_anxiety.extend(q["anxiety_scores"])
            total_gaze_center += q["gaze_center_frames"]
            total_posture_stable += q["posture_stable_frames"]

        # [ê³„ì‚°] í‰ê· ê°’ ì‚°ì¶œ (0ìœ¼ë¡œ ë‚˜ëˆ„ê¸° ë°©ì§€)
        if not all_smiles: avg_smile = 0.0
        else: avg_smile = (sum(all_smiles) / len(all_smiles)) * 100  # 0~1 -> 0~100ì  í™˜ì‚°
        
        if not all_anxiety: avg_anxiety = 0.0
        else: avg_anxiety = (sum(all_anxiety) / len(all_anxiety)) * 100 # 0~1 -> 0~100ì  í™˜ì‚°
        
        gaze_ratio = (total_gaze_center / total_frames) * 100
        posture_ratio = (total_posture_stable / total_frames) * 100

        # [ë³´ì •] POC ìˆ˜ì‹ì€ ë„ˆë¬´ ì—„ê²©í•¨ (ë¯¸ì†Œê°€ 0ì´ë©´ ìì‹ ê° 0ì  ì²˜ë¦¬ë¨)
        # ë©´ì ‘ ë¬¸ë§¥ì— ë§ê²Œ ë³´ì •: (í‰ê·  ì ìˆ˜ * 0.6) + 40 (ê¸°ë³¸ 40ì  ë² ì´ìŠ¤)
        
        # 1. ìì‹ ê° (ë¯¸ì†Œ): ë¬´í‘œì •(0%)ì¼ ë•Œ 40ì , í™œì§(100%)ì¼ ë•Œ 100ì 
        adj_smile = (avg_smile * 0.6) + 40
        score_conf = adj_smile * 0.3
        
        # 2. ì‹œì„ ì§‘ì¤‘: ì •ë©´ ì‘ì‹œ ë¹„ìœ¨ì— ë”°ë¼ 40~100ì 
        adj_focus = (gaze_ratio * 0.6) + 40
        score_focus = adj_focus * 0.3
        
        # 3. ìì„¸ì•ˆì •: 40~100ì 
        adj_posture = (posture_ratio * 0.6) + 40
        score_posture = adj_posture * 0.2
        
        # 4. ì •ì„œì•ˆì •: ê¸´ì¥ë„(anxiety)ê°€ 0ì¼ ë•Œ 100ì , 100ì¼ ë•Œ 40ì 
        adj_emotion = ((100 - avg_anxiety) * 0.6) + 40
        score_emotion = adj_emotion * 0.2
        
        overall_score = score_conf + score_focus + score_posture + score_emotion
        
        return {
            "avg_smile": adj_smile, "avg_anxiety": avg_anxiety,
            "gaze_ratio": adj_focus, "posture_ratio": adj_posture,
            "raw_smile": avg_smile, "raw_focus": gaze_ratio, # ë””ë²„ê¹…ìš© ì›ë³¸ê°’
            "score_conf": score_conf, "score_focus": score_focus,
            "score_posture": score_posture, "score_emotion": score_emotion,
            "overall_score": overall_score, "total_frames": total_frames
        }

    def _log_question_summary(self):
        """ì§ˆë¬¸ë³„ ìƒì„¸ ì±„ì  ë¦¬í¬íŠ¸ ë¡œê·¸ ì¶œë ¥ (POC ë””ìì¸)"""
        s = self._calculate_scores(self.current_q_data)
        if not s: return
        
        print("\n" + "-"*50)
        print(f"ğŸ“ AI ë©´ì ‘ [{self.current_q_index}ë²ˆ] ì§ˆë¬¸ ë¶„ì„ ë¦¬í¬íŠ¸")
        print("-" * 50)
        print(f"   1. ìì‹ ê°(ë¯¸ì†Œ) : {s['avg_smile']:5.1f}ì  x 0.3 = {s['score_conf']:4.1f}ì ")
        print(f"   2. ì‹œì„ ì§‘ì¤‘     : {s['gaze_ratio']:5.1f}ì  x 0.3 = {s['score_focus']:4.1f}ì ")
        print(f"   3. ìì„¸ì•ˆì •     : {s['posture_ratio']:5.1f}ì  x 0.2 = {s['score_posture']:4.1f}ì ")
        print(f"   4. ì •ì„œì•ˆì •     : {100-s['avg_anxiety']:5.1f}ì  x 0.2 = {s['score_emotion']:4.1f}ì ")
        print(f"   -------------------------------------------")
        print(f"   âˆ‘ í•´ë‹¹ ì§ˆë¬¸ í•©ê³„: {s['overall_score']:.1f}ì ")
        print("-" * 50 + "\n")

    def generate_final_report(self):
        """ë©´ì ‘ ì¢…ë£Œ ì‹œ ì „ì²´ í•©ì‚° ë¦¬í¬íŠ¸ ë¡œê·¸ ì¶œë ¥ (POC ë””ìì¸)"""
        # [ë³€ê²½] ëª¨ë“  í”„ë ˆì„ì´ ì´ë¯¸ session_all_dataì— ëª¨ì—¬ìˆìœ¼ë¯€ë¡œ ì´ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ê³„ì‚°
        s = self._calculate_scores(self.session_all_data)
        if not s: 
            print(f"âš ï¸ [{self.session_id}] ì„¸ì…˜ ë™ì•ˆ ë¶„ì„ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
            return

        print("\n" + "="*50)
        print(f"ğŸ† AI ë©´ì ‘ [ìµœì¢… ì¢…í•©] ë¶„ì„ ë¦¬í¬íŠ¸ [{self.session_id}]")
        print("="*50)
        print(f"â±ï¸ ì´ ì§ˆë¬¸ ìˆ˜: {len(self.questions_history) + 1}ê°œ")
        print(f"â±ï¸ ë¶„ì„ ê¸°ê°„: {int(time.time() - self.session_started_at)}ì´ˆ / {s['total_frames']} frames")
        print("-" * 50)
        print("ğŸ§® [ì˜ìƒë¶„ì„] ì „ì²´ í‰ê·  ì±„ì  ë‚´ì—­:")
        print(f"   1. ìì‹ ê°(ë¯¸ì†Œ) : {s['avg_smile']:5.1f}ì  x 0.3 = {s['score_conf']:4.1f}ì ")
        print(f"   2. ì‹œì„ ì§‘ì¤‘     : {s['gaze_ratio']:5.1f}ì  x 0.3 = {s['score_focus']:4.1f}ì ")
        print(f"   3. ìì„¸ì•ˆì •     : {s['posture_ratio']:5.1f}ì  x 0.2 = {s['score_posture']:4.1f}ì ")
        print(f"   4. ì •ì„œì•ˆì •     : {100-s['avg_anxiety']:5.1f}ì  x 0.2 = {s['score_emotion']:4.1f}ì ")
        print(f"   -------------------------------------------")
        print(f"   âˆ‘ ìµœì¢… ì¢…í•© í•©ê³„: {s['overall_score']:.1f}ì ")
        print("="*50 + "\n")

    async def process_vision(self, frame, timestamp_ms):
        if not self.analyzer.is_ready:
            print(f"âš ï¸ [{self.session_id}] ë¶„ì„ ì—”ì§„ì´ ì•„ì§ ì¤€ë¹„ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.", flush=True)
            return

        try:
            # print(f"[{self.session_id}] Processing frame at {timestamp_ms}", flush=True)
            img = frame.to_ndarray(format="bgr24")
            
            # [ìµœì í™”] CPU ì§‘ì•½ì  ì‘ì—…(MediaPipe)ì„ ìŠ¤ë ˆë“œ í’€ë¡œ ìœ„ì„í•˜ì—¬ ì´ë²¤íŠ¸ ë£¨í”„ ì°¨ë‹¨ ë°©ì§€
            loop = asyncio.get_event_loop()
            result = await loop.run_in_executor(None, self.analyzer.process_frame, img, timestamp_ms)
            
            if result and result.get("status") == "detected":
                self.total_frames += 1
                
                # 1. í˜„ì¬ ì§ˆë¬¸ ë°ì´í„° ëˆ„ì 
                q = self.current_q_data
                q["total_frames"] += 1
                q["smile_scores"].append(result["scores"]["smile"])
                q["anxiety_scores"].append(result["scores"]["anxiety"])
                if result["flags"]["is_center"]: q["gaze_center_frames"] += 1
                if result["flags"]["is_stable"]: q["posture_stable_frames"] += 1

                # 2. ì „ì²´ ì„¸ì…˜ ë°ì´í„°ì—ë„ í†µí•© ëˆ„ì 
                a = self.session_all_data
                a["total_frames"] += 1
                a["smile_scores"].append(result["scores"]["smile"])
                a["anxiety_scores"].append(result["scores"]["anxiety"])
                if result["flags"]["is_center"]: a["gaze_center_frames"] += 1
                if result["flags"]["is_stable"]: a["posture_stable_frames"] += 1

                # [DEBUG] ì²« í”„ë ˆì„ ìˆ˜ì‹  ì‹œ ë¡œê·¸
                if self.total_frames == 1:
                    print(f"ğŸ“Š [{self.session_id}] ì˜ìƒ ìº¡ì²˜ ì‹œì‘ (ì „ì²´ ì„¸ì…˜ ë¶„ì„ ì¤‘...)", flush=True)

                current_time = time.time()
                # [ìˆ˜ì •] ê°ì§€ëœ ê²½ìš°ì—ë„ 2ì´ˆë§ˆë‹¤ ì›¹ì†Œì¼“ ì „ì†¡ (HUD ì—…ë°ì´íŠ¸ìš©)
                if current_time - self.last_log_time > 2.0:
                    self.last_log_time = current_time
                    s = self._calculate_scores(self.session_all_data)
                    labels = result["labels"]
                    # [ì‚¬ìš©ì ì»¨íŒìš© ë¡œê·¸]
                    print(f"[{self.session_id}] {self.current_q_index}ë²ˆ ì§ˆë¬¸ | [ì‹¤ì‹œê°„ ì¢…í•©ì ìˆ˜: {s['overall_score']:5.1f}ì ] | ğŸ‘€ ì‹œì„ : {labels['gaze']:8} | ğŸ‘¤ ìì„¸: {labels['posture']:12} | ğŸ˜Š ë¯¸ì†Œ: {int(result['scores']['smile']*100):3}%", flush=True)
                    
                    # [ì¶”ê°€] ì‹¤ì‹œê°„ HUD ë°ì´í„° ì „ì†¡
                    await send_to_websocket(self.session_id, {
                        "type": "vision_analysis",
                        "data": {
                            "gaze": result["flags"]["is_center"], # í”„ë¡ íŠ¸ì—”ë“œ ê¸°ëŒ€ í¬ë§·ìœ¼ë¡œ ê°€ê³µ
                            "posture": result["labels"]["posture"],
                            "emotion": result["labels"]["emotion"],
                            "scores": result["scores"]
                        }
                    })
            else:
                # ì–¼êµ´ ë¯¸ê°ì§€ ì‹œì—ë„ 5ì´ˆë§ˆë‹¤ ë¡œê·¸ ì¶œë ¥
                current_time = time.time()
                if current_time - self.last_log_time > 5.0:
                    self.last_log_time = current_time
                    status = result.get("status", "unknown") if result else "no_result"
                    print(f"â“ [{self.session_id}] ì–¼êµ´ ì¸ì‹ ëŒ€ê¸° ì¤‘... (ìƒíƒœ: {status})", flush=True)

                    await send_to_websocket(self.session_id, {
                        "type": "vision_analysis",
                        "data": result if result else {"status": "not_detected"},
                        "timestamp": current_time
                    })
        except Exception as e:
            logger.error(f"Vision analysis failed: {e}")

    async def recv(self):
        # MediaStreamTrack ì„œë¸Œí´ë˜ì‹± ìœ ì§€ (ì´í›„ í•„ìš” ì‹œ í™•ì¥ì„ ìœ„í•´)
        return await self.track.recv()

async def start_video_analysis(track, session_id):
    """ë¹„ë””ì˜¤ íŠ¸ë™ì„ ì§ì ‘ ì†Œë¹„í•˜ë©° ë¶„ì„í•˜ëŠ” ë°±ê·¸ë¼ìš´ë“œ ë£¨í”„ (ê°•ì œ í”„ë ˆì„ ìˆ˜ì‹ )"""
    # [DEBUG] Track ì •ë³´ ì¶œë ¥
    print(f"ğŸ¬ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ì§„ì…: Track Kind={track.kind}, ID={track.id}, State={track.readyState}", flush=True)
    
    # Track ê°ì²´ ìƒì„± (ì´ ë¶€ë¶„ì´ ì˜¤ë˜ ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ ë¡œê·¸ë¡œ ê°ìŒˆ)
    try:
        print(f"âš™ï¸ [{session_id}] VideoAnalysisTrack ê°ì²´ ìƒì„± ì‹œë„...", flush=True)
        analysis_track = VideoAnalysisTrack(track, session_id)
        active_video_tracks[session_id] = analysis_track
        print(f"âš™ï¸ [{session_id}] VideoAnalysisTrack ê°ì²´ ìƒì„± ì„±ê³µ!", flush=True)
    except Exception as e:
        print(f"âŒ [{session_id}] VideoAnalysisTrack ìƒì„± ì‹¤íŒ¨: {e}", flush=True)
        return

    frame_count = 0
    try:
        while True:
            try:
                # [DEBUG] recv ëŒ€ê¸° ìƒíƒœ ë¡œê·¸ (ë„ˆë¬´ ìì£¼ ì°íˆì§€ ì•Šë„ë¡ frame_count 0ì¼ ë•Œë§Œ)
                if frame_count == 0:
                    print(f"â³ [{session_id}] ì²« í”„ë ˆì„ ìˆ˜ì‹  ëŒ€ê¸° ì¤‘...", flush=True)

                # 5ì´ˆ íƒ€ì„ì•„ì›ƒìœ¼ë¡œ í”„ë ˆì„ ìˆ˜ì‹  ëŒ€ê¸° (ë¬´í•œ ëŒ€ê¸° ë°©ì§€)
                frame = await asyncio.wait_for(track.recv(), timeout=5.0)
                frame_count += 1
                curr = time.time()
                
                # [HEARTBEAT] ì²« í”„ë ˆì„ ë° 100í”„ë ˆì„ë§ˆë‹¤ ë¡œê·¸
                if frame_count == 1:
                    print(f"ğŸ‰ [{session_id}] ì²« í”„ë ˆì„ ìˆ˜ì‹  ì„±ê³µ!", flush=True)
                if frame_count % 100 == 0:
                    print(f"ğŸ“½ï¸ [{session_id}] í˜„ì¬ê¹Œì§€ {frame_count} í”„ë ˆì„ ìˆ˜ì‹ ë¨...", flush=True)

                # [ì„±ëŠ¥ ì¡°ì ˆ] 5FPS (0.2s ê°„ê²©) ë¶„ì„ 
                # (LLM ì§ˆë¬¸ ìƒì„± ì†ë„ ì €í•˜ ë°©ì§€ë¥¼ ìœ„í•´ ë¶„ì„ ë¶€í•˜ ê°ì†Œ)
                if curr - analysis_track.last_tracking_time > 0.2:
                    analysis_track.last_tracking_time = curr
                    asyncio.create_task(analysis_track.process_vision(frame, int(curr * 1000)))

            except asyncio.TimeoutError:
                print(f"â° [{session_id}] 5ì´ˆê°„ í”„ë ˆì„ ìˆ˜ì‹  ì—†ìŒ (íƒ€ì„ì•„ì›ƒ)", flush=True)
                # íƒ€ì„ì•„ì›ƒ ë°œìƒí•´ë„ ë£¨í”„ëŠ” ê³„ì† ìœ ì§€ (ì¼ì‹œì  ë„¤íŠ¸ì›Œí¬ ì§€ì—°ì¼ ìˆ˜ ìˆìŒ)
                continue
    except asyncio.CancelledError:
        print(f"ğŸ›‘ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ì·¨ì†Œë¨", flush=True)
    except Exception as e:
        print(f"âš ï¸ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ì—ëŸ¬: {e}", flush=True)
    finally:
        print(f"ğŸ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ì¢…ë£Œë¨", flush=True)
        if analysis_track.current_q_data["total_frames"] > 0:
            analysis_track._log_question_summary()
        analysis_track.generate_final_report()
        active_video_tracks.pop(session_id, None)


async def send_to_websocket(ws: WebSocket, data: dict):
    """WebSocketìœ¼ë¡œ ë°ì´í„° ì „ì†¡"""
    try:
        await ws.send_json(data)
    except Exception as e:
        logger.error(f"WebSocket ì „ì†¡ ì‹¤íŒ¨: {e}")

# ============== WebSocket ì—”ë“œí¬ì¸íŠ¸ ==============

# STT ì¤‘ê³„ í•¨ìˆ˜ (Remote STT)
# WebRTC ì˜¤ë””ì˜¤ ìŠ¤íŠ¸ë¦¼ -> WAV íŒŒì¼ ë³€í™˜ -> AI Workerë¡œ ì „ì†¡
async def start_remote_stt(track, session_id):
    logger.info(f"[{session_id}] ğŸ™ï¸ ì›ê²© STT ì‹œì‘ (Remote STT Started)")
    
    # ì•½ 2ì´ˆ ë‹¨ìœ„ë¡œ ì˜¤ë””ì˜¤ë¥¼ ëª¨ì•„ì„œ ì „ì†¡ (Responsiveness í–¥ìƒ)
    CHUNK_THRESHOLD = 100 # ì•½ 2ì´ˆ (20ms * 100 = 2000ms)
    accumulated_frames = []
    
    try:
        while True:
            # 1. ì˜¤ë””ì˜¤ í”„ë ˆì„ ìˆ˜ì‹ 
            frame = await track.recv()
            accumulated_frames.append(frame)
            
            if len(accumulated_frames) >= CHUNK_THRESHOLD:
                
                # 2. WAV ë³€í™˜ (In-Memory)
                # av ë¼ì´ë¸ŒëŸ¬ë¦¬ì˜ Output Container ì‚¬ìš©
                output_buffer = io.BytesIO()
                output_container = av.open(output_buffer, mode='w', format='wav')
                output_stream = output_container.add_stream('pcm_s16le', rate=16000, layout='mono')
                
                for f in accumulated_frames:
                    # ë¦¬ìƒ˜í”Œë§ ë° íŒ¨í‚· ì‘ì„±
                    for packet in output_stream.encode(f):
                        output_container.mux(packet)
                        
                # 3. ë§ˆë¬´ë¦¬ (Flush)
                for packet in output_stream.encode(None):
                    output_container.mux(packet)
                output_container.close()
                
                # 4. Base64 ì¸ì½”ë”©
                wav_bytes = output_buffer.getvalue()
                audio_b64 = base64.b64encode(wav_bytes).decode('utf-8')
                
                # 5. Celery Task ë°°ë‹¬ (AI Workerì—ê²Œ)
                # [ê°œì„ ] ê²°ê³¼ë¥¼ ê¸°ë‹¤ë ¸ë‹¤ê°€(ë¸Œë¼ìš°ì €ê°€ ì•„ë‹Œ ì„œë²„ê°€ ê¸°ë‹¤ë¦¼) ì›¹ì†Œì¼“ìœ¼ë¡œ ì¦‰ì‹œ ì¤‘ê³„
                task = celery_app.send_task(
                    "tasks.stt.recognize",
                    args=[audio_b64],
                    queue="cpu_queue"
                )
                
                # ë¹„ëŒ€ê¸°(Non-blocking) ë°©ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°›ì•„ ì „ì†¡
                async def wait_and_relay(celery_task, sid):
                    try:
                        loop = asyncio.get_event_loop()
                        
                        # ìµœëŒ€ 15ì´ˆ ë™ì•ˆ ê²°ê³¼ ì¶”ì  (í ëŒ€ê¸° ì‹œê°„ ê³ ë ¤)
                        start_time = time.time()
                        is_ready = False
                        while time.time() - start_time < 15:
                            is_ready = await loop.run_in_executor(None, celery_task.ready)
                            if is_ready:
                                break
                            await asyncio.sleep(0.5) 
                        
                        if is_ready:
                            result = await loop.run_in_executor(None, lambda: celery_task.result)
                            if result and result.get("status") == "success":
                                text = result.get("text", "").strip()
                                if text:
                                    await send_to_websocket(sid, {
                                        "type": "stt_result",
                                        "text": text
                                    })
                                    logger.info(f"[{sid}] ğŸ¤ ì‹¤ì‹œê°„ ìë§‰ ì „ì†¡ ì„±ê³µ: {text[:30]}...")
                    except Exception as e:
                        if "closed file" not in str(e).lower():
                            logger.error(f"[{sid}] STT ê²°ê³¼ ì¤‘ê³„ ì‹¤íŒ¨: {e}")
                    finally:
                        try:
                            celery_task.forget()
                        except:
                            pass

                # ê²°ê³¼ ëŒ€ê¸° ë£¨í‹´ ì‹¤í–‰
                asyncio.create_task(wait_and_relay(task, session_id))
                
                logger.info(f"[{session_id}] ğŸ“¤ ì˜¤ë””ì˜¤ ì²­í¬ ì „ì†¡ ì™„ë£Œ ({len(wav_bytes)} bytes)")
                
                # ë²„í¼ ì´ˆê¸°í™”
                accumulated_frames = []

    except Exception as e:
        logger.info(f"[{session_id}] STT ìŠ¤íŠ¸ë¦¼ ì¢…ë£Œ: {e}")
    finally:
        logger.info(f"[{session_id}] STT ë¦¬ì†ŒìŠ¤ ì •ë¦¬")


@app.websocket("/ws/{session_id}")
async def websocket_endpoint(websocket: WebSocket, session_id: str):
    await websocket.accept()
    active_websockets[session_id] = websocket
    logger.info(f"[{session_id}] âœ… WebSocket ì—°ê²° ì„±ê³µ")
    
    try:
        while True:
            # í´ë¼ì´ì–¸íŠ¸ë¡œë¶€í„° ë©”ì‹œì§€ ìˆ˜ì‹  ëŒ€ê¸°
            data = await websocket.receive_text()
            try:
                msg = json.loads(data)
                # [ì¶”ê°€] ì§ˆë¬¸ ì „í™˜ ì‹ í˜¸ ì²˜ë¦¬
                if msg.get("type") == "next_question":
                    new_idx = msg.get("index", 0)
                    # [ë³€ê²½] active_video_tracksì—ì„œ ì§ì ‘ íŠ¸ë™ ì°¾ê¸°
                    video_track = active_video_tracks.get(session_id)
                    if video_track:
                        video_track.switch_question(new_idx)
            except json.JSONDecodeError:
                pass
            
    except WebSocketDisconnect:
        logger.info(f"[{session_id}] âŒ WebSocket ì—°ê²° ì¢…ë£Œ")
    except Exception as e:
        logger.error(f"[{session_id}] WebSocket ì—ëŸ¬: {e}")
    finally:
        if session_id in active_websockets:
            del active_websockets[session_id]
        if session_id in active_pcs:
            # PCëŠ” ë³„ë„ë¡œ ë‹«íˆì§€ ì•Šì•˜ì„ ê²½ìš°ë¥¼ ìœ„í•´ ìœ ì§€í•˜ê±°ë‚˜ ì¢…ë£Œ ì²˜ë¦¬ ê³ ë¯¼
            # ì—¬ê¸°ì„œëŠ” WebSocket ì¢…ë£Œ ì‹œ PCë„ ì •ë¦¬í•˜ë„ë¡ êµ¬í˜„
            pc = active_pcs.pop(session_id, None)
            if pc:
                await pc.close()
            logger.info(f"[{session_id}] ì„¸ì…˜ ë¦¬ì†ŒìŠ¤ ì •ë¦¬ ì™„ë£Œ")
        
        # [ì¶”ê°€] ì¢€ë¹„ ë¶„ì„ ë£¨í”„ ê°•ì œ ì¢…ë£Œ
        analysis_task = active_analysis_tasks.pop(session_id, None)
        if analysis_task and not analysis_task.done():
            print(f"ğŸ›‘ [{session_id}] ì›¹ì†Œì¼“ ì¢…ë£Œë¡œ ì¸í•œ ì˜ìƒ ë¶„ì„ ë£¨í”„ ê°•ì œ ì·¨ì†Œ...", flush=True)
            analysis_task.cancel()
            try:
                await analysis_task
            except asyncio.CancelledError:
                print(f"âœ… [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ì·¨ì†Œ ì™„ë£Œ", flush=True)

# ============== WebRTC ì—”ë“œí¬ì¸íŠ¸ ==============
def force_localhost_candidate(sdp_str):
    """
    Docker í™˜ê²½ì—ì„œ ë‚´ë¶€ IP(172.x.x.x)ë¥¼ Host IP(127.0.0.1)ë¡œ ë³€í™˜í•˜ì—¬
    í´ë¼ì´ì–¸íŠ¸ê°€ í¬íŠ¸ í¬ì›Œë”©ì„ í†µí•´ ì ‘ì†í•  ìˆ˜ ìˆë„ë¡ í•¨.
    Regexë¥¼ ì‚¬ìš©í•˜ì—¬ ì•ˆì „í•˜ê²Œ ì¹˜í™˜ (íŒŒì‹± ì—ëŸ¬ ë°©ì§€)
    """
    import re
    # 1. 172.16.x.x ~ 172.31.x.x (Docker Bridge)
    # \b ë¬¸ìë¥¼ ì‚¬ìš©í•˜ì—¬ IP ì£¼ì†Œì˜ ê²½ê³„ë¥¼ ëª…í™•íˆ í•¨ (ì˜¤íƒ ë°©ì§€)
    sdp_str = re.sub(r'\b172\.(1[6-9]|2\d|3[0-1])\.\d{1,3}\.\d{1,3}\b', '127.0.0.1', sdp_str)
    
    # 2. 10.x.x.x (Private)
    sdp_str = re.sub(r'\b10\.\d{1,3}\.\d{1,3}\.\d{1,3}\b', '127.0.0.1', sdp_str)
    
    # 3. 192.168.x.x (Private)
    sdp_str = re.sub(r'\b192\.168\.\d{1,3}\.\d{1,3}\b', '127.0.0.1', sdp_str)
    
    return sdp_str

@app.post("/offer")
async def offer(request: Request):
    params = await request.json()
    offer = RTCSessionDescription(sdp=params["sdp"], type=params["type"])
    session_id = str(params.get("session_id", "unknown")) # ë¬´ì¡°ê±´ ë¬¸ìì—´ë¡œ ë³€í™˜
    
    print(f"ğŸ“¨ [{session_id}] Received Offer SDP (First 500 chars): {params['sdp'][:500]}...", flush=True)

    # [ìˆ˜ì •] ë¡œì»¬ ê°œë°œ í™˜ê²½ ê°•ì œ (STUN ì œê±°)
    # Docker NAT ì´ìŠˆë¥¼ í”¼í•˜ê¸° ìœ„í•´, ì™¸ë¶€ STUN ì„œë²„ë¥¼ ì“°ì§€ ì•Šê³  
    # ì˜¤ì§ Host Candidate(ë¡œì»¬ IP)ë§Œ ì‚¬ìš©í•˜ì—¬ ì—°ê²°ì„ ì‹œë„í•¨.
    # force_localhost_candidateê°€ 127.0.0.1ë¡œ ë°”ê¿”ì£¼ë¯€ë¡œ, ë¸Œë¼ìš°ì €ëŠ” ë¡œì»¬ë¡œ ë¶™ê²Œ ë¨.
    pc = RTCPeerConnection()
    
    active_pcs[session_id] = pc # [ì¶”ê°€] ì„¸ì…˜ë³„ PC ì €ì¥

    @pc.on("iceconnectionstatechange")
    async def on_ice_connection_state_change():
        print(f"â„ï¸ [{session_id}] ICE Connection State: {pc.iceConnectionState}", flush=True)
        if pc.iceConnectionState == "failed":
            print(f"âŒ [{session_id}] WebRTC ì—°ê²° ì‹¤íŒ¨ (ë°©í™”ë²½/ë„¤íŠ¸ì›Œí¬ ë¬¸ì œ ê°€ëŠ¥ì„±)", flush=True)

    @pc.on("track")
    def on_track(track):
        # [ë³€ê²½] ë¡œê·¸ ë ˆë²¨ ì¼ê´€ì„±
        print(f"ğŸ¯ [{session_id}] íŠ¸ë™ ìˆ˜ì‹ ë¨: {track.kind}", flush=True)

        if track.kind == "audio":
            # [ë³€ê²½ ë‚´ì—­: 2026-02-11]
            # 1. ì´ì „ ì½”ë“œì˜ `start_stt_with_local_whisper` í•¨ìˆ˜ëŠ” ì •ì˜ë˜ì§€ ì•Šì•„ ì„œë²„ í¬ë˜ì‹œë¥¼ ìœ ë°œí–ˆìŠµë‹ˆë‹¤.
            # 2. ë¯¸ë””ì–´ ì„œë²„ì—ì„œ ëª¨ë¸ì„ ì§ì ‘ ëŒë¦¬ë©´ ë¹„ë””ì˜¤ ì¤‘ê³„ê°€ ë ‰ê±¸ë¦´ ìˆ˜ ìˆìœ¼ë¯€ë¡œ,
            #    ë¬´ê±°ìš´ STT ì‘ì—…ì€ ì „ìš© GPU ì›Œì»¤(AI-Worker)ì—ê²Œ ìœ„ì„(Delegate)í•©ë‹ˆë‹¤.
            asyncio.ensure_future(start_remote_stt(track, session_id))
            print(f"[{session_id}] ì˜¤ë””ì˜¤ íŠ¸ë™ ì²˜ë¦¬ ì‹œì‘ (AI-Workerë¥¼ í†µí•œ ì›ê²© STT)", flush=True)
            
        elif track.kind == "video":
            # ë¹„ë””ì˜¤ íŠ¸ë™: ë°±ê·¸ë¼ìš´ë“œ ë¶„ì„ ë£¨í”„ ì‹œì‘ (addTrack ëŒ€ì‹  ì§ì ‘ ì†Œë¹„)
            # [ë³€ê²½] Relay ìš°íšŒí•˜ê³  íŠ¸ë™ ì§ì ‘ ì†Œë¹„ (ë¸”ë¡œí‚¹ ì´ìŠˆ ë””ë²„ê¹…)
            print(f"ğŸ”„ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ìŠ¤ì¼€ì¤„ë§ ì‹œë„...", flush=True)
            task = asyncio.create_task(start_video_analysis(track, session_id))
            active_analysis_tasks[session_id] = task  # [ì¶”ê°€] íƒœìŠ¤í¬ ì €ì¥
            print(f"ğŸ”„ [{session_id}] ì˜ìƒ ë¶„ì„ ë£¨í”„ ìŠ¤ì¼€ì¤„ë§ ì™„ë£Œ (Direct Track)", flush=True)

    await pc.setRemoteDescription(offer)
    answer = await pc.createAnswer()
    await pc.setLocalDescription(answer)

    # [ìˆ˜ì •] Docker í™˜ê²½ì„ ìœ„í•œ SDP IP ë³€ì¡° (Masquerading)
    final_sdp = force_localhost_candidate(pc.localDescription.sdp)
    print(f"ğŸ”§ [{session_id}] SDP Localhost Patch Applied. Result (Candidate Line Only):\n" + 
          "\n".join([line for line in final_sdp.splitlines() if "a=candidate" in line]), flush=True)

    return {
        "sdp": final_sdp,
        "type": pc.localDescription.type
    }

async def consume_audio(track):
    """ì˜¤ë””ì˜¤ íŠ¸ë™ì„ ì†Œë¹„í•˜ì—¬ ë²„í¼ê°€ ì°¨ì§€ ì•Šë„ë¡ í•¨"""
    try:
        while True:
            await track.recv()
    except Exception:
        # íŠ¸ë™ì´ ì¢…ë£Œë˜ë©´ ì˜ˆì™¸ ë°œìƒ (ì •ìƒì ì¸ ì¢…ë£Œ)
        pass

@app.get("/")
async def root():
    return {
        "service": "AI Interview Media Server",
        "status": "running",
        "mode": "Video Analysis + Remote STT (via AI-Worker)"
    }


# EnvTestPage.jsx í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ í•„ìˆ˜ ì—”ë“œí¬ì¸íŠ¸
from fastapi import UploadFile, File, HTTPException

@app.post("/stt/recognize")
async def stt_recognize(file: UploadFile = File(...)):
    """
    STT í…ŒìŠ¤íŠ¸ìš© ì—”ë“œí¬ì¸íŠ¸ (EnvTestPage.jsxì—ì„œ í˜¸ì¶œ)
    """
    try:
        audio_bytes = await file.read()
        audio_b64 = base64.b64encode(audio_bytes).decode('utf-8')
        
        task = celery_app.send_task(
            "tasks.stt.recognize",
            args=[audio_b64],
            queue="cpu_queue"
        )
        # í…ŒìŠ¤íŠ¸ìš©ì´ë¯€ë¡œ ê²°ê³¼ ëŒ€ê¸°
        result = task.get(timeout=30)
        return result
    except Exception as e:
        logger.error(f"STT Test Error: {e}")
        raise HTTPException(status_code=500, detail=str(e))

@app.on_event("startup")
async def on_startup():
    print("ğŸš€ [Media-Server] FastAPI startup complete. Port 8080 is now open.", flush=True)
    # ì„œë²„ ê¸°ë™ ì§í›„ ë°±ê·¸ë¼ìš´ë“œì—ì„œ ëª¨ë¸ ë¡œë”© ì‹œì‘ (ë¹„ë¸”ë¡œí‚¹)
    asyncio.create_task(background_init_analyzer())

@app.get("/status")
async def status():
    is_ready = analyzer_instance.is_ready if analyzer_instance else False
    return {
        "status": "running",
        "vision_analyzer_ready": is_ready,
        "session_count": len(active_pcs)
    }

if __name__ == "__main__":
    import uvicorn
    # [ì¤‘ìš”] MonkeyPatchê°€ ì‘ë™í•˜ë ¤ë©´ uvicornì´ uvloop ëŒ€ì‹  asyncio ë£¨í”„ë¥¼ ì‚¬ìš©í•´ì•¼ í•  ìˆ˜ ìˆìŒ.
    # Docker í™˜ê²½ì—ì„œ aiortc ì†Œì¼“ ë°”ì¸ë”©ì„ ë³´ì¥í•˜ê¸° ìœ„í•´ ëª…ì‹œì ìœ¼ë¡œ ì„¤ì •.
    uvicorn.run(app, host="0.0.0.0", port=8080, log_level="info", loop="asyncio")