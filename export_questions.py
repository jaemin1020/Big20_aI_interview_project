import os
import sys
import json
import logging
from datetime import datetime
from sqlmodel import Session, select

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ë° backend-core ê²½ë¡œ ì¶”ê°€
root_dir = os.path.abspath(os.path.dirname(__file__))
backend_dir = os.path.join(root_dir, "backend-core")
if backend_dir not in sys.path:
    sys.path.append(backend_dir)

# í™˜ê²½ ë³€ìˆ˜ ì„¤ì • (ë¡œì»¬ ì‹¤í–‰ ì‹œ DB ì ‘ì†ìš©)
if not os.environ.get("DATABASE_URL"):
    os.environ["DATABASE_URL"] = "postgresql+psycopg://postgres:1234@localhost:15432/interview_db"

# ëª¨ë“ˆ ì„í¬íŠ¸
try:
    from database import engine
    from db_models import Question
except ImportError as e:
    # ë§Œì•½ ìœ„ ë°©ì‹ì´ ì‹¤íŒ¨í•˜ë©´ ë‹¤ë¥¸ ê²½ë¡œ ì‹œë„ (ì˜ˆ: ai-worker/db)
    logging.error(f"âŒ ì„í¬íŠ¸ ì‹¤íŒ¨: {e}. ê²½ë¡œì„¤ì •ì„ ë‹¤ì‹œ í™•ì¸í•©ë‹ˆë‹¤.")
    ai_worker_dir = os.path.join(root_dir, "ai-worker")
    if ai_worker_dir not in sys.path:
        sys.path.append(ai_worker_dir)
    from db import engine
    from db_models import Question

# ë¡œê·¸ ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

def export_all_question_data():
    """DBì˜ Question í…Œì´ë¸” ì „ì²´(ì„ë² ë”© í¬í•¨)ë¥¼ JSONìœ¼ë¡œ ì¶”ì¶œí•©ë‹ˆë‹¤."""
    logger.info("ğŸ“‚ DB ë°ì´í„°(ì„ë² ë”© í¬í•¨) ì¶”ì¶œ ì‹œì‘...")
    
    try:
        with Session(engine) as session:
            # 1. ëª¨ë“  ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°
            statement = select(Question)
            questions = session.exec(statement).all()
            
            if not questions:
                logger.warning("âš ï¸ ë°±ì—…í•  ì§ˆë¬¸ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
                return

            export_data = []
            for q in questions:
                # SQLModel ê°ì²´ë¥¼ dictë¡œ ë³€í™˜
                q_dict = q.model_dump()
                
                # datetime ë° embedding(vector) ì²˜ë¦¬
                for key, value in q_dict.items():
                    if isinstance(value, datetime):
                        q_dict[key] = value.isoformat()
                    # embeddingì´ pgvector ê°ì²´ì¼ ê²½ìš° ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
                    elif key == "embedding" and value is not None:
                        try:
                            # pgvector ê°ì²´ë©´ list(value)ë¡œ ë³€í™˜ ê°€ëŠ¥
                            q_dict[key] = [float(x) for x in value]
                        except:
                            try:
                                q_dict[key] = list(value)
                            except:
                                q_dict[key] = str(value)

                export_data.append(q_dict)

            # íŒŒì¼ ì €ì¥
            filename = f"db_questions_full_backup_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
            with open(filename, "w", encoding="utf-8") as f:
                json.dump(export_data, f, ensure_ascii=False, indent=2)
            
            logger.info(f"âœ… ì´ {len(export_data)}ê°œì˜ ì§ˆë¬¸ ë°ì´í„°(ì„ë² ë”© í¬í•¨)ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        logger.error(f"âŒ ë°ì´í„° ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        logger.error(traceback.format_exc())

if __name__ == "__main__":
    export_all_question_data()
