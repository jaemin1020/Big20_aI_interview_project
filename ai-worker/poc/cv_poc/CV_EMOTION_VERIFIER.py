import cv2
import mediapipe as mp
from mediapipe.tasks import python
from mediapipe.tasks.python import vision
import numpy as np
import time
import os
from PIL import Image, ImageDraw, ImageFont

# ëª¨ë¸ íŒŒì¼ í™•ì¸
model_path = 'face_landmarker.task'

def get_korean_font(size):
    try: return ImageFont.truetype("malgun.ttf", size)
    except: return ImageFont.load_default()

font_title = get_korean_font(30)
font_label = get_korean_font(25)
font_raw = get_korean_font(18)

def draw_korean_text(img, text, position, color, font=font_label):
    img_pil = Image.fromarray(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
    draw = ImageDraw.Draw(img_pil)
    draw.text(position, text, font=font, fill=color)
    return cv2.cvtColor(np.array(img_pil), cv2.COLOR_RGB2BGR)

def analyze_emotions():
    print("ğŸ¯ ê°ì • ì¸ì‹ ì •ë°€ ê²€ì¦ ëª¨ë“œ ê°€ë™...")
    
    if not os.path.exists(model_path):
        print("âŒ ëª¨ë¸ íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
        return

    detector = vision.FaceLandmarker.create_from_options(vision.FaceLandmarkerOptions(
        base_options=python.BaseOptions(model_asset_path=model_path),
        output_face_blendshapes=True,
        running_mode=vision.RunningMode.VIDEO
    ))
    
    cap = cv2.VideoCapture(0)

    while cap.isOpened():
        success, frame = cap.read()
        if not success: break
        frame = cv2.flip(frame, 1)
        h, w, _ = frame.shape
        
        mp_image = mp.Image(image_format=mp.ImageFormat.SRGB, data=cv2.cvtColor(frame, cv2.COLOR_BGR2RGB))
        result = detector.detect_for_video(mp_image, int(time.time() * 1000))

        if result.face_blendshapes:
            # 47ê°€ì§€ ë¯¸ì„¸ ê·¼ìœ¡ ì ìˆ˜ ì¶”ì¶œ
            shapes = {b.category_name: b.score for b in result.face_blendshapes[0]}
            
            # [1. í–‰ë³µ] ê¸°ì¡´ ìœ ì§€ (ì˜ ì‘ë™í•¨)
            happy_score = (shapes.get('mouthSmileLeft', 0) + shapes.get('mouthSmileRight', 0)) / 2
            
            # [2. ìŠ¬í””] ë¯¼ê°ë„ ìµœì í™” (ë°¸ëŸ°ìŠ¤ ëª¨ë“œ)
            mouth_frown = (shapes.get('mouthFrownLeft', 0) + shapes.get('mouthFrownRight', 0)) / 2
            brow_down = (shapes.get('browDownLeft', 0) + shapes.get('browDownRight', 0)) / 2
            sad_score = max(mouth_frown * 1.8, brow_down * 1.2) # ì ì ˆí•œ ê°€ì¤‘ì¹˜ë¡œ ì¡°ì ˆ
            
            # [3. ë†€ëŒ/ë‘ë ¤ì›€]
            eye_wide = (shapes.get('eyeWideLeft', 0) + shapes.get('eyeWideRight', 0)) / 2
            brow_up = shapes.get('browInnerUp', 0)
            surprise_score = max(eye_wide, brow_up * 1.2) 
            
            # [4. ìµœì¢… íŒë³„]
            current_emotion = "í‰ì˜¨ (Neutral)"
            color = (255, 255, 255)
            
            # ìš°ì„ ìˆœìœ„: í–‰ë³µ > ë†€ëŒ > ìŠ¬í”” ìˆœìœ¼ë¡œ ê°•í•œ ì‹ í˜¸ ê°ì§€
            if happy_score > 0.35: 
                current_emotion = "í–‰ë³µ (Happy) ğŸ˜Š"
                color = (0, 255, 0)
            elif surprise_score > 0.25: 
                current_emotion = "ë†€ëŒ/ë‘ë ¤ì›€ (Surprise/Fear) ğŸ˜²"
                color = (0, 255, 255)
            elif sad_score > 0.12: # ì ì ˆí•œ ì„ê³„ê°’ ì„¤ì •
                current_emotion = "ìŠ¬í”” (Sad) ğŸ˜¢"
                color = (255, 50, 50)

            # UI ê·¸ë¦¬ê¸°
            overlay = frame.copy()
            cv2.rectangle(overlay, (20, 20), (500, 350), (0, 0, 0), -1)
            cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)

            frame = draw_korean_text(frame, "ğŸ“Š ê°ì • ì •ë°€ ê²€ì¦ ì‹œìŠ¤í…œ", (40, 40), (255, 255, 0), font=font_title)
            frame = draw_korean_text(frame, f"í˜„ì¬ ê°ì •: {current_emotion}", (40, 100), color)
            
            # ì‹¤ì‹œê°„ ë¡œìš° ë°ì´í„° ë°” (ì‹œê°í™”)
            cv2.rectangle(frame, (40, 160), (40 + int(happy_score*300), 180), (0, 255, 0), -1)
            frame = draw_korean_text(frame, f"í–‰ë³µ ì§€ìˆ˜: {int(happy_score*100)}%", (350, 155), (200, 200, 200), font=font_raw)
            
            cv2.rectangle(frame, (40, 210), (40 + int(sad_score*300), 230), (0, 0, 255), -1)
            frame = draw_korean_text(frame, f"ìŠ¬í”” ì§€ìˆ˜: {int(sad_score*100)}%", (350, 205), (200, 200, 200), font=font_raw)
            
            cv2.rectangle(frame, (40, 260), (40 + int(surprise_score*300), 280), (0, 255, 255), -1)
            frame = draw_korean_text(frame, f"ë†€ëŒ ì§€ìˆ˜: {int(surprise_score*100)}%", (350, 255), (200, 200, 200), font=font_raw)

            frame = draw_korean_text(frame, "íŒíŠ¸: ì›ƒì–´ë³´ê³ , ìŠ¬í¼ë³´ê³ , ëˆˆì„ í¬ê²Œ ë– ë³´ì„¸ìš”!", (40, 310), (150, 150, 150), font=font_raw)

        cv2.imshow('Emotion Precision Verifier', frame)
        if cv2.waitKey(1) & 0xFF == ord('q'): break

    detector.close(); cap.release(); cv2.destroyAllWindows()

if __name__ == "__main__":
    analyze_emotions()
