# ============================================================
# Qwen3-TTS í•œêµ­ì–´ ìŒì„± í•©ì„± ëª¨ë“ˆ
# ============================================================
# íŒŒì¼ëª…: tts_qwen3.py
# ëª¨ë¸: Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice
# ëª©ì : AI ë©´ì ‘ê´€ì´ ì§ˆë¬¸ì„ ìŒì„±ìœ¼ë¡œ ì½ì–´ì£¼ëŠ” TTS ì—”ì§„
# ============================================================

# ============================================================
# [Step 0] í•„ìˆ˜ ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
# ============================================================
import torch  # PyTorch: GPU ê°€ì† ë° í…ì„œ ì—°ì‚°ì„ ìœ„í•œ ë”¥ëŸ¬ë‹ í”„ë ˆì„ì›Œí¬
import soundfile as sf  # soundfile: WAV ì˜¤ë””ì˜¤ íŒŒì¼ ì½ê¸°/ì“°ê¸°ë¥¼ ìœ„í•œ ë¼ì´ë¸ŒëŸ¬ë¦¬
import os  # os: íŒŒì¼ ê²½ë¡œ ë° ë””ë ‰í† ë¦¬ ê´€ë¦¬
import time  # time: ì‹¤í–‰ ì‹œê°„ ì¸¡ì •ìš©
import logging  # logging: ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥ì„ ìœ„í•œ í‘œì¤€ ë¼ì´ë¸ŒëŸ¬ë¦¬
from abc import ABC, abstractmethod  # ABC: ì¶”ìƒ í´ë˜ìŠ¤ ì •ì˜ë¥¼ ìœ„í•œ ëª¨ë“ˆ

# ============================================================
# [Step 1] ë¡œê±° ì„¤ì •
# ============================================================
# ë¡œê±°ë¥¼ ì„¤ì •í•˜ì—¬ TTS ì‘ì—…ì˜ ì§„í–‰ ìƒí™©ê³¼ ì˜¤ë¥˜ë¥¼ ê¸°ë¡í•©ë‹ˆë‹¤.
logger = logging.getLogger("TTS-Qwen3")
logging.basicConfig(level=logging.INFO)

# ============================================================
# [Step 2] TTS ë² ì´ìŠ¤ í´ë˜ìŠ¤ ì •ì˜ (í†µí•©ìš© ì¸í„°í˜ì´ìŠ¤)
# ============================================================
# ëª¨ë“  TTS ëª¨ë¸ì´ ê³µí†µìœ¼ë¡œ êµ¬í˜„í•´ì•¼ í•˜ëŠ” ì¸í„°í˜ì´ìŠ¤ì…ë‹ˆë‹¤.
# ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ Qwen3-TTS, StyleTTS2 ë“± ë‹¤ì–‘í•œ ëª¨ë¸ì„ êµ¬í˜„í•©ë‹ˆë‹¤.
# í†µí•© ì‹œ, ì–´ë–¤ TTS ëª¨ë¸ì„ ì‚¬ìš©í•˜ë“  ë™ì¼í•œ ë°©ì‹ìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

class TTSBase(ABC):
    """
    TTS ëª¨ë¸ì˜ ì¶”ìƒ ë² ì´ìŠ¤ í´ë˜ìŠ¤
    
    ëª¨ë“  TTS êµ¬í˜„ì²´ëŠ” ì´ í´ë˜ìŠ¤ë¥¼ ìƒì†ë°›ì•„ ë‹¤ìŒ ë©”ì„œë“œë¥¼ êµ¬í˜„í•´ì•¼ í•©ë‹ˆë‹¤:
    - load_model(): ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¡œë“œ
    - generate_speech(): í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜
    - get_model_name(): ëª¨ë¸ ì´ë¦„ ë°˜í™˜
    """
    
    @abstractmethod
    def load_model(self):
        """ëª¨ë¸ì„ ë¡œë“œí•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ"""
        pass
    
    @abstractmethod
    def generate_speech(self, text: str, output_path: str, speaker: str = "default", language: str = "Korean") -> dict:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ
        
        Args:
            text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            output_path: ì €ì¥í•  WAV íŒŒì¼ ê²½ë¡œ
            speaker: í™”ì (ëª©ì†Œë¦¬) ì„ íƒ
            language: ì–¸ì–´ ì„ íƒ
            
        Returns:
            dict: ìƒì„± ê²°ê³¼ (ì„±ê³µ ì—¬ë¶€, ìƒì„± ì‹œê°„, íŒŒì¼ ê²½ë¡œ ë“±)
        """
        pass
    
    @abstractmethod
    def get_model_name(self) -> str:
        """ëª¨ë¸ ì´ë¦„ì„ ë°˜í™˜í•˜ëŠ” ì¶”ìƒ ë©”ì„œë“œ"""
        pass


# ============================================================
# [Step 3] Qwen3-TTS êµ¬í˜„ í´ë˜ìŠ¤
# ============================================================
# Alibabaì˜ Qwen3-TTS ëª¨ë¸ì„ ì‚¬ìš©í•œ TTS êµ¬í˜„ì²´ì…ë‹ˆë‹¤.
# í•œêµ­ì–´ë¥¼ í¬í•¨í•œ 10ê°œ ì–¸ì–´ë¥¼ ê³µì‹ ì§€ì›í•©ë‹ˆë‹¤.

class Qwen3TTS(TTSBase):
    """
    Qwen3-TTS ìŒì„± í•©ì„± ì—”ì§„
    
    íŠ¹ì§•:
    - ëª¨ë¸: Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice
    - ì§€ì› ì–¸ì–´: í•œêµ­ì–´, ì˜ì–´, ì¤‘êµ­ì–´, ì¼ë³¸ì–´ ë“± 10ê°œ
    - ì§€ì› í™”ì: Vivian, Ethan ë“± 9ê°œ í”„ë¦¬ë¯¸ì—„ ìŒìƒ‰
    - ê°ì •/ìŠ¤íƒ€ì¼ ì¡°ì ˆ: ìì—°ì–´ ì§€ì‹œë¡œ í†¤ ë³€ê²½ ê°€ëŠ¥
    """
    
    # ì‹±ê¸€í†¤ íŒ¨í„´ì„ ìœ„í•œ í´ë˜ìŠ¤ ë³€ìˆ˜
    _instance = None
    _model = None
    
    def __new__(cls):
        """
        ì‹±ê¸€í†¤ íŒ¨í„´ êµ¬í˜„
        - ëª¨ë¸ì´ ë§¤ë²ˆ ìƒˆë¡œ ë¡œë“œë˜ì§€ ì•Šë„ë¡ í•©ë‹ˆë‹¤.
        - GPU ë©”ëª¨ë¦¬ë¥¼ íš¨ìœ¨ì ìœ¼ë¡œ ì‚¬ìš©í•©ë‹ˆë‹¤.
        """
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    def __init__(self):
        """
        ì´ˆê¸°í™” ë©”ì„œë“œ
        - ì´ë¯¸ ì´ˆê¸°í™”ë˜ì—ˆë‹¤ë©´ ë‹¤ì‹œ ì´ˆê¸°í™”í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.
        """
        if hasattr(self, '_initialized') and self._initialized:
            return
        self._initialized = True
        self.model = None
        self.model_id = "Qwen/Qwen3-TTS-12Hz-0.6B-CustomVoice"
        
    def load_model(self):
        """
        Qwen3-TTS ëª¨ë¸ì„ GPUì— ë¡œë“œí•©ë‹ˆë‹¤.
        
        í”„ë¡œì„¸ìŠ¤:
        1. qwen_tts ë¼ì´ë¸ŒëŸ¬ë¦¬ì—ì„œ Qwen3TTSModel ì„í¬íŠ¸
        2. Hugging Faceì—ì„œ ëª¨ë¸ ê°€ì¤‘ì¹˜ ë‹¤ìš´ë¡œë“œ (ìµœì´ˆ 1íšŒ)
        3. GPU ë©”ëª¨ë¦¬ì— ëª¨ë¸ ë¡œë“œ (bfloat16 ì •ë°€ë„)
        
        Returns:
            bool: ë¡œë“œ ì„±ê³µ ì—¬ë¶€
        """
        if self.model is not None:
            logger.info("âœ… ëª¨ë¸ì´ ì´ë¯¸ ë¡œë“œë˜ì–´ ìˆìŠµë‹ˆë‹¤.")
            return True
            
        try:
            # [Step 3-1] qwen_tts ë¼ì´ë¸ŒëŸ¬ë¦¬ ì„í¬íŠ¸
            # ì´ ë¼ì´ë¸ŒëŸ¬ë¦¬ëŠ” pip install qwen-ttsë¡œ ì„¤ì¹˜ë©ë‹ˆë‹¤.
            from qwen_tts import Qwen3TTSModel
            logger.info("ğŸ”„ Qwen3-TTS ëª¨ë¸ ë¡œë”© ì‹œì‘...")
            
            load_start = time.time()
            
            # [Step 3-2] Hugging Faceì—ì„œ ëª¨ë¸ ë¡œë“œ
            # - device_map="cuda:0": ì²« ë²ˆì§¸ GPU ì‚¬ìš©
            # - dtype=torch.bfloat16: ë©”ëª¨ë¦¬ íš¨ìœ¨ì„ ìœ„í•´ 16ë¹„íŠ¸ ì •ë°€ë„ ì‚¬ìš©
            self.model = Qwen3TTSModel.from_pretrained(
                self.model_id,  # Hugging Face ëª¨ë¸ ID
                device_map="cuda:0",  # GPU ë””ë°”ì´ìŠ¤ ì§€ì •
                dtype=torch.bfloat16,  # ë©”ëª¨ë¦¬ ì ˆì•½ì„ ìœ„í•œ ë°ì´í„° íƒ€ì…
            )
            
            load_time = time.time() - load_start
            logger.info(f"âœ… Qwen3-TTS ëª¨ë¸ ë¡œë“œ ì™„ë£Œ! (ì†Œìš” ì‹œê°„: {load_time:.2f}ì´ˆ)")
            return True
            
        except ImportError as e:
            # [ì—ëŸ¬ ì²˜ë¦¬] ë¼ì´ë¸ŒëŸ¬ë¦¬ ë¯¸ì„¤ì¹˜ ì‹œ
            logger.error(f"âŒ qwen_tts ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {e}")
            logger.error("   í•´ê²°: pip install qwen-tts ì‹¤í–‰")
            return False
            
        except Exception as e:
            # [ì—ëŸ¬ ì²˜ë¦¬] ê¸°íƒ€ ì˜¤ë¥˜ (GPU ë©”ëª¨ë¦¬ ë¶€ì¡± ë“±)
            logger.error(f"âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
            return False
    
    def generate_speech(self, text: str, output_path: str, speaker: str = "Vivian", language: str = "Korean") -> dict:
        """
        í…ìŠ¤íŠ¸ë¥¼ ìŒì„±ìœ¼ë¡œ ë³€í™˜í•˜ì—¬ WAV íŒŒì¼ë¡œ ì €ì¥í•©ë‹ˆë‹¤.
        
        Args:
            text (str): ë³€í™˜í•  í…ìŠ¤íŠ¸ (ì˜ˆ: "ì•ˆë…•í•˜ì„¸ìš”, ë©´ì ‘ì„ ì‹œì‘í•˜ê² ìŠµë‹ˆë‹¤.")
            output_path (str): ì €ì¥í•  íŒŒì¼ ê²½ë¡œ (ì˜ˆ: "/app/output/question_1.wav")
            speaker (str): í™”ì ì„ íƒ ("Vivian", "Ethan" ë“±)
            language (str): ì–¸ì–´ ("Korean", "English", "Chinese" ë“±)
            
        Returns:
            dict: {
                "success": bool,        # ì„±ê³µ ì—¬ë¶€
                "model": str,           # ì‚¬ìš©ëœ ëª¨ë¸ëª…
                "output_path": str,     # ì €ì¥ëœ íŒŒì¼ ê²½ë¡œ
                "duration_ms": float,   # ìƒì„± ì†Œìš” ì‹œê°„ (ë°€ë¦¬ì´ˆ)
                "sample_rate": int,     # ìƒ˜í”Œë§ ë ˆì´íŠ¸
                "error": str (optional) # ì—ëŸ¬ ë©”ì‹œì§€ (ì‹¤íŒ¨ ì‹œ)
            }
        """
        # [Step 4-1] ëª¨ë¸ ë¡œë“œ í™•ì¸
        if self.model is None:
            if not self.load_model():
                return {"success": False, "error": "ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨"}
        
        try:
            gen_start = time.time()
            
            # [Step 4-2] ìŒì„± ìƒì„±
            # - text: ë³€í™˜í•  í…ìŠ¤íŠ¸
            # - language: ë°œí™” ì–¸ì–´ (í•œêµ­ì–´, ì˜ì–´ ë“±)
            # - speaker: ëª©ì†Œë¦¬ í†¤ (Vivian: ì—¬ì„±, Ethan: ë‚¨ì„±)
            # - instruct: ë°œí™” ìŠ¤íƒ€ì¼ ì§€ì‹œ (ë§¤ìš° í˜ì‹ ì ì¸ ê¸°ëŠ¥!)
            wavs, sr = self.model.generate_custom_voice(
                text=text,
                language=language,
                speaker=speaker,
                instruct="ë¶€ë“œëŸ½ê³  ì „ë¬¸ì ì¸ ë©´ì ‘ê´€ ì–´ì¡°ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.",  # ìŠ¤íƒ€ì¼ ì§€ì‹œ
            )
            
            # [Step 4-3] íŒŒì¼ ì €ì¥
            # - wavs[0]: ìƒì„±ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (NumPy ë°°ì—´)
            # - sr: ìƒ˜í”Œë§ ë ˆì´íŠ¸ (ë³´í†µ 24000Hz)
            output_dir = os.path.dirname(output_path)
            if output_dir and not os.path.exists(output_dir):
                os.makedirs(output_dir)
                
            sf.write(output_path, wavs[0], sr)
            
            gen_time_ms = (time.time() - gen_start) * 1000
            
            logger.info(f"âœ… ìŒì„± ìƒì„± ì™„ë£Œ: {output_path} ({gen_time_ms:.0f}ms)")
            
            return {
                "success": True,
                "model": self.get_model_name(),
                "output_path": output_path,
                "duration_ms": gen_time_ms,
                "sample_rate": sr,
            }
            
        except Exception as e:
            logger.error(f"âŒ ìŒì„± ìƒì„± ì‹¤íŒ¨: {e}")
            return {"success": False, "error": str(e)}
    
    def get_model_name(self) -> str:
        """ëª¨ë¸ ì´ë¦„ ë°˜í™˜"""
        return "Qwen3-TTS-12Hz-0.6B-CustomVoice"


# ============================================================
# [Step 5] ë…ë¦½ ì‹¤í–‰ í…ŒìŠ¤íŠ¸
# ============================================================
# ì´ íŒŒì¼ì„ ì§ì ‘ ì‹¤í–‰í•˜ë©´ í…ŒìŠ¤íŠ¸ê°€ ìˆ˜í–‰ë©ë‹ˆë‹¤.
# í†µí•© ì‹œì—ëŠ” ì´ ë¶€ë¶„ì´ ì‹¤í–‰ë˜ì§€ ì•ŠìŠµë‹ˆë‹¤.

if __name__ == "__main__":
    print("=" * 60)
    print("ğŸ™ï¸ Qwen3-TTS í•œêµ­ì–´ ìŒì„± í•©ì„± í…ŒìŠ¤íŠ¸")
    print("=" * 60)
    
    # [í…ŒìŠ¤íŠ¸ 1] TTS ì—”ì§„ ì´ˆê¸°í™”
    tts = Qwen3TTS()
    
    # [í…ŒìŠ¤íŠ¸ 2] ëª¨ë¸ ë¡œë“œ
    if not tts.load_model():
        print("âŒ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨. ì¢…ë£Œí•©ë‹ˆë‹¤.")
        exit(1)
    
    # [í…ŒìŠ¤íŠ¸ 3] í•œêµ­ì–´ ìŒì„± ìƒì„±
    test_text = "ì•ˆë…•í•˜ì„¸ìš”. ì˜¤ëŠ˜ ë©´ì ‘ì— ì°¸ì„í•´ ì£¼ì…”ì„œ ëŒ€ë‹¨íˆ ê°ì‚¬í•©ë‹ˆë‹¤. í¸ì•ˆí•œ ë§ˆìŒìœ¼ë¡œ ì‹œì‘í•´ ë³¼ê¹Œìš”?"
    output_path = "/app/stt_poc/outputs/qwen3_test_output.wav"
    
    result = tts.generate_speech(
        text=test_text,
        output_path=output_path,
        speaker="Vivian",
        language="Korean"
    )
    
    # [í…ŒìŠ¤íŠ¸ 4] ê²°ê³¼ ì¶œë ¥
    if result["success"]:
        print(f"âœ… í…ŒìŠ¤íŠ¸ ì„±ê³µ!")
        print(f"   - ëª¨ë¸: {result['model']}")
        print(f"   - íŒŒì¼: {result['output_path']}")
        print(f"   - ìƒì„± ì‹œê°„: {result['duration_ms']:.0f}ms")
        print(f"   - ìƒ˜í”Œ ë ˆì´íŠ¸: {result['sample_rate']}Hz")
    else:
        print(f"âŒ í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {result['error']}")
    
    print("=" * 60)
