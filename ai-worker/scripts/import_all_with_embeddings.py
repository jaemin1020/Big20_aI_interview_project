
import json
import os
import sys
from pathlib import Path

# ai-worker ë° backend-core ê²½ë¡œ ì„¤ì •
# ì´ë¥¼ í†µí•´ backend-coreì˜ models.pyë¥¼ ì§ì ‘ ì„í¬íŠ¸í•˜ì—¬ ìŠ¤í‚¤ë§ˆ ì¤‘ë³µ ì •ì˜ë¥¼ ë°©ì§€í•©ë‹ˆë‹¤.
current_dir = Path(__file__).parent
backend_core_path = current_dir.parent.parent / "backend-core"
ai_worker_path = current_dir.parent

sys.path.append(str(backend_core_path))
sys.path.append(str(ai_worker_path))

from abc import ABC
from sqlmodel import Session, create_engine, select
# backend-core/models.py ì—ì„œ ì„í¬íŠ¸
from models import Question, AnswerBank, QuestionCategory, QuestionDifficulty, Company
# vector_utilsì—ì„œ ì¤‘ì•™ ê´€ë¦¬í˜• EmbeddingGenerator ì‚¬ìš©
from utils.vector_utils import get_embedding_generator
from datetime import datetime

# ì‹¤í–‰ ì˜ˆì‹œ
# docker exec -it interview_worker //bin/bash python import_data.py

# ==========================================
# Configuration
# ==========================================

DATABASE_URL = os.getenv("DATABASE_URL", "postgresql+psycopg://admin:1234@interview_db:5432/interview_db")

# ë°ì´í„° íŒŒì¼ ê²½ë¡œ (backend-coreì˜ data ë””ë ‰í† ë¦¬ ì°¸ì¡°)
# Docker ì»¨í…Œì´ë„ˆ ë‚´ì—ì„œ ê²½ë¡œê°€ ë‹¤ë¥¼ ìˆ˜ ìˆìœ¼ë¯€ë¡œ volume mount í™•ì¸ í•„ìš”
# ì—¬ê¸°ì„œëŠ” ìƒëŒ€ ê²½ë¡œë¡œ ì ‘ê·¼ ì‹œë„. ì‹¤íŒ¨ ì‹œ ì ˆëŒ€ ê²½ë¡œ í™•ì¸ í•„ìš”.

POSSIBLE_DATA_DIRS = [
    "../backend-core/data", 
    "/backend-core/data",
    "c:/big20/git/Big20_aI_interview_project/backend-core/data",
    "/app/data", # Maybe mounted here
    "/data"
]

DATA_FILE_NAME_OLD = "preprocessed_data.json"
DATA_FILE_NAME_CORP = "corp_data.json"

def find_file(filename):
    for directory in POSSIBLE_DATA_DIRS:
        filepath = os.path.join(directory, filename)
        if os.path.exists(filepath):
            return filepath
    return None

DATA_FILE_OLD = find_file(DATA_FILE_NAME_OLD) or "preprocessed_data.json"
DATA_FILE_CORP = find_file(DATA_FILE_NAME_CORP) or "corp_data.json"


# ==========================================
# Script
# ==========================================

def get_engine():
    try:
        engine = create_engine(DATABASE_URL)
        with Session(engine) as session:
            pass
        return engine
    except Exception as e:
        print(f"âŒ Database connection failed: {e}")
        return None

def import_questions(session, file_path, source_name, generator):
    if not os.path.exists(file_path):
        print(f"âš ï¸ Warning: File not found at {file_path}. Skipping {source_name}.")
        return

    print(f"ğŸ“‚ Reading {source_name} from: {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ Error reading {source_name}: {e}")
        return

    print(f"ğŸš€ Importing {len(data)} items from {source_name}...")
    
    count = 0
    skipped = 0
    duplicates = 0

    def classify_question(text):
        """í‚¤ì›Œë“œ ê¸°ë°˜ ê°„ë‹¨í•œ ë¶„ë¥˜ (ë°ì´í„°ì— ì¹´í…Œê³ ë¦¬ê°€ ì—†ì„ ê²½ìš° ì‚¬ìš©)"""
        text = text.lower()
        
        # 1. ì¸ì„±/ë¬¸í™” ì í•©ì„± (CULTURAL_FIT)
        if any(w in text for w in ["ì§€ì›ë™ê¸°", "ì…ì‚¬", "í¬ë¶€", "ì¥ì ", "ë‹¨ì ", "ê°ˆë“±", "í˜‘ì—…", "ì†Œí†µ", "íŒ€ì›Œí¬", "ì‹¤íŒ¨", "ì„±ê³µ", "ì¡´ê²½", "ë¬¸í™”", "why"]):
            return QuestionCategory.CULTURAL_FIT, "ì¸ì„±ë©´ì ‘"
            
        # 2. ì§ë¬´/ê²½í—˜ (BEHAVIORAL)
        if any(w in text for w in ["í”„ë¡œì íŠ¸", "ê²½í—˜", "ì—­ëŸ‰", "ê¸°ì—¬", "í•´ê²°", "ì§ë¬´", "ì»¤ë¦¬ì–´", "ì–´ë–»ê²Œ"]):
            return QuestionCategory.BEHAVIORAL, "ì§ë¬´ê²½í—˜"
            
        # 3. ê¸°ìˆ  (TECHNICAL) - Default
        return QuestionCategory.TECHNICAL, "ì§ë¬´ì§€ì‹"

    for item in data:
        q_text = item.get("question") or item.get("ì§ˆë¬¸")
        # answer_cleaned ìš°ì„ , ì—†ìœ¼ë©´ answer/ë‹µë³€ ì‚¬ìš©
        a_text = item.get("answer_cleaned") or item.get("answer") or item.get("ë‹µë³€")

        if not q_text or not a_text:
            skipped += 1
            continue

        # Check for duplicates
        statement = select(Question).where(Question.content == q_text)
        existing_q = session.exec(statement).first()
        
        if existing_q:
            duplicates += 1
            # ì´ë¯¸ ìˆìœ¼ë©´ ìŠ¤í‚µ
            continue

        # 1. Category Parsing
        category_str = item.get("QuestionCategory", "").lower()
        try:
            category = QuestionCategory(category_str)
        except ValueError:
            # Fallback
            category, _ = classify_question(q_text)

        # 2. Difficulty Parsing
        difficulty_str = item.get("QuestionDifficulty", "").lower()
        try:
            difficulty = QuestionDifficulty(difficulty_str)
        except ValueError:
            difficulty = QuestionDifficulty.MEDIUM

        # 3. Question Type Parsing
        q_type = item.get("QUESTION_TYPE")
        if not q_type:
            _, q_type = classify_question(q_text)

        # Embedding ìƒì„± (Query ëª¨ë“œ ì‚¬ìš© ê¶Œì¥? Question ìì²´ëŠ” DBì— ì €ì¥ë˜ì–´ ê²€ìƒ‰ë¨(Passage ì„±ê²©ë„ ìˆìŒ)
        # í•˜ì§€ë§Œ ì§ˆë¬¸-ì§ˆë¬¸ ìœ ì‚¬ë„ ê²€ìƒ‰ ì‹œì—ëŠ” ë‘˜ ë‹¤ Query ë˜ëŠ” ë‘˜ ë‹¤ Passageë¡œ ë§ì¶°ì•¼ í•¨.
        # ë²¡í„° DB ê²€ìƒ‰ ì‹œ ìœ ì € ì¿¼ë¦¬ëŠ” "query:", DB ë¬¸ì„œëŠ” "passage:"ë¥¼ ë¶™ì—¬ ì €ì¥í•˜ëŠ” ë¹„ëŒ€ì¹­ ë°©ì‹ì´ ì¼ë°˜ì .
        # ì—¬ê¸°ì„œëŠ” Questionì„ 'ê²€ìƒ‰ ëŒ€ìƒ'ìœ¼ë¡œ ì €ì¥í•˜ë¯€ë¡œ "passage:" ì ‘ë‘ì–´ë¥¼ ì‚¬ìš©í•˜ì—¬ ì €ì¥.
        # ë‚˜ì¤‘ì— ìœ ì €ê°€ ì§ˆë¬¸ì„ ê²€ìƒ‰í•  ë•Œ "query:"ë¥¼ ë¶™ì—¬ì„œ ê²€ìƒ‰.
        q_embedding = generator.encode_passage(q_text)

        # Create Question
        question = Question(
            content=q_text,
            category=category,
            difficulty=difficulty,
            rubric_json={"keywords": []}, 
            question_type=q_type, 
            usage_count=0,
            is_active=True,
            embedding=q_embedding # ì„ë² ë”© ì €ì¥
        )
        session.add(question)
        session.flush() # To get ID

        # Answer Embedding (Passage)
        a_embedding = generator.encode_passage(a_text)

        # Create AnswerBank
        answer = AnswerBank(
            question_id=question.id,
            answer_text=a_text,
            score=100.0,
            reference_count=0,
            is_active=True,
            embedding=a_embedding # ì„ë² ë”© ì €ì¥
        )
        session.add(answer)
        count += 1
        
        if count % 100 == 0:
            print(f"   - {count} items processed...")

    try:
        session.commit()
        print(f"âœ… Finished {source_name}: Imported {count}, Duplicates {duplicates}, Skipped {skipped}")
    except Exception as e:
        session.rollback()
        print(f"âŒ Failed to commit {source_name}: {e}")

def import_companies(session, file_path, generator):
    if not os.path.exists(file_path):
        print(f"âš ï¸ Warning: File not found at {file_path}. Skipping Companies.")
        return

    print(f"ğŸ“‚ Reading Companies from: {file_path}")
    try:
        with open(file_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
    except Exception as e:
        print(f"âŒ Error reading Companies: {e}")
        return

    print(f"ğŸš€ Importing {len(data)} companies...")
    
    count = 0
    duplicates = 0

    for item in data:
        name = item.get("name")
        code = item.get("code")
        ideal = item.get("ideal") or ""
        desc = item.get("description") or ""

        if not name or not code:
            continue

        code_str = str(code).strip()

        # Check for duplicates
        statement = select(Company).where(Company.id == code_str)
        existing_c = session.exec(statement).first()

        if existing_c:
            duplicates += 1
            # Update existing if needed, or skip
            # ì—¬ê¸°ì„œëŠ” ìŠ¤í‚µ
            continue
            
        # Embedding text
        text_for_embedding = f"{ideal} {desc}".strip()
        # Company Infoë„ ê²€ìƒ‰ ëŒ€ìƒ -> Passage
        embedding = generator.encode_passage(text_for_embedding)

        company = Company(
            id=code_str,
            company_name=name,
            ideal=ideal,
            description=desc,
            embedding=embedding # ì„ë² ë”© ì €ì¥
        )
        session.add(company)
        count += 1
        
        if count % 50 == 0:
            print(f"   - {count} companies processed...")

    try:
        session.commit()
        print(f"âœ… Finished Companies: Imported {count}, Duplicates {duplicates}")
    except Exception as e:
        session.rollback()
        print(f"âŒ Failed to commit Companies: {e}")


def main():
    print("ğŸš€ Starting Data Import with Embeddings...")
    
    # Init Embedding Generator
    print("ğŸ“¦ Loading embedding model (KURE-v1)...")
    generator = get_embedding_generator()
    print("âœ… Model loaded.")

    engine = get_engine()
    if not engine:
        return

    with Session(engine) as session:
        # Import Questions
        if DATA_FILE_OLD:
             import_questions(session, DATA_FILE_OLD, "General Questions", generator)
        else:
            print("âš ï¸ Questions data file not found.")

        print("-" * 40)

        # Import Companies
        if DATA_FILE_CORP:
            import_companies(session, DATA_FILE_CORP, generator)
        else:
             print("âš ï¸ Corp data file not found.")

    print("=" * 40)
    print("ğŸ‰ All imports completed.")

if __name__ == "__main__":
    main()
