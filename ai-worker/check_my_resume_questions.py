import logging
import os
import sys
import json

# ê²½ë¡œ ì„¤ì •
app_root = os.path.dirname(os.path.abspath(__file__))
backend_root = os.path.abspath(os.path.join(app_root, "..", "backend-core"))
sys.path.insert(0, backend_root)
sys.path.insert(0, app_root)

from utils.question_retriever import get_question_retriever
from tasks.parse_resume import parse_resume_final
from utils.exaone_llm import get_exaone_llm
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

logging.basicConfig(level=logging.INFO, format='%(asctime)s [%(levelname)s] %(name)s: %(message)s')
logger = logging.getLogger("ResumePersonalizationDemo")

def run_personalization_test(pdf_path: str):
    logger.info(f"--- [1. ì´ë ¥ì„œ íŒŒì‹± ì‹œì‘] ---")
    # ë„ì»¤ ë‚´ë¶€ ê²½ë¡œ í›„ë³´ë“¤
    paths_to_try = [
        f"/app/uploads/{os.path.basename(pdf_path)}",
        f"/backend-core/uploads/{os.path.basename(pdf_path)}",
        f"/app/uploads/test_resume.pdf",  # ë¦¬ë„¤ì„ëœ íŒŒì¼ í´ë°±
        f"/app/{os.path.basename(pdf_path)}"
    ]
    
    docker_pdf_path = None
    for p in paths_to_try:
        if os.path.exists(p):
            docker_pdf_path = p
            break
            
    if not docker_pdf_path:
        logger.error(f"âŒ ì´ë ¥ì„œ íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {pdf_path}")
        return

    logger.info(f"ğŸ“‚ ì‚¬ìš©ëœ ì´ë ¥ì„œ ê²½ë¡œ: {docker_pdf_path}")
    structured_data = parse_resume_final(docker_pdf_path)
    
    # ì´ë ¥ì„œì˜ í•µì‹¬ ë‚´ìš©ì„ í…ìŠ¤íŠ¸ë¡œ ìš”ì•½ (ê²€ìƒ‰ìš©)
    experience = structured_data.get("experience", [])
    projects = structured_data.get("projects", [])
    skills = structured_data.get("skills", [])
    self_intro = structured_data.get("self_intro", [])
    candidate_name = structured_data.get('header', {}).get('name') or "ê¹€ë¦°"
    
    print("\n" + "-"*30)
    print(f"ğŸ“„ íŒŒì‹±ëœ ì´ë ¥ì„œ ì •ë³´ ({candidate_name} ì§€ì›ì)")
    print(f"ì´ë¦„: {candidate_name}")
    print(f"ê¸°ìˆ : {', '.join(skills) if skills else 'ì¶”ì¶œëœ ê¸°ìˆ  ì—†ìŒ'}")
    print(f"í”„ë¡œì íŠ¸ ìˆ˜: {len(projects)}")
    print(f"ìì†Œì„œ ë¬¸í•­ ìˆ˜: {len(self_intro)}")
    print("-"*30)
    
    # ê²€ìƒ‰ ë¬¸ë§¥ êµ¬ì„± (ë” í’ë¶€í•˜ê²Œ)
    summary_for_search = ""
    if skills:
        summary_for_search += f"ê¸°ìˆ  ìŠ¤íƒ ë° ì—­ëŸ‰: {', '.join(skills)}\n"
    
    if projects:
        for p in projects[:2]:
            summary_for_search += f"í”„ë¡œì íŠ¸: {p.get('title')} - {p.get('description')}\n"
            
    if self_intro:
        # ì²« ë²ˆì§¸ ìì†Œì„œ ë¬¸í•­ ë‹µë³€ ìš”ì•½
        first_intro = self_intro[0].get("answer", "")[:200]
        summary_for_search += f"ìê¸°ì†Œê°œ í•µì‹¬: {first_intro}\n"

    logger.info(f"--- [2. ì§ˆë¬¸ ì€í–‰ì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ì¶”ì¶œ] ---")
    retriever = get_question_retriever()
    # ì´ë ¥ì„œ ë§¥ë½ê³¼ ê°€ì¥ ìœ ì‚¬í•œ ì§ˆë¬¸ Top 5 ì¶”ì¶œ
    base_questions = retriever.find_relevant_questions(
        text_context=summary_for_search,
        question_type="ì§ë¬´ì§€ì‹",
        top_k=5
    )
    
    print("\n" + "="*60)
    print(f"ğŸ” [ê¹€ë¦° ì§€ì›ì] AI ì§ˆë¬¸ ì€í–‰(6ë§Œ ê°œ) ê¸°ë°˜ ìƒìœ„ ì§ˆë¬¸ 5ê°œ")
    print("="*60)
    for idx, q in enumerate(base_questions):
        # ì‹¤ì œ í™˜ê²½ì—ì„œëŠ” q.distance ë“±ìœ¼ë¡œ ê´€ë ¨ë„ ì²´í¬ ê°€ëŠ¥
        print(f"{idx+1}. [{q.category}] {q.content}")
    print("-" * 60)

    logger.info(f"--- [3. LLMì„ í†µí•œ ì´ˆê°œì¸í™” ì§ˆë¬¸ ìƒì„±] ---")
    llm = get_exaone_llm()
    prompt = PromptTemplate.from_template("""[|system|]
ë„ˆëŠ” ëŒ€í•œë¯¼êµ­ ìµœê³ ì˜ ê¸°ìˆ  ë©´ì ‘ê´€ì´ë‹¤. DBì—ì„œ ì¶”ì¶œëœ 'ê¸°ë³¸ ì§ˆë¬¸'ê³¼ ì§€ì›ìì˜ 'ì´ë ¥ì„œ ë‚´ìš©'ì„ ê²°í•©í•˜ì—¬, 
ì˜¤ì§ ì´ ì§€ì›ìë§Œì„ ìœ„í•œ ë‚ ì¹´ë¡œìš´ 'ì´ˆê°œì¸í™” ì§ˆë¬¸'ì„ 1ê°œ ìƒì„±í•˜ë¼.

[ê¹€ë¦° ì§€ì›ì ì •ë³´]
{resume_info}

[DB ì¶”ì¶œ ê¸°ë³¸ ì§ˆë¬¸ í›„ë³´]
{base_question}

[ì§€ì¹¨]
1. ì´ë ¥ì„œì— ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ í”„ë¡œì íŠ¸ë‚˜ ê¸°ìˆ  ìŠ¤íƒì„ ë°˜ë“œì‹œ ì–¸ê¸‰í•˜ë©° ì§ˆë¬¸ì„ ì‹œì‘í•  ê²ƒ.
2. DB ì§ˆë¬¸ì˜ í•µì‹¬ ê°œë…ì„ ì§€ì›ìì˜ ê²½í—˜ê³¼ ì—°ê²°í•˜ì—¬ ì§ˆë¬¸í•  ê²ƒ.
3. 150ì ì´ë‚´, ë‘ ë¬¸ì¥ìœ¼ë¡œ ê°„ê²°í•˜ê²Œ ì‘ì„±í•  ê²ƒ.
[|endofturn|]
[|user|]
ê¹€ë¦° ì§€ì›ì ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ì¤˜.
[|endofturn|]
[|assistant|]
""")
    
    chain = prompt | llm | StrOutputParser()
    
    # ìƒìœ„ 5ê°œ ì§ˆë¬¸ ì¤‘ ê°€ì¥ ê´€ë ¨ì„± ë†’ì€ ì²« ë²ˆì§¸ ì§ˆë¬¸ì„ ê¸°ë°˜ìœ¼ë¡œ ê°œì¸í™” ì‹œë„
    if base_questions:
        target_q = base_questions[0]
        personalized_q = chain.invoke({
            "resume_info": summary_for_search,
            "base_question": target_q.content
        })
        
        print("\n" + "âœ¨" * 30)
        print("ğŸš€ [ìµœì¢… íƒ„ìƒí•œ ì´ˆê°œì¸í™” ì§ˆë¬¸]")
        print(f"ê¸°ë°˜ì´ ëœ DB ì§ˆë¬¸: {target_q.content}")
        print(f"ğŸ‘‰ ê¹€ë¦°ë‹˜ ì „ìš© ì§ˆë¬¸: {personalized_q}")
        print("âœ¨" * 30 + "\n")

if __name__ == "__main__":
    pdf_file = "ê¹€ë¦°_ì‹ ì…_ì´ë ¥ì„œ.pdf"
    run_personalization_test(pdf_file)
