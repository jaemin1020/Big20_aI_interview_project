import sys
import os
import torch
from sqlalchemy import text

# ğŸš¨ [ìµœì‹  í‘œì¤€] langchain_huggingface ì‚¬ìš©
try:
    from langchain_huggingface import HuggingFaceEmbeddings
except ImportError:
    from langchain_community.embeddings import HuggingFaceEmbeddings

# -----------------------------------------------------------
# [ê²½ë¡œ ì„¤ì •]
# -----------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
sys.path.append(os.path.join(current_dir, "ai-worker"))

try:
    from db import engine
except ImportError:
    try:
        sys.path.append("/app/backend-core") 
        from db import engine
    except ImportError:
        print("âŒ db.py ë¡œë“œ ì‹¤íŒ¨")
        sys.exit(1)

# -----------------------------------------------------------
# [ëª¨ë¸ ì„¤ì •] Step 6(ì €ì¥) ë•Œ ì“´ ëª¨ë¸ê³¼ 100% ì¼ì¹˜í•´ì•¼ í•¨!
# -----------------------------------------------------------
EMBEDDING_MODEL = "nlpai-lab/KURE-v1" 

# GPU/CPU ìë™ ì„¤ì •
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(f"[STEP7] ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì¤‘ ({EMBEDDING_MODEL}) on {device}...")

try:
    embedder = HuggingFaceEmbeddings(
        model_name=EMBEDDING_MODEL,
        model_kwargs={'device': device},
        encode_kwargs={'normalize_embeddings': True}
    )
except Exception as e:
    print(f"âŒ ì„ë² ë”© ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {e}")
    sys.exit(1)

# -----------------------------------------------------------
# [í•µì‹¬] ê²€ìƒ‰ í•¨ìˆ˜ (í•˜ì´ë¸Œë¦¬ë“œ ê²€ìƒ‰ ì ìš©)
# -----------------------------------------------------------
def retrieve_context(query, resume_id=1, top_k=3, filter_category=None):
    """
    Args:
        query (str): ê²€ìƒ‰í•  ì§ˆë¬¸ ë‚´ìš©
        resume_id (int): ëŒ€ìƒ ì§€ì›ì ID
        top_k (int): ê°€ì ¸ì˜¬ ê°œìˆ˜
        filter_category (str): 'project', 'narrative', 'activity' ë“± (ì—†ìœ¼ë©´ ì „ì²´ ê²€ìƒ‰)
    """
    print(f"\nğŸ” [RAG ê²€ìƒ‰] í‚¤ì›Œë“œ: '{query}' (í•„í„°: {filter_category})")
    
    # 1. ê²€ìƒ‰ì–´(Query)ë¥¼ ë²¡í„°ë¡œ ë³€í™˜
    try:
        query_vector = embedder.embed_query(query)
    except Exception as e:
        print(f"âŒ ì¿¼ë¦¬ ì„ë² ë”© ì‹¤íŒ¨: {e}")
        return []
    
    results = []
    
    try:
        with engine.connect() as conn:
            # 2. ë™ì  SQL ìƒì„± (í•„í„°ë§ ì¡°ê±´ ì¶”ê°€)
            # ê¸°ë³¸ ì¿¼ë¦¬
            base_sql = """
                SELECT chunk_text, metadata, (embedding <=> :qv) as distance
                FROM resume_embeddings
                WHERE resume_id = :rid
            """
            
            # â˜… ë©”íƒ€ë°ì´í„° í•„í„°ë§ ì¶”ê°€ (ì´ê²Œ í•µì‹¬!)
            # DBì— ì €ì¥ëœ metadata JSONì˜ 'category' í‚¤ë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
            if filter_category:
                base_sql += f" AND metadata->>'category' = '{filter_category}'"
            
            # ì •ë ¬ ë° ì œí•œ
            final_sql = base_sql + " ORDER BY distance ASC LIMIT :k"
            
            # 3. ì¿¼ë¦¬ ì‹¤í–‰
            rows = conn.execute(text(final_sql), {
                "qv": str(query_vector),
                "rid": int(resume_id),
                "k": top_k
            }).fetchall()

            # 4. ê²°ê³¼ ê°€ê³µ
            for row in rows:
                chunk_text = row[0]
                meta_data = row[1] # DBì—ì„œ êº¼ë‚¸ ë©”íƒ€ë°ì´í„° (dict)
                
                # ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ì— í…ìŠ¤íŠ¸ì™€ ë©”íƒ€ë°ì´í„°ë¥¼ í•¨ê»˜ ë‹´ìŒ
                results.append({
                    'text': chunk_text,
                    'meta': meta_data  # Step 8ì—ì„œ í™œìš© ê°€ëŠ¥
                })

            print(f"   ğŸ‘‰ {len(results)}ê°œì˜ ê´€ë ¨ ë‚´ìš©ì„ ì°¾ì•˜ìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"âŒ DB ê²€ìƒ‰ ì‹¤íŒ¨: {e}")
        
    return results

# -----------------------------------------------------------
# í…ŒìŠ¤íŠ¸ ì½”ë“œ
# -----------------------------------------------------------
if __name__ == "__main__":
    # í…ŒìŠ¤íŠ¸ 1: í•„í„° ì—†ì´ ê²€ìƒ‰ (ê¸°ë³¸)
    print("--- [Test 1: ì „ì²´ ê²€ìƒ‰] ---")
    retrieve_context("ë³´ì•ˆ ê¸°ìˆ  ìŠ¤í‚¬", resume_id=1)
    
    # í…ŒìŠ¤íŠ¸ 2: 'í”„ë¡œì íŠ¸'ë§Œ ì½• ì§‘ì–´ì„œ ê²€ìƒ‰ (í•˜ì´ë¸Œë¦¬ë“œ)
    print("\n--- [Test 2: í”„ë¡œì íŠ¸ í•„í„°ë§ ê²€ìƒ‰] ---")
    found = retrieve_context("ì„±ê³¼ ë‹¬ì„± ê²½í—˜", resume_id=1, filter_category="project")

    if found:
        print("\nâœ… [ê²€ìƒ‰ ê²°ê³¼ í™•ì¸]")
        for item in found:
            # ë©”íƒ€ë°ì´í„°ë„ ê°™ì´ ì¶œë ¥í•´ë´…ë‹ˆë‹¤.
            print(f"[ì¹´í…Œê³ ë¦¬: {item['meta'].get('category')}] {item['text'][:50]}...")