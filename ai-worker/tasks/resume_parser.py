import logging
import os
import json
from celery import shared_task, current_app
from sqlmodel import Session

# [ë¬¸ë²•] __name__: í˜„ì¬ ëª¨ë“ˆì˜ ì´ë¦„ì„ ìë™ìœ¼ë¡œ ê°€ì ¸ì˜µë‹ˆë‹¤. 
# ë¡œê·¸ì— ì–´ëŠ íŒŒì¼ì—ì„œ ë°œìƒí•œ ì¼ì¸ì§€ ì°ì–´ì£¼ëŠ” ì´ì •í‘œê°€ ë©ë‹ˆë‹¤.
logger = logging.getLogger(__name__)

# [ë¬¸ë²•] try-except: ì„í¬íŠ¸ ì—ëŸ¬ê°€ ë‚˜ë”ë¼ë„ ì „ì²´ ì„œë²„ê°€ ì£½ì§€ ì•Šê²Œ ë³´í˜¸í•©ë‹ˆë‹¤.
# íŠ¹íˆ DB ëª¨ë¸ì€ ë‹¤ë¥¸ íŒŒì¼ì—ì„œ ê°€ì ¸ì˜¤ê¸° ë•Œë¬¸ì— ê²½ë¡œ ë¬¸ì œê°€ ìƒê¸¸ ìˆ˜ ìˆì–´ ì•ˆì „ì¥ì¹˜ë¥¼ ë‘” ê²ƒì…ë‹ˆë‹¤.
try:
    from db_models import Resume
    from db import engine
except ImportError as e:
    logger.error(f"âŒ Critical Import Error in resume_parser: {e}")
    
# ì•ì„œ ìš°ë¦¬ê°€ ë¶„ì„í–ˆë˜ íŒŒì‹± í•¨ìˆ˜ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
from .parse_resume import parse_resume_final

logger.info("âœ… Task Module 'tasks.resume_pipeline' is being loaded.")

# ==========================================
# ë©”ì¸ ì‘ì—…: ì´ë ¥ì„œ íŒŒì´í”„ë¼ì¸ (parse_resume_pdf)
# ==========================================

# [ë¬¸ë²•] bind=True: ì´ í•¨ìˆ˜ê°€ Celery ì‘ì—… ìì²´ì˜ ì†ì„±(ì˜ˆ: ì¬ì‹œë„ íšŸìˆ˜ ë“±)ì— ì ‘ê·¼í•  ìˆ˜ ìˆê²Œ 'self'ë¥¼ ì²« ë²ˆì§¸ ì¸ìë¡œ ë°›ìŠµë‹ˆë‹¤.
# [ë¬¸ë²•] queue='cpu_queue': ì´ ì‘ì—…ì€ ì—°ì‚°ëŸ‰ì´ ë§ìœ¼ë¯€ë¡œ 'CPU ì „ìš© ì¼ê¾¼'ì—ê²Œë§Œ ì‹œí‚¤ê² ë‹¤ëŠ” ëª…ì‹œì ì¸ ì§€ì •ì…ë‹ˆë‹¤.
@shared_task(bind=True, name="tasks.resume_pipeline.parse_pdf", queue='cpu_queue')
def parse_resume_pdf(self, resume_id: int, file_path: str):
    """
    ì´ë ¥ì„œ PDFë¥¼ ì½ì–´ DBì— ì €ì¥í•˜ê³ , ë‹¤ìŒ AI ë‹¨ê³„ë¡œ ë„˜ê¸°ëŠ” 'ê³µì¥ì¥' í•¨ìˆ˜
    """
    
    # -------------------------------------------------------
    # 1. íŒŒì¼ ê²½ë¡œ ì •ê·œí™” (Docker/ì»¨í…Œì´ë„ˆ í™˜ê²½ ëŒ€ì‘)
    # -------------------------------------------------------
    # [í•´ì„] ì„œë²„(Backend)ì™€ ì¼ê¾¼(Worker)ì€ ì„œë¡œ ë‹¤ë¥¸ ì»¨í…Œì´ë„ˆì¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
    # ì„œë²„ê°€ ì•Œë ¤ì¤€ ê²½ë¡œê°€ ì¼ê¾¼ ì…ì¥ì—ì„œëŠ” ë‹¤ë¥¼ ìˆ˜ ìˆê¸° ë•Œë¬¸ì—, ì»¨í…Œì´ë„ˆ ë‚´ ê³µí†µ ê²½ë¡œ(/app/uploads/resumes)ë¡œ ê°•ì œ ì¡°ì •í•©ë‹ˆë‹¤.
    filename = os.path.basename(file_path) # íŒŒì¼ëª…ë§Œ ì™ ë½‘ê¸° (ì˜ˆ: "my_resume.pdf")
    normalized_path = os.path.join("/app/uploads/resumes", filename)
    
    logger.info(f"ğŸš€ [START] Resume parsing ID: {resume_id}")
    
    try:
        # íŒŒì¼ì´ ì‹¤ì œë¡œ ìˆëŠ”ì§€ í™•ì¸ (ì—†ìœ¼ë©´ íŒŒì‹±ì„ ëª» í•˜ë‹ˆê¹Œìš”!)
        if not os.path.exists(normalized_path):
            logger.error(f"âŒ File not found: {normalized_path}")
            # í´ë°±: ì •ê·œí™”ëœ ê²½ë¡œì— ì—†ìœ¼ë©´ ì›ë˜ ê²½ë¡œë¡œë¼ë„ í•œ ë²ˆ ë” ì‹œë„í•´ë´…ë‹ˆë‹¤.
            if os.path.exists(file_path):
                normalized_path = file_path
            else:
                # ë‘˜ ë‹¤ ì—†ìœ¼ë©´ ì‹¤íŒ¨ ì²˜ë¦¬í•˜ê³  ì¢…ë£Œ
                _update_status(resume_id, "failed")
                return
            
        # -------------------------------------------------------
        # 2. íŒŒì‹± ì‹¤í–‰ (ìš°ë¦¬ê°€ ë§Œë“  ì—”ì§„ ê°€ë™)
        # -------------------------------------------------------
        logger.info(f"ğŸ” Parsing PDF...")
        parsed_data = parse_resume_final(normalized_path)
        logger.info(f"âœ… Parsing Success: {parsed_data.get('header', {}).get('name')} detected")
        
        # -------------------------------------------------------
        # 3. DB ì—…ë°ì´íŠ¸ (SQLModel ì‚¬ìš©)
        # -------------------------------------------------------
        # [ë¬¸ë²•] with Session(engine) as session: DB ì—°ê²°ì„ ì—´ê³ , ì‘ì—…ì´ ëë‚˜ë©´ ìë™ìœ¼ë¡œ ë‹«ì•„ì£¼ëŠ” ë¬¸ë²•ì…ë‹ˆë‹¤.
        with Session(engine) as session:
            # DBì—ì„œ í•´ë‹¹ IDì˜ ì´ë ¥ì„œ ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤.
            resume = session.get(Resume, resume_id)
            if not resume:
                logger.error(f"âŒ Resume {resume_id} not found in DB")
                return

            # íŒŒì‹±ëœ ê²°ê³¼(JSON í˜•íƒœ)ë¥¼ DB ì»¬ëŸ¼ì— ì €ì¥í•©ë‹ˆë‹¤.
            resume.structured_data = parsed_data
            
            # íŒŒì„œê°€ ì°¾ì•„ë‚¸ 'ì§€ì› ì§ë¬´'ê°€ ìˆë‹¤ë©´ DBì— ë”°ë¡œ ê¸°ë¡í•´ì¤ë‹ˆë‹¤.
            target_pos = parsed_data.get("header", {}).get("target_role")
            if target_pos:
                resume.target_position = target_pos
                
            # [ë¬¸ë²•] json.dumps: íŒŒì´ì¬ ë”•ì…”ë„ˆë¦¬ë¥¼ í…ìŠ¤íŠ¸ í˜•íƒœì˜ JSONìœ¼ë¡œ ë³€í™˜í•˜ì—¬ DBì— ë„£ê¸° ì¢‹ê²Œ ë§Œë“­ë‹ˆë‹¤.
            resume.extracted_text = json.dumps(parsed_data, ensure_ascii=False)
            
            # í˜„ì¬ ìƒíƒœë¥¼ 'ì²˜ë¦¬ ì¤‘(processing)'ìœ¼ë¡œ ë°”ê¿‰ë‹ˆë‹¤. (ë‹¤ìŒ ë‹¨ê³„ì¸ ì„ë² ë”©ì´ ë‚¨ì•˜ìœ¼ë¯€ë¡œ)
            resume.processing_status = "processing" 
            
            session.add(resume) # ë³€ê²½ì‚¬í•­ ë“±ë¡
            session.commit()    # DBì— ìµœì¢… ì €ì¥!
            logger.info(f"ğŸ’¾ DB Updated for Resume {resume_id}")
            
        # -------------------------------------------------------
        # 4. ë‹¤ìŒ ë‹¨ê³„(ì„ë² ë”©) í˜¸ì¶œ - ë¦´ë ˆì´ ê²½ì£¼!
        # -------------------------------------------------------
        # [í•´ì„] íŒŒì‹±ì´ ëë‚¬ìœ¼ë‹ˆ, ì´ì œ ì´ê±¸ ë²¡í„° ë°ì´í„°ë¡œ ë°”ê¿€ 'GPU ì „ìš© ì¼ê¾¼'ì—ê²Œ ì¼ì„ ë„˜ê¹ë‹ˆë‹¤.
        # [ë¬¸ë²•] send_task: ë‹¤ë¥¸ íŒŒì¼ì— ì •ì˜ëœ Celery ì‘ì—…ì„ ì´ë¦„ë§Œìœ¼ë¡œ í˜¸ì¶œí•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        current_app.send_task(
            "tasks.resume_pipeline.generate_embeddings",
            args=[resume_id],
            queue='gpu_queue' # ì„ë² ë”©ì€ GPU ì„œë²„ê°€ ì²˜ë¦¬
        )
        logger.info(f"â¡ï¸ [NEXT] Sent embedding task for Resume {resume_id}")

    except Exception as e:
        # ì—ëŸ¬ ë°œìƒ ì‹œ ë¡œê·¸ë¥¼ ë‚¨ê¸°ê³  DB ìƒíƒœë¥¼ 'failed'ë¡œ ë³€ê²½í•©ë‹ˆë‹¤.
        logger.error(f"Error parsing resume {resume_id}: {e}", exc_info=True)
        _update_status(resume_id, "failed")

# ==========================================
# ë³´ì¡° í•¨ìˆ˜: ìƒíƒœ ì—…ë°ì´íŠ¸ (DRY ì›ì¹™)
# ==========================================

def _update_status(resume_id: int, status: str):
    """
    ì´ í•¨ìˆ˜ëŠ” ì½”ë“œ ì¤‘ë³µì„ í”¼í•˜ê¸° ìœ„í•´ ë§Œë“  'ìƒíƒœ ì—…ë°ì´íŠ¸ ì „ìš©' í•¨ìˆ˜ì…ë‹ˆë‹¤.
    í•¨ìˆ˜ ì´ë¦„ ì•ì— ì–¸ë”ë°”(_)ë¥¼ ë¶™ì—¬ì„œ 'ì´ íŒŒì¼ ì•ˆì—ì„œë§Œ ì£¼ë¡œ ì“°ê² ë‹¤'ëŠ” ì‹ í˜¸ë¥¼ ì¤ë‹ˆë‹¤.
    """
    with Session(engine) as session:
        resume = session.get(Resume, resume_id)
        if resume:
            resume.processing_status = status
            session.add(resume)
            session.commit()