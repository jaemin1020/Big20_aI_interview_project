import sys
import os
import json
from sqlalchemy import text as sql_text

# -----------------------------------------------------------
# [1. ê²½ë¡œ ì„¤ì •] ì™œ ì´ ì½”ë“œê°€ í•„ìš”í• ê¹Œ?
# ì„œë²„ í™˜ê²½(Docker)ê³¼ ê°œë°œì ì»´í“¨í„°(Local)ëŠ” í´ë” êµ¬ì¡°ê°€ ë‹¤ë¦…ë‹ˆë‹¤.
# ì–´ë””ì„œë“  ë‹¤ë¥¸ íŒŒì¼(db.py ë“±)ì„ ì˜ ë¶ˆëŸ¬ì˜¬ ìˆ˜ ìˆë„ë¡ ê¸¸ì„ í„°ì£¼ëŠ” ì‘ì—…ì…ë‹ˆë‹¤.
# -----------------------------------------------------------
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_core_docker = "/backend-core"
backend_core_local = os.path.join(current_dir, "backend-core")

# [ë¬¸ë²•] sys.path.append: íŒŒì´ì¬ì´ ëª¨ë“ˆì„ ì°¾ì„ ë•Œ ê²€ìƒ‰í•˜ëŠ” ëª…ë‹¨ì— íŠ¹ì • í´ë”ë¥¼ ì¶”ê°€í•©ë‹ˆë‹¤.
if os.path.exists(backend_core_docker):
    sys.path.append(backend_core_docker)
elif os.path.exists(backend_core_local):
    sys.path.append(backend_core_local)

# ğŸš¨ db.pyì—ì„œ engine ë¶ˆëŸ¬ì˜¤ê¸° (ë°ì´í„°ë² ì´ìŠ¤ì™€ ì—°ê²°í•˜ëŠ” í†µë¡œ)
try:
    from db import engine
except ImportError as e:
    print(f"âŒ db.pyë¥¼ ë¶ˆëŸ¬ì˜¤ëŠ”ë° ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤: {e}")
    sys.exit(1) # [ë¬¸ë²•] sys.exit(1): ì‹¬ê°í•œ ì—ëŸ¬ê°€ ë°œìƒí–ˆìœ¼ë¯€ë¡œ í”„ë¡œê·¸ë¨ì„ ì¦‰ì‹œ ì¢…ë£Œí•©ë‹ˆë‹¤.

# -----------------------------------------------------------
# [2. ë„êµ¬ ë¶ˆëŸ¬ì˜¤ê¸°]
# LangChainì€ AI ì•±ì„ ë§Œë“¤ê¸° ìœ„í•œ 'ë ˆê³  ë¸”ë¡' ê°™ì€ ë„êµ¬ì…ë‹ˆë‹¤.
# PGVector: PostgreSQLì— ë²¡í„°ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ê²Œ í•´ì£¼ëŠ” ë ˆê³  ë¸”ë¡ì…ë‹ˆë‹¤.
# -----------------------------------------------------------
from langchain_community.vectorstores import PGVector
from langchain_core.documents import Document

try:
    from .embedding import get_embedder # í˜„ì¬ í´ë”ì—ì„œ ê°€ì ¸ì˜¤ê¸° ì‹œë„
except ImportError:
    from embedding import get_embedder    # ì‹¤íŒ¨ ì‹œ ê·¸ëƒ¥ ê°€ì ¸ì˜¤ê¸°

# -----------------------------------------------------------
# [3. í•µì‹¬ í•¨ìˆ˜: store_embeddings]
# [ì¡´ì¬ ì´ìœ ] ì„ë² ë”©ëœ ìˆ«ì ë°ì´í„°ëŠ” ê·¸ëƒ¥ ë‘ë©´ íœ˜ë°œë©ë‹ˆë‹¤. ì´ë¥¼ DBì— 'ì˜êµ¬ ì €ì¥'í•´ì•¼ 
# ë‚˜ì¤‘ì— ë©´ì ‘ê´€ AIê°€ ì´ ë°ì´í„°ë¥¼ ë³´ê³  ì§ˆë¬¸ì„ ë˜ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
# -----------------------------------------------------------
def store_embeddings(resume_id, embedded_chunks):
    """
    [í•¨ìˆ˜ì˜ ì—­í• ] ì„ë² ë”©ëœ ë°ì´í„° ì¡°ê°ë“¤ì„ Document ê°ì²´ë¡œ ë³€í™˜í•˜ì—¬ DBì— ì €ì¥í•©ë‹ˆë‹¤.
    """
    if not embedded_chunks:
        print("âŒ ì €ì¥í•  ì„ë² ë”© ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    print(f"\n[STEP6] DB ì €ì¥ ì‹œì‘ (Resume ID: {resume_id})...")

    # -------------------------------------------------------
    # 3-1. ë¬¸ì„œí™” (Document ê°ì²´ ìƒì„±)
    # [ì¡´ì¬ ì´ìœ ] LangChain DB ë„êµ¬ë¥¼ ì“°ë ¤ë©´ ë°ì´í„°ë¥¼ 'Document'ë¼ëŠ” í‘œì¤€ í˜•ì‹ìœ¼ë¡œ í¬ì¥í•´ì•¼ í•©ë‹ˆë‹¤.
    # -------------------------------------------------------
    documents = []
    for item in embedded_chunks:
        # [í•´ì„] ë©”íƒ€ë°ì´í„°(Metadata)ëŠ” ë°ì´í„°ì˜ 'ê²¬ì¶œì§€'ì…ë‹ˆë‹¤.
        # ë‚˜ì¤‘ì— ìˆ˜ì²œ ëª…ì˜ ì´ë ¥ì„œê°€ ì„ì—¬ ìˆì–´ë„ resume_idë¡œ ë‚´ ê²ƒë§Œ ì™ ê³¨ë¼ë‚¼ ìˆ˜ ìˆìŠµë‹ˆë‹¤.
        metadata = item.get("metadata", {})
        metadata["resume_id"] = resume_id # ëˆ„êµ¬ì˜ ì´ë ¥ì„œì¸ì§€ ê¸°ë¡
        metadata["chunk_type"] = item.get("type", "unknown") # ì´ê²Œ í•™ë ¥ì¸ì§€ ê²½ë ¥ì¸ì§€ ê¸°ë¡
        
        doc = Document(
            page_content=item["text"], # ì‹¤ì œ í…ìŠ¤íŠ¸ ë‚´ìš©
            metadata=metadata          # ë¶€ê°€ ì •ë³´(ê²¬ì¶œì§€)
        )
        documents.append(doc)

    # -------------------------------------------------------
    # 3-2. DB ì—°ê²° ë° ì €ì¥
    # -------------------------------------------------------
    # [ë¬¸ë²•] os.getenv: í™˜ê²½ ë³€ìˆ˜ì—ì„œ DB ì ‘ì† ì •ë³´ë¥¼ ê°€ì ¸ì˜µë‹ˆë‹¤. ë³´ì•ˆì„ ìœ„í•´ ì•„ì´ë””/ë¹„ë²ˆì„ ì½”ë“œì— ì§ì ‘ ì ì§€ ì•ŠìŠµë‹ˆë‹¤.
    connection_string = os.getenv("DATABASE_URL", "postgresql+psycopg://postgres:1234@db:5432/interview_db")
    
    import torch
    device = 'cuda' if torch.cuda.is_available() else 'cpu'
    embeddings = get_embedder(device) # ì €ì¥í•  ë•Œë„ í…ìŠ¤íŠ¸ë¥¼ ìˆ«ìë¡œ ë°”ê¿€ ë˜‘ê°™ì€ ëª¨ë¸ì´ í•„ìš”í•©ë‹ˆë‹¤.

    try:
        # [ê°œì„ ] connection_stringê³¼ í•¨ê»˜ engineì„ ì „ë‹¬í•˜ì—¬ ì»¤ë„¥ì…˜ í’€ ê³µìœ  ë³´ì¥
        from db import engine
        vector_store = PGVector.from_documents(
            documents,              # 1. ìœ„ì¹˜ ì¸ì
            embeddings,             # 2. ìœ„ì¹˜ ì¸ì
            collection_name="resume_all_embeddings",
            connection_string=connection_string,
            connection=engine,      # engine ê°ì²´ ì „ë‹¬ë¡œ ì„¸ì…˜ ê¼¬ì„ ë°©ì§€
            pre_delete_collection=False
        )
        
        print(f"[STEP6] âœ… ì´ {len(documents)}ê°œì˜ ì¡°ê°ì´ DBì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    except Exception as e:
        print(f"\nâŒ DB ì €ì¥ ì‹¤íŒ¨: {e}")

# -----------------------------------------------------------
# [4. ë©”ì¸ ì‹¤í–‰ë¶€] 
# ì „ì²´ ê³µì •(íŒŒì‹±->ì²­í‚¹->ì„ë² ë”©->ì €ì¥)ì„ í•œ ë²ˆì— í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
# -----------------------------------------------------------
if __name__ == "__main__":
    # ... (ìƒëµ) ...
    # ì‹¤ì œ ì‹¤í–‰ ì‹œ store_embeddings(resume_id=1, ...)ì„ í†µí•´ DBì— ìµœì¢… ì €ì¥ë©ë‹ˆë‹¤.
    pass
