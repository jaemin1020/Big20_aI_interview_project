<<<<<<< HEAD
<<<<<<< HEAD
from celery import shared_task
from faster_whisper import WhisperModel
=======

>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======

>>>>>>> ë¦°_phase4
import os
import logging
import base64
import tempfile
<<<<<<< HEAD
<<<<<<< HEAD
import torch
=======
from celery import shared_task
from faster_whisper import WhisperModel
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
from celery import shared_task
from faster_whisper import WhisperModel
>>>>>>> ë¦°_phase4

logger = logging.getLogger("STT-Task")

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜
stt_model = None
<<<<<<< HEAD
<<<<<<< HEAD
MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "large-v3-turbo") 
=======
# ëª¨ë¸ ì‚¬ì´ì¦ˆ: tiny, base, small, medium, large-v3-turbo. 
# CPU í™˜ê²½ì„ ìœ„í•´ ê¸°ë³¸ê°’ì€ 'medium' ë˜ëŠ” 'small' ê¶Œì¥.
MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "large-v3-turbo")
>>>>>>> ë¦°_phase4

def load_stt_model():
    """
    Faster-Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ì‹±ê¸€í†¤ íŒ¨í„´)
    Compute Type: int8 (CPU ì„±ëŠ¥ ìµœì í™”)
    """
    global stt_model
    
    if stt_model is not None:
        return

    try:
        device = "cpu"
        # CPUì—ì„œ int8 ì–‘ìí™” ì‚¬ìš© ì‹œ ì†ë„ ëŒ€í­ í–¥ìƒ
        compute_type = "int8" 
        
        logger.info(f"ğŸš€ [LOADING] Faster-Whisper ({MODEL_SIZE}) on {device} (compute_type={compute_type})...")
        
        # ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œë¨)
        stt_model = WhisperModel(MODEL_SIZE, device=device, compute_type=compute_type)
        
        logger.info("âœ… Faster-Whisper loaded successfully.")
    except Exception as e:
<<<<<<< HEAD
        logger.error(f"âŒ Failed to load Whisper Pipeline: {e}")
        stt_pipeline = None

# ëª¨ë“ˆ ë¡œë“œ ì‹œ ì „ì—­ í˜¸ì¶œ ì œê±° (ì‹¤ì œ íƒœìŠ¤í¬ ìˆ˜í–‰ ì‹œ ë¡œë“œí•˜ë„ë¡ ìˆ˜ì •)
# load_stt_pipeline()
=======
# ëª¨ë¸ ì‚¬ì´ì¦ˆ: tiny, base, small, medium, large-v3-turbo. 
# CPU í™˜ê²½ì„ ìœ„í•´ ê¸°ë³¸ê°’ì€ 'medium' ë˜ëŠ” 'small' ê¶Œì¥.
MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "large-v3-turbo")

def load_stt_model():
    """
    Faster-Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ì‹±ê¸€í†¤ íŒ¨í„´)
    Compute Type: int8 (CPU ì„±ëŠ¥ ìµœì í™”)
    """
    global stt_model
    
    if stt_model is not None:
        return

    try:
        device = "cpu"
        # CPUì—ì„œ int8 ì–‘ìí™” ì‚¬ìš© ì‹œ ì†ë„ ëŒ€í­ í–¥ìƒ
        compute_type = "int8" 
        
        logger.info(f"ğŸš€ [LOADING] Faster-Whisper ({MODEL_SIZE}) on {device} (compute_type={compute_type})...")
        
        # ëª¨ë¸ ë¡œë“œ (ìµœì´ˆ ì‹¤í–‰ ì‹œ ë‹¤ìš´ë¡œë“œë¨)
        stt_model = WhisperModel(MODEL_SIZE, device=device, compute_type=compute_type)
        
        logger.info("âœ… Faster-Whisper loaded successfully.")
    except Exception as e:
        logger.error(f"âŒ Failed to load Faster-Whisper: {e}", exc_info=True)
        stt_model = None
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
        logger.error(f"âŒ Failed to load Faster-Whisper: {e}", exc_info=True)
        stt_model = None
>>>>>>> ë¦°_phase4

@shared_task(name="tasks.stt.recognize")
def recognize_audio_task(audio_b64: str):
    """
<<<<<<< HEAD
<<<<<<< HEAD
    Faster-Whisperë¥¼ ì‚¬ìš©í•œ í†µí•© STT Task (íŒŒì¼/ì²­í¬)
    
=======
    Faster-Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤(Base64)ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
>>>>>>> ë¦°_phase4
    Args:
        audio_b64 (str): Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (í—¤ë” í¬í•¨ë  ìˆ˜ ìˆìŒ)
    """
    global stt_model
    
    # ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)
    if stt_model is None:
        load_stt_model()
        if stt_model is None:
<<<<<<< HEAD
             return {"status": "error", "message": "Model loading failed"}
=======
    Faster-Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤(Base64)ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Args:
        audio_b64 (str): Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (í—¤ë” í¬í•¨ë  ìˆ˜ ìˆìŒ)
    """
    global stt_model
    
    # ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)
    if stt_model is None:
        load_stt_model()
        if stt_model is None:
             return {"status": "error", "message": "STT Model loading failed"}
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
             return {"status": "error", "message": "STT Model loading failed"}
>>>>>>> ë¦°_phase4

    temp_path = None
    try:
        if not audio_b64:
            return {"status": "error", "message": "Empty audio data"}
            
<<<<<<< HEAD
<<<<<<< HEAD
        # Base64 decoding & Save to Temp File
        audio_bytes = base64.b64decode(audio_b64)
        
        # íŒŒì¼ ì €ì¥ (faster-whisperëŠ” íŒŒì¼ ê²½ë¡œ ë˜ëŠ” binary stream ì§€ì›)
=======
        # Base64 í—¤ë” ì²˜ë¦¬ (data:audio/webm;base64,...)
        if "," in audio_b64:
            audio_b64 = audio_b64.split(",")[1]
            
        try:
            audio_bytes = base64.b64decode(audio_b64)
        except Exception as e:
            return {"status": "error", "message": f"Base64 decode failed: {e}"}
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥ (faster-whisperëŠ” íŒŒì¼ ê²½ë¡œ ì…ë ¥ ê¶Œì¥)
        # suffixëŠ” webmìœ¼ë¡œ ê°€ì •í•˜ë‚˜, ffmpegê°€ ì•Œì•„ì„œ ì²˜ë¦¬í•¨
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
        # Base64 í—¤ë” ì²˜ë¦¬ (data:audio/webm;base64,...)
        if "," in audio_b64:
            audio_b64 = audio_b64.split(",")[1]
            
        try:
            audio_bytes = base64.b64decode(audio_b64)
        except Exception as e:
            return {"status": "error", "message": f"Base64 decode failed: {e}"}
        
        # ì„ì‹œ íŒŒì¼ ì €ì¥ (faster-whisperëŠ” íŒŒì¼ ê²½ë¡œ ì…ë ¥ ê¶Œì¥)
        # suffixëŠ” webmìœ¼ë¡œ ê°€ì •í•˜ë‚˜, ffmpegê°€ ì•Œì•„ì„œ ì²˜ë¦¬í•¨
>>>>>>> ë¦°_phase4
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as tmp:
            tmp.write(audio_bytes)
            temp_path = tmp.name
        
        # Inference
<<<<<<< HEAD
<<<<<<< HEAD
        segments, info = stt_model.transcribe(
            temp_path, 
            beam_size=5, 
            language="ko", # í•œêµ­ì–´ ê°•ì œ
            vad_filter=True # ìŒì„± í™œë™ ê°ì§€ ì‚¬ìš©
=======
        # segmentsëŠ” generatorì´ë¯€ë¡œ ìˆœíšŒí•´ì•¼ ì‹¤ì œ ì¶”ë¡ ì´ ìˆ˜í–‰ë¨
        segments, info = stt_model.transcribe(
            temp_path, 
            beam_size=5, 
            language="ko", 
            vad_filter=True, # ìŒì„± êµ¬ê°„ ê°ì§€ í™œì„±í™” (ë¬´ìŒ ì œê±°)
            vad_parameters=dict(min_silence_duration_ms=500)
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
        # segmentsëŠ” generatorì´ë¯€ë¡œ ìˆœíšŒí•´ì•¼ ì‹¤ì œ ì¶”ë¡ ì´ ìˆ˜í–‰ë¨
        segments, info = stt_model.transcribe(
            temp_path, 
            beam_size=5, 
            language="ko", 
            vad_filter=True, # ìŒì„± êµ¬ê°„ ê°ì§€ í™œì„±í™” (ë¬´ìŒ ì œê±°)
            vad_parameters=dict(min_silence_duration_ms=500)
>>>>>>> ë¦°_phase4
        )
        
        full_text = ""
        for segment in segments:
            full_text += segment.text
        
        full_text = full_text.strip()
<<<<<<< HEAD
<<<<<<< HEAD
        logger.info(f"STT Success: {len(full_text)} chars")
=======
        logger.info(f"STT Success: {len(full_text)} chars. Preview: {full_text[:50]}")
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
        logger.info(f"STT Success: {len(full_text)} chars. Preview: {full_text[:50]}")
>>>>>>> ë¦°_phase4
        
        return {"status": "success", "text": full_text}
        
    except Exception as e:
        logger.error(f"STT Error: {e}", exc_info=True)
        return {"status": "error", "message": str(e)}
        
    finally:
<<<<<<< HEAD
<<<<<<< HEAD
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
=======
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
>>>>>>> 3c3c7ad852cb791ad6eea3c101528407d064e29d
=======
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
>>>>>>> ë¦°_phase4
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except OSError:
                pass
