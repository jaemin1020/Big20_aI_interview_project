
import os
import logging
import base64
import tempfile
from celery import shared_task
from faster_whisper import WhisperModel

logger = logging.getLogger("STT-Task")

# ì „ì—­ ëª¨ë¸ ë³€ìˆ˜
stt_model = None
# ëª¨ë¸ ì‚¬ì´ì¦ˆ: tiny, base, small, medium, large-v1, large-v2, large-v3, large-v3-turbo
# CPU í™˜ê²½: small ë˜ëŠ” medium ê¶Œì¥ (ì •í™•ë„ 80-85%, ì†ë„ 5-15ì´ˆ)
# GPU í™˜ê²½: large-v3-turbo ê¶Œì¥ (ì •í™•ë„ 90%, ì†ë„ 2-5ì´ˆ)
MODEL_SIZE = os.getenv("WHISPER_MODEL_SIZE", "large-v3-turbo")

def load_stt_model():
    """
    Faster-Whisper ëª¨ë¸ì„ ë¡œë“œí•©ë‹ˆë‹¤. (ì‹±ê¸€í†¤ íŒ¨í„´)
    """
    global stt_model
    
    if stt_model is not None:
        logger.info(f"âœ… STT Model already loaded: {MODEL_SIZE}")
        return True

    try:
        # GPU ì‚¬ìš© ê°€ëŠ¥ ì—¬ë¶€ í™•ì¸
        import torch
        if torch.cuda.is_available():
            device = "cuda"
            compute_type = "float16" # GPUì—ì„œëŠ” float16ì´ ê°€ì¥ ë¹ ë¦„
            logger.info("ğŸ“¡ [STT_LOAD] Using CUDA for Faster-Whisper")
        else:
            device = "cpu"
            compute_type = "int8" # CPUì—ì„œëŠ” int8 ì–‘ìí™”ê°€ íš¨ìœ¨ì 
            logger.info("ğŸ“¡ [STT_LOAD] Using CPU for Faster-Whisper")
        
        logger.info(f"ğŸš€ [LOADING] Faster-Whisper ({MODEL_SIZE}) on {device} (compute_type={compute_type})...")
        
        # ëª¨ë¸ ë¡œë“œ
        stt_model = WhisperModel(MODEL_SIZE, device=device, compute_type=compute_type)
        
        logger.info(f"âœ… Faster-Whisper loaded successfully: {MODEL_SIZE}")
        return True
    except Exception as e:
        logger.error(f"âŒ Failed to load Faster-Whisper ({MODEL_SIZE}): {e}", exc_info=True)
        logger.error(f"Error type: {type(e).__name__}")
        logger.error(f"Error details: {str(e)}")
        stt_model = None
        return False

@shared_task(name="tasks.stt.recognize")
def recognize_audio_task(audio_b64: str):
    """
    Faster-Whisperë¥¼ ì‚¬ìš©í•˜ì—¬ ì˜¤ë””ì˜¤(Base64)ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜í•©ë‹ˆë‹¤.
    Args:
        audio_b64 (str): Base64 ì¸ì½”ë”©ëœ ì˜¤ë””ì˜¤ ë°ì´í„° (í—¤ë” í¬í•¨ë  ìˆ˜ ìˆìŒ)
    """
    global stt_model
    
    logger.info(f"[STT] Task received. Model status: {'Loaded' if stt_model else 'Not loaded'}")
    
    # ëª¨ë¸ ë¡œë“œ (ì§€ì—° ë¡œë”©)
    if stt_model is None:
        logger.info("[STT] Model not loaded. Attempting to load...")
        success = load_stt_model()
        if not success or stt_model is None:
            error_msg = f"STT Model loading failed. Model: {MODEL_SIZE}"
            logger.error(f"[STT] {error_msg}")
            return {"status": "error", "message": error_msg}

    temp_path = None
    try:
        if not audio_b64:
            return {"status": "error", "message": "Empty audio data"}
            
        # Base64 í—¤ë” ì²˜ë¦¬ (data:audio/webm;base64,...)
        if "," in audio_b64:
            audio_b64 = audio_b64.split(",")[1]
            
        try:
            audio_bytes = base64.b64decode(audio_b64)
        except Exception as e:
            return {"status": "error", "message": f"Base64 decode failed: {e}"}
        
        # 1. raw PCM í™•ì¸ (media-serverì—ì„œ ë³´ë‚¸ 2ì´ˆ chunksì¸ ê²½ìš°)
        # 16000Hz * 1ch * 2bytes(int16) * 2sec = 64000 bytes
        import numpy as np
        if len(audio_bytes) == 64000:
            try:
                # np.int16 -> np.float32 (Whisper ê¶Œì¥ í¬ë§·)
                audio_np = np.frombuffer(audio_bytes, dtype=np.int16).astype(np.float32) / 32768.0
                segments, info = stt_model.transcribe(audio_np, beam_size=5, language="ko")
                full_text = "".join([s.text for s in segments]).strip()
                if full_text:
                    logger.info(f"STT Success (Raw): {len(full_text)} chars.")
                    return {"status": "success", "text": full_text}
            except Exception as e:
                logger.warning(f"Raw PCM processing failed, falling back to file: {e}")

        # 2. íŒŒì¼ ê¸°ë°˜ ì²˜ë¦¬ (ê¸°ì¡´ ë¡œì§ - backend-core ë“±ì—ì„œ ì‚¬ìš©)
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as tmp:
            tmp.write(audio_bytes)
            temp_path = tmp.name
        
        segments, info = stt_model.transcribe(
            temp_path, 
            beam_size=5, 
            language="ko", 
            vad_filter=True,
            vad_parameters=dict(min_silence_duration_ms=500)
        )
        
        full_text = "".join([s.text for s in segments]).strip()
        logger.info(f"STT Success (File): {len(full_text)} chars.")
        return {"status": "success", "text": full_text}
        
    except Exception as e:
        logger.error(f"STT Error: {e}", exc_info=True)
        return {"status": "error", "message": str(e)}
        
    finally:
        # ì„ì‹œ íŒŒì¼ ì •ë¦¬
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except OSError:
                pass
