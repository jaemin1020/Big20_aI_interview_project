from celery import shared_task
from transformers import pipeline
import torch
import os
import logging
import base64
import tempfile

logger = logging.getLogger("STT-Task")

# ì „ì—­ íŒŒì´í”„ë¼ì¸ ë³€ìˆ˜
stt_pipeline = None
MODEL_ID = os.getenv("WHISPER_MODEL_ID", "openai/whisper-large-v3-turbo") 

def load_stt_pipeline():
    global stt_pipeline
    
    # [ìµœì í™”] GPU ì›Œì»¤(ì§ˆë¬¸ ìƒì„± ì „ìš©)ëŠ” STT ëª¨ë¸ì„ ë¡œë“œí•  í•„ìš”ê°€ ì—†ìŒ
    gpu_layers = int(os.getenv("N_GPU_LAYERS", "-1"))
    if gpu_layers == -1:
        logger.info("â© [SKIP] GPU Worker detected. Skipping Whisper Pipeline loading.")
        return

    try:
        # cuDNN ì—ëŸ¬ ë°©ì§€ë¥¼ ìœ„í•´ CPU ì‚¬ìš© ê°•ì œ
        device = "cpu" 
        torch_dtype = torch.float32

        logger.info(f"ğŸš€ [LOADING] Whisper Pipeline ({MODEL_ID}) on {device}...")
        
        stt_pipeline = pipeline(
            "automatic-speech-recognition",
            model=MODEL_ID,
            torch_dtype=torch_dtype,
            device=device,
            chunk_length_s=30,
        )
        logger.info("âœ… Whisper Pipeline loaded successfully.")
    except Exception as e:
        logger.error(f"âŒ Failed to load Whisper Pipeline: {e}")
        stt_pipeline = None

# ëª¨ë“ˆ ë¡œë“œ ì‹œ ì „ì—­ í˜¸ì¶œ ì œê±° (ì‹¤ì œ íƒœìŠ¤í¬ ìˆ˜í–‰ ì‹œ ë¡œë“œí•˜ë„ë¡ ìˆ˜ì •)
# load_stt_pipeline()

@shared_task(name="tasks.stt.recognize")
def recognize_audio_task(audio_b64: str):
    """
    Transformers Pipelineì„ ì‚¬ìš©í•œ ë¡œì»¬ STT Task
    
    Args:
        audio_b64: Base64 encoded audio string
        
    Returns:
        dict: {"status": "success", "text": "..."}
    """
    global stt_pipeline
    
    if stt_pipeline is None:
        load_stt_pipeline()
        if stt_pipeline is None:
             return {"status": "error", "message": "Model loading failed"}

    temp_path = None
    try:
        if not audio_b64:
            return {"status": "error", "message": "Empty audio data"}
            
        # Base64 decoding & Save to Temp File
        audio_bytes = base64.b64decode(audio_b64)
        
        # Transformers Pipelineì€ íŒŒì¼ ê²½ë¡œë¥¼ ì…ë ¥ë°›ëŠ” ê²ƒì´ ì•ˆì •ì  (ffmpeg ì‚¬ìš©)
        with tempfile.NamedTemporaryFile(suffix=".webm", delete=False) as tmp:
            tmp.write(audio_bytes)
            temp_path = tmp.name
        
        # Inference
        # generate_kwargs={"language": "korean"} ì¶”ê°€í•˜ì—¬ í•œêµ­ì–´ ê°•ì œ ê°€ëŠ¥ (ì„ íƒ ì‚¬í•­)
        result = stt_pipeline(
            temp_path, 
            generate_kwargs={"language": "korean"}
        )
        
        text = result.get("text", "").strip()
        logger.info(f"STT Pipeline Success: {len(text)} chars")
        
        return {"status": "success", "text": text}
        
    except Exception as e:
        logger.error(f"STT Pipeline Error: {e}", exc_info=True)
        return {"status": "error", "message": str(e)}
        
    finally:
        # ì„ì‹œ íŒŒì¼ ì‚­ì œ
        if temp_path and os.path.exists(temp_path):
            try:
                os.remove(temp_path)
            except OSError:
                pass
