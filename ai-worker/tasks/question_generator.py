import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================

PROMPT_TEMPLATE = """[|system|]ë‹¹ì‹ ì€ ì§€ì›ìì˜ ì—­ëŸ‰ì„ ì •ë°€í•˜ê²Œ ê²€ì¦í•˜ëŠ” ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì œê³µëœ [ì´ë ¥ì„œ ë¬¸ë§¥]ê³¼ [ë©´ì ‘ ì§„í–‰ ìƒí™©]ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì—ê²Œ ë˜ì§ˆ 'ë‹¤ìŒ ì§ˆë¬¸' 1ê°œë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
2. ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•˜ë©°, 150ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
3. íŠ¹ìˆ˜ë¬¸ì(JSON ê¸°í˜¸, ì—­ë”°ì˜´í‘œ ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. "ì§ˆë¬¸:" ì´ë¼ëŠ” ìˆ˜ì‹ì–´ ì—†ì´ ë°”ë¡œ ì§ˆë¬¸ ë³¸ë¬¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
5. ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ í•˜ì‹­ì‹œì˜¤.
7. **ê¼¬ë¦¬ì§ˆë¬¸(Follow-up) ê·œì¹™**: ë°˜ë“œì‹œ ì§€ì›ìì˜ ë‹µë³€ì„ "~ë¼ê³  ë§ì”€í•´ ì£¼ì…¨êµ°ìš”."ì™€ ê°™ì´ ë¨¼ì € í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ì‹­ì‹œì˜¤. ê·¸ í›„, ë‹µë³€ì—ì„œ ì–¸ê¸‰ëœ êµ¬ì²´ì ì¸ ê¸°ìˆ ì´ë‚˜ ë°©ë²•ë¡ ì— ëŒ€í•´ **ê·¸ ë°©ì‹ì„ ì„ íƒí•œ ì´ìœ ** ë˜ëŠ” ì‹¤ì œ í”„ë¡œì íŠ¸ì—ì„œ ì§ë©´í–ˆë˜ **ê¸°ìˆ ì  í•œê³„ë‚˜ ë¬¸ì œì **ì„ ì½• ì§‘ì–´ ì‹¬ì¸µ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤.
8. **í™˜ê° ë° ëŒ€ê´„í˜¸ ê¸ˆì§€**: ì§€ì›ìê°€ ë§í•˜ì§€ ì•Šì€ ì™¸ë¶€ ê¸°ìˆ (ì˜ˆ: AWS Lambda ë“±)ì´ë‚˜ ì´ë¦„(ì´ì§€ì€ë‹˜ ë“±)ì„ ì ˆëŒ€ ì§€ì–´ë‚´ì§€ ë§ˆì‹­ì‹œì˜¤. ê°€ì´ë“œì— ì íŒ '[ì˜ˆì‹œ]'ë‚˜ ëŒ€ê´„í˜¸ ê¸°í˜¸([...])ë„ ì ˆëŒ€ ì¶œë ¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë‹µë³€ì´ ë„ˆë¬´ ì§§ë‹¤ë©´ ì–µì§€ë¡œ ê¹Šì€ ë‚´ìš©ì„ ë¬»ì§€ ë§ê³  í•´ë‹¹ í‚¤ì›Œë“œì˜ í•™ìŠµ ë™ê¸°ë‚˜ ì¼ë°˜ì ì¸ íŠ¹ì§•ì„ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤.

[ì´ë ¥ì„œ ë° ë‹µë³€ ë¬¸ë§¥]
{context}

[í˜„ì¬ ë©´ì ‘ ë‹¨ê³„ ì •ë³´]
- ë‹¨ê³„ëª…: {stage_name}
- ê°€ì´ë“œ: {guide}

[|user|]ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ë©”ì¸ ì‘ì—…: ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬
# ==========================================

@shared_task(name="tasks.question_generation.generate_next_question")
def generate_next_question_task(interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ AI ë°œí™” í™•ì¸ (Stage íŒë³„ + ì¤‘ë³µ ë°©ì§€)
            # [ìˆ˜ì •] User transcriptëŠ” question_idê°€ ì—†ì–´ stage íŒë³„ ë¶ˆê°€ â†’ ë§ˆì§€ë§‰ AI ë°œí™” ê¸°ì¤€ìœ¼ë¡œ íŒë³„
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.order.desc())
            last_transcript = session.exec(stmt_all).first()

            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.order.desc(), Transcript.id.desc())  # idë¥¼ tiebreakerë¡œ ì‚¬ìš© (order ê°™ì„ ë•Œ ìµœì‹  AI ë°œí™” ë³´ì¥)
            last_ai_transcript = session.exec(stmt_ai).first()

            # [ìˆ˜ì •] RAG ì¿¼ë¦¬ë¡œ ì‚¬ìš©í•  ì§€ì›ìì˜ 'ì§„ì§œ' ë§ˆì§€ë§‰ ë‹µë³€ ë³„ë„ ì¶”ì¶œ
            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.USER
            ).order_by(Transcript.order.desc(), Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # ë§ˆì§€ë§‰ AI ë°œí™”ê°€ 10ì´ˆ ì´ë‚´ë¼ë©´ ìŠ¤í‚µ (Race Condition ë°©ì§€)
            if last_ai_transcript:
                diff = (datetime.utcnow() - last_ai_transcript.timestamp).total_seconds()
                if diff < 10:
                    logger.info(f"Skipping duplicate request for interview {interview_id}")
                    return {"status": "skipped"}

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ê¼¬ë¦¬ì§ˆë¬¸(followup) ìƒì„± ì œí•œ ë¡œì§
            # ë‹¤ìŒ ë‹¨ê³„ê°€ followupì¸ë°, ë§ˆì§€ë§‰ ë°œí™”ìê°€ ì—¬ì „íˆ AIë¼ë©´ ì§€ì›ìê°€ ì•„ì§ ë‹µë³€ì„ ì•ˆ í•œ ê²ƒì„.
            if next_stage.get("type") == "followup":
                if last_transcript and last_transcript.speaker == "AI":
                    logger.info(f"Next stage is followup, but WAITING for user answer. Skipping generation.")
                    return {"status": "waiting_for_user"}

            # [ì¤‘ë³µ ë°©ì§€ ê°œì„ ] next_stageê°€ ì´ë¯¸ ìƒì„±ëëŠ”ì§€ í™•ì¸ (timestamp ê¸°ë°˜ X â†’ stage ê¸°ë°˜ O)
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    diff = (datetime.utcnow() - last_ai_transcript.timestamp).total_seconds()
                    if diff < 30:
                        logger.info(f"Next stage '{next_stage['stage']}' already generated {diff:.1f}s ago, skipping duplicate")
                        return {"status": "skipped"}

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                candidate_name = "ì§€ì›ì"
                target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
                course_name = "ê´€ë ¨ í”„ë¡œì íŠ¸"
                cert_name = "ê´€ë ¨ ìê²©"

                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str):
                        sd = json.loads(sd)
                    
                    candidate_name = sd.get("header", {}).get("name") or sd.get("header", {}).get("candidate_name") or "ì§€ì›ì"
                    target_role = sd.get("header", {}).get("target_role") or target_role
                    
                    # 1. ì§€ì› ì§ë¬´ì™€ ê´€ë ¨ëœ í•µì‹¬ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ë¶€ì—¬ìš©)
                    priority_keywords = ["ë°ì´í„°", "ë¶„ì„", "RAG", "AI", "í´ë¼ìš°ë“œ", "ì´ì»¤ë¨¸ìŠ¤", "ì‹œìŠ¤í…œ", "ì˜ˆì¸¡", "ëª¨ë¸ë§", "SQL", "ë³´ì•ˆ","ì •ë³´",'ì»´í“¨í„°']
                    # 2. ì œì™¸í•´ì•¼ í•  ë‹¨ì–´ (ê°€ì´ë“œ ë¬¸êµ¬ë‚˜ ë¬´ê´€í•œ ë°ì´í„°)
                    blacklist = ["ê³¼ì •ëª…", "ë‚´ìš©", "ìƒì„¸ ë‚´ìš©", "ìƒì„¸ë‚´ìš©", "ì œëª©", "ê¸°ê°„", "ìê²©ì¦ëª…", "ìš´ì „ë©´í—ˆ"]

                    # í”„ë¡œì íŠ¸ ì „ë¬¸ ë°ì´í„°ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                    projects = sd.get("projects", [])
                    found_project = None
                    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í”„ë¡œì íŠ¸ ë¨¼ì € ì°¾ê¸°
                    for p in projects:
                        title = p.get("title") or p.get("name") or ""
                        if any(kw in title for kw in priority_keywords) and not any(bl in title for bl in blacklist):
                            found_project = title
                            break
                    # ëª» ì°¾ì•˜ë‹¤ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ë§Œ í”¼í•´ì„œ ì°¾ê¸°
                    if not found_project:
                        for p in projects:
                            title = p.get("title") or p.get("name") or ""
                            if title and not any(bl in title for bl in blacklist):
                                found_project = title
                                break
                    if found_project: course_name = found_project
                    
                    # ìê²©ì¦ ì „ë¬¸ ë°ì´í„°ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                    certs = sd.get("certifications", [])
                    found_cert = None
                    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ìê²©ì¦ ì°¾ê¸°
                    for c in certs:
                        title = c.get("title") or c.get("name") or ""
                        if any(kw in title for kw in priority_keywords) and not any(bl in title for bl in blacklist):
                            found_cert = title
                            break
                    # ëª» ì°¾ì•˜ë‹¤ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸(ìš´ì „ë©´í—ˆ ë“±) í”¼í•´ì„œ ì°¾ê¸°
                    if not found_cert:
                        for c in certs:
                            title = c.get("title") or c.get("name") or ""
                            if title and not any(bl in title for bl in blacklist):
                                found_cert = title
                                break
                    if found_cert: cert_name = found_cert

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "major": major or "ë³´ê´€ ì „ê³µ",
                    "course_name": course_name,
                    "cert_name": cert_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except KeyError:
                    # í•„ìš”í•œ í‚¤ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ ì¥ì¹˜
                    formatted = tpl.replace("{candidate_name}", candidate_name).replace("{course_name}", course_name).replace("{cert_name}", cert_name)

                intro_msg = next_stage.get("intro_sentence", "")
                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"Template stage '{next_stage['stage']}' (v2) â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ (Direct Extraction)")

            else:
                # [ë¡œì§ ë‹¨ìˆœí™˜] ê¼¬ë¦¬ì§ˆë¬¸ê³¼ ì¼ë°˜ ì§ˆë¬¸ì˜ ì»¨í…ìŠ¤íŠ¸ ë¶„ë¦¬
                if next_stage.get("type") == "followup":
                    # ê¼¬ë¦¬ì§ˆë¬¸: RAG/ì§ˆë¬¸ì€í–‰ ëª¨ë‘ ìŠ¤í‚µí•˜ê³  ì˜¤ì§ 'ì§ˆë¬¸-ë‹µë³€' ë§¥ë½ë§Œ ì‚¬ìš© (í™˜ê° 0%)
                    logger.info("ğŸ¯ Follow-up mode: RAG & Question Bank disabled. Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                else:
                    # ì¼ë°˜ AI ì§ˆë¬¸ (ê²½í—˜/ë¬¸ì œí•´ê²° ë“±): ì´ë ¥ì„œ RAG ê²€ìƒ‰ ìˆ˜í–‰
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(
                            target_role=interview.position or "í•´ë‹¹ ì§ë¬´",
                            major=major or ""
                        )
                    except (KeyError, ValueError):
                        query = query_template

                    category_raw = next_stage.get("category")
                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        sd = interview.resume.structured_data
                        if isinstance(sd, str): sd = json.loads(sd)
                        certs = sd.get("certifications", [])
                        important_certs = [c for c in certs if any(kw in c.get('title', '') for kw in ["ë°ì´í„°", "ë¶„ì„", "RAG", "AI", "í´ë¼ìš°ë“œ", "SQL", "ADSP", "ì •ë³´ì²˜ë¦¬"])]
                        final_certs = important_certs if important_certs else certs
                        if final_certs:
                            logger.info(f"âœ… RAG ê±´ë„ˆëœ€ (êµ¬ì¡°í™” ë°ì´í„° í™œìš©)")
                            context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + "\n".join([f"- {c.get('title')}" for c in final_certs])
                            rag_results = [{'text': f"ìê²©ëª…: {final_certs[0].get('title')}"}]
                        else:
                            rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3)
                            context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                    else:
                        filter_type = None
                        if category_raw == "certification": filter_type = "certifications"
                        rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3, filter_type=filter_type)
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "guide": next_stage.get('guide', '')
                })

                # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì¡°í•© (3ë²ˆ ì§ˆë¬¸ ì „ìš© ë¡œì§ í¬í•¨)
                candidate_name = "ì§€ì›ì"
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    candidate_name = sd.get("header", {}).get("name", "ì§€ì›ì")

                intro_tpl = next_stage.get("intro_sentence", "")
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    # RAG ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ìê²©ì¦ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        # "[ìê²©ì¦] ìê²©ëª…: XXX" í˜•íƒœì—ì„œ ì´ë¦„ ì¶”ì¶œ
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                else:
                    intro_msg = ""

                if next_stage.get("type") == "followup":
                    intro_msg = "ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìŠµë‹ˆë‹¤."
                
                display_name = next_stage.get("display_name", "ì‹¬ì¸µ ë©´ì ‘")
                final_content = f"[{display_name}] {intro_msg} {final_content}".strip() if intro_msg else f"[{display_name}] {final_content}".strip()

            # 6. DB ì €ì¥ (Question ë° Transcript)

            # 6. DB ì €ì¥ (Question ë° Transcript)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 7. ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 8. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±°
            if q_id:
                logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                synthesize_task.delay(final_content, language="auto", question_id=q_id)

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry ì‹œë„): {e}")
        raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()