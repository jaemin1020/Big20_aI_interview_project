import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime, timezone
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

def is_meaningless(text: str) -> bool:
    """ì§€ì›ìì˜ ë‹µë³€ì´ ë¬´ì˜ë¯¸í•œì§€(ììŒ ë‚˜ì—´, ë„ˆë¬´ ì§§ìŒ ë“±) ì²´í¬í•©ë‹ˆë‹¤."""
    if not text: return True
    text = text.strip()
    # 1. ë„ˆë¬´ ì§§ìŒ (5ì ë¯¸ë§Œ)
    if len(text) < 5: return True
    # 2. ììŒ/ëª¨ìŒë§Œ ë‚˜ì—´ (ã„´ã…‡ã„¹ã„´ã…‡ã„¹, ã…‹ã…‹ã…‹ã…‹ ë“±)
    if re.fullmatch(r'[ã„±-ã…ã…-ã…£\s]+', text): return True
    # 3. ë‹¨ìˆœ íŠ¹ìˆ˜ë¬¸ì/ìˆ«ì ë°˜ë³µ (...., 123123 ë“±)
    if re.fullmatch(r'[\.\,\!\?\-\=\s\d]+', text): return True
    # 4. ì˜ì–´ ëœë¤ ë¬¸ìì—´ (asdf, qwer ë“±)
    if re.fullmatch(r'[a-zA-Z]{1,5}', text): return True
    return False

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================
PROMPT_TEMPLATE = """[|user|]ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì§€ì‹ê³¼ ê³µì •í•œ íƒœë„ë¥¼ ê²¸ë¹„í•œ ë² í…Œë‘ AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì§€ì›ìì˜ ì ì¬ë ¥ì„ ì˜ˆë¦¬í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” **ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.

### [ë©´ì ‘ ì „ëµ ë° í˜ë¥´ì†Œë‚˜]
- í‰ê°€ ëŒ€ìƒ ì§ë¬´: {target_role}
- í•µì‹¬ ì¸ì¬ìƒ: {company_ideal}
- ë©´ì ‘ ë‹¨ê³„: {stage_name} ({guide})

### [ì°¸ê³  ë¬¸ë§¥: ì§€ì›ì ì •ë³´ ë° ì´ì „ ë‹µë³€]
{context}

### [ì‹¤ì‹œê°„ í•µì‹¬ ì„ë¬´]
- ìˆ˜í–‰ ê³¼ì—…: {mode_task_instruction}
- ì‹¤í–‰ ìƒì„¸: {mode_instruction}
- ì „ì—­ ì œì•½: {global_constraint}

### [ì¶œë ¥ ê·œì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜]
1. ì¸ì‚¬ë§, ë¶€ì—° ì„¤ëª…, ìê¸°ì†Œê°œ, ê°€ì„¤ ì œì‹œë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. "ì§ˆë¬¸ì…ë‹ˆë‹¤", "ë‹¤ìŒ ì§ˆë¬¸ì€" ë“± ì„œë‘ë¥¼ ì¼ì ˆ ë¶™ì´ì§€ ë§ˆì‹­ì‹œì˜¤.
3. ì˜¤ì§ ì§€ì›ìì—ê²Œ ì§ì ‘ ë˜ì§€ëŠ” **ë¬¼ìŒí‘œ(?)ë¡œ ëë‚˜ëŠ” ë‹¨ì¼ ë¬¸ì¥ì˜ ì§ˆë¬¸**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. ì „ë¬¸ì ì¸ í•œêµ­ì–´ êµ¬ì–´ì²´(í•˜ì‹­ì‹œì˜¤ì²´)ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ëª¨ë¸ ì‚¬ì „ ë¡œë”© ë° ë©”ì¸ ì‘ì—…
# ==========================================

@shared_task(name="tasks.question_generation.preload_model")
def preload_model_task():
    """
    EXAONE ëª¨ë¸ì„ ë¹„ë™ê¸°ë¡œ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤. (ë©´ì ‘ ì‹œì‘ ì‹œ í˜¸ì¶œ)
    """
    from utils.exaone_llm import get_exaone_llm
    try:
        logger.info("ğŸ”¥ [Preload] Starting EXAONE model preloading...")
        get_exaone_llm() # ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ëª¨ë¸ ë¡œë“œë¨
        logger.info("âœ… [Preload] EXAONE model preloaded inside Celery worker.")
        return {"status": "success", "message": "Model preloaded"}
    except Exception as e:
        logger.error(f"âŒ [Preload] Failed to preload model: {e}")
        return {"status": "error", "message": str(e)}

@shared_task(bind=True, name="tasks.question_generation.generate_next_question")
def generate_next_question_task(self, interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question, Company, get_kst_now
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ ë° Stage íŒë³„
            # [ìˆ˜ì •] ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ (Order í•„ë“œ ëŒ€ì‹  ID/ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •í•©ì„± í™•ë³´)
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.id.desc())
            last_transcript = session.exec(stmt_all).first()

            # ë§ˆì§€ë§‰ AI ë°œí™” ê°€ì ¸ì˜¤ê¸°
            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.id.desc())
            last_ai_transcript = session.exec(stmt_ai).first()

            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë°œí™” ê°€ì ¸ì˜¤ê¸° (ë‹¨, ì•„ì£¼ ì§§ì€ ë…¸ì´ì¦ˆëŠ” ë¬´ì‹œí•˜ë˜ 1ì ì´ìƒì´ë©´ ë‹µë³€ìœ¼ë¡œ ì¸ì •)
            from sqlalchemy import func
            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker != Speaker.AI,
                func.length(Transcript.text) >= 1  # 1ì ì´ìƒì´ë©´ ì‹¤ì œ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼
            ).order_by(Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # ë§Œì•½ ìœ„ì—ì„œ ëª»ì°¾ì•˜ë‹¤ë©´ ì§„ì§œ ë§ˆì§€ë§‰ ë°œí™”ë¼ë„ ê°€ì ¸ì˜´ (ëŒ€ê¸° ë¡œì§ìš©)
            if not last_user_transcript:
                stmt_user_any = select(Transcript).where(
                    Transcript.interview_id == interview_id,
                    Transcript.speaker != Speaker.AI
                ).order_by(Transcript.id.desc())
                last_user_transcript = session.exec(stmt_user_any).first()

            # [ì‚­ì œ] 10ì´ˆ ì´ë‚´ ìŠ¤í‚µ ë¡œì§ (Race Condition ë°©ì§€ ëª©ì ì´ì—ˆìœ¼ë‚˜ ì´ˆê¸° í…œí”Œë¦¿ ë¡œë“œ ì‹œ ë°©í•´ë¨)

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
                
                # [ë³µêµ¬ ë¡œì§] ë§Œì•½ ë§ˆì§€ë§‰ ìŠ¤í…Œì´ì§€ê°€ 'fallback' ì´ë¼ë©´, ê·¸ ì´ì „ì˜ ì •ìƒì ì¸ ìŠ¤í…Œì´ì§€ë¥¼ ì°¾ì•„ì•¼ í•¨
                if last_stage_name == "fallback":
                    logger.warning(f"âš ï¸ Last stage was 'fallback'. Searching for previous valid stage for Interview {interview_id}.")
                    stmt_ai_prev = select(Transcript).where(
                        Transcript.interview_id == interview_id,
                        Transcript.speaker == Speaker.AI,
                        Transcript.id < last_ai_transcript.id
                    ).order_by(Transcript.id.desc())
                    prev_ai = session.exec(stmt_ai_prev).first()
                    if prev_ai and prev_ai.question_id:
                        prev_q = session.get(Question, prev_ai.question_id)
                        if prev_q and prev_q.question_type and prev_q.question_type != "fallback":
                            last_stage_name = prev_q.question_type
                            logger.info(f"ğŸ”„ Recovered stage from fallback: {last_stage_name}")
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ë™ê¸°í™” ë° ìŠ¤í…Œì´ì§€ ìŠ¤í‚µ ë°©ì§€ ë¡œì§ ê°•í™”
            if last_ai_transcript and last_user_transcript:
                # 1. ë§Œì•½ ë§ˆì§€ë§‰ AI ì§ˆë¬¸ì´ ë°©ê¸ˆ ì „(3ì´ˆ ì´ë‚´)ì— ë˜ì ¸ì¡Œë‹¤ë©´, ì‚¬ìš©ì ë‹µë³€ì´ ì¶©ë¶„íˆ ê¸¸ì§€ ì•Šì€ ì´ìƒ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
                #    (ìŒì„± ì¸ì‹ ì§€ì—°/ì§€í„°ë¡œ ì¸í•´ ì´ì „ ë‹µë³€ì´ ìƒˆ ì§ˆë¬¸ IDì— ê½‚íˆëŠ” í˜„ìƒ ë°©ì§€)
                time_since_ai = (get_kst_now() - last_ai_transcript.timestamp.replace(tzinfo=None)).total_seconds()
                is_short_answer = len(last_user_transcript.text.strip()) < 10
                
                if time_since_ai < 3.0 and is_short_answer:
                    logger.info(f"AI just spoke {time_since_ai:.1f}s ago. Current user answer is short ('{last_user_transcript.text}'). Waiting for a real answer.")
                    return {"status": "waiting_for_user_to_catch_up"}

                # 2. ë§ˆì§€ë§‰ AI ë°œí™”ê°€ ì•„ì§ ì‚¬ìš©ì ë‹µë³€ì— ì˜í•´ ì°¸ì¡°ë˜ì§€ ì•Šì•˜ë‹¤ë©´? (ì¦‰, ì•„ì§ ë‹µí•˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´)
                if last_user_transcript.question_id != last_ai_transcript.question_id:
                    logger.info(f"AI has already spoken up to stage '{last_stage_name}', but user just answered a previous question. Waiting for user to answer current question.")
                    return {"status": "waiting_for_user_to_catch_up"}

            # [ìˆ˜ì •] ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°œì„ : ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì •ë³´ë¥¼ í•¨ê»˜ ë¦¬í„´
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    logger.info(f"Next stage '{next_stage['stage']}' already exists. Re-triggering TTS/Broadcast.")
                    # TTS ë‹¤ì‹œ í•œ ë²ˆ ì°”ëŸ¬ì¤Œ (ì´ë¯¸ ìˆìœ¼ë©´ 1ì´ˆë„ ì•ˆ ê±¸ë¦¼)
                    synthesize_task.delay(last_ai_transcript.text, language="auto", question_id=last_ai_transcript.question_id)
                    return {
                        "status": "success", 
                        "stage": next_stage['stage'], 
                        "question": last_ai_transcript.text,
                        "question_id": last_ai_transcript.question_id
                    }
            # [ìˆ˜ì •] ê³µí†µ ì •ë³´ ì¶”ì¶œ (í…œí”Œë¦¿/AI/ê¼¬ë¦¬ì§ˆë¬¸ ëª¨ë‘ ì‚¬ìš©)
            candidate_name = "ì§€ì›ì"
            target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
            company_name = "ì €í¬ íšŒì‚¬"
            company_ideal = "ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ ì„ í†µí•´ ì‚¬ìš©ìì˜ ì„¸ê³„ë¥¼ í™•ì¥í•˜ê³ , ìƒˆë¡œìš´ ê´€ì ê³¼ ì•„ì´ë””ì–´ë¡œ ì„¸ìƒì„ í’ìš”ë¡­ê²Œ í•˜ëŠ” ì¸ì¬" # ê¸°ë³¸ê°’

            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str): sd = json.loads(sd)
                header = sd.get("header", {})
                candidate_name = header.get("name") or header.get("candidate_name") or candidate_name
                target_role = header.get("target_role") or target_role
                company_name = header.get("target_company") or header.get("company") or company_name

            # DBì—ì„œ íšŒì‚¬ì˜ ì¸ì¬ìƒ(ideal) ì¡°íšŒ
            db_company = None
            if interview.company_id:
                db_company = session.get(Company, interview.company_id)
            if not db_company and company_name != "ì €í¬ íšŒì‚¬":
                stmt_co = select(Company).where(Company.company_name == company_name)
                db_company = session.exec(stmt_co).first()
            
            if db_company and db_company.ideal:
                company_ideal = db_company.ideal
                logger.info(f"ğŸ¢ Dynamic Talent Image Loaded: {company_ideal[:30]}...")

            # [ê³µí†µ] ì¹´í…Œê³ ë¦¬ ë° DB ë³€ìˆ˜ ì„ ì–¸ (NameError ë°©ì§€)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                cert_list = ""
                act_org, act_role = "ê´€ë ¨ ê¸°ê´€", "ë‹´ë‹¹ ì—…ë¬´"
                proj_org, proj_name = "í•´ë‹¹ ê¸°ê´€", "ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸"
                
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    # 1. ìê²©ì¦ ë¦¬ìŠ¤íŠ¸ì—…
                    certs = sd.get("certifications", [])
                    if certs:
                        cert_names = [c.get("title") or c.get("name") for c in certs if (c.get("title") or c.get("name"))]
                        cert_list = ", ".join(cert_names)
                    
                    # 4-1. ê²½ë ¥ (activities)
                    acts = sd.get("activities", [])
                    act_header_kws = ["ê¸°ê°„", "ì—­í• ", "ê¸°ê´€", "ì†Œì†", "ì¥ì†Œ", "ì œëª©", "ë‚´ìš©"]
                    for act in acts:
                        tmp_org = act.get("organization") or act.get("name") or ""
                        tmp_role = act.get("role") or act.get("position") or ""
                        if not any(kw in tmp_org for kw in act_header_kws) and not any(kw in tmp_role for kw in act_header_kws):
                            act_org = tmp_org or act_org
                            act_role = tmp_role or act_role
                            break
                    
                    # 4-2. í”„ë¡œì íŠ¸ (projects)
                    projs = sd.get("projects", [])
                    proj_header_kws = ["ê¸°ê°„", "ì œëª©", "ê³¼ì •ëª…", "ê¸°ê´€", "ì„¤ëª…", "ë‚´ìš©"]
                    for proj in projs:
                        tmp_name = proj.get("title") or proj.get("name") or ""
                        tmp_org = proj.get("organization") or ""
                        if not any(kw in tmp_name for kw in proj_header_kws) and not any(kw in tmp_org for kw in proj_header_kws):
                            proj_name = tmp_name or proj_name
                            proj_org = tmp_org or proj_org
                            break
                
                if not cert_list: cert_list = "ê´€ë ¨ ìê²©"

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "company_name": company_name,
                    "company_ideal": company_ideal,
                    "major": major or "í•´ë‹¹ ì „ê³µ",
                    "cert_list": cert_list,
                    "act_org": act_org,
                    "act_role": act_role,
                    "proj_org": proj_org,
                    "proj_name": proj_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except Exception as e:
                    logger.warning(f"Template formatting error: {e}")
                    for k, v in template_vars.items():
                        tpl = tpl.replace("{" + k + "}", str(v))
                    formatted = tpl

                intro_msg = next_stage.get("intro_sentence", "")
                final_content = f"{intro_msg} {formatted}".strip() if intro_msg else formatted
                # [ì¤‘ìš”] í…œí”Œë¦¿ ìŠ¤í…Œì´ì§€ì—ì„œë„ scë¥¼ ì •ì˜í•´ë‘ì–´ì•¼ ì•„ë˜ ì •ì œ ë¡œì§ì—ì„œ ì°¸ì¡° ì˜¤ë¥˜ê°€ ì•ˆ ë‚¨
                sc = final_content.strip()
                logger.info(f"Template stage '{next_stage['stage']}' â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ")

            else:
                # category_rawëŠ” ìœ„ì—ì„œ ê³µí†µìœ¼ë¡œ ì •ì˜ë¨
                
                # [í•µì‹¬ ìˆ˜ì •] narrative ì¹´í…Œê³ ë¦¬(9-14ë²ˆ)ëŠ” ì´ë ¥ì„œ RAGë¥¼ ê±´ë„ˆë›°ê³  ì¸ì¬ìƒì—ë§Œ ì§‘ì¤‘
                if next_stage.get("type") == "followup":
                    logger.info("ğŸ¯ Follow-up mode: Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                elif category_raw == "narrative":
                    if next_stage.get("stage") == "responsibility":
                        # [íŠ¹ìƒí™œìš©] 11ë²ˆ ì±…ì„ê°/ê°€ì¹˜ê´€ ì§ˆë¬¸ì€ ì´ë ¥ì„œ(ìê¸°ì†Œê°œì„œ) ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                        logger.info("âœ¨ Responsibility Stage (11): Prioritizing Self-Intro Question 1 for values.")
                        
                        # 1. êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ [ì§ˆë¬¸1] ì •ë°€ íƒìƒ‰
                        values_text = ""
                        try:
                            if interview.resume and interview.resume.structured_data:
                                s_data = interview.resume.structured_data
                                if isinstance(s_data, str): s_data = json.loads(s_data)
                                
                                self_intro_list = s_data.get("self_intro", [])
                                for item in self_intro_list:
                                    q_text = item.get("question", "")
                                    # [ê°œì„ ] ë”ìš± ìœ ì—°í•˜ê²Œ ì§ˆë¬¸1 íƒìƒ‰ (ì¸ë±ìŠ¤ ë˜ëŠ” í‚¤ì›Œë“œ)
                                    if "[ì§ˆë¬¸1]" in q_text or "ì§ˆë¬¸ 1" in q_text or q_text.startswith("1."):
                                        ans = item.get('answer', '')
                                        if len(ans) > 20: # ìµœì†Œí•œì˜ ìœ ì˜ë¯¸í•œ ê¸¸ì´
                                            values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ì§ˆë¬¸1 ë‹µë³€]: {ans}"
                                            logger.info("ğŸ“ Found Question 1 in Self-Intro.")
                                            break
                                
                                # ë§Œì•½ ì§ˆë¬¸ 1ì„ ëª»ì°¾ì•˜ë‹¤ë©´, ì „ì²´ ìì†Œì„œì—ì„œ ê°€ì¹˜ê´€ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ì¶”ì¶œ (fallback)
                                if not values_text and self_intro_list:
                                    all_answers = " ".join([i.get("answer", "") for i in self_intro_list if i.get("answer")])
                                    values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ìš”ì•½]: {all_answers[:300]}" # ì•ë¶€ë¶„ 300ìë¼ë„ ì œê³µ
                        except Exception as e:
                            logger.error(f"Failed to extract self_intro values: {e}")

                        # 2. RAG ê²°ê³¼ì™€ ê²°í•©
                        rag_results = retrieve_context("ì§€ì›ìì˜ ê·¼ë³¸ì ì¸ ê°€ì¹˜ê´€, ìƒí™œ ì‹ ë…, ì§ì—… ìœ¤ë¦¬, ì •ì§í•¨", resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = f"{values_text}\n\n[ì¶”ê°€ ì°¸ê³  ì •ë³´]:\n{rag_context}".strip()
                        if not context_text: context_text = "íŠ¹ë³„í•œ ê°€ì¹˜ê´€ ì •ë³´ ì—†ìŒ"
                    else:
                        # [ê°œì„ ] 9-14ë²ˆ ì¸ì„± ë©´ì ‘: ê° ì—­ëŸ‰(í˜‘ì—…, ì„±ì¥, ì±…ì„ê°)ì— íŠ¹í™”ëœ RAG ìˆ˜í–‰
                        s_name = next_stage.get('stage', '')
                        behavioral_keywords = {
                            "communication": "í˜‘ì—… ì‚¬ë¡€, íŒ€ í”„ë¡œì íŠ¸ ì¤‘ ê°ˆë“± ì¡°ìœ¨, íŒ€ì›Œí¬ ë°œíœ˜, ì†Œí†µ ëŠ¥ë ¥",
                            "growth": "ìê¸°ê³„ë°œ ë…¸ë ¥, ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµ íƒœë„, ì‹¤íŒ¨ ê·¹ë³µ ë° ì„±ì¥ ì‚¬ë¡€",
                            "responsibility": "ì§ì—… ìœ¤ë¦¬, ì•½ì† ì´í–‰, ì •ì§í•¨ê³¼ ê´€ë ¨ëœ ê²½í—˜"
                        }
                        # í•´ë‹¹ ë‹¨ê³„ì— ë§ëŠ” ì¿¼ë¦¬ ì„ íƒ (ì—†ìœ¼ë©´ ê¸°ë³¸ ê°€ì¹˜ê´€ ê²½í—˜ ê²€ìƒ‰)
                        target_query = behavioral_keywords.get(s_name, "ë³¸ì¸ì˜ ê°•ì , ì„±ì·¨ê°, ë„ì „ì ì¸ ê²½í—˜ ì‚¬ë¡€")
                        
                        logger.info(f"âœ¨ Behavioral RAG ({s_name}): Searching for '{target_query}'")
                        rag_results = retrieve_context(target_query, resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = (
                            f"ì´ ë‹¨ê³„ëŠ” {next_stage['display_name']}ë¥¼ í™•ì¸í•˜ëŠ” ì¸ì„± ë©´ì ‘ì…ë‹ˆë‹¤.\n"
                            f"ì§€ì›ìì˜ ê¸°ìˆ ë ¥ ê²€ì¦ë³´ë‹¤ëŠ” **íƒœë„, ê°€ì¹˜ê´€, ì¡°ì§ ì ì‘ë ¥**ì„ íŒŒì•…í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤.\n"
                            f"ì•„ë˜ [ì§€ì›ì ê²½í—˜ ì •ë³´]ë¥¼ 'ë°°ê²½'ìœ¼ë¡œ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.\n\n"
                            f"[ì§€ì›ì ê²½í—˜ ì •ë³´]:\n{rag_context}"
                        )
                else:
                    # ì¼ë°˜ ê¸°ìˆ /ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸ (4, 5, 8ë²ˆ ë“± ìƒˆë¡œìš´ ì£¼ì œ ì‹œì‘ ì‹œ)
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(target_role=target_role, major=major or "")
                    except:
                        query = query_template

                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        # êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ìê²©ì¦ ì¶”ì¶œ ë¡œì§ (ìƒëµ ë°©ì§€ë¥¼ ìœ„í•œ ìœ ì§€)
                        context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + cert_list
                        rag_results = [{'text': f"ë³´ìœ  ìê²©: {cert_list}"}]
                    else:
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        # [ì „ëµ 4] ë¬´ì˜ë¯¸í•œ ë‹µë³€ì¼ ê²½ìš° ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚­ì œí•˜ì—¬ í™˜ê° ë°©ì–´
                        if is_meaningless(last_user_transcript.text):
                             context_text = "[ì£¼ì˜: ì§€ì›ìì˜ ì´ì „ ë‹µë³€ì´ ë¬´ì˜ë¯¸í•˜ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ê³¼ê±° ì •ë³´ì— ì˜ì¡´í•˜ì§€ ë§ê³  ë‹¤ì‹œ ë¬¼ì–´ë³´ì‹­ì‹œì˜¤.]"
                             logger.warning("ğŸš« Meaningless input detected! Isolating context to prevent hallucination.")
                        
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    else:
                        context_text += "\n[ì§€ì›ìì˜ ì‘ë‹µ ì •ë³´ê°€ ì•„ì§ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.]"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                # ê°€ì´ë“œ ë‚´ ë³€ìˆ˜ ì¹˜í™˜
                guide_raw = next_stage.get('guide', '')
                try:
                    guide_formatted = guide_raw.format(company_ideal=company_ideal)
                except:
                    guide_formatted = guide_raw

                # [ì¶”ê°€] ë‹¨ê³„ë³„ ë§ì¶¤í˜• ì „ëµ ì§€ì¹¨ ê²°ì • (ì§€ì›ìë‹˜ ìš”ì²­ ë°˜ì˜)
                mode_instruction = "ì¼ë°˜ì ì¸ ë‹¨ì¼ ì§ˆë¬¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤."
                mode_task_instruction = "ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì˜ˆë¦¬í•œ ê¼¬ë¦¬ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤. ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ ë‚´ìš©ì—ì„œ êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ë…¼ë¦¬ì  í—ˆì ì„ ì°Œë¥´ëŠ” ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤." # ê¸°ë³¸ê°’
                global_constraint = "ì˜¤ì§ ì§ˆë¬¸ë§Œì„ ìƒì„±í•˜ê³ , ê¸°ìˆ  ìŠ¤íƒê³¼ ìˆ˜ì¹˜ë¥¼ ì ì ˆíˆ ì¸ìš©í•˜ì‹­ì‹œì˜¤." # ê¸°ë³¸ ê¸°ìˆ  ì§€ì¹¨
                
                s_name = next_stage.get('stage', '')
                s_type = next_stage.get('type', '')
                
                # ì¸ì„± ë©´ì ‘ ë‹¨ê³„(9~14) ì—¬ë¶€ í™•ì¸
                is_narrative = (next_stage.get('category') == 'narrative') or (s_name in ['communication', 'communication_followup', 'responsibility', 'responsibility_followup', 'growth', 'growth_followup'])

                if is_narrative:
                    global_constraint = "ì¸ì„± ë‹¨ê³„ì…ë‹ˆë‹¤. **ì½”ë“œ, ì„¤ê³„, ê°œë°œê³¼ ê°™ì€ ì§ë¬´ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³ **, íƒœë„ì™€ ê°€ì¹˜ê´€ì„ ì¸ìš©í•˜ì—¬ ì§§ê²Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤."
                
                if s_name == 'problem_solving':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 7ë²ˆ(ë¬¸ì œí•´ê²°ì§ˆë¬¸)ì…ë‹ˆë‹¤. ì§ˆë¬¸ ê³¼ì •ì—ì„œ 'ê·¸ëŸ°ë°' í˜¹ì€ 'ê·¸ë ‡ë‹¤ë©´'ê³¼ ê°™ì€ ì ‘ì†ì‚¬ë¥¼ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ìƒí™©ì„ ì œì‹œí•˜ë˜, ë°˜ë“œì‹œ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility':
                    # 11ë²ˆ ê°€ì¹˜ê´€ ì§ˆë¬¸: ê¸°ìˆ  ì¤‘ì‹¬ ì¸ìš© ëŒ€ì‹  ê°€ì¹˜ ì¤‘ì‹¬ ì „í™˜ (ì „ì²´ ê¸¸ì´ 30% ì¶•ì†Œ)
                    mode_task_instruction = "ìê¸°ì†Œê°œì„œì—ì„œ ë‚˜íƒ€ë‚œ ì§€ì›ìì˜ í•µì‹¬ ê°€ì¹˜ê´€(ì •ì§, ì±…ì„ê° ë“±)ì„ íŒŒì•…í•˜ì—¬ ì¸ì¬ìƒê³¼ ì—°ê²°í•˜ì‹­ì‹œì˜¤. ì„œë¹„ìŠ¤ ì„¤ê³„ë‚˜ ì½”ë“œ ê°™ì€ ê¸°ìˆ  ë‚´ìš©ì€ ì¼ì ˆ ì–¸ê¸‰í•˜ì§€ ë§ê³  ì˜¤ì§ ì¸ì„±ì ì¸ ë©´ëª¨ë¥¼ 80ì ì´ë‚´ë¡œ ë¬¼ìœ¼ì‹­ì‹œì˜¤."
                    mode_instruction = "ì´ì „ ë‹µë³€ ìš”ì•½ì„ ìƒëµí•˜ê³ , 'ìê¸°ì†Œê°œì„œì—ì„œ ~í•œ ê°€ì¹˜ê´€ì´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´...'ê³¼ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì‹­ì‹œì˜¤. 30% ë” ì§§ê²Œ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility_followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 12ë²ˆ(ê°€ì¹˜ê´€ ì‹¬ì¸µ)ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì•„ì£¼ ì§§ê²Œ ìš”ì•½í•˜ê³ , ê³§ë°”ë¡œ ê°€ì¹˜ê´€ì— ëŒ€í•œ ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ë˜ì§€ì‹­ì‹œì˜¤. 60ì ì´ë‚´ë¡œ êµ¬ì„±í•˜ì‹­ì‹œì˜¤."
                elif s_name in ['communication', 'growth']:
                    # 9ë²ˆ, 13ë²ˆ ì¸ì„± ì§ˆë¬¸: íƒœë„ ê°•ì¡° ë° ê¸¸ì´ ì¶•ì†Œ
                    mode_task_instruction = "ì¸ì¬ìƒê³¼ ì´ë ¥ì„œë¥¼ ê²°í•©í•˜ë˜, ê¸°ìˆ ì  ì„±ì·¨ê°€ ì›ì¸ì´ ì•„ë‹Œ 'í˜‘ì—… íƒœë„'ì™€ 'ì„±ì¥ ì˜ì§€'ê°€ ì§ˆë¬¸ì˜ ì£¼ì¸ê³µì´ ë˜ê²Œ í•˜ì‹­ì‹œì˜¤. ëª¨ë“  ë¬¸ì¥ì€ í˜„ì¬ë³´ë‹¤ 30% ë” ì§§ê³  ê°„ëµí•˜ê²Œ êµ¬ì„±í•˜ì‹­ì‹œì˜¤."
                    mode_instruction = f"ì´ ë‹¨ê³„ëŠ” {s_name} ê²€ì¦ì…ë‹ˆë‹¤. ì½”ë“œ, ê°œë°œ, ìŠ¤íƒ ê°™ì€ ë‹¨ì–´ë¥¼ ë°°ì œí•˜ê³  ëŒ€í™”í•˜ë“¯ ë”± í•˜ë‚˜ì˜ ê°„ê²°í•œ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤."
                elif s_type == 'followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹µë³€ ìš”ì•½ê³¼ ì§ˆë¬¸ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                
                # [ì¶”ê°€] ì§€ì›ìì˜ ë¶€ì •ì  ë‹µë³€ ê°ì§€ ë° íŠ¹ìˆ˜ ì§€ì‹œ (ë¬´ì§€/íšŒí”¼ ëŒ€ì‘)
                if last_user_transcript:
                    u_text = last_user_transcript.text.strip()
                    # "ì‹«ë‹¤", "ëª°ë¼" ë“± í‚¤ì›Œë“œ ë³´ê°•
                    negative_keywords = ["ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ëª¨ë¥´ê² ì–´ìš”", "ì•„ë‹ˆìš”", "ì—†ìŠµë‹ˆë‹¤", "ê¸°ì–µì´ ì•ˆ ë‚¨", "ì˜ ëª¨ë¦„", "ëª°ë¼ìš”", "ëª°ë¼", "ì‹«ì–´", "ì‹«ìŒ", "ì‹«ë‹¤"]
                    
                    # [ì „ëµ 3] ë¬´ì˜ë¯¸í•œ ì…ë ¥ì´ê±°ë‚˜ ëª…ì‹œì  ê±°ì ˆì¼ ë•Œ ì§€ì‹œì–´ ì „í™˜
                    if is_meaningless(u_text) or any(kw in u_text for kw in negative_keywords):
                        mode_task_instruction = "ì§€ì›ìê°€ ë‹µë³€ì„ í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì…ë ¥ì„ í–ˆìŠµë‹ˆë‹¤. ì´ì „ ë‚´ìš©ì— ëŒ€í•œ ìš”ì•½ì´ë‚˜ ì¶”ì¸¡ì„ 100% ìƒëµí•˜ê³ , ì •ì¤‘í•˜ê²Œ ë‹¤ì‹œ ì„¤ëª…ì„ ìš”ì²­í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì£¼ì œë¡œ ì „í™˜í•˜ì‹­ì‹œì˜¤."
                        global_constraint = "ì´ì „ ë‹µë³€ ìš”ì•½ì„ **ì ˆëŒ€** í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë‹µë³€ì„ ì§€ì–´ë‚´ì§€ ë§ê³ , 'ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ë²ˆì—ëŠ”...'ê³¼ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì‹­ì‹œì˜¤."
                        mode_instruction = "í™˜ê°(Hallucination) ì—†ì´ ë‹´ë°±í•˜ê²Œ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê±°ë‚˜ ì¬ì„¤ëª…ì„ ìš”ì²­í•˜ì‹­ì‹œì˜¤."

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "company_ideal": company_ideal,
                    "guide": guide_formatted,
                    "mode_instruction": mode_instruction,
                    "mode_task_instruction": mode_task_instruction,
                    "global_constraint": global_constraint,
                    "target_role": target_role
                })

                # [ì •ì œ ê°€ì†í™” ë° ë¡œì§ ê°•í™”]
                final_content = final_content.strip()
                # ì„œë‘/ë§ë¯¸ ë”°ì˜´í‘œ ì œê±°
                final_content = re.sub(r'^["\'\sâ€œ]+|["\'\sâ€]+$', '', final_content)
                
                # 1. ë©”íƒ€ ì„¤ëª… ë° ê°€ì´ë“œ ë¬¸êµ¬ ê°•ì œ ì‚­ì œ (íŒ¨í„´ ë³´ê°•)
                meta_patterns = [
                    r'(ê·¸ë ‡ë‹¤ë©´|ë”°ë¼ì„œ|ì´ì—|ì œê³µëœ|ë¶„ì„í•˜ì—¬)\s*(ì§€ì›ìì˜|ë‚´ìš©ì„|ë¶€ì¡±í•œ|ë¶€ë¶„ì„|íŒŒì•…í•˜ì—¬|íƒêµ¬í• )\s*.*?(ì œì‹œí•˜ê² ìŠµë‹ˆë‹¤|ë“œë¦¬ê² ìŠµë‹ˆë‹¤|í•˜ê² ìŠµë‹ˆë‹¤|ì§ˆë¬¸ì…ë‹ˆë‹¤)[\.\s]*',
                    r'(ì´\s*ì§ˆë¬¸ì€|ì˜ë„ëŠ”|~ë¼ê³ \s*ë‹µë³€í–ˆë‹¤ë©´|ê²€ì¦í•©ë‹ˆë‹¤|ì˜ë„í•¨|í™•ì¸í•©ë‹ˆë‹¤|ìš”êµ¬í•˜ì—¬).*', 
                    r'ì§€ì›ìê°€\s*.*ë¼ê³ \s*ë§í–ˆë‹¤ë©´.*',
                    r'ìœ„\s*ì§ˆë¬¸ì€\s*.*',
                    r'ë³¸\s*ì§ˆë¬¸ì€\s*.*'
                ]
                for pattern in meta_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE | re.DOTALL)

                # 2. ì„œë‘ ë ˆì´ë¸” ì œê±° (í•œê¸€/ì˜ë¬¸/íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
                label_patterns = [
                    r'^\**ì§€ì›ìì˜?\s*ë‹µë³€\s*ìš”ì•½\s*(ë°\s*ê¼¬ë¦¬ì§ˆë¬¸)?:\**\s*',
                    r'^\**ì‹¬ì¸µ\s*ì§ˆë¬¸:\**\s*',
                    r'^\**í•µì‹¬\s*ìš”ì•½:\**\s*',
                    r'^\**ê¼¬ë¦¬ì§ˆë¬¸:\**\s*',
                    r'^\**ìš”ì•½:\**\s*',
                    r'^\**ì§ˆë¬¸:\**\s*',
                    r'^\**[QA]:\**\s*',
                    r'^\d+\.\s*',
                    r'^-\s*'
                ]
                for pattern in label_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE | re.MULTILINE)

                # 3. [í•µì‹¬] ë§Œì•½ ì—¬ì „íˆ "ìš”ì•½: ... ì§ˆë¬¸: ..." êµ¬ì¡°ë¼ë©´ 'ì§ˆë¬¸:' ì´í›„ë§Œ ì¶”ì¶œ
                if 'ì§ˆë¬¸:' in final_content:
                    final_content = final_content.split('ì§ˆë¬¸:')[-1].strip()
                elif 'ì§ˆë¬¸ :' in final_content:
                    final_content = final_content.split('ì§ˆë¬¸ :')[-1].strip()

                # 3. ë¬¸ì¥ ì¤‘ê°„ì— ì‚½ì…ë˜ëŠ” ì—°ê²° ë ˆì´ë¸” ì œê±°
                bridge_patterns = [
                    r'ì´ì—\s*ëŒ€í•œ\s*ì§ˆë¬¸ì…ë‹ˆë‹¤:?',
                    r'ë‹¤ìŒì€\s*ì§ˆë¬¸ì…ë‹ˆë‹¤:?',
                    r'ì§ˆë¬¸ë“œë¦½ë‹ˆë‹¤:?',
                    r'ì§ˆë¬¸ì€\s*ë‹¤ìŒê³¼\s*ê°™ìŠµë‹ˆë‹¤:?',
                    r'\*\*.*\*\*:\s*' # ë³¼íŠ¸ê°€ í¬í•¨ëœ ëª¨ë“  ë ˆì´ë¸” í˜•íƒœ ì œê±°
                ]
                for pattern in bridge_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE)

                # 4. Markdown ì œëª©(#) ë° ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (## ì œëª©, [ì§ˆë¬¸ë ˆì´ë¸”] ë“±)
                final_content = re.sub(r'#+\s*.*?\n', '\n', final_content) # ## ì œëª© ì œê±°
                final_content = re.sub(r'#+\s*.*$', '', final_content)    # ì¤„ ëì˜ # ì œê±°
                final_content = re.sub(r'\[.*?ì§ˆë¬¸\]', '', final_content)   # [ì„±ì¥ê°€ëŠ¥ì„±ì§ˆë¬¸] ë“± ì œê±°
                
                # 5. [í•µì‹¬] ë§Œì•½ AIê°€ "..." ì²˜ëŸ¼ ë”°ì˜´í‘œ ì•ˆì— ì§ˆë¬¸ì„ ë„£ì—ˆë‹¤ë©´ ê·¸ê²ƒë§Œ ì¶”ì¶œ
                quote_match = re.search(r'["\'â€œ]([^"\'â€]*\?+)["\'â€]', final_content)
                if quote_match:
                    final_content = quote_match.group(1)

                # 5. [ì •ì œ ë¡œì§ ì™„í™”] ë¬¼ìŒí‘œ ìë¥´ê¸°ë¥¼ ì •êµí•˜ê²Œ ìˆ˜í–‰ (ë¬¸ë§¥ ë³´ì¡´)
                # ë‹¨ì¼ ë¬¸ì¥ë§Œ ë‚¨ê¸°ëŠ” ëŒ€ì‹ , ë§ˆì§€ë§‰ ë¬¼ìŒí‘œ ì´í›„ì˜ 'ë¶€ì—° ì„¤ëª…(ê°€ì´ë“œë¼ì¸)'ë§Œ ì œê±°
                # AIê°€ ê°€ë” ë§ëì— "ì´ ì§ˆë¬¸ì€ ~ë¥¼ ì˜ë„í•¨" ë“±ì„ ë¶™ì´ëŠ” ê²ƒ ë°©ì§€
                final_content = final_content.replace("**", "").strip()
                if '?' in final_content:
                    # íŒ¨í„´ ê¸°ë°˜: ì§ˆë¬¸ ì˜ë„ë‚˜ ì„¤ëª…ì´ ì‹œì‘ë˜ëŠ” í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ ì•ê¹Œì§€ë§Œ ìœ ì§€
                    cut_patterns = ["ì´ ì§ˆë¬¸ì€", "ì§ˆë¬¸ì˜ ì˜ë„", "ì˜ë„ëŠ”", "ë‹µë³€ì„ í†µí•´", "í™•ì¸í•˜ê³ ì í•¨", "ê²€ì¦í•˜ê³ ì í•˜ëŠ”"]
                    for pattern in cut_patterns:
                        if pattern in final_content:
                            final_content = final_content.split(pattern)[0].strip()
                    
                    # ë§Œì•½ ë¬¼ìŒí‘œê°€ ìˆê³  ê·¸ ë’¤ì— ì•„ì£¼ ì§§ì€ ë¬¸ì¥(ì„¤ëª…ì¡°)ì´ ë” ìˆë‹¤ë©´ ë§ˆì§€ë§‰ ë¬¼ìŒí‘œê¹Œì§€ë§Œ ìœ ì§€
                    q_last_idx = final_content.rfind('?') + 1
                    if q_last_idx < len(final_content) and len(final_content) - q_last_idx < 30:
                        final_content = final_content[:q_last_idx]

                # [ì™„í™”] ë¬´ì¡°ê±´ì ì¸ ë¬¼ìŒí‘œ 1ê°œ ì œí•œ ëŒ€ì‹ , ë„ˆë¬´ ì—¬ëŸ¬ ê°œ(3ê°œ ì´ìƒ)ì¸ ê²½ìš°ë§Œ ìƒìœ„ 2ê°œë¡œ ì œí•œ
                if final_content.count('?') > 2:
                    logger.warning(f"âš ï¸ Excessive questions detected. Truncating to first two.")
                    q_parts = final_content.split('?')
                    final_content = q_parts[0] + '?' + q_parts[1] + '?'
                
                final_content = final_content.strip()

                intro_tpl = next_stage.get("intro_sentence", "")
                intro_msg = ""
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                
                # Follow-upì€ intro_sentenceë¥¼ ë¬´ì‹œí•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë‚˜ í•„ìš”ì‹œ ê²°í•©
                if next_stage.get("type") == "followup":
                    # íŒ”ë¡œì—…ì€ íë¦„ìƒ ì¸íŠ¸ë¡œë¥¼ ìµœì†Œí™”
                    pass 
                
                final_content = f"{intro_msg} {final_content}".strip() if intro_msg else final_content.strip()
                sc = final_content.strip() if final_content else ""
                if len(sc) < 10:
                    logger.warning(f"âš ï¸ [Empty/Short Question Detected] Stage: {next_stage['stage']}, Content: '{final_content}'")
                    if not sc:
                        s_name = next_stage.get('stage', '')
                        if s_name == 'communication':
                            final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ê°ˆë“±ì„ ì¡°ìœ¨í•˜ì—¬ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                        elif s_name == 'growth':
                            final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                        else:
                            final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"

            # [ì „ì—­ ì •ì œ] ëª¨ë“  ì§ˆë¬¸ íƒ€ì…ì— ëŒ€í•´ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ì œ ìˆ˜í–‰
            final_content = final_content.strip()
            # ì½¤ë§ˆ(,), ë¬¼ìŒí‘œ(?), ë§ˆì¹¨í‘œ(.), ëŠë‚Œí‘œ(!), ê´„í˜¸(()), ë”°ì˜´í‘œ(", '), ë¬¼ê²°(~) ë“±ì„ í—ˆìš©í•˜ë„ë¡ í™•ì¥
            final_content = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£a-zA-Z0-9\s,\?\.\!\(\)\~\"\'\:]', '', final_content)
            
            # [ê°•ë ¥ ì œì•½] ë§Œì•½ ì •ì œ ê³¼ì •ì—ì„œ ë‚´ìš©ì´ ì‚¬ë¼ì¡Œê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° í´ë°±
            # ê³µë°± ì œì™¸ ì‹¤ì§ˆì ì¸ í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            sc = final_content.strip()
            if len(sc) < 15:
                logger.warning(f"âš ï¸ [Short Question Detected] Stage: {next_stage['stage']}, Content: '{final_content}'")
                s_name = next_stage.get('stage', '')
                if s_name == 'skill':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê´€ë ¨ ìê²©ì´ë‚˜ ê¸°ìˆ  ì¤‘ì—ì„œ, ì‹¤ì œ ì—…ë¬´ì— ê°€ì¥ í° ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
                elif s_name == 'experience':
                    final_content = "ì‹¤í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ ì—…ë¬´ ê²½í—˜ ì¤‘ì—ì„œ, ë³¸ì¸ì´ ê°€ì¥ ì£¼ë„ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ì„±ê³¼ë¥¼ ëƒˆë˜ ì‚¬ë¡€ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'experience_followup':
                    final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ê²½í—˜ì„ í†µí•´ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ í¬ê²Œ ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ì‹  ë¶€ë¶„ì€ ë¬´ì—‡ì¸ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
                elif s_name == 'problem_solving':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì–´ë ¤ì›€ì´ ìˆì—ˆì„ ë•Œ, ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì…¨ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                elif s_name == 'problem_solving_followup' or s_name == 'problem_solving_deep':
                    final_content = "ê·¸ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ì…¨ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'communication':
                    final_content = "íŒ€ì›ë“¤ê³¼ ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ì¡°ìœ¨í•˜ì—¬ ì›ë§Œí•˜ê²Œ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'communication_followup':
                    final_content = "ë‹¹ì‹œ ë³¸ì¸ì˜ ì˜ê²¬ì„ ê´€ì² ì‹œí‚¤ê¸°ë³´ë‹¤ëŠ” íŒ€ì˜ ëª©í‘œë¥¼ ìœ„í•´ ì–‘ë³´í•˜ê±°ë‚˜ í˜‘í˜‘í–ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility':
                    final_content = "ì§€ì›ìë‹˜ì˜ ê°€ì¹˜ê´€ê³¼ ì±…ì„ê°ì„ ì—¿ë³¼ ìˆ˜ ìˆëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ ê²½í—˜ í•˜ë‚˜ë¥¼ ì„ ì •í•˜ì—¬ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility_followup':
                    final_content = "ì§€ì›ìë‹˜, ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"
                elif s_name == 'growth':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'growth_followup':
                    final_content = "ì§€ì›ìë‹˜, ë°°ì›€ì˜ ê³¼ì •ì—ì„œ ë³¸ì¸ì˜ ëª©í‘œê°€ ëœ»ëŒ€ë¡œ ë˜ì§€ ì•Šì„ ë•Œ ì´ë¥¼ ê·¹ë³µí•˜ê³  ê¾¸ì¤€íˆ ë‚˜ì•„ê°€ëŠ” ë³¸ì¸ë§Œì˜ ì›ë™ë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'final_statement':
                    final_content = "ì§€ì›ìë‹˜, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¼­ í•˜ê³  ì‹¶ìœ¼ì‹  ë§ì”€ì´ë‚˜ ë³¸ì¸ì„ ì–´í•„í•  ìˆ˜ ìˆëŠ” í•œ ë§ˆë””ê°€ ìˆë‹¤ë©´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                elif next_stage.get("type") == "followup":
                    final_content = "ì§€ì›ìë‹˜ì˜ ë‹µë³€ ë‚´ìš©ì„ ì˜ ë“¤ì–´ë³´ì•˜ìŠµë‹ˆë‹¤. ê·¸ ê³¼ì •ì—ì„œ ê°€ì¥ í° ë°°ì›€ì„ ì–»ê±°ë‚˜ ê¹¨ë‹¬ì•˜ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                else:
                    final_content = "ì§€ì›ìë‹˜ì˜ ì†Œì¤‘í•œ ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „, ë³¸ì¸ì˜ ê°•ì ì— ëŒ€í•´ í•œ ê°€ì§€ë§Œ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
            
            final_content = final_content.strip()
            
            # [ìµœì¢… ë°±ì§€ ë°©ì§€] ë§Œì•½ ì—¬ê¸°ê¹Œì§€ ì™”ëŠ”ë°ë„ ë¹„ì–´ìˆë‹¤ë©´ ê°•ì œ í´ë°± ì ìš© (ì›ì¸ ë¶ˆëª…ì˜ ë¹ˆ ë¬¸ìì—´ ë°©ì§€)
            if not final_content.strip():
                s_name = next_stage.get('stage', '')
                if s_name == 'skill':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê´€ë ¨ ìê²©ì´ë‚˜ ê¸°ìˆ  ì¤‘ì—ì„œ, ì‹¤ì œ ì—…ë¬´ì— ê°€ì¥ í° ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
                elif s_name == 'experience':
                    final_content = "ì‹¤í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ ì—…ë¬´ ê²½í—˜ ì¤‘ì—ì„œ, ë³¸ì¸ì´ ê°€ì¥ ì£¼ë„ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ì„±ê³¼ë¥¼ ëƒˆë˜ ì‚¬ë¡€ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'experience_followup':
                    final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ê²½í—˜ì„ í†µí•´ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ í¬ê²Œ ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ì‹  ë¶€ë¶„ì€ ë¬´ì—‡ì¸ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
                elif s_name == 'problem_solving':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì–´ë ¤ì›€ì´ ìˆì—ˆì„ ë•Œ, ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì…¨ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                elif s_name == 'problem_solving_followup' or s_name == 'problem_solving_deep':
                    final_content = "ê·¸ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ì…¨ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'communication':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ê°ˆë“±ì„ ì¡°ìœ¨í•˜ì—¬ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'communication_followup':
                    final_content = "ë‹¹ì‹œ ë³¸ì¸ì˜ ì˜ê²¬ì„ ê´€ì² ì‹œí‚¤ê¸°ë³´ë‹¤ëŠ” íŒ€ì˜ ëª©í‘œë¥¼ ìœ„í•´ ì–‘ë³´í•˜ê±°ë‚˜ í˜‘ë ¥í–ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility':
                    final_content = "ì§€ì›ìë‹˜ì˜ ê°€ì¹˜ê´€ê³¼ ì±…ì„ê°ì„ ì—¿ë³¼ ìˆ˜ ìˆëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ ê²½í—˜ í•˜ë‚˜ë¥¼ ì„ ì •í•˜ì—¬ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility_followup':
                    final_content = "ì§€ì›ìë‹˜, ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"
                elif s_name == 'growth':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'growth_followup':
                    final_content = "ì§€ì›ìë‹˜, ë°°ì›€ì˜ ê³¼ì •ì—ì„œ ë³¸ì¸ì˜ ëª©í‘œê°€ ëœ»ëŒ€ë¡œ ë˜ì§€ ì•Šì„ ë•Œ ì´ë¥¼ ê·¹ë³µí•˜ê³  ê¾¸ì¤€íˆ ë‚˜ì•„ê°€ëŠ” ë³¸ì¸ë§Œì˜ ì›ë™ë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'final_statement':
                    final_content = "ì§€ì›ìë‹˜, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¼­ í•˜ê³  ì‹¶ìœ¼ì‹  ë§ì”€ì´ë‚˜ ë³¸ì¸ì„ ì–´í•„í•  ìˆ˜ ìˆëŠ” í•œ ë§ˆë””ê°€ ìˆë‹¤ë©´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                else:
                    final_content = "ì§€ì›ìë‹˜ì˜ ë‹µë³€ì„ ì‹ ì¤‘í•˜ê²Œ ê²½ì²­í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"

            # [ë¬¸ì¥ ë¶€í˜¸ ìµœì¢… ì •ì œ] .? -> . / ?. -> . / ?? -> ? / .. -> . ë“± ì¤‘ë³µ ë° í˜¼ìš© ì œê±° (ì‚¬ìš©ì ìš”ì²­: ë§ˆì¹¨í‘œ ìœ ì§€)
            final_content = final_content.strip()
            
            # ë§ˆì¹¨í‘œ ë’¤ì— ë°”ë¡œ ê¸€ìê°€ ì˜¤ëŠ” ê²½ìš° ë„ì–´ì“°ê¸° ì¶”ê°€ (ê°€ë…ì„±)
            final_content = re.sub(r'\.([ê°€-í£])', r'. \1', final_content)

            # ë§ˆì¹¨í‘œì™€ ë¬¼ìŒí‘œê°€ ì„ì—¬ ìˆìœ¼ë©´ ë§ˆì¹¨í‘œë¥¼ ìš°ì„ ìˆœìœ„ë¡œ í•˜ì—¬ í•˜ë‚˜ë§Œ ë‚¨ê¹€
            final_content = re.sub(r'[\.\s]+\?+', '.', final_content)  # ". ?" ë˜ëŠ” ".?" -> "."
            final_content = re.sub(r'\?+[\.\s]+', '.', final_content)  # "?." ë˜ëŠ” "? ." -> "."
            final_content = re.sub(r'\?+', '?', final_content)         # "??" -> "?"
            final_content = re.sub(r'\.+', '.', final_content)          # ".." -> "."
            
            # í•œ ë²ˆ ë” ê³µë°± ì •ë¦¬
            final_content = re.sub(r'\s+', ' ', final_content).strip()

            # 7. DB ì €ì¥ (Question ë° Transcript)
                # db_categoryëŠ” ìµœìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë¨

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 8. ë©”ëª¨ë¦¬ ì •ë¦¬ (ë” ê°•ë ¥í•˜ê²Œ)
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                with torch.cuda.device(torch.cuda.current_device()):
                    torch.cuda.empty_cache()
            
            logger.info(f"âœ… [SUCCESS] Next question generated for Interview {interview_id}: {final_content[:50]}...")

            # 9. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±°
            if q_id:
                import pathlib
                tts_file = pathlib.Path(f"/app/uploads/tts/q_{q_id}.wav")
                if not tts_file.exists():
                    clean_text = final_content
                    if final_content.startswith('[') and ']' in final_content:
                        clean_text = final_content.split(']', 1)[-1].strip()
                    logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                    synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                else:
                    logger.info(f"ğŸ”Š TTS file already exists for Question ID: {q_id}, skipping.")

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry: {self.request.retries}/3): {e}")
        if self.request.retries >= 3:
            logger.warning("âš ï¸ ì§ˆë¬¸ ìƒì„± ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ìŠ¤í…Œì´ì§€ë³„ í´ë°± ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            try:
                from db import save_generated_question
                from tasks.tts import synthesize_task
                with Session(engine) as session:
                    # í˜„ì¬ ìŠ¤í…Œì´ì§€ì— ë§ëŠ” ì§ˆë¬¸ ì„ íƒ (ê°™ì€ ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€)
                    s_name = next_stage['stage'] if 'next_stage' in locals() and next_stage else ""
                    fallback_dict = {
                        "skill": "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê¸°ìˆ  ì¤‘, ì‹¤ì œ ì—…ë¬´ì—ì„œ ê°€ì¥ ìì‹  ìˆê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?",
                        "skill_followup": "ì•ì„  ë‹µë³€ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "experience": "ìˆ˜í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ í™œë™ ì¤‘ì—ì„œ ë³¸ì¸ì´ ê°€ì¥ í° ê¸°ì—¬ë¥¼ í–ˆë˜ ì‚¬ë¡€ë¥¼ í•˜ë‚˜ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "experience_followup": "ê·¸ ê³¼ì •ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì…¨ë‚˜ìš”?",
                        "problem_solving": "ê¸°ìˆ ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ê°€ì¥ ë³´ëŒì°¼ë˜ ìˆœê°„ì€ ì–¸ì œì…ë‹ˆê¹Œ?",
                        "problem_solving_followup": "ê·¸ íŒë‹¨ì„ ë‚´ë¦´ ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•œ ê¸°ì¤€ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
                        "communication": "íŒ€ì›ë“¤ê³¼ í˜‘ì—…í•  ë•Œ ë³¸ì¸ë§Œì˜ ì†Œí†µ ë°©ì‹ì´ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        "communication_followup": "ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ ë³¸ì¸ì€ ì£¼ë¡œ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹­ë‹ˆê¹Œ?",
                        "responsibility": "ì§€ì›ìë‹˜ì´ í‰ì†Œ ì¼ì— ì„í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì±…ì„ê°ì€ ì–´ë–¤ ëª¨ìŠµì…ë‹ˆê¹Œ?",
                        "responsibility_followup": "ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
                        "growth": "ì§€ì›ìë‹˜ì´ ì•ìœ¼ë¡œ ì´ ì§ë¬´ì—ì„œ ì–´ë–¤ ì „ë¬¸ê°€ë¡œ ì„±ì¥í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ëª©í‘œë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "growth_followup": "ëª©í‘œ ë‹¬ì„±ì´ ì–´ë µê²Œ ëŠê»´ì§ˆ ë•Œ ë³¸ì¸ë§Œì˜ ê·¹ë³µ ë°©ë²•ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "final_statement": "ë§ˆì§€ë§‰ìœ¼ë¡œ ë³¸ì¸ì„ ë” ì–´í•„í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    }
                    fallback_text = fallback_dict.get(s_name, "ì§€ì›ìë‹˜, í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?")
                    fallback_stage_name = s_name if s_name else "fallback"
                    
                    q_id = save_generated_question(
                        interview_id=interview_id,
                        content=fallback_text,
                        category="behavioral",
                        stage=fallback_stage_name,
                        guide="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìŠ¤í…Œì´ì§€ë³„ í´ë°± ì§ˆë¬¸",
                        session=session
                    )
                    if q_id:
                        synthesize_task.delay(fallback_text, language="ko", question_id=q_id)
                    return {"status": "success", "stage": fallback_stage_name, "question": fallback_text}
            except Exception as fallback_e:
                logger.error(f"âŒ í´ë°± ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {fallback_e}")
                return {"status": "error", "message": "Fallback question failed"}
        else:
            raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()