import os
import logging
import re
from celery import shared_task
from typing import Optional, List

# DB í—¬í¼ í•¨ìˆ˜ import
from db import (
    get_best_questions_by_position,
    increment_question_usage,
    engine
)
from sqlmodel import Session, select

# EXAONE LLM import
from utils.exaone_llm import get_exaone_llm

logger = logging.getLogger("AI-Worker-QuestionGen")

class QuestionGenerator:
    """
    í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ìƒì„±ê¸° (EXAONE-3.5-7.8B-Instruct ì‚¬ìš©)
    ì „ëµ: DB ì¬í™œìš© (40%) + Few-Shot LLM ìƒì„± (60%)

    Attributes:
        _instance (QuestionGenerator): ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤
        _initialized (bool): ì´ˆê¸°í™” ì—¬ë¶€
        llm (LLM): EXAONE LLM ì¸ìŠ¤í„´ìŠ¤

    ìƒì„±ì: ejm
    ìƒì„±ì¼ì: 2026-02-04
    """
    _instance = None

    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
            cls._instance._initialized = False
        return cls._instance

    def __init__(self):
        if self._initialized:
            return

        logger.info("Initializing Question Generator with EXAONE model")
        self.llm = get_exaone_llm()
        self._initialized = True

    def generate_questions(self, position: str, interview_id: Optional[int] = None, count: int = 5, reuse_ratio: float = 0.4):
        """
        í•˜ì´ë¸Œë¦¬ë“œ ì§ˆë¬¸ ìƒì„± ë¡œì§ (ì´ë ¥ì„œ ë° íšŒì‚¬ ì •ë³´ ê¸°ë°˜)
        1. DBì—ì„œ ê²€ì¦ëœ ì§ˆë¬¸ ì¼ë¶€ ì¬í™œìš© (Reuse)
        2. ì´ë ¥ì„œ + íšŒì‚¬ ì •ë³´ë¡œ ì»¨í…ìŠ¤íŠ¸ êµ¬ì„±
        3. ì¬í™œìš©ëœ ì§ˆë¬¸ì„ ì˜ˆì‹œ(Few-Shot)ë¡œ ì‚¼ì•„ ë‚˜ë¨¸ì§€ ì§ˆë¬¸ ìƒì„± (Create)

        Args:
            position: ì§€ì› ì§ë¬´
            interview_id: ë©´ì ‘ ID (ì´ë ¥ì„œ/íšŒì‚¬ ì •ë³´ ì¡°íšŒìš©)
            count: ìƒì„±í•  ì´ ì§ˆë¬¸ ìˆ˜
            reuse_ratio: ì¬í™œìš© ë¹„ìœ¨ (0.0 ~ 1.0)

        Returns:
            List[str]: ìƒì„±ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸

        Raises:
            ValueError: ì¬í™œìš© ë¹„ìœ¨ì´ ìœ íš¨í•˜ì§€ ì•Šì„ ê²½ìš°

        ìƒì„±ì: ejm
        ìƒì„±ì¼ì: 2026-02-04
        """
        from tools import ResumeTool, CompanyTool

        resume_summary = ""
        if interview_id:
            resume_info = ResumeTool.get_resume_by_interview(interview_id)
            if resume_info.get("has_resume"):
                context_parts.append(ResumeTool.format_for_llm(resume_info))
                logger.info(f"ì´ë ¥ì„œ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {resume_info.get('summary', '')[:50]}...")

            # íšŒì‚¬ ì •ë³´
            company_info = CompanyTool.get_company_by_interview(interview_id)
            if company_info.get("has_company"):
                context_parts.append(CompanyTool.format_for_llm(company_info))
                logger.info(f"íšŒì‚¬ ì •ë³´ ë¡œë“œ ì™„ë£Œ: {company_info.get('name', '')}")

        context = "\n\n".join(context_parts) if context_parts else ""

        # 2. DBì—ì„œ ê¸°ì¡´ ì§ˆë¬¸ ì¬í™œìš© (Reuse)
        if reuse_count > 0:
            reused = self._reuse_questions_from_db(position, reuse_count)
            questions.extend(reused)
            logger.info(f"âœ… DBì—ì„œ {len(reused)}ê°œ ì§ˆë¬¸ ì¬í™œìš©")

        # 3. EXAONE LLMìœ¼ë¡œ ìƒˆ ì§ˆë¬¸ ìƒì„± (Create with Context)
        if generate_count > 0:
            generated = self.llm.generate_questions(
                position=position,
                context=context,
                examples=questions,  # Few-shot ì˜ˆì‹œë¡œ ì¬í™œìš©ëœ ì§ˆë¬¸ ì‚¬ìš©
                count=generate_count
            )
            questions.extend(generated)
            logger.info(f"âœ… EXAONEìœ¼ë¡œ {len(generated)}ê°œ ì§ˆë¬¸ ìƒì„± (ì»¨í…ìŠ¤íŠ¸ í¬í•¨)")

        return questions[:count]  # ì •í™•íˆ countê°œë§Œ ë°˜í™˜

    def _reuse_questions_from_db(self, position: str, count: int):
        """
        DBì—ì„œ ê²€ì¦ëœ ì§ˆë¬¸ ê°€ì ¸ì˜¤ê¸°

        Args:
            position (str): ì§€ì› ì§ë¬´
            count (int): ê°€ì ¸ì˜¬ ì§ˆë¬¸ ìˆ˜

        Returns:
            List[str]: DBì—ì„œ ê°€ì ¸ì˜¨ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸

        Raises:
            Exception: DB ì¡°íšŒ ì‹¤íŒ¨

        ìƒì„±ì: ejm
        ìƒì„±ì¼ì: 2026-02-04
        """

        try:
            db_questions = get_best_questions_by_position(position, limit=count)
            for q in db_questions:
                try:
                    increment_question_usage(q.id)
                except:
                    pass
            return [q.content for q in db_questions]
        except Exception as e:
            logger.warning(f"DB ì§ˆë¬¸ ì¡°íšŒ ì‹¤íŒ¨: {e}")
            return []

    def generate_deep_dive_question(self, history: str, current_answer: str):
        """ë™ì  ê¼¬ë¦¬ì§ˆë¬¸(Deep-Dive) ìƒì„± - ë©´ì ‘ê´€ í†¤ìœ¼ë¡œ ìƒì„±"""
        if not self.llm: return "ì¶”ê°€ ì§ˆë¬¸ì„ êµ¬ì„±í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        prompt = f"""ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì„ ë“£ê³ , ë” êµ¬ì²´ì ì¸ í™•ì¸ì´ í•„ìš”í•œ ë¶€ë¶„ì— ëŒ€í•´ ì •ì¤‘í•˜ê³  ë‚ ì¹´ë¡œìš´ ê¼¬ë¦¬ì§ˆë¬¸ì„ í•˜ë‚˜ë§Œ ë˜ì ¸ì£¼ì„¸ìš”.

ì´ì „ ì§ˆë¬¸: {history}
ì§€ì›ì ë‹µë³€: {current_answer}

ì§€ì :
- ë§íˆ¬ëŠ” ì •ì¤‘í•œ ê²©ì‹ì²´(~ìŠµë‹ˆê¹Œ?, ~í•˜ì‹­ì‹œì˜¤)ë¥¼ ì‚¬ìš©í•˜ì„¸ìš”.
- ë¶ˆí•„ìš”í•œ ë¶„ì„ì´ë‚˜ ë©”íƒ€ ì •ë³´ ì—†ì´ 'ì§ˆë¬¸ ë¬¸ì¥'ë§Œ ì¶œë ¥í•˜ì„¸ìš”.

ì§ˆë¬¸:"""

        try:
            response = self.llm.invoke(prompt)
            # ì§ˆë¬¸ë§Œ ê¹”ë”í•˜ê²Œ ì¶”ì¶œ
            lines = response.strip().split('\n')
            for line in lines:
                line = line.strip()
                if line and not line.startswith('[') and not line.startswith('###'):
                    # "ì§ˆë¬¸:" ì´ë‚˜ ìˆ«ì ë“±ì´ í¬í•¨ëœ ê²½ìš° ì œê±°
                    clean_q = re.sub(r'^(ì§ˆë¬¸|ì§ˆë¬¸ ë‚´ìš©|Q|A|1|2|3|4|5)[\.\s:]+', '', line).strip()
                    # ëì— ë¶™ëŠ” ë…¸ì´ì¦ˆ(ë‚ ì§œ, ì ìˆ˜ ë“±) ì œê±°
                    clean_q = re.sub(r'\s*\|.*\|?\s*$', '', clean_q).strip()
                    if len(clean_q) > 10:
                        return clean_q

            return response.strip()

        except Exception as e:
            logger.error(f"Deep-Dive ìƒì„± ì‹¤íŒ¨: {e}")
            return "ë°©ê¸ˆ ë§ì”€í•˜ì‹  ë¶€ë¶„ê³¼ ê´€ë ¨í•˜ì—¬, ì‹¤ë¬´ì—ì„œ ì–´ë–¤ ë°©ì‹ìœ¼ë¡œ ë¬¸ì œë¥¼ í•´ê²°í•˜ì…¨ëŠ”ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"

    def generate_answer_analysis(self, history: str, current_answer: str):
        """[Task 3] ë‹µë³€ ì •ë°€ ë¶„ì„ - ì„¹ì…˜ ê¸°ë°˜ íŒŒì‹± (ì¤„ë°”ê¿ˆ í—ˆìš©)"""
        if not self.llm: return "ë¶„ì„ì„ ìˆ˜í–‰í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."

        prompt = f"""ë‹¹ì‹ ì€ ë©´ì ‘ê´€ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì„ ê¸°ìˆ ì  êµ¬ì²´ì„±, ìˆ˜ì¹˜ ë° ì„±ê³¼, ë…¼ë¦¬ì  ì •í•©ì„±, ì‹¤ë¬´ ì ìš©ì„±, ì¢…í•© í‰ê°€ 5ê°€ì§€ ê¸°ì¤€ìœ¼ë¡œ í‰ê°€í•˜ì‹­ì‹œì˜¤.
ê° í•­ëª©ì— ëŒ€í•´ ì ìˆ˜([ì ìˆ˜/5])ì™€ êµ¬ì²´ì ì¸ ì´ìœ ë¥¼ ì‘ì„±í•˜ì‹­ì‹œì˜¤.

ì§ˆë¬¸: {history}
ë‹µë³€: {current_answer}

[í‰ê°€ ì‹œì‘]
- ê¸°ìˆ ì  êµ¬ì²´ì„±:"""

        try:
            response = self.llm.invoke(prompt).strip()
            # ë¡œê·¸ë¡œ ì›ë³¸ í™•ì¸
            logger.info(f"Raw Analysis Response:\n{response}")

            full_response = "- ê¸°ìˆ ì  êµ¬ì²´ì„±: " + response

            import re
            categories = ["ê¸°ìˆ ì  êµ¬ì²´ì„±", "ìˆ˜ì¹˜ ë° ì„±ê³¼", "ë…¼ë¦¬ì  ì •í•©ì„±", "ì‹¤ë¬´ ì ìš©ì„±", "ì¢…í•© í‰ê°€"]

            # 1. ê° ì¹´í…Œê³ ë¦¬ì˜ ì‹œì‘ ìœ„ì¹˜ ì°¾ê¸°
            # (?:-|\d+\.|#)? \s* ì¹´í…Œê³ ë¦¬ëª… \s* :?
            # ìœ„ íŒ¨í„´ìœ¼ë¡œ ê° ì¹´í…Œê³ ë¦¬ê°€ í…ìŠ¤íŠ¸ ë‚´ ì–´ë””ì— ìˆëŠ”ì§€ ì¸ë±ì‹±
            indices = []
            for cat in categories:
                # ìœ ì—°í•œ ë§¤ì¹­: ì•ë¶€ë¶„ ê¸°í˜¸(-, 1., # ë“±) í—ˆìš©, ì½œë¡  í—ˆìš©
                pattern = r'(?:-|\d+\.|#)?\s*' + re.escape(cat) + r'\s*:?'
                match = re.search(pattern, full_response)
                if match:
                    indices.append((match.start(), cat))

            # ìœ„ì¹˜ ìˆœì„œëŒ€ë¡œ ì •ë ¬
            indices.sort()

            results = []

            for i, (start_idx, cat) in enumerate(indices):
                # í˜„ì¬ ì¹´í…Œê³ ë¦¬ë¶€í„° ë‹¤ìŒ ì¹´í…Œê³ ë¦¬ ì‹œì‘ ì „ê¹Œì§€ê°€ ë‚´ìš©
                end_idx = indices[i+1][0] if i + 1 < len(indices) else len(full_response)

                content_chunk = full_response[start_idx:end_idx]

                # ì¹´í…Œê³ ë¦¬ í—¤ë” ì œê±° (ì˜ˆ: "- ê¸°ìˆ ì  êµ¬ì²´ì„±:")
                # ì²« ë²ˆì§¸ ì½œë¡ (:) ì´í›„ ë‚´ìš©ì„ ê°€ì ¸ì˜¤ê±°ë‚˜, í—¤ë” ê¸¸ì´ë§Œí¼ ìë¦„
                split_content = content_chunk.split(':', 1)
                if len(split_content) > 1:
                    content_body = split_content[1]
                else:
                    # ì½œë¡ ì´ ì—†ìœ¼ë©´ ì¹´í…Œê³ ë¦¬ ì´ë¦„ ê¸¸ì´ë§Œí¼ ë„˜ê¹€ (ëŒ€ì¶© ì²˜ë¦¬)
                    content_body = content_chunk[len(cat):]

                # ì ìˆ˜ ì°¾ê¸°
                score_pattern = r'(\d+(?:\.\d+)?)\s*/\s*5|(\d+(?:\.\d+)?)\s*/\s*10|(\d+(?:\.\d+)?)\s*ì '
                score_match = re.search(score_pattern, content_body)

                score_txt = "0"
                if score_match:
                    val = 0.0
                    if score_match.group(1): val = float(score_match.group(1))
                    elif score_match.group(2): val = float(score_match.group(2)) / 2
                    elif score_match.group(3): val = float(score_match.group(3))

                    if val > 5.0: val = 5.0 # ë³´ì •
                    score_txt = str(int(val)) if val.is_integer() else str(val)

                    # ì ìˆ˜ ë¶€ë¶„ ì œê±° (ë‚´ìš© ì •ì œìš©)
                    content_body = content_body.replace(score_match.group(0), '')

                # ë‚´ìš© ì •ì œ
                # ëŒ€ê´„í˜¸ ì”ì—¬ë¬¼ [ ] ì œê±°
                content_body = re.sub(r'\[\s*\]', '', content_body)
                content_body = re.sub(r'\[\s*/\s*5\s*\]', '', content_body)

                # ë¶ˆí•„ìš”í•œ ê³µë°±/ì¤„ë°”ê¿ˆ ì••ì¶•
                reason = " ".join(content_body.split()).strip()
                # ì•ë¶€ë¶„ ê¸°í˜¸ ì œê±° (. , - )
                reason = re.sub(r'^[\.\,\-\s]+', '', reason)

                if reason:
                    results.append(f"- {cat}: {score_txt}/5ì . {reason}")

            if len(results) >= 3:
                return "\n".join(results)

            return full_response[:300]

        except Exception as e:
            logger.error(f"ë‹µë³€ ë¶„ì„ ì‹¤íŒ¨: {e}")
            return "ë‹µë³€ ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."

@shared_task(name="tasks.question_generator.generate_questions")
def generate_questions_task(position: str, interview_id: int = None, count: int = 5):
    """
    ì§ˆë¬¸ ìƒì„± Task

    Args:
        position (str): ì§€ì› ì§ë¬´
        interview_id (int, optional): ë©´ì ‘ ID. Defaults to None.
        count (int, optional): ìƒì„±í•  ì§ˆë¬¸ ìˆ˜. Defaults to 5.

    Returns:
        List[str]: ìƒì„±ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸

    Raises:
        Exception: ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨

    ìƒì„±ì: ejm
    ìƒì„±ì¼ì: 2026-02-04
    """
    try:
        generator = QuestionGenerator()
        return generator.generate_questions(position, interview_id, count)
    except Exception as e:
        logger.error(f"Task Error: {e}")
        return []

# Eager Initialization: Worker ì‹œì‘ ì‹œ ëª¨ë¸ ë¯¸ë¦¬ ë¡œë“œ
try:
    logger.info("ğŸ”¥ Pre-loading Question Generator with EXAONE...")
    _warmup_generator = QuestionGenerator()
    logger.info("âœ… Question Generator ready for requests")
except Exception as e:
    logger.warning(f"âš ï¸ Failed to pre-load model (will load on first request): {e}")
