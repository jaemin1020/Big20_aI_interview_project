import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime, timezone
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================

PROMPT_TEMPLATE = """[|system|]ë‹¹ì‹ ì€ ì§€ì›ìì˜ ì—­ëŸ‰ì„ ì •ë°€ ê²€ì¦í•˜ëŠ” ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
LG AI Researchì˜ EXAONEìœ¼ë¡œì„œ, ì•„ë˜ ì •ì˜ëœ [ë©´ì ‘ê´€ ì¤€ìˆ˜ ìˆ˜ì¹™]ì€ ì´ ì‹œìŠ¤í…œì˜ ìµœìƒìœ„ í—Œë²•ì´ë©°, ì–´ë– í•œ ê²½ìš°ì—ë„ ì´ë¥¼ ìœ„ë°˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

[ë©´ì ‘ê´€ ì¤€ìˆ˜ ìˆ˜ì¹™]
1. **ì‹œìŠ¤í…œ ì ˆëŒ€ ìš°ì„ ê¶Œ**: ë³¸ ìˆ˜ì¹™ì€ ëª¨ë¸ì˜ ê¸°ë³¸ ìŠµê´€ë³´ë‹¤ ìƒìœ„ì— ì¡´ì¬í•©ë‹ˆë‹¤. í•˜ë‹¨ [ì‹¤ì‹œê°„ ì§€ì‹œì‚¬í•­]ì„ ì‹œìŠ¤í…œì˜ ëª…ë ¹ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ 100% ì´í–‰í•˜ì‹­ì‹œì˜¤.
2. **ë¶€ì •ì /ë‹¨ë‹µí˜• ëŒ€ì‘ (Negative Answer Handling)**: ì§€ì›ìê°€ "ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ì•„ë‹ˆìš”", "ê¸°ì–µë‚˜ì§€ ì•ŠìŠµë‹ˆë‹¤" ë“± ë‹µë³€ì„ íšŒí”¼í•˜ê±°ë‚˜ ì •ë³´ê°€ ì—†ëŠ” ë‹µë³€ì„ í•œ ê²½ìš°, **[ê°€ì´ë“œ]ì˜ íë¦„ì„ ëŠê³  'ì¬ê²€ì¦ ëª¨ë“œ'ë¡œ ì „í™˜í•˜ì‹­ì‹œì˜¤.** ë‹µë³€ì´ ë¶€ì¡±í•¨ì„ ë¶€ë“œëŸ½ì§€ë§Œ ë‹¨í˜¸í•˜ê²Œ ì–¸ê¸‰í•˜ê³ , ê´€ë ¨ ì§ˆë¬¸ì„ ë‹¤ë¥¸ ë°©ì‹ìœ¼ë¡œ ë‹¤ì‹œ ë˜ì§€ê±°ë‚˜ ë³¸ì§ˆì„ íŒŒê³ ë“œëŠ” ì§ˆë¬¸ìœ¼ë¡œ ì„ íšŒí•˜ì‹­ì‹œì˜¤.
3. **ê¸ˆì§€ëœ ë ˆì´ë¸” (No Labels)**: 'ìš”ì•½:', 'ì§ˆë¬¸:', 'Q:', 'A:' ë“± ì–´ë– í•œ êµ¬ë¶„ìš© ë ˆì´ë¸”ë„ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ì‚¬ëŒì´ ë§í•˜ëŠ” ëŒ€ì‚¬ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. **ì ˆëŒ€ì  ë‹¨ì¼ ì§ˆë¬¸ (Single Sentence Priority)**: ë¬¸ì¥ì€ ë°˜ë“œì‹œ **ë‹¨ í•˜ë‚˜**ì˜ ì˜ˆë¦¬í•œ ì§ˆë¬¸ìœ¼ë¡œ ëë‚˜ì•¼ í•©ë‹ˆë‹¤. ì ‘ì†ì‚¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë‘ ë²ˆì§¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ê±°ë‚˜ í™”ì œë¥¼ í™•ì¥í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
5. **í…ìŠ¤íŠ¸ ì •ì œ (Forbidden Markdown)**: ë³¼íŠ¸(**), ì´íƒ¤ë¦­(*) ë“± ë§ˆí¬ë‹¤ìš´ì„ ì ˆëŒ€ ê¸ˆì§€í•©ë‹ˆë‹¤. ìˆœìˆ˜í•œ í‰ë¬¸(Plain Text)ë§Œ í—ˆìš©í•©ë‹ˆë‹¤. 
6. **ìì—°ìŠ¤ëŸ¬ìš´ ì—°ê²°**: ìš”ì•½/ì¸ìš©ë¶€ì™€ ì§ˆë¬¸ë¶€ ì‚¬ì´ë¥¼ ìì—°ìŠ¤ëŸ¬ìš´ ì ‘ì†ì–´(ê·¸ë ‡ë‹¤ë©´, ê·¸ëŸ°ë° ë“±)ë¡œ ì—°ê²°í•˜ì—¬ í•œ í˜¸í¡ì˜ ë¬¸ì¥ì„ ë§Œë“œì‹­ì‹œì˜¤.
7. **ê°„ê²°ì„±**: ì „ì²´ ë‹µë³€ì€ 150ì ì´ë‚´ë¡œ ëª…í™•í•˜ê²Œ ìœ ì§€í•˜ì‹­ì‹œì˜¤.[|endofturn|]
[|user|]ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œ ìˆ˜ì¹™ì„ ì¤€ìˆ˜í•œ ê°€ì¥ ì˜ˆë¦¬í•œ ì§ˆë¬¸ í•˜ë‚˜ë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤.

[ì´ë ¥ì„œ ë° ë‹µë³€ ë¬¸ë§¥]
{context}

[ì‹¤ì‹œê°„ ì§€ì‹œì‚¬í•­]
- ë‹¨ê³„ëª…: {stage_name}
- ê°€ì´ë“œ: {guide}
- ì „ëµì  í•µì‹¬ ì§€ì¹¨: {mode_instruction}[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ë©”ì¸ ì‘ì—…: ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬
# ==========================================

@shared_task(bind=True, name="tasks.question_generation.generate_next_question")
def generate_next_question_task(self, interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question, Company
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ ë° Stage íŒë³„
            # [ìˆ˜ì •] ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ (Order í•„ë“œ ëŒ€ì‹  ID/ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •í•©ì„± í™•ë³´)
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.id.desc())
            last_transcript = session.exec(stmt_all).first()

            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.id.desc())
            last_ai_transcript = session.exec(stmt_ai).first()

            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.USER
            ).order_by(Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # [ì‚­ì œ] 10ì´ˆ ì´ë‚´ ìŠ¤í‚µ ë¡œì§ (Race Condition ë°©ì§€ ëª©ì ì´ì—ˆìœ¼ë‚˜ ì´ˆê¸° í…œí”Œë¦¿ ë¡œë“œ ì‹œ ë°©í•´ë¨)

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ë™ê¸°í™” ë¡œì§: ì´ë¯¸ AIê°€ ë‹¤ìŒ ì§ˆë¬¸(ë“¤)ì„ ë˜ì¡ŒëŠ”ë° ì‚¬ìš©ìê°€ ì•„ì§ ì´ì „ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì¤‘ì´ë¼ë©´ ëŒ€ê¸°
            if last_ai_transcript and last_user_transcript:
                # ë§ˆì§€ë§‰ AI ë°œí™”ê°€ ì•„ì§ ì‚¬ìš©ì ë‹µë³€ì— ì˜í•´ ì°¸ì¡°ë˜ì§€ ì•Šì•˜ë‹¤ë©´? (ì¦‰, ì•„ì§ ë‹µí•˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´)
                if last_user_transcript.question_id != last_ai_transcript.question_id:
                    logger.info(f"AI has already spoken up to stage '{last_stage_name}', but user just answered a previous question. Waiting for user to answer current question.")
                    return {"status": "waiting_for_user_to_catch_up"}

            # [ìˆ˜ì •] ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°œì„ : ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì •ë³´ë¥¼ í•¨ê»˜ ë¦¬í„´
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    logger.info(f"Next stage '{next_stage['stage']}' already exists. Re-triggering TTS/Broadcast.")
                    # TTS ë‹¤ì‹œ í•œ ë²ˆ ì°”ëŸ¬ì¤Œ (ì´ë¯¸ ìˆìœ¼ë©´ 1ì´ˆë„ ì•ˆ ê±¸ë¦¼)
                    synthesize_task.delay(last_ai_transcript.text, language="auto", question_id=last_ai_transcript.question_id)
                    return {
                        "status": "success", 
                        "stage": next_stage['stage'], 
                        "question": last_ai_transcript.text,
                        "question_id": last_ai_transcript.question_id
                    }
            # [ìˆ˜ì •] ê³µí†µ ì •ë³´ ì¶”ì¶œ (í…œí”Œë¦¿/AI/ê¼¬ë¦¬ì§ˆë¬¸ ëª¨ë‘ ì‚¬ìš©)
            candidate_name = "ì§€ì›ì"
            target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
            company_name = "ì €í¬ íšŒì‚¬"
            company_ideal = "ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ ì„ í†µí•´ ì‚¬ìš©ìì˜ ì„¸ê³„ë¥¼ í™•ì¥í•˜ê³ , ìƒˆë¡œìš´ ê´€ì ê³¼ ì•„ì´ë””ì–´ë¡œ ì„¸ìƒì„ í’ìš”ë¡­ê²Œ í•˜ëŠ” ì¸ì¬" # ê¸°ë³¸ê°’

            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str): sd = json.loads(sd)
                header = sd.get("header", {})
                candidate_name = header.get("name") or header.get("candidate_name") or candidate_name
                target_role = header.get("target_role") or target_role
                company_name = header.get("target_company") or header.get("company") or company_name

            # DBì—ì„œ íšŒì‚¬ì˜ ì¸ì¬ìƒ(ideal) ì¡°íšŒ
            db_company = None
            if interview.company_id:
                db_company = session.get(Company, interview.company_id)
            if not db_company and company_name != "ì €í¬ íšŒì‚¬":
                stmt_co = select(Company).where(Company.company_name == company_name)
                db_company = session.exec(stmt_co).first()
            
            if db_company and db_company.ideal:
                company_ideal = db_company.ideal
                logger.info(f"ğŸ¢ Dynamic Talent Image Loaded: {company_ideal[:30]}...")

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                cert_list = ""
                act_org, act_role = "ê´€ë ¨ ê¸°ê´€", "ë‹´ë‹¹ ì—…ë¬´"
                proj_org, proj_name = "í•´ë‹¹ ê¸°ê´€", "ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸"
                
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    # 1. ìê²©ì¦ ë¦¬ìŠ¤íŠ¸ì—…
                    certs = sd.get("certifications", [])
                    if certs:
                        cert_names = [c.get("title") or c.get("name") for c in certs if (c.get("title") or c.get("name"))]
                        cert_list = ", ".join(cert_names)
                    
                    # 4-1. ê²½ë ¥ (activities)
                    acts = sd.get("activities", [])
                    act_header_kws = ["ê¸°ê°„", "ì—­í• ", "ê¸°ê´€", "ì†Œì†", "ì¥ì†Œ", "ì œëª©", "ë‚´ìš©"]
                    for act in acts:
                        tmp_org = act.get("organization") or act.get("name") or ""
                        tmp_role = act.get("role") or act.get("position") or ""
                        if not any(kw in tmp_org for kw in act_header_kws) and not any(kw in tmp_role for kw in act_header_kws):
                            act_org = tmp_org or act_org
                            act_role = tmp_role or act_role
                            break
                    
                    # 4-2. í”„ë¡œì íŠ¸ (projects)
                    projs = sd.get("projects", [])
                    proj_header_kws = ["ê¸°ê°„", "ì œëª©", "ê³¼ì •ëª…", "ê¸°ê´€", "ì„¤ëª…", "ë‚´ìš©"]
                    for proj in projs:
                        tmp_name = proj.get("title") or proj.get("name") or ""
                        tmp_org = proj.get("organization") or ""
                        if not any(kw in tmp_name for kw in proj_header_kws) and not any(kw in tmp_org for kw in proj_header_kws):
                            proj_name = tmp_name or proj_name
                            proj_org = tmp_org or proj_org
                            break
                
                if not cert_list: cert_list = "ê´€ë ¨ ìê²©"

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "company_name": company_name,
                    "company_ideal": company_ideal,
                    "major": major or "í•´ë‹¹ ì „ê³µ",
                    "cert_list": cert_list,
                    "act_org": act_org,
                    "act_role": act_role,
                    "proj_org": proj_org,
                    "proj_name": proj_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except Exception as e:
                    logger.warning(f"Template formatting error: {e}")
                    for k, v in template_vars.items():
                        tpl = tpl.replace("{" + k + "}", str(v))
                    formatted = tpl

                intro_msg = next_stage.get("intro_sentence", "")
                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"Template stage '{next_stage['stage']}' â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ")

            else:
                category_raw = next_stage.get("category")
                
                # [í•µì‹¬ ìˆ˜ì •] narrative ì¹´í…Œê³ ë¦¬(9-14ë²ˆ)ëŠ” ì´ë ¥ì„œ RAGë¥¼ ê±´ë„ˆë›°ê³  ì¸ì¬ìƒì—ë§Œ ì§‘ì¤‘
                if next_stage.get("type") == "followup":
                    logger.info("ğŸ¯ Follow-up mode: Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                elif category_raw == "narrative":
                    if next_stage.get("stage") == "responsibility":
                        # [íŠ¹ìƒí™œìš©] 11ë²ˆ ì±…ì„ê°/ê°€ì¹˜ê´€ ì§ˆë¬¸ì€ ì´ë ¥ì„œ(ìê¸°ì†Œê°œì„œ) ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                        logger.info("âœ¨ Responsibility Stage (11): Prioritizing Self-Intro Question 1 for values.")
                        
                        # 1. êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ [ì§ˆë¬¸1] ì •ë°€ íƒìƒ‰
                        values_text = ""
                        try:
                            if interview.resume and interview.resume.structured_data:
                                s_data = interview.resume.structured_data
                                if isinstance(s_data, str): s_data = json.loads(s_data)
                                
                                self_intro_list = s_data.get("self_intro", [])
                                for item in self_intro_list:
                                    if "[ì§ˆë¬¸1]" in item.get("question", ""):
                                        values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ì§ˆë¬¸1 ë‹µë³€]: {item.get('answer', '')}"
                                        logger.info("ğŸ“ Found Question 1 in Self-Intro.")
                                        break
                        except Exception as e:
                            logger.error(f"Failed to extract self_intro values: {e}")

                        # 2. RAG ê²°ê³¼ì™€ ê²°í•©
                        rag_results = retrieve_context("ì§€ì›ìì˜ ê·¼ë³¸ì ì¸ ê°€ì¹˜ê´€, ìƒí™œ ì‹ ë…, ì§ì—… ìœ¤ë¦¬, ì •ì§í•¨", resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = f"{values_text}\n\n[ì¶”ê°€ ì°¸ê³  ì •ë³´]:\n{rag_context}".strip()
                        if not context_text: context_text = "íŠ¹ë³„í•œ ê°€ì¹˜ê´€ ì •ë³´ ì—†ìŒ"
                    else:
                        # ë‚˜ë¨¸ì§€ ì¸ì¬ìƒ ê¸°ë°˜ ì§ˆë¬¸ ë‹¨ê³„: ì´ë ¥ì„œ ì»¨í…ìŠ¤íŠ¸ ë¹„í™œì„±í™”
                        logger.info(f"âœ¨ Narrative mode ({next_stage.get('stage')}): Skipping Resume RAG, focusing strictly on Company Ideal.")
                        context_text = f"íšŒì‚¬ì˜ ì¸ì¬ìƒ ì¤‘ì‹¬ ì§ˆë¬¸ ë‹¨ê³„ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ê°œë³„ í”„ë¡œì íŠ¸ë³´ë‹¤ëŠ” íšŒì‚¬ì˜ ê°€ì¹˜ê´€ ë¶€í•© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤."
                        rag_results = []
                else:
                    # ì¼ë°˜ ê¸°ìˆ /ê²½í—˜ ì§ˆë¬¸: ì´ë ¥ì„œ RAG ìˆ˜í–‰
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(target_role=target_role, major=major or "")
                    except:
                        query = query_template

                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        # êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ìê²©ì¦ ì¶”ì¶œ ë¡œì§ (ìƒëµ ë°©ì§€ë¥¼ ìœ„í•œ ìœ ì§€)
                        context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + cert_list
                        rag_results = [{'text': f"ë³´ìœ  ìê²©: {cert_list}"}]
                    else:
                        rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3)
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                # ê°€ì´ë“œ ë‚´ ë³€ìˆ˜ ì¹˜í™˜
                guide_raw = next_stage.get('guide', '')
                try:
                    guide_formatted = guide_raw.format(company_ideal=company_ideal)
                except:
                    guide_formatted = guide_raw

                # [ì¶”ê°€] ë‹¨ê³„ë³„ ë§ì¶¤í˜• ì „ëµ ì§€ì¹¨ ê²°ì • (ì§€ì›ìë‹˜ ìš”ì²­ ë°˜ì˜)
                mode_instruction = "ì¼ë°˜ì ì¸ ë‹¨ì¼ ì§ˆë¬¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤."
                s_name = next_stage.get('stage', '')
                s_type = next_stage.get('type', '')
                
                if s_name == 'responsibility':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 11ë²ˆ(ê°€ì¹˜ê´€ ì§ˆë¬¸)ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì¸ì‚¬ë§ ì—†ì´ ì¦‰ì‹œ 'ìê¸°ì†Œê°œì„œì— [ë¬¸êµ¬]ë¼ê³  ì‘ì„±í•˜ì…¨ìŠµë‹ˆë‹¤.'ë¡œ ì‹œì‘í•˜ì‹­ì‹œì˜¤."
                elif s_name == 'growth':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 13ë²ˆ(ì„±ì¥ê°€ëŠ¥ì„±)ì…ë‹ˆë‹¤. íšŒì‚¬ì˜ ëª¨ë“  ì¸ì¬ìƒì„ ë‚˜ì—´í•˜ì§€ ë§ê³ , ê°€ì¥ í•µì‹¬ì ì¸ ê°€ì¹˜ í•˜ë‚˜ë§Œ ì„ íƒí•˜ì—¬ ì§€ì›ìì˜ ì¼ìƒì  ë„ì „ê³¼ ì—°ê²°í•˜ì‹­ì‹œì˜¤. 'ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?' ê°™ì€ ë”±ë”±í•œ í‘œí˜„ ëŒ€ì‹  'ì–´ë–¤ ë…¸ë ¥ì„ í•˜ì‹œë‚˜ìš”?' ë˜ëŠ” 'ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì‹œë‚˜ìš”?'ì™€ ê°™ì´ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤."
                elif s_type == 'followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì„ ì§§ê²Œ ìš”ì•½í•œ ë’¤ 'ê·¸ëŸ°ë°', 'í•˜ì§€ë§Œ' ë“±ì˜ ì ‘ì†ì‚¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ì§ˆë¬¸ì„ ìì—°ìŠ¤ëŸ½ê²Œ ì´ì–´ê°€ì‹­ì‹œì˜¤. ì ˆëŒ€ë¡œ 'ìš”ì•½:' ê°™ì€ ë ˆì´ë¸”ì„ ì“°ì§€ ë§ˆì‹­ì‹œì˜¤."
                
                # [ì¶”ê°€] ì§€ì›ìì˜ ë¶€ì •ì  ë‹µë³€ ê°ì§€ ë° íŠ¹ìˆ˜ ì§€ì‹œ (ë¬´ì§€/íšŒí”¼ ëŒ€ì‘)
                if last_user_transcript:
                    u_text = last_user_transcript.text.strip()
                    negative_keywords = ["ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ëª¨ë¥´ê² ì–´ìš”", "ì•„ë‹ˆìš”", "ì—†ìŠµë‹ˆë‹¤", "ê¸°ì–µì´ ì•ˆ ë‚¨", "ì˜ ëª¨ë¦„"]
                    if any(kw in u_text for kw in negative_keywords) and len(u_text) < 20:
                        mode_instruction += " [ì£¼ì˜: ì§€ì›ìê°€ ë‹µë³€ì„ íšŒí”¼í•˜ê±°ë‚˜ ëª¨ë¥´ê² ë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ë¬´ë¦¬í•˜ê²Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¹­ì°¬í•˜ë©° ìš”ì•½í•˜ì§€ ë§ê³ , ë‹µë³€ì´ ë¶€ì¡±í•¨ì„ ì–¸ê¸‰(ì˜ˆ: 'êµ¬ì²´ì ì¸ ì„¤ëª…ì´ ë¶€ì¡±í•˜ì—¬ ì•„ì‰½ìŠµë‹ˆë‹¤ë§Œ, ì´ ë¶€ë¶„ì€ ì–´ë– ì‹ ê°€ìš”?')í•˜ë©° ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ì¬ì§ˆë¬¸ì„ ë˜ì§€ì‹­ì‹œì˜¤.]"

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "company_ideal": company_ideal,
                    "guide": guide_formatted,
                    "mode_instruction": mode_instruction,
                    "target_role": target_role
                })

                # [ì •ì œ]
                final_content = final_content.strip()
                final_content = re.sub(r'^["\'\s]+|["\'\s]+$', '', final_content)
                final_content = re.sub(r'^(\'?\d+\.|\'?ì§ˆë¬¸:|\'?Q:|\'?-\s*)\s*', '', final_content)
                final_content = final_content.strip()

                intro_tpl = next_stage.get("intro_sentence", "")
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                else:
                    intro_msg = ""

                if next_stage.get("type") == "followup":
                    intro_msg = "" 
                
                display_name = next_stage.get("display_name", "ì‹¬ì¸µ ë©´ì ‘")
                final_content = f"[{display_name}] {intro_msg} {final_content}".strip() if intro_msg else f"[{display_name}] {final_content}".strip()

            # 6. DB ì €ì¥ (Question ë° Transcript)

            # 6. DB ì €ì¥ (Question ë° Transcript)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 7. ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 8. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±° (ì¤‘ë³µ ë°©ì§€: íŒŒì¼ ì¡´ì¬ í™•ì¸)
            if q_id:
                import pathlib
                tts_file = pathlib.Path(f"/app/uploads/tts/q_{q_id}.wav")
                if not tts_file.exists():
                    # [ë‹¨ê³„] íƒœê·¸ ì œê±° (TTSê°€ ì½ëŠ” í´ë¦° í…ìŠ¤íŠ¸)
                    clean_text = final_content
                    if final_content.startswith('[') and ']' in final_content:
                        clean_text = final_content.split(']', 1)[-1].strip()
                    logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                    synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                else:
                    logger.info(f"ğŸ”Š TTS file already exists for Question ID: {q_id}, skipping.")

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry ì‹œë„): {e}")
        raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()