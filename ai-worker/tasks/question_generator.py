import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime, timezone
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================

PROMPT_TEMPLATE = """[|system|]ë‹¹ì‹ ì€ ì§€ì›ìì˜ ì—­ëŸ‰ì„ ì •ë°€ ê²€ì¦í•˜ëŠ” ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
LG AI Researchì˜ EXAONEìœ¼ë¡œì„œ, ì•„ë˜ ì •ì˜ëœ [ë©´ì ‘ê´€ ì¤€ìˆ˜ ìˆ˜ì¹™]ì€ ì‹œìŠ¤í…œì˜ ìµœìƒìœ„ í—Œë²•ì´ë©°, ì–´ë– í•œ ê²½ìš°ì—ë„ ìœ„ë°˜í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

[ë©´ì ‘ê´€ ì¤€ìˆ˜ ìˆ˜ì¹™]
1. ì‹œìŠ¤í…œ ì ˆëŒ€ ìš°ì„ ê¶Œ: ë³¸ ìˆ˜ì¹™ì€ ëª¨ë¸ì˜ ê¸°ë³¸ ìŠµê´€ë³´ë‹¤ ìƒìœ„ì— ì¡´ì¬í•©ë‹ˆë‹¤.
2. ë¶€ì •ì /ë‹¨ë‹µí˜• ëŒ€ì‘: ì§€ì›ìê°€ ë‹µë³€ì„ íšŒí”¼í•˜ê±°ë‚˜ ì •ë³´ê°€ ë¶€ì¡±í•˜ë©´ 'ì¬ê²€ì¦ ëª¨ë“œ'ë¡œ ì „í™˜í•˜ê³ , ë³¸ì§ˆì  ì§ˆë¬¸ìœ¼ë¡œ ì„ íšŒí•˜ì‹­ì‹œì˜¤.
3. ê¸ˆì§€ëœ ë ˆì´ë¸”: **í•µì‹¬ ìš”ì•½:**, **ê¼¬ë¦¬ì§ˆë¬¸:**, ìš”ì•½:, ì§ˆë¬¸:, ì§€ì›ìì˜ ë‹µë³€ ìš”ì•½ ë° ê¼¬ë¦¬ì§ˆë¬¸:, ì´ì— ëŒ€í•œ ì§ˆë¬¸ì…ë‹ˆë‹¤: ë“± ëª¨ë“  ë ˆì´ë¸” ì‚¬ìš©ì„ ì—„ê²©íˆ ê¸ˆì§€í•©ë‹ˆë‹¤.
4. ì ˆëŒ€ì  ë‹¨ì¼ ì§ˆë¬¸: ì¶œë ¥ì—ëŠ” í•µì‹¬ í•œ ê°€ì§€ ì§ˆë¬¸ë§Œ í¬í•¨í•˜ë©°, ë ˆì´ë¸”ì´ë‚˜ 'ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„ ë“œë¦½ë‹ˆë‹¤', 'ì§€ì›ìê°€ ~ë¼ê³  í–ˆìœ¼ë¯€ë¡œ' ì™€ ê°™ì€ ì„œë‘ ì„¤ëª… ë¬¸ì¥ì„ ì¼ì ˆ í¬í•¨í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ì§ˆë¬¸ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
5. í…ìŠ¤íŠ¸ ì •ì œ: ë³¼íŠ¸(**), ë§ˆí¬ë‹¤ìš´, ~, [ ], ( ) ë“±ì˜ íŠ¹ìˆ˜ ê¸°í˜¸ ì‚¬ìš©ì„ ê¸ˆì§€í•˜ê³  ì˜¤ì§ í‰ë¬¸ë§Œ í—ˆìš©í•©ë‹ˆë‹¤.
6. ê°„ê²°ì„±: ê°€ê¸‰ì  150ì ë‚´ë¡œ í•µì‹¬ë§Œ ë¬»ë„ë¡ ìœ ì§€í•˜ì‹­ì‹œì˜¤. ì§ˆë¬¸ ì™¸ì˜ ëª¨ë“  ì‚¬ì¡±(intro/outro)ì€ ê°ì  ìš”ì¸ì´ì ìˆ˜ì¹™ ìœ„ë°˜ì…ë‹ˆë‹¤.[|endofturn|]

[|user|]ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ì‹œìŠ¤í…œ ìˆ˜ì¹™ì„ ì¤€ìˆ˜í•œ ê°€ì¥ ì˜ˆë¦¬í•œ ê¼¬ë¦¬ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤.
ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ ë‚´ìš©ì—ì„œ êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ë…¼ë¦¬ì  í—ˆì ì„ ì°Œë¥´ëŠ” ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤.

[ì´ë ¥ì„œ ë° ë‹µë³€ ë¬¸ë§¥]
{context}

[ì‹¤ì‹œê°„ ì§€ì‹œì‚¬í•­]
- ë‹¨ê³„ëª…: {stage_name}
- ê°€ì´ë“œ: {guide}
- ì „ëµì  í•µì‹¬ ì§€ì¹¨: {mode_instruction}
- ê¼¬ë¦¬ì§ˆë¬¸ ëª©ì : ì´ì „ ë‹µë³€ì—ì„œ ì–¸ê¸‰í•œ ê²½í—˜ì˜ ì‹¤ì œ ì ìš©, ë¬¸ì œ í•´ê²° ê³¼ì •, ì‚¬ìš© ë„êµ¬, ì„±ê³¼ë¥¼ í™•ì¸í•˜ê³  ë¶€ì¡±í•œ ë¶€ë¶„ì„ ê¹Šì´ íŒŒê³ ë“œëŠ” ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
- ì»¨í…ìŠ¤íŠ¸ í™œìš©: {context}ë¥¼ ë¶„ì„í•˜ì—¬ ì§€ì›ìì˜ ê²½í—˜ í•œê³„ì™€ ì‹¤ë¬´ ì ìš© ì‚¬ë¡€ ì¤‘ì‹¬ìœ¼ë¡œ ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.[|endofturn|]

[|assistant|]"""

# ==========================================
# 3. ë©”ì¸ ì‘ì—…: ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬
# ==========================================

@shared_task(bind=True, name="tasks.question_generation.generate_next_question")
def generate_next_question_task(self, interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question, Company
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ ë° Stage íŒë³„
            # [ìˆ˜ì •] ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ (Order í•„ë“œ ëŒ€ì‹  ID/ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •í•©ì„± í™•ë³´)
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.id.desc())
            last_transcript = session.exec(stmt_all).first()

            # ë§ˆì§€ë§‰ AI ë°œí™” ê°€ì ¸ì˜¤ê¸°
            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.id.desc())
            last_ai_transcript = session.exec(stmt_ai).first()

            # ë§ˆì§€ë§‰ ì‚¬ìš©ì ë°œí™” ê°€ì ¸ì˜¤ê¸° (ë‹¨, ì•„ì£¼ ì§§ì€ ë…¸ì´ì¦ˆëŠ” ë¬´ì‹œí•˜ì—¬ ìŠ¤í…Œì´ì§€ ìŠ¤í‚µ ë°©ì§€)
            from sqlalchemy import func
            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker != Speaker.AI,
                func.length(Transcript.text) > 5  # ìµœì†Œ 6ì ì´ìƒì¸ ê²½ìš°ë§Œ ì‹¤ì œ ë‹µë³€ìœ¼ë¡œ ê°„ì£¼í•˜ì—¬ ìŠ¤í…Œì´ì§€ ì „í™˜ íŒë‹¨
            ).order_by(Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # ë§Œì•½ ìœ„ì—ì„œ ëª»ì°¾ì•˜ë‹¤ë©´ ì§„ì§œ ë§ˆì§€ë§‰ ë°œí™”ë¼ë„ ê°€ì ¸ì˜´ (ëŒ€ê¸° ë¡œì§ìš©)
            if not last_user_transcript:
                stmt_user_any = select(Transcript).where(
                    Transcript.interview_id == interview_id,
                    Transcript.speaker != Speaker.AI
                ).order_by(Transcript.id.desc())
                last_user_transcript = session.exec(stmt_user_any).first()

            # [ì‚­ì œ] 10ì´ˆ ì´ë‚´ ìŠ¤í‚µ ë¡œì§ (Race Condition ë°©ì§€ ëª©ì ì´ì—ˆìœ¼ë‚˜ ì´ˆê¸° í…œí”Œë¦¿ ë¡œë“œ ì‹œ ë°©í•´ë¨)

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
                
                # [ë³µêµ¬ ë¡œì§] ë§Œì•½ ë§ˆì§€ë§‰ ìŠ¤í…Œì´ì§€ê°€ 'fallback' ì´ë¼ë©´, ê·¸ ì´ì „ì˜ ì •ìƒì ì¸ ìŠ¤í…Œì´ì§€ë¥¼ ì°¾ì•„ì•¼ í•¨
                if last_stage_name == "fallback":
                    logger.warning(f"âš ï¸ Last stage was 'fallback'. Searching for previous valid stage for Interview {interview_id}.")
                    stmt_ai_prev = select(Transcript).where(
                        Transcript.interview_id == interview_id,
                        Transcript.speaker == Speaker.AI,
                        Transcript.id < last_ai_transcript.id
                    ).order_by(Transcript.id.desc())
                    prev_ai = session.exec(stmt_ai_prev).first()
                    if prev_ai and prev_ai.question_id:
                        prev_q = session.get(Question, prev_ai.question_id)
                        if prev_q and prev_q.question_type and prev_q.question_type != "fallback":
                            last_stage_name = prev_q.question_type
                            logger.info(f"ğŸ”„ Recovered stage from fallback: {last_stage_name}")
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ë™ê¸°í™” ë° ìŠ¤í…Œì´ì§€ ìŠ¤í‚µ ë°©ì§€ ë¡œì§ ê°•í™”
            if last_ai_transcript and last_user_transcript:
                # 1. ë§Œì•½ ë§ˆì§€ë§‰ AI ì§ˆë¬¸ì´ ë°©ê¸ˆ ì „(3ì´ˆ ì´ë‚´)ì— ë˜ì ¸ì¡Œë‹¤ë©´, ì‚¬ìš©ì ë‹µë³€ì´ ì¶©ë¶„íˆ ê¸¸ì§€ ì•Šì€ ì´ìƒ ë‹¤ìŒ ë‹¨ê³„ë¡œ ë„˜ì–´ê°€ì§€ ì•ŠìŒ
                #    (ìŒì„± ì¸ì‹ ì§€ì—°/ì§€í„°ë¡œ ì¸í•´ ì´ì „ ë‹µë³€ì´ ìƒˆ ì§ˆë¬¸ IDì— ê½‚íˆëŠ” í˜„ìƒ ë°©ì§€)
                time_since_ai = (get_kst_now() - last_ai_transcript.timestamp.replace(tzinfo=None)).total_seconds()
                is_short_answer = len(last_user_transcript.text.strip()) < 10
                
                if time_since_ai < 3.0 and is_short_answer:
                    logger.info(f"AI just spoke {time_since_ai:.1f}s ago. Current user answer is short ('{last_user_transcript.text}'). Waiting for a real answer.")
                    return {"status": "waiting_for_user_to_catch_up"}

                # 2. ë§ˆì§€ë§‰ AI ë°œí™”ê°€ ì•„ì§ ì‚¬ìš©ì ë‹µë³€ì— ì˜í•´ ì°¸ì¡°ë˜ì§€ ì•Šì•˜ë‹¤ë©´? (ì¦‰, ì•„ì§ ë‹µí•˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´)
                if last_user_transcript.question_id != last_ai_transcript.question_id:
                    logger.info(f"AI has already spoken up to stage '{last_stage_name}', but user just answered a previous question. Waiting for user to answer current question.")
                    return {"status": "waiting_for_user_to_catch_up"}

            # [ìˆ˜ì •] ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°œì„ : ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì •ë³´ë¥¼ í•¨ê»˜ ë¦¬í„´
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    logger.info(f"Next stage '{next_stage['stage']}' already exists. Re-triggering TTS/Broadcast.")
                    # TTS ë‹¤ì‹œ í•œ ë²ˆ ì°”ëŸ¬ì¤Œ (ì´ë¯¸ ìˆìœ¼ë©´ 1ì´ˆë„ ì•ˆ ê±¸ë¦¼)
                    synthesize_task.delay(last_ai_transcript.text, language="auto", question_id=last_ai_transcript.question_id)
                    return {
                        "status": "success", 
                        "stage": next_stage['stage'], 
                        "question": last_ai_transcript.text,
                        "question_id": last_ai_transcript.question_id
                    }
            # [ìˆ˜ì •] ê³µí†µ ì •ë³´ ì¶”ì¶œ (í…œí”Œë¦¿/AI/ê¼¬ë¦¬ì§ˆë¬¸ ëª¨ë‘ ì‚¬ìš©)
            candidate_name = "ì§€ì›ì"
            target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
            company_name = "ì €í¬ íšŒì‚¬"
            company_ideal = "ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ ì„ í†µí•´ ì‚¬ìš©ìì˜ ì„¸ê³„ë¥¼ í™•ì¥í•˜ê³ , ìƒˆë¡œìš´ ê´€ì ê³¼ ì•„ì´ë””ì–´ë¡œ ì„¸ìƒì„ í’ìš”ë¡­ê²Œ í•˜ëŠ” ì¸ì¬" # ê¸°ë³¸ê°’

            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str): sd = json.loads(sd)
                header = sd.get("header", {})
                candidate_name = header.get("name") or header.get("candidate_name") or candidate_name
                target_role = header.get("target_role") or target_role
                company_name = header.get("target_company") or header.get("company") or company_name

            # DBì—ì„œ íšŒì‚¬ì˜ ì¸ì¬ìƒ(ideal) ì¡°íšŒ
            db_company = None
            if interview.company_id:
                db_company = session.get(Company, interview.company_id)
            if not db_company and company_name != "ì €í¬ íšŒì‚¬":
                stmt_co = select(Company).where(Company.company_name == company_name)
                db_company = session.exec(stmt_co).first()
            
            if db_company and db_company.ideal:
                company_ideal = db_company.ideal
                logger.info(f"ğŸ¢ Dynamic Talent Image Loaded: {company_ideal[:30]}...")

            # [ê³µí†µ] ì¹´í…Œê³ ë¦¬ ë° DB ë³€ìˆ˜ ì„ ì–¸ (NameError ë°©ì§€)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                cert_list = ""
                act_org, act_role = "ê´€ë ¨ ê¸°ê´€", "ë‹´ë‹¹ ì—…ë¬´"
                proj_org, proj_name = "í•´ë‹¹ ê¸°ê´€", "ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸"
                
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    # 1. ìê²©ì¦ ë¦¬ìŠ¤íŠ¸ì—…
                    certs = sd.get("certifications", [])
                    if certs:
                        cert_names = [c.get("title") or c.get("name") for c in certs if (c.get("title") or c.get("name"))]
                        cert_list = ", ".join(cert_names)
                    
                    # 4-1. ê²½ë ¥ (activities)
                    acts = sd.get("activities", [])
                    act_header_kws = ["ê¸°ê°„", "ì—­í• ", "ê¸°ê´€", "ì†Œì†", "ì¥ì†Œ", "ì œëª©", "ë‚´ìš©"]
                    for act in acts:
                        tmp_org = act.get("organization") or act.get("name") or ""
                        tmp_role = act.get("role") or act.get("position") or ""
                        if not any(kw in tmp_org for kw in act_header_kws) and not any(kw in tmp_role for kw in act_header_kws):
                            act_org = tmp_org or act_org
                            act_role = tmp_role or act_role
                            break
                    
                    # 4-2. í”„ë¡œì íŠ¸ (projects)
                    projs = sd.get("projects", [])
                    proj_header_kws = ["ê¸°ê°„", "ì œëª©", "ê³¼ì •ëª…", "ê¸°ê´€", "ì„¤ëª…", "ë‚´ìš©"]
                    for proj in projs:
                        tmp_name = proj.get("title") or proj.get("name") or ""
                        tmp_org = proj.get("organization") or ""
                        if not any(kw in tmp_name for kw in proj_header_kws) and not any(kw in tmp_org for kw in proj_header_kws):
                            proj_name = tmp_name or proj_name
                            proj_org = tmp_org or proj_org
                            break
                
                if not cert_list: cert_list = "ê´€ë ¨ ìê²©"

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "company_name": company_name,
                    "company_ideal": company_ideal,
                    "major": major or "í•´ë‹¹ ì „ê³µ",
                    "cert_list": cert_list,
                    "act_org": act_org,
                    "act_role": act_role,
                    "proj_org": proj_org,
                    "proj_name": proj_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except Exception as e:
                    logger.warning(f"Template formatting error: {e}")
                    for k, v in template_vars.items():
                        tpl = tpl.replace("{" + k + "}", str(v))
                    formatted = tpl

                intro_msg = next_stage.get("intro_sentence", "")
                final_content = f"{intro_msg} {formatted}".strip() if intro_msg else formatted
                # [ì¤‘ìš”] í…œí”Œë¦¿ ìŠ¤í…Œì´ì§€ì—ì„œë„ scë¥¼ ì •ì˜í•´ë‘ì–´ì•¼ ì•„ë˜ ì •ì œ ë¡œì§ì—ì„œ ì°¸ì¡° ì˜¤ë¥˜ê°€ ì•ˆ ë‚¨
                sc = final_content.strip()
                logger.info(f"Template stage '{next_stage['stage']}' â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ")

            else:
                # category_rawëŠ” ìœ„ì—ì„œ ê³µí†µìœ¼ë¡œ ì •ì˜ë¨
                
                # [í•µì‹¬ ìˆ˜ì •] narrative ì¹´í…Œê³ ë¦¬(9-14ë²ˆ)ëŠ” ì´ë ¥ì„œ RAGë¥¼ ê±´ë„ˆë›°ê³  ì¸ì¬ìƒì—ë§Œ ì§‘ì¤‘
                if next_stage.get("type") == "followup":
                    logger.info("ğŸ¯ Follow-up mode: Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                elif category_raw == "narrative":
                    if next_stage.get("stage") == "responsibility":
                        # [íŠ¹ìƒí™œìš©] 11ë²ˆ ì±…ì„ê°/ê°€ì¹˜ê´€ ì§ˆë¬¸ì€ ì´ë ¥ì„œ(ìê¸°ì†Œê°œì„œ) ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                        logger.info("âœ¨ Responsibility Stage (11): Prioritizing Self-Intro Question 1 for values.")
                        
                        # 1. êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ [ì§ˆë¬¸1] ì •ë°€ íƒìƒ‰
                        values_text = ""
                        try:
                            if interview.resume and interview.resume.structured_data:
                                s_data = interview.resume.structured_data
                                if isinstance(s_data, str): s_data = json.loads(s_data)
                                
                                self_intro_list = s_data.get("self_intro", [])
                                for item in self_intro_list:
                                    q_text = item.get("question", "")
                                    # [ê°œì„ ] ë”ìš± ìœ ì—°í•˜ê²Œ ì§ˆë¬¸1 íƒìƒ‰ (ì¸ë±ìŠ¤ ë˜ëŠ” í‚¤ì›Œë“œ)
                                    if "[ì§ˆë¬¸1]" in q_text or "ì§ˆë¬¸ 1" in q_text or q_text.startswith("1."):
                                        ans = item.get('answer', '')
                                        if len(ans) > 20: # ìµœì†Œí•œì˜ ìœ ì˜ë¯¸í•œ ê¸¸ì´
                                            values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ì§ˆë¬¸1 ë‹µë³€]: {ans}"
                                            logger.info("ğŸ“ Found Question 1 in Self-Intro.")
                                            break
                                
                                # ë§Œì•½ ì§ˆë¬¸ 1ì„ ëª»ì°¾ì•˜ë‹¤ë©´, ì „ì²´ ìì†Œì„œì—ì„œ ê°€ì¹˜ê´€ìŠ¤ëŸ¬ìš´ ë¬¸ì¥ì„ ì¶”ì¶œ (fallback)
                                if not values_text and self_intro_list:
                                    all_answers = " ".join([i.get("answer", "") for i in self_intro_list if i.get("answer")])
                                    values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ìš”ì•½]: {all_answers[:300]}" # ì•ë¶€ë¶„ 300ìë¼ë„ ì œê³µ
                        except Exception as e:
                            logger.error(f"Failed to extract self_intro values: {e}")

                        # 2. RAG ê²°ê³¼ì™€ ê²°í•©
                        rag_results = retrieve_context("ì§€ì›ìì˜ ê·¼ë³¸ì ì¸ ê°€ì¹˜ê´€, ìƒí™œ ì‹ ë…, ì§ì—… ìœ¤ë¦¬, ì •ì§í•¨", resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = f"{values_text}\n\n[ì¶”ê°€ ì°¸ê³  ì •ë³´]:\n{rag_context}".strip()
                        if not context_text: context_text = "íŠ¹ë³„í•œ ê°€ì¹˜ê´€ ì •ë³´ ì—†ìŒ"
                    else:
                        # ë‚˜ë¨¸ì§€ ì¸ì¬ìƒ ê¸°ë°˜ ì§ˆë¬¸ ë‹¨ê³„: ì´ë ¥ì„œ ì»¨í…ìŠ¤íŠ¸ ë¹„í™œì„±í™”
                        logger.info(f"âœ¨ Narrative mode ({next_stage.get('stage')}): Skipping Resume RAG, focusing strictly on Company Ideal.")
                        context_text = f"íšŒì‚¬ì˜ ì¸ì¬ìƒ ì¤‘ì‹¬ ì§ˆë¬¸ ë‹¨ê³„ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ê°œë³„ í”„ë¡œì íŠ¸ë³´ë‹¤ëŠ” íšŒì‚¬ì˜ ê°€ì¹˜ê´€ ë¶€í•© ì—¬ë¶€ë¥¼ í™•ì¸í•˜ì‹­ì‹œì˜¤."
                        rag_results = []
                else:
                    # ì¼ë°˜ ê¸°ìˆ /ê²½í—˜ ì§ˆë¬¸: ì´ë ¥ì„œ RAG ìˆ˜í–‰
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(target_role=target_role, major=major or "")
                    except:
                        query = query_template

                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        # êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ìê²©ì¦ ì¶”ì¶œ ë¡œì§ (ìƒëµ ë°©ì§€ë¥¼ ìœ„í•œ ìœ ì§€)
                        context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + cert_list
                        rag_results = [{'text': f"ë³´ìœ  ìê²©: {cert_list}"}]
                    else:
                        rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3)
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    else:
                        context_text += "\n[ì§€ì›ìì˜ ì‘ë‹µ ì •ë³´ê°€ ì•„ì§ ì „ë‹¬ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.]"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                # ê°€ì´ë“œ ë‚´ ë³€ìˆ˜ ì¹˜í™˜
                guide_raw = next_stage.get('guide', '')
                try:
                    guide_formatted = guide_raw.format(company_ideal=company_ideal)
                except:
                    guide_formatted = guide_raw

                # â”€â”€ [ì—°ì† ì €ì ìˆ˜ ê°ì§€] ì•„ì´ìŠ¤ë¸Œë ˆí‚¹ ë‚œì´ë„ í•˜í–¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
                LOW_SCORE_THRESHOLD = 60   # ì €ì ìˆ˜ ê¸°ì¤€ (0-100ì  ì²™ë„)
                LOW_SCORE_CONSECUTIVE = 3  # ì—°ì† ì €ì ìˆ˜ íšŸìˆ˜ ì„ê³„ê°’

                user_transcripts_scored = session.exec(
                    select(Transcript)
                    .where(
                        Transcript.interview_id == interview_id,
                        Transcript.speaker != Speaker.AI,
                        Transcript.total_score.isnot(None),
                    )
                    .order_by(Transcript.id.desc())
                    .limit(LOW_SCORE_CONSECUTIVE)
                ).all()

                is_low_score_streak = (
                    len(user_transcripts_scored) >= LOW_SCORE_CONSECUTIVE
                    and all(
                        (t.total_score or 0) < LOW_SCORE_THRESHOLD
                        for t in user_transcripts_scored
                    )
                )
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                # [ì¶”ê°€] ë‹¨ê³„ë³„ ë§ì¶¤í˜• ì „ëµ ì§€ì¹¨ ê²°ì • (ì§€ì›ìë‹˜ ìš”ì²­ ë°˜ì˜)
                mode_instruction = "ì¼ë°˜ì ì¸ ë‹¨ì¼ ì§ˆë¬¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤."
                s_name = next_stage.get('stage', '')
                s_type = next_stage.get('type', '')
                
                if s_name == 'problem_solving':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 7ë²ˆ(ë¬¸ì œí•´ê²°ì§ˆë¬¸)ì…ë‹ˆë‹¤. ì§ˆë¬¸ ê³¼ì •ì—ì„œ 'ê·¸ëŸ°ë°' í˜¹ì€ 'ê·¸ë ‡ë‹¤ë©´'ê³¼ ê°™ì€ ì ‘ì†ì‚¬ë¥¼ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ìƒí™©ì„ ì œì‹œí•˜ë˜, ë°˜ë“œì‹œ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 11ë²ˆ(ê°€ì¹˜ê´€ ì§ˆë¬¸)ì…ë‹ˆë‹¤. ë°˜ë“œì‹œ ì¸ì‚¬ë§ ì—†ì´ ì¦‰ì‹œ 'ìê¸°ì†Œê°œì„œì— [ë¬¸êµ¬]ë¼ê³  ì‘ì„±í•˜ì…¨ìŠµë‹ˆë‹¤.'ë¡œ ì‹œì‘í•˜ê³ , 'ê·¸ë ‡ë‹¤ë©´'ìœ¼ë¡œ ì´ì–´ê°€ë©° ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility_followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 12ë²ˆ(ê°€ì¹˜ê´€ ì‹¬ì¸µ)ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì„ ìš”ì•½í•œ ë’¤ 'ê·¸ëŸ°ë°' ë“±ì˜ ì ‘ì†ì‚¬ë¥¼ ì‚¬ìš©í•˜ì—¬ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ ìì—°ìŠ¤ëŸ½ê²Œ ì—°ê²°í•˜ì‹­ì‹œì˜¤."
                elif s_name == 'growth':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 13ë²ˆ(ì„±ì¥ê°€ëŠ¥ì„±)ì…ë‹ˆë‹¤. í•µì‹¬ ì¸ì¬ìƒ ê°€ì¹˜ í•˜ë‚˜ë¥¼ ì„ íƒí•˜ì—¬ ìì—°ìŠ¤ëŸ¬ìš´ êµ¬ì–´ì²´ë¡œ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_name == 'communication':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 9ë²ˆ(í˜‘ì—…ì†Œí†µì§ˆë¬¸)ì…ë‹ˆë‹¤. ì¸ì‚¬ë§ì´ë‚˜ ìƒí™© ì„¤ëª… ì—†ì´, ì¸ì¬ìƒ ê°€ì¹˜ë¥¼ ë°”íƒ•ìœ¼ë¡œ ì§€ì›ìì˜ íƒœë„ë¥¼ í™•ì¸í•˜ëŠ” ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ì¦‰ì‹œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_type == 'followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹µë³€ ìš”ì•½ê³¼ ì§ˆë¬¸ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                
                # â”€â”€ [ì•„ì´ìŠ¤ë¸Œë ˆí‚¹ ì£¼ì…] ì—°ì† ì €ì ìˆ˜ ì‹œ ê²©ë ¤ ë° ë‚œì´ë„ í•˜í–¥ â”€â”€â”€â”€â”€â”€
                if is_low_score_streak:
                    mode_instruction += (
                        " [ì§€ì›ì ì§€ì› ëª¨ë“œ] ì§€ì›ìê°€ ì—¬ëŸ¬ ì°¨ë¡€ ë‹µë³€ì— ì–´ë ¤ì›€ì„ ê²ªê³  ìˆìŠµë‹ˆë‹¤."
                        " ì´ë²ˆ ì§ˆë¬¸ì€ ë‚œì´ë„ë¥¼ í•œ ë‹¨ê³„ ë‚®ì¶”ì–´ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                        " ë°˜ë“œì‹œ ì§ˆë¬¸ ë¬¸ì¥ ì•ì— 'ì²œì²œíˆ ë‹µë³€í•˜ì…”ë„ ê´œì°®ìŠµë‹ˆë‹¤, ë„ˆë¬´ ê¸´ì¥í•˜ì§€ ë§ˆì„¸ìš”.' ì™€ ê°™ì€"
                        " ìì—°ìŠ¤ëŸ¬ìš´ ê²©ë ¤ ë¬¸ì¥ì„ ë¨¼ì € í¬í•¨í•˜ê³ , ê·¸ ë’¤ì— ì‰½ê³  ê°„ê²°í•œ ì§ˆë¬¸ì„ ì´ì–´ê°€ì‹­ì‹œì˜¤."
                    )
                    logger.info(
                        f"ğŸ§Š [ICE-BREAK] {LOW_SCORE_CONSECUTIVE}íšŒ ì—°ì† ì €ì ìˆ˜ ê°ì§€ "
                        f"(ê¸°ì¤€: {LOW_SCORE_THRESHOLD}ì  ë¯¸ë§Œ). ë‚œì´ë„ í•˜í–¥ ë° ê²©ë ¤ ë©˜íŠ¸ ì£¼ì…."
                    )
                # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

                # [ì¶”ê°€] ì§€ì›ìì˜ ë¶€ì •ì  ë‹µë³€ ê°ì§€ ë° íŠ¹ìˆ˜ ì§€ì‹œ (ë¬´ì§€/íšŒí”¼ ëŒ€ì‘)
                if last_user_transcript:
                    u_text = last_user_transcript.text.strip()
                    negative_keywords = ["ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ëª¨ë¥´ê² ì–´ìš”", "ì•„ë‹ˆìš”", "ì—†ìŠµë‹ˆë‹¤", "ê¸°ì–µì´ ì•ˆ ë‚¨", "ì˜ ëª¨ë¦„"]
                    if any(kw in u_text for kw in negative_keywords) and len(u_text) < 20:
                        mode_instruction += " [ì£¼ì˜: ì§€ì›ìê°€ ë‹µë³€ì„ íšŒí”¼í•˜ê±°ë‚˜ ëª¨ë¥´ê² ë‹¤ê³  í–ˆìŠµë‹ˆë‹¤. ë¬´ë¦¬í•˜ê²Œ ë‹¤ìŒ ë‹¨ê³„ë¥¼ ì¹­ì°¬í•˜ë©° ìš”ì•½í•˜ì§€ ë§ê³ , ë‹µë³€ì´ ë¶€ì¡±í•¨ì„ ì–¸ê¸‰(ì˜ˆ: 'êµ¬ì²´ì ì¸ ì„¤ëª…ì´ ë¶€ì¡±í•˜ì—¬ ì•„ì‰½ìŠµë‹ˆë‹¤ë§Œ, ì´ ë¶€ë¶„ì€ ì–´ë– ì‹ ê°€ìš”?')í•˜ë©° ë‹¤ë¥¸ ë°©í–¥ìœ¼ë¡œ ì¬ì§ˆë¬¸ì„ ë˜ì§€ì‹­ì‹œì˜¤.]"

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "company_ideal": company_ideal,
                    "guide": guide_formatted,
                    "mode_instruction": mode_instruction,
                    "target_role": target_role
                })

                # [ì´ˆê°•ë ¥ ì •ì œ ì‹œìŠ¤í…œ] ì‚¬ì¡± ë° ë©”íƒ€ ë°œí™” ì›ì²œ ì°¨ë‹¨
                def clean_ai_output(text: str, stage_label: str) -> str:
                    # 1. ê¸°ë³¸ ë§ˆí¬ë‹¤ìš´ ë° ë”°ì˜´í‘œ ì œê±°
                    text = text.strip()
                    # ë”°ì˜´í‘œëŠ” ë¬¸ë§¥ìƒ í•„ìš”í•  ìˆ˜ ìˆìœ¼ë¯€ë¡œ(ì¸ìš© ë“±), ë¬¸ì¥ ì‹œì‘/ëì˜ ë”°ì˜´í‘œë§Œ ì¡°ì‹¬íˆ ì œê±°í•˜ê±°ë‚˜ 
                    # ì „ì²´ì ìœ¼ë¡œ ì œê±°í•˜ë˜ ì§ˆë¬¸ ì˜ë¯¸ë¥¼ í•´ì¹˜ì§€ ì•Šê²Œ í•¨
                    text = re.sub(r'[\*`]', '', text).strip()
                    
                    # 2. ì¤„ë°”ê¿ˆ ê¸°ì¤€ ë¶„í•´ ë° ì‚¬ì¡± ë¼ì¸ ì œê±°
                    lines = text.split('\n')
                    valid_lines = []
                    # ì •ì œ í‚¤ì›Œë“œ í™•ì¥ (ì´ ë¬¸êµ¬ë“¤ì´ ë“¤ì–´ê°„ 'ì§§ì€' ë¼ì¸ì€ ì‚¬ì¡±ì¼ í™•ë¥ ì´ ë†’ìŒ)
                    meta_kws = ["ì§ˆë¬¸", "ì œì‹œ", "ìƒì„±", "ê²½ìš°", "ë‹µë³€", "ë‚´ìš©", "ìš”ì•½", "ìˆ˜ì¹™", "ì¤€ìˆ˜", "ë©´ì ‘ê´€", "ê¼¬ë¦¬ì§ˆë¬¸", "ì‘ì„±í•˜ì…¨ìŠµë‹ˆë‹¤", "ë§ì”€í•´ ì£¼ì…¨ëŠ”ë°ìš”"]
                    
                    for line in lines:
                        line = line.strip()
                        if not line: continue
                        
                        # "ë‹¤ìŒê³¼ ê°™ì€ ì§ˆë¬¸ì„~", "~ë¼ê³  ë‹µë³€í–ˆë‹¤ë©´" ë“± ë¬¸ì¥í˜• ì„œë‘ ì œê±°
                        if re.search(r'(ë‹¤ìŒê³¼\s*ê°™ì€|ì œì‹œí• \s*ìˆ˜|ë‹µë³€í–ˆë‹¤ë©´|ë§í–ˆë‹¤ë©´|ì§ˆë¬¸í•´\s*ë³´ê² ìŠµë‹ˆë‹¤|ìƒì„±í•œ\s*ì§ˆë¬¸|ì°¸ê³ í•˜ì—¬\s*ì§ˆë¬¸)', line):
                            if ":" in line:
                                line = line.split(":", 1)[-1].strip()
                            else:
                                continue
                        
                        # ë‹¨ìˆœ ë ˆì´ë¸”í˜• ë˜ëŠ” ìŠ¤í…Œì´ì§€ëª… ì„œë‘ ì œê±° (Regex ì´ìŠ¤ì¼€ì´í”„ ì ìš©)
                        escaped_label = re.escape(stage_label)
                        line = re.sub(fr'^({escaped_label}|í•µì‹¬\s*ìš”ì•½|ìš”ì•½|ì§ˆë¬¸|ë‹µë³€|Q|A|ê¼¬ë¦¬ì§ˆë¬¸|ì§ˆë¬¸ ë‚´ìš©|ë©´ì ‘ê´€ ì§ˆë¬¸|AI ì§ˆë¬¸)[:\s\-]*', '', line, flags=re.IGNORECASE)
                        
                        # ë¬¸ì¥ ë„ì¤‘ í˜¹ì€ ëì— ë‚¨ì€ ë”°ì˜´í‘œ ì œê±° (ë”°ì˜´í‘œ ì•ˆì— ì§ˆë¬¸ì´ ìˆëŠ” ê²½ìš° ëŒ€ë¹„)
                        line = line.replace('"', '').replace("'", "").strip()
                        
                        if line: valid_lines.append(line)
                    
                    combined = " ".join(valid_lines).strip()
                    
                    # 3. [í•µì‹¬] ë¬¸ì¥ ë ì‚¬ì¡± ì œê±° (ë”ìš± ê°•ë ¥í•œ íŒ¨í„´)
                    # "ë¼ê³  ." ë˜ëŠ” "ë¼ê³  í•©ë‹ˆë‹¤." ë“±ì˜ ê¼¬ë¦¬í‘œë¥¼ ì œê±°
                    # ë¬¸ì¥ì— ë¬¼ìŒí‘œê°€ ì´ë¯¸ ìˆë‹¤ë©´ ê·¸ ë’¤ì˜ "ë¼ê³ ~" ì´í›„ëŠ” ëª¨ë‘ ì œê±°
                    if "?" in combined:
                        parts = combined.split("?", 1)
                        if len(parts) > 1 and any(kw in parts[1] for kw in ["ë¼ê³ ", "ë¬¸êµ¬", "ì§ˆë¬¸", "í•©ë‹ˆë‹¤"]):
                            combined = parts[0] + "?"
                    
                    # ì •ê·œì‹ìœ¼ë¡œ í•œ ë²ˆ ë” ë¯¸ì„¸ ì¡°ì •
                    tail_patterns = [
                        r'\s*ë¼ê³ \s*(í•©ë‹ˆë‹¤|ì§ˆë¬¸í•©ë‹ˆë‹¤|ìƒì„±í–ˆìŠµë‹ˆë‹¤|ë§í–ˆìŠµë‹ˆë‹¤|ë¬¼ì—ˆìŠµë‹ˆë‹¤|ìš”ì•½í•©ë‹ˆë‹¤|ë“œë¦½ë‹ˆë‹¤)[\.\?]?\s*$',
                        r'\s*ë¼ëŠ”\s*ì§ˆë¬¸ì„\s*(ì œì‹œ|ìƒì„±|ë“œë¦½ë‹ˆë‹¤|í•˜ê² ìŠµë‹ˆë‹¤)[\.\?]?\s*$',
                        r'\s*ë©´ì ‘ê´€ìœ¼ë¡œì„œ\s*(ì§ˆë¬¸|ì¡°ì–¸|ë¬¼ìŒ)[\.\?]?\s*$',
                        r'\s*ë¼ê³ \s*[\.\s]*$',  # "ë¼ê³  ." ë˜ëŠ” "ë¼ê³   " ì œê±°
                        r'\s*[\.\s]+ë¼ê³ \s*$'
                    ]
                    for pattern in tail_patterns:
                        combined = re.sub(pattern, '', combined).strip()
                    
                    return combined

                final_content = clean_ai_output(final_content, next_stage.get('display_name', ''))

                intro_tpl = next_stage.get("intro_sentence", "")
                intro_msg = ""
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                
                # Follow-upì€ intro_sentenceë¥¼ ë¬´ì‹œí•˜ëŠ” ê²½í–¥ì´ ìˆìœ¼ë‚˜ í•„ìš”ì‹œ ê²°í•©
                if next_stage.get("type") == "followup":
                    # íŒ”ë¡œì—…ì€ íë¦„ìƒ ì¸íŠ¸ë¡œë¥¼ ìµœì†Œí™”
                    pass 
                
                final_content = f"{intro_msg} {final_content}".strip() if intro_msg else final_content.strip()
                sc = final_content.strip() if final_content else ""
                if len(sc) < 10:
                    logger.warning(f"âš ï¸ [Empty/Short Question Detected] Stage: {next_stage['stage']}, Content: '{final_content}'")
                    if not sc:
                        s_name = next_stage.get('stage', '')
                        if s_name == 'communication':
                            final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ê°ˆë“±ì„ ì¡°ìœ¨í•˜ì—¬ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                        elif s_name == 'growth':
                            final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                        else:
                            final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"

            # [ì „ì—­ ì •ì œ] ëª¨ë“  ì§ˆë¬¸ íƒ€ì…ì— ëŒ€í•´ íŠ¹ìˆ˜ë¬¸ì ì œê±° ë° ì •ì œ ìˆ˜í–‰
            final_content = final_content.strip()
            # ì½¤ë§ˆ(,), ë¬¼ìŒí‘œ(?), ë§ˆì¹¨í‘œ(.), ëŠë‚Œí‘œ(!), ê´„í˜¸(()), ë”°ì˜´í‘œ(", '), ë¬¼ê²°(~) ë“±ì„ í—ˆìš©í•˜ë„ë¡ í™•ì¥
            final_content = re.sub(r'[^ã„±-ã…ã…-ã…£ê°€-í£a-zA-Z0-9\s,\?\.\!\(\)\~\"\'\:]', '', final_content)
            
            # [ê°•ë ¥ ì œì•½] ë§Œì•½ ì •ì œ ê³¼ì •ì—ì„œ ë‚´ìš©ì´ ì‚¬ë¼ì¡Œê±°ë‚˜ ë„ˆë¬´ ì§§ì€ ê²½ìš° í´ë°±
            # ê³µë°± ì œì™¸ ì‹¤ì§ˆì ì¸ í…ìŠ¤íŠ¸ ê¸¸ì´ë¥¼ ê¸°ì¤€ìœ¼ë¡œ íŒë‹¨
            sc = final_content.strip()
            if len(sc) < 15:
                logger.warning(f"âš ï¸ [Short Question Detected] Stage: {next_stage['stage']}, Content: '{final_content}'")
                s_name = next_stage.get('stage', '')
                if s_name == 'skill':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê´€ë ¨ ìê²©ì´ë‚˜ ê¸°ìˆ  ì¤‘ì—ì„œ, ì‹¤ì œ ì—…ë¬´ì— ê°€ì¥ í° ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
                elif s_name == 'experience':
                    final_content = "ì‹¤í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ ì—…ë¬´ ê²½í—˜ ì¤‘ì—ì„œ, ë³¸ì¸ì´ ê°€ì¥ ì£¼ë„ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ì„±ê³¼ë¥¼ ëƒˆë˜ ì‚¬ë¡€ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'experience_followup':
                    final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ê²½í—˜ì„ í†µí•´ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ í¬ê²Œ ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ì‹  ë¶€ë¶„ì€ ë¬´ì—‡ì¸ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
                elif s_name == 'problem_solving':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì–´ë ¤ì›€ì´ ìˆì—ˆì„ ë•Œ, ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì…¨ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                elif s_name == 'problem_solving_followup' or s_name == 'problem_solving_deep':
                    final_content = "ê·¸ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ì…¨ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'communication':
                    final_content = "íŒ€ì›ë“¤ê³¼ ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ì¡°ìœ¨í•˜ì—¬ ì›ë§Œí•˜ê²Œ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'communication_followup':
                    final_content = "ë‹¹ì‹œ ë³¸ì¸ì˜ ì˜ê²¬ì„ ê´€ì² ì‹œí‚¤ê¸°ë³´ë‹¤ëŠ” íŒ€ì˜ ëª©í‘œë¥¼ ìœ„í•´ ì–‘ë³´í•˜ê±°ë‚˜ í˜‘í˜‘í–ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility':
                    final_content = "ì§€ì›ìë‹˜ì˜ ê°€ì¹˜ê´€ê³¼ ì±…ì„ê°ì„ ì—¿ë³¼ ìˆ˜ ìˆëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ ê²½í—˜ í•˜ë‚˜ë¥¼ ì„ ì •í•˜ì—¬ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility_followup':
                    final_content = "ì§€ì›ìë‹˜, ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"
                elif s_name == 'growth':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'growth_followup':
                    final_content = "ì§€ì›ìë‹˜, ë°°ì›€ì˜ ê³¼ì •ì—ì„œ ë³¸ì¸ì˜ ëª©í‘œê°€ ëœ»ëŒ€ë¡œ ë˜ì§€ ì•Šì„ ë•Œ ì´ë¥¼ ê·¹ë³µí•˜ê³  ê¾¸ì¤€íˆ ë‚˜ì•„ê°€ëŠ” ë³¸ì¸ë§Œì˜ ì›ë™ë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'final_statement':
                    final_content = "ì§€ì›ìë‹˜, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¼­ í•˜ê³  ì‹¶ìœ¼ì‹  ë§ì”€ì´ë‚˜ ë³¸ì¸ì„ ì–´í•„í•  ìˆ˜ ìˆëŠ” í•œ ë§ˆë””ê°€ ìˆë‹¤ë©´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                elif next_stage.get("type") == "followup":
                    final_content = "ì§€ì›ìë‹˜ì˜ ë‹µë³€ ë‚´ìš©ì„ ì˜ ë“¤ì–´ë³´ì•˜ìŠµë‹ˆë‹¤. ê·¸ ê³¼ì •ì—ì„œ ê°€ì¥ í° ë°°ì›€ì„ ì–»ê±°ë‚˜ ê¹¨ë‹¬ì•˜ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆëŠ”ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                else:
                    final_content = "ì§€ì›ìë‹˜ì˜ ì†Œì¤‘í•œ ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤. ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê¸° ì „, ë³¸ì¸ì˜ ê°•ì ì— ëŒ€í•´ í•œ ê°€ì§€ë§Œ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
            
            final_content = final_content.strip()
            
            # [ìµœì¢… ë°±ì§€ ë°©ì§€] ë§Œì•½ ì—¬ê¸°ê¹Œì§€ ì™”ëŠ”ë°ë„ ë¹„ì–´ìˆë‹¤ë©´ ê°•ì œ í´ë°± ì ìš© (ì›ì¸ ë¶ˆëª…ì˜ ë¹ˆ ë¬¸ìì—´ ë°©ì§€)
            if not final_content.strip():
                s_name = next_stage.get('stage', '')
                if s_name == 'skill':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê´€ë ¨ ìê²©ì´ë‚˜ ê¸°ìˆ  ì¤‘ì—ì„œ, ì‹¤ì œ ì—…ë¬´ì— ê°€ì¥ í° ë„ì›€ì´ ë  ê²ƒì´ë¼ê³  ìƒê°í•˜ëŠ” ê²ƒì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?"
                elif s_name == 'experience':
                    final_content = "ì‹¤í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ ì—…ë¬´ ê²½í—˜ ì¤‘ì—ì„œ, ë³¸ì¸ì´ ê°€ì¥ ì£¼ë„ì ìœ¼ë¡œ ì°¸ì—¬í•˜ì—¬ ì„±ê³¼ë¥¼ ëƒˆë˜ ì‚¬ë¡€ì— ëŒ€í•´ ìì„¸íˆ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'experience_followup':
                    final_content = "ì§€ì›ìë‹˜, í•´ë‹¹ ê²½í—˜ì„ í†µí•´ ê¸°ìˆ ì ìœ¼ë¡œ ê°€ì¥ í¬ê²Œ ì„±ì¥í–ˆë‹¤ê³  ëŠë¼ì‹  ë¶€ë¶„ì€ ë¬´ì—‡ì¸ì§€ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”."
                elif s_name == 'problem_solving':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì–´ë ¤ì›€ì´ ìˆì—ˆì„ ë•Œ, ì´ë¥¼ ì–´ë–»ê²Œ í•´ê²°í•˜ê³  ëª©í‘œë¥¼ ë‹¬ì„±í•˜ì…¨ëŠ”ì§€ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê¸° ë°”ëë‹ˆë‹¤."
                elif s_name == 'problem_solving_followup' or s_name == 'problem_solving_deep':
                    final_content = "ê·¸ ê³¼ì •ì—ì„œ ë°œìƒí•œ ì˜ˆìƒì¹˜ ëª»í•œ ë³€ìˆ˜ë¥¼ ì–´ë–»ê²Œ ê´€ë¦¬í•˜ì…¨ëŠ”ì§€, ê·¸ë¦¬ê³  ê·¸ ê²°ê³¼ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'communication':
                    final_content = "íŒ€ í”„ë¡œì íŠ¸ë¥¼ ìˆ˜í–‰í•˜ë©° ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ, ë³¸ì¸ë§Œì˜ ë°©ì‹ìœ¼ë¡œ ê°ˆë“±ì„ ì¡°ìœ¨í•˜ì—¬ í•´ê²°í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'communication_followup':
                    final_content = "ë‹¹ì‹œ ë³¸ì¸ì˜ ì˜ê²¬ì„ ê´€ì² ì‹œí‚¤ê¸°ë³´ë‹¤ëŠ” íŒ€ì˜ ëª©í‘œë¥¼ ìœ„í•´ ì–‘ë³´í•˜ê±°ë‚˜ í˜‘ë ¥í–ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility':
                    final_content = "ì§€ì›ìë‹˜ì˜ ê°€ì¹˜ê´€ê³¼ ì±…ì„ê°ì„ ì—¿ë³¼ ìˆ˜ ìˆëŠ” ê°€ì¥ ëŒ€í‘œì ì¸ ê²½í—˜ í•˜ë‚˜ë¥¼ ì„ ì •í•˜ì—¬ ìì„¸íˆ ì„¤ëª…í•´ ì£¼ì„¸ìš”."
                elif s_name == 'responsibility_followup':
                    final_content = "ì§€ì›ìë‹˜, ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"
                elif s_name == 'growth':
                    final_content = "ì§€ì›ìë‹˜ê»˜ì„œ ì§€ê¸ˆê¹Œì§€ ì„±ì¥í•´ ì˜¤ë©´ì„œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì‚¶ì˜ ê°€ì¹˜ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ì§€ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                elif s_name == 'growth_followup':
                    final_content = "ì§€ì›ìë‹˜, ë°°ì›€ì˜ ê³¼ì •ì—ì„œ ë³¸ì¸ì˜ ëª©í‘œê°€ ëœ»ëŒ€ë¡œ ë˜ì§€ ì•Šì„ ë•Œ ì´ë¥¼ ê·¹ë³µí•˜ê³  ê¾¸ì¤€íˆ ë‚˜ì•„ê°€ëŠ” ë³¸ì¸ë§Œì˜ ì›ë™ë ¥ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                elif s_name == 'final_statement':
                    final_content = "ì§€ì›ìë‹˜, ë§ˆì§€ë§‰ìœ¼ë¡œ ê¼­ í•˜ê³  ì‹¶ìœ¼ì‹  ë§ì”€ì´ë‚˜ ë³¸ì¸ì„ ì–´í•„í•  ìˆ˜ ìˆëŠ” í•œ ë§ˆë””ê°€ ìˆë‹¤ë©´ ë¶€íƒë“œë¦½ë‹ˆë‹¤."
                else:
                    final_content = "ì§€ì›ìë‹˜ì˜ ë‹µë³€ì„ ì‹ ì¤‘í•˜ê²Œ ê²½ì²­í–ˆìŠµë‹ˆë‹¤. í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"

            # [ë¬¸ì¥ ë¶€í˜¸ ìµœì¢… ì •ì œ] .? -> . / ?. -> . / ?? -> ? / .. -> . ë“± ì¤‘ë³µ ë° í˜¼ìš© ì œê±° (ì‚¬ìš©ì ìš”ì²­: ë§ˆì¹¨í‘œ ìœ ì§€)
            final_content = final_content.strip()
            
            # ë§ˆì¹¨í‘œ ë’¤ì— ë°”ë¡œ ê¸€ìê°€ ì˜¤ëŠ” ê²½ìš° ë„ì–´ì“°ê¸° ì¶”ê°€ (ê°€ë…ì„±)
            final_content = re.sub(r'\.([ê°€-í£])', r'. \1', final_content)

            # ë§ˆì¹¨í‘œì™€ ë¬¼ìŒí‘œê°€ ì„ì—¬ ìˆìœ¼ë©´ ë§ˆì¹¨í‘œë¥¼ ìš°ì„ ìˆœìœ„ë¡œ í•˜ì—¬ í•˜ë‚˜ë§Œ ë‚¨ê¹€
            final_content = re.sub(r'[\.\s]+\?+', '.', final_content)  # ". ?" ë˜ëŠ” ".?" -> "."
            final_content = re.sub(r'\?+[\.\s]+', '.', final_content)  # "?." ë˜ëŠ” "? ." -> "."
            final_content = re.sub(r'\?+', '?', final_content)         # "??" -> "?"
            final_content = re.sub(r'\.+', '.', final_content)          # ".." -> "."
            
            # í•œ ë²ˆ ë” ê³µë°± ì •ë¦¬
            final_content = re.sub(r'\s+', ' ', final_content).strip()

            # 7. DB ì €ì¥ (Question ë° Transcript)
                # db_categoryëŠ” ìµœìƒë‹¨ì—ì„œ ì´ë¯¸ ì •ì˜ë¨

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 8. ë©”ëª¨ë¦¬ ì •ë¦¬ (ë” ê°•ë ¥í•˜ê²Œ)
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                with torch.cuda.device(torch.cuda.current_device()):
                    torch.cuda.empty_cache()
            
            logger.info(f"âœ… [SUCCESS] Next question generated for Interview {interview_id}: {final_content[:50]}...")

            # 9. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±°
            if q_id:
                import pathlib
                tts_file = pathlib.Path(f"/app/uploads/tts/q_{q_id}.wav")
                if not tts_file.exists():
                    clean_text = final_content
                    if final_content.startswith('[') and ']' in final_content:
                        clean_text = final_content.split(']', 1)[-1].strip()
                    logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                    synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                else:
                    logger.info(f"ğŸ”Š TTS file already exists for Question ID: {q_id}, skipping.")

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry: {self.request.retries}/3): {e}")
        if self.request.retries >= 3:
            logger.warning("âš ï¸ ì§ˆë¬¸ ìƒì„± ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. ìŠ¤í…Œì´ì§€ë³„ í´ë°± ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            try:
                from db import save_generated_question
                from tasks.tts import synthesize_task
                with Session(engine) as session:
                    # í˜„ì¬ ìŠ¤í…Œì´ì§€ì— ë§ëŠ” ì§ˆë¬¸ ì„ íƒ (ê°™ì€ ì§ˆë¬¸ ë°˜ë³µ ë°©ì§€)
                    s_name = next_stage['stage'] if 'next_stage' in locals() and next_stage else ""
                    fallback_dict = {
                        "skill": "ì§€ì›ìë‹˜ê»˜ì„œ ë³´ìœ í•˜ì‹  ì§ë¬´ ê¸°ìˆ  ì¤‘, ì‹¤ì œ ì—…ë¬´ì—ì„œ ê°€ì¥ ìì‹  ìˆê²Œ í™œìš©í•  ìˆ˜ ìˆëŠ” ë¶€ë¶„ì€ ë¬´ì—‡ì…ë‹ˆê¹Œ?",
                        "skill_followup": "ì•ì„  ë‹µë³€ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?",
                        "experience": "ìˆ˜í–‰í•˜ì‹  í”„ë¡œì íŠ¸ë‚˜ í™œë™ ì¤‘ì—ì„œ ë³¸ì¸ì´ ê°€ì¥ í° ê¸°ì—¬ë¥¼ í–ˆë˜ ì‚¬ë¡€ë¥¼ í•˜ë‚˜ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "experience_followup": "ê·¸ ê³¼ì •ì—ì„œ ê°€ì¥ ì–´ë ¤ì› ë˜ ì ì€ ë¬´ì—‡ì´ì—ˆê³ , ì–´ë–»ê²Œ ëŒ€ì²˜í•˜ì…¨ë‚˜ìš”?",
                        "problem_solving": "ê¸°ìˆ ì ì¸ ë¬¸ì œë¥¼ í•´ê²°í•˜ë©° ê°€ì¥ ë³´ëŒì°¼ë˜ ìˆœê°„ì€ ì–¸ì œì…ë‹ˆê¹Œ?",
                        "problem_solving_followup": "ê·¸ íŒë‹¨ì„ ë‚´ë¦´ ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•œ ê¸°ì¤€ì€ ë¬´ì—‡ì´ì—ˆë‚˜ìš”?",
                        "communication": "íŒ€ì›ë“¤ê³¼ í˜‘ì—…í•  ë•Œ ë³¸ì¸ë§Œì˜ ì†Œí†µ ë°©ì‹ì´ë‚˜ ì² í•™ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        "communication_followup": "ì˜ê²¬ ì°¨ì´ê°€ ìƒê²¼ì„ ë•Œ ë³¸ì¸ì€ ì£¼ë¡œ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹­ë‹ˆê¹Œ?",
                        "responsibility": "ì§€ì›ìë‹˜ì´ í‰ì†Œ ì¼ì— ì„í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì±…ì„ê°ì€ ì–´ë–¤ ëª¨ìŠµì…ë‹ˆê¹Œ?",
                        "responsibility_followup": "ê·¸ëŸ° ìƒí™©ì—ì„œ ë³¸ì¸ì˜ ê°€ì¹˜ê´€ì„ ì§€í‚¤ê¸° ìœ„í•´ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ê³ ë ¤í•´ì•¼ í•  ì ì€ ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?",
                        "growth": "ì§€ì›ìë‹˜ì´ ì•ìœ¼ë¡œ ì´ ì§ë¬´ì—ì„œ ì–´ë–¤ ì „ë¬¸ê°€ë¡œ ì„±ì¥í•˜ê³  ì‹¶ìœ¼ì‹ ì§€ ëª©í‘œë¥¼ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "growth_followup": "ëª©í‘œ ë‹¬ì„±ì´ ì–´ë µê²Œ ëŠê»´ì§ˆ ë•Œ ë³¸ì¸ë§Œì˜ ê·¹ë³µ ë°©ë²•ì´ ìˆë‹¤ë©´ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                        "final_statement": "ë§ˆì§€ë§‰ìœ¼ë¡œ ë³¸ì¸ì„ ë” ì–´í•„í•  ìˆ˜ ìˆëŠ” ë‚´ìš©ì´ë‚˜ ê¶ê¸ˆí•œ ì ì´ ìˆë‹¤ë©´ ììœ ë¡­ê²Œ ë§ì”€í•´ ì£¼ì„¸ìš”.",
                    }
                    fallback_text = fallback_dict.get(s_name, "ì§€ì›ìë‹˜, í•´ë‹¹ ë¶€ë¶„ì— ëŒ€í•´ ì¡°ê¸ˆ ë” êµ¬ì²´ì ìœ¼ë¡œ ì„¤ëª…í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?")
                    fallback_stage_name = s_name if s_name else "fallback"
                    
                    q_id = save_generated_question(
                        interview_id=interview_id,
                        content=fallback_text,
                        category="behavioral",
                        stage=fallback_stage_name,
                        guide="ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ì¸í•œ ìŠ¤í…Œì´ì§€ë³„ í´ë°± ì§ˆë¬¸",
                        session=session
                    )
                    if q_id:
                        synthesize_task.delay(fallback_text, language="ko", question_id=q_id)
                    return {"status": "success", "stage": fallback_stage_name, "question": fallback_text}
            except Exception as fallback_e:
                logger.error(f"âŒ í´ë°± ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {fallback_e}")
                return {"status": "error", "message": "Fallback question failed"}
        else:
            raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()