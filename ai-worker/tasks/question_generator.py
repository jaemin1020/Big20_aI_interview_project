import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================

PROMPT_TEMPLATE = """[|system|]ë‹¹ì‹ ì€ ì§€ì›ìì˜ ì—­ëŸ‰ì„ ì •ë°€í•˜ê²Œ ê²€ì¦í•˜ëŠ” ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì œê³µëœ [ì´ë ¥ì„œ ë¬¸ë§¥]ê³¼ [ë©´ì ‘ ì§„í–‰ ìƒí™©]ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì—ê²Œ ë˜ì§ˆ 'ë‹¤ìŒ ì§ˆë¬¸' 1ê°œë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
2. ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•˜ë©°, 150ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
3. íŠ¹ìˆ˜ë¬¸ì(JSON ê¸°í˜¸, ì—­ë”°ì˜´í‘œ ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. "ì§ˆë¬¸:" ì´ë¼ëŠ” ìˆ˜ì‹ì–´ ì—†ì´ ë°”ë¡œ ì§ˆë¬¸ ë³¸ë¬¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
5. ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ í•˜ì‹­ì‹œì˜¤.
6. **í™˜ê° ì£¼ì˜**: ì´ë ¥ì„œì— "ìµíˆê³  ì‹¶ë‹¤", "ê³µë¶€í•  ê³„íšì´ë‹¤", "ì„±ì¥í•˜ê² ë‹¤" ë“± ë¯¸ë˜ í¬ë¶€ë¡œ ì íŒ ë‚´ìš©ì€ ì‹¤ì œ ì‹¤ë¬´ ê²½í—˜ì´ë‚˜ í”„ë¡œì íŠ¸ ì„±ê³¼ë¡œ ì·¨ê¸‰í•˜ì—¬ ì§ˆë¬¸í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë¯¸ë˜ í¬ë¶€ëŠ” í•™ìŠµ ì˜ì§€ë‚˜ ê´€ì‹¬ë„ë¥¼ ë¬»ëŠ” ìš©ë„ë¡œë§Œ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.
7. **ê¼¬ë¦¬ì§ˆë¬¸(Follow-up) ê·œì¹™**: ì§€ì›ìì˜ ë‹µë³€ì— ëŒ€í•œ ê¼¬ë¦¬ì§ˆë¬¸ì„ í•  ë•ŒëŠ” ë°˜ë“œì‹œ ì§€ì›ìì˜ ë‹µë³€ ë‚´ìš©ì„ ë¨¼ì € í•œ ë¬¸ì¥ìœ¼ë¡œ ìš”ì•½í•˜ê³ , ë‹µë³€ì—ì„œ ì‚¬ìš©ëœ êµ¬ì²´ì ì¸ ê¸°ìˆ  ìš©ì–´ë‚˜ ê³ ìœ  ëª…ì‚¬ë¥¼ í™œìš©í•˜ì—¬ ë” ê¹Šì€ ë‚´ìš©ì„ ë¬¼ì–´ë³´ì‹­ì‹œì˜¤. ë‹µë³€ì— ì—†ëŠ” ë»”í•œ ì§ˆë¬¸ì€ í”¼í•˜ì‹­ì‹œì˜¤.

[ì´ë ¥ì„œ ë° ë‹µë³€ ë¬¸ë§¥]
{context}

[í˜„ì¬ ë©´ì ‘ ë‹¨ê³„ ì •ë³´]
- ë‹¨ê³„ëª…: {stage_name}
- ê°€ì´ë“œ: {guide}

[|user|]ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ë©”ì¸ ì‘ì—…: ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬
# ==========================================

@shared_task(name="tasks.question_generation.generate_next_question")
def generate_next_question_task(interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ AI ë°œí™” í™•ì¸ (Stage íŒë³„ + ì¤‘ë³µ ë°©ì§€)
            # [ìˆ˜ì •] User transcriptëŠ” question_idê°€ ì—†ì–´ stage íŒë³„ ë¶ˆê°€ â†’ ë§ˆì§€ë§‰ AI ë°œí™” ê¸°ì¤€ìœ¼ë¡œ íŒë³„
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.order.desc())
            last_transcript = session.exec(stmt_all).first()

            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.order.desc(), Transcript.id.desc())  # idë¥¼ tiebreakerë¡œ ì‚¬ìš© (order ê°™ì„ ë•Œ ìµœì‹  AI ë°œí™” ë³´ì¥)
            last_ai_transcript = session.exec(stmt_ai).first()

            # ë§ˆì§€ë§‰ AI ë°œí™”ê°€ 10ì´ˆ ì´ë‚´ë¼ë©´ ìŠ¤í‚µ (Race Condition ë°©ì§€)
            if last_ai_transcript:
                diff = (datetime.utcnow() - last_ai_transcript.timestamp).total_seconds()
                if diff < 10:
                    logger.info(f"Skipping duplicate request for interview {interview_id}")
                    return {"status": "skipped"}

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ê¼¬ë¦¬ì§ˆë¬¸(followup) ìƒì„± ì œí•œ ë¡œì§
            # ë‹¤ìŒ ë‹¨ê³„ê°€ followupì¸ë°, ë§ˆì§€ë§‰ ë°œí™”ìê°€ ì—¬ì „íˆ AIë¼ë©´ ì§€ì›ìê°€ ì•„ì§ ë‹µë³€ì„ ì•ˆ í•œ ê²ƒì„.
            if next_stage.get("type") == "followup":
                if last_transcript and last_transcript.speaker == "AI":
                    logger.info(f"Next stage is followup, but WAITING for user answer. Skipping generation.")
                    return {"status": "waiting_for_user"}

            # [ì¤‘ë³µ ë°©ì§€ ê°œì„ ] next_stageê°€ ì´ë¯¸ ìƒì„±ëëŠ”ì§€ í™•ì¸ (timestamp ê¸°ë°˜ X â†’ stage ê¸°ë°˜ O)
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    diff = (datetime.utcnow() - last_ai_transcript.timestamp).total_seconds()
                    if diff < 30:
                        logger.info(f"Next stage '{next_stage['stage']}' already generated {diff:.1f}s ago, skipping duplicate")
                        return {"status": "skipped"}

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                candidate_name = "ì§€ì›ì"
                target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
                course_name = "ê´€ë ¨ í”„ë¡œì íŠ¸"
                cert_name = "ê´€ë ¨ ìê²©"

                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str):
                        sd = json.loads(sd)
                    
                    candidate_name = sd.get("header", {}).get("name") or sd.get("header", {}).get("candidate_name") or "ì§€ì›ì"
                    target_role = sd.get("header", {}).get("target_role") or target_role
                    
                    # 1. ì§€ì› ì§ë¬´ì™€ ê´€ë ¨ëœ í•µì‹¬ í‚¤ì›Œë“œ (ìš°ì„ ìˆœìœ„ ë¶€ì—¬ìš©)
                    priority_keywords = ["ë°ì´í„°", "ë¶„ì„", "RAG", "AI", "í´ë¼ìš°ë“œ", "ì´ì»¤ë¨¸ìŠ¤", "ì‹œìŠ¤í…œ", "ì˜ˆì¸¡", "ëª¨ë¸ë§", "SQL", "ë³´ì•ˆ","ì •ë³´",'ì»´í“¨í„°']
                    # 2. ì œì™¸í•´ì•¼ í•  ë‹¨ì–´ (ê°€ì´ë“œ ë¬¸êµ¬ë‚˜ ë¬´ê´€í•œ ë°ì´í„°)
                    blacklist = ["ê³¼ì •ëª…", "ë‚´ìš©", "ìƒì„¸ ë‚´ìš©", "ìƒì„¸ë‚´ìš©", "ì œëª©", "ê¸°ê°„", "ìê²©ì¦ëª…", "ìš´ì „ë©´í—ˆ"]

                    # í”„ë¡œì íŠ¸ ì „ë¬¸ ë°ì´í„°ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                    projects = sd.get("projects", [])
                    found_project = None
                    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œê°€ í¬í•¨ëœ í”„ë¡œì íŠ¸ ë¨¼ì € ì°¾ê¸°
                    for p in projects:
                        title = p.get("title") or p.get("name") or ""
                        if any(kw in title for kw in priority_keywords) and not any(bl in title for bl in blacklist):
                            found_project = title
                            break
                    # ëª» ì°¾ì•˜ë‹¤ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸ë§Œ í”¼í•´ì„œ ì°¾ê¸°
                    if not found_project:
                        for p in projects:
                            title = p.get("title") or p.get("name") or ""
                            if title and not any(bl in title for bl in blacklist):
                                found_project = title
                                break
                    if found_project: course_name = found_project
                    
                    # ìê²©ì¦ ì „ë¬¸ ë°ì´í„°ì—ì„œ ì´ë¦„ ì¶”ì¶œ
                    certs = sd.get("certifications", [])
                    found_cert = None
                    # ìš°ì„ ìˆœìœ„ í‚¤ì›Œë“œ ìê²©ì¦ ì°¾ê¸°
                    for c in certs:
                        title = c.get("title") or c.get("name") or ""
                        if any(kw in title for kw in priority_keywords) and not any(bl in title for bl in blacklist):
                            found_cert = title
                            break
                    # ëª» ì°¾ì•˜ë‹¤ë©´ ë¸”ë™ë¦¬ìŠ¤íŠ¸(ìš´ì „ë©´í—ˆ ë“±) í”¼í•´ì„œ ì°¾ê¸°
                    if not found_cert:
                        for c in certs:
                            title = c.get("title") or c.get("name") or ""
                            if title and not any(bl in title for bl in blacklist):
                                found_cert = title
                                break
                    if found_cert: cert_name = found_cert

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "major": major or "ë³´ê´€ ì „ê³µ",
                    "course_name": course_name,
                    "cert_name": cert_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except KeyError:
                    # í•„ìš”í•œ í‚¤ê°€ ì—†ì„ ê²½ìš°ë¥¼ ëŒ€ë¹„í•œ ì•ˆì „ ì¥ì¹˜
                    formatted = tpl.replace("{candidate_name}", candidate_name).replace("{course_name}", course_name).replace("{cert_name}", cert_name)

                intro_msg = next_stage.get("intro_sentence", "")
                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"Template stage '{next_stage['stage']}' (v2) â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ (Direct Extraction)")

            else:
                # 4-b. AI stage: ë¬¸ë§¥ í™•ë³´ í›„ LLM ìƒì„±
                query_template = next_stage.get("query_template", interview.position)
                try:
                    query = query_template.format(
                        target_role=interview.position or "í•´ë‹¹ ì§ë¬´",
                        major=major or ""
                    )
                except (KeyError, ValueError):
                    query = query_template 
                
                # [ê°œì„ ] ì¹´í…Œê³ ë¦¬ê°€ 'certification'ì¸ ê²½ìš° RAG ëŒ€ì‹  êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ì§ì ‘ ì¶”ì¶œ (ì •í™•ë„ 100%)
                category_raw = next_stage.get("category")
                rag_results = []
                context_text = ""

                if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    certs = sd.get("certifications", [])
                    # ì§ë¬´ ê´€ë ¨ì„± ë†’ì€ ìê²©ì¦ ìš°ì„  í•„í„°ë§ (í‚¤ì›Œë“œ ê¸°ë°˜)
                    important_certs = [c for c in certs if any(kw in c.get('title', '') for kw in ["ë°ì´í„°", "ë¶„ì„", "RAG", "AI", "í´ë¼ìš°ë“œ", "SQL", "ADSP", "ì •ë³´ì²˜ë¦¬"])]
                    
                    # ë§Œì•½ í•„í„°ë§ëœ ê²Œ ì—†ë‹¤ë©´ ì „ì²´ ìê²©ì¦ ì‚¬ìš©
                    final_certs = important_certs if important_certs else certs
                    
                    if final_certs:
                        logger.info(f"âœ… RAG ê±´ë„ˆëœ€: êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ìê²©ì¦ {len(final_certs)}ê°œë¥¼ ì§ì ‘ ê°€ì ¸ì™”ìŠµë‹ˆë‹¤.")
                        context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + "\n".join([f"- ìê²©ëª…: {c.get('title')}, ë°œí–‰ê¸°ê´€: {c.get('organization')}, ì¼ì: {c.get('date')}" for c in final_certs])
                        # intro_sentence í¬ë§·íŒ… í˜¸í™˜ì„±ì„ ìœ„í•´ rag_results í˜•íƒœë¡œ ë³€í™˜ (ì²« ë²ˆì§¸ ê²ƒë§Œ)
                        rag_results = [{'text': f"ìê²©ëª…: {final_certs[0].get('title')}"}]
                    else:
                        logger.info("âš ï¸ ì´ë ¥ì„œì— ìê²©ì¦ ì •ë³´ê°€ ì—†ì–´ ì¼ë°˜ RAG ê²€ìƒ‰ìœ¼ë¡œ ì „í™˜í•©ë‹ˆë‹¤.")
                        rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3)
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                else:
                    # ì¼ë°˜ì ì¸ ê²½ìš°ì—ëŠ” RAG ê²€ìƒ‰ ìˆ˜í–‰
                    filter_type = None
                    if category_raw == "certification": filter_type = "certifications"
                    
                    rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3, filter_type=filter_type)
                    context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"

                if last_transcript and last_transcript.speaker == "User":
                    context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_transcript.text}"
                    
                    # [ì¶”ê°€] ê¼¬ë¦¬ì§ˆë¬¸ ì‹œ ì§ˆë¬¸ ì€í–‰(13,000ê°œ ë°ì´í„°) í™œìš©
                    if next_stage.get("type") == "followup":
                        logger.info(f"ğŸ” Searching Question Bank for smarter follow-up. Query: '{last_transcript.text[:30]}...'")
                        similar_questions = retrieve_similar_questions(last_transcript.text, top_k=3)
                        if similar_questions:
                            context_text += "\n\n[ì°¸ê³ í•  ë§Œí•œ ì „ë¬¸ ë©´ì ‘ ì§ˆë¬¸ ëª©ë¡]:\n"
                            context_text += "\n".join([f"- {q['text']}" for q in similar_questions])
                            context_text += "\n(ê°€ì´ë“œ: ìœ„ ì§ˆë¬¸ ëª©ë¡ì˜ ìˆ˜ì¤€ê³¼ í˜•ì‹ì„ ì°¸ê³ í•˜ì—¬, ì§€ì›ìì˜ ë‹µë³€ì„ ìš”ì•½í•œ ë’¤ êµ¬ì²´ì ìœ¼ë¡œ ê¼¬ë¦¬ì§ˆë¬¸ì„ í•˜ì„¸ìš”.)"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "guide": next_stage.get('guide', '')
                })

                # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì¡°í•© (3ë²ˆ ì§ˆë¬¸ ì „ìš© ë¡œì§ í¬í•¨)
                candidate_name = "ì§€ì›ì"
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    candidate_name = sd.get("header", {}).get("name", "ì§€ì›ì")

                intro_tpl = next_stage.get("intro_sentence", "")
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    # RAG ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ìê²©ì¦ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        # "[ìê²©ì¦] ìê²©ëª…: XXX" í˜•íƒœì—ì„œ ì´ë¦„ ì¶”ì¶œ
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                else:
                    intro_msg = ""

                if next_stage.get("type") == "followup":
                    intro_msg = "ë‹µë³€ ê°ì‚¬í•©ë‹ˆë‹¤. ì¶”ê°€ì ìœ¼ë¡œ ê¶ê¸ˆí•œ ì ì´ ìˆìŠµë‹ˆë‹¤."
                
                display_name = next_stage.get("display_name", "ì‹¬ì¸µ ë©´ì ‘")
                final_content = f"[{display_name}] {intro_msg} {final_content}".strip() if intro_msg else f"[{display_name}] {final_content}".strip()

            # 6. DB ì €ì¥ (Question ë° Transcript)

            # 6. DB ì €ì¥ (Question ë° Transcript)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 7. ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 8. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±°
            if q_id:
                logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                synthesize_task.delay(final_content, language="auto", question_id=q_id)

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry ì‹œë„): {e}")
        raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()