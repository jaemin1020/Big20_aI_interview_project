import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime, timezone
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

def is_meaningless(text: str) -> bool:
    """ì§€ì›ìì˜ ë‹µë³€ì´ ë¬´ì˜ë¯¸í•œì§€(ììŒ ë‚˜ì—´, ë„ˆë¬´ ì§§ìŒ ë“±) ì²´í¬í•©ë‹ˆë‹¤."""
    if not text: return True
    text = text.strip()
    # 1. ë„ˆë¬´ ì§§ìŒ (5ì ë¯¸ë§Œ)
    if len(text) < 5: return True
    # 2. ììŒ/ëª¨ìŒë§Œ ë‚˜ì—´ (ã„´ã…‡ã„¹ã„´ã…‡ã„¹, ã…‹ã…‹ã…‹ã…‹ ë“±)
    if re.fullmatch(r'[ã„±-ã…ã…-ã…£\s]+', text): return True
    # 3. ë‹¨ìˆœ íŠ¹ìˆ˜ë¬¸ì/ìˆ«ì ë°˜ë³µ (...., 123123 ë“±)
    if re.fullmatch(r'[\.\,\!\?\-\=\s\d]+', text): return True
    # 4. ì˜ì–´ ëœë¤ ë¬¸ìì—´ (asdf, qwer ë“±)
    if re.fullmatch(r'[a-zA-Z]{1,5}', text): return True
    return False

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================
PROMPT_TEMPLATE = """[|user|]ë‹¹ì‹ ì€ ì „ë¬¸ì ì¸ ì§€ì‹ê³¼ ê³µì •í•œ íƒœë„ë¥¼ ê²¸ë¹„í•œ ë² í…Œë‘ AI ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ë‹¤ìŒ ì§€ì¹¨ì— ë”°ë¼ ì§€ì›ìì˜ ì ì¬ë ¥ì„ ì˜ˆë¦¬í•˜ê²Œ íŒŒì•…í•  ìˆ˜ ìˆëŠ” **ë‹¨ í•˜ë‚˜ì˜ ì§ˆë¬¸**ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.

### [ë©´ì ‘ ì „ëµ ë° í˜ë¥´ì†Œë‚˜]
- í‰ê°€ ëŒ€ìƒ ì§ë¬´: {target_role}
- í•µì‹¬ ì¸ì¬ìƒ: {company_ideal}
- ë©´ì ‘ ë‹¨ê³„: {stage_name} ({guide})

### [ì°¸ê³  ë¬¸ë§¥: ì§€ì›ì ì •ë³´ ë° ì´ì „ ë‹µë³€]
{context}

### [ì‹¤ì‹œê°„ í•µì‹¬ ì„ë¬´]
- ìˆ˜í–‰ ê³¼ì—…: {mode_task_instruction}
- ì‹¤í–‰ ìƒì„¸: {mode_instruction}
- ì „ì—­ ì œì•½: {global_constraint}

### [ì¶œë ¥ ê·œì¹™ - ë°˜ë“œì‹œ ì¤€ìˆ˜]
1. ì¸ì‚¬ë§, ë¶€ì—° ì„¤ëª…, ìê¸°ì†Œê°œ, ê°€ì„¤ ì œì‹œë¥¼ ì ˆëŒ€ í•˜ì§€ ë§ˆì‹­ì‹œì˜¤.
2. "ì§ˆë¬¸ì…ë‹ˆë‹¤", "ë‹¤ìŒ ì§ˆë¬¸ì€" ë“± ì„œë‘ë¥¼ ì¼ì ˆ ë¶™ì´ì§€ ë§ˆì‹­ì‹œì˜¤.
3. ì˜¤ì§ ì§€ì›ìì—ê²Œ ì§ì ‘ ë˜ì§€ëŠ” **ë¬¼ìŒí‘œ(?)ë¡œ ëë‚˜ëŠ” ë‹¨ì¼ ë¬¸ì¥ì˜ ì§ˆë¬¸**ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
4. ì „ë¬¸ì ì¸ í•œêµ­ì–´ êµ¬ì–´ì²´(í•˜ì‹­ì‹œì˜¤ì²´)ë¥¼ ì‚¬ìš©í•˜ì‹­ì‹œì˜¤.[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ëª¨ë¸ ì‚¬ì „ ë¡œë”© ë° ë©”ì¸ ì‘ì—…
# ==========================================

@shared_task(name="tasks.question_generation.preload_model")
def preload_model_task():
    """
    EXAONE ëª¨ë¸ì„ ë¹„ë™ê¸°ë¡œ ë¯¸ë¦¬ ë¡œë“œí•©ë‹ˆë‹¤. (ë©´ì ‘ ì‹œì‘ ì‹œ í˜¸ì¶œ)
    """
    from utils.exaone_llm import get_exaone_llm
    try:
        logger.info("ğŸ”¥ [Preload] Starting EXAONE model preloading...")
        get_exaone_llm() # ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ìƒì„± ì‹œ ëª¨ë¸ ë¡œë“œë¨
        logger.info("âœ… [Preload] EXAONE model preloaded inside Celery worker.")
        return {"status": "success", "message": "Model preloaded"}
    except Exception as e:
        logger.error(f"âŒ [Preload] Failed to preload model: {e}")
        return {"status": "error", "message": str(e)}

@shared_task(bind=True, name="tasks.question_generation.generate_next_question")
def generate_next_question_task(self, interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question, Company
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ ë° Stage íŒë³„
            # [ìˆ˜ì •] ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ (Order í•„ë“œ ëŒ€ì‹  ID/ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •í•©ì„± í™•ë³´)
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.id.desc())
            last_transcript = session.exec(stmt_all).first()

            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.id.desc())
            last_ai_transcript = session.exec(stmt_ai).first()

            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.USER
            ).order_by(Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # [ì‚­ì œ] 10ì´ˆ ì´ë‚´ ìŠ¤í‚µ ë¡œì§ (Race Condition ë°©ì§€ ëª©ì ì´ì—ˆìœ¼ë‚˜ ì´ˆê¸° í…œí”Œë¦¿ ë¡œë“œ ì‹œ ë°©í•´ë¨)

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ë™ê¸°í™” ë¡œì§: ì´ë¯¸ AIê°€ ë‹¤ìŒ ì§ˆë¬¸(ë“¤)ì„ ë˜ì¡ŒëŠ”ë° ì‚¬ìš©ìê°€ ì•„ì§ ì´ì „ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì¤‘ì´ë¼ë©´ ëŒ€ê¸°
            if last_ai_transcript and last_user_transcript:
                # ë§ˆì§€ë§‰ AI ë°œí™”ê°€ ì•„ì§ ì‚¬ìš©ì ë‹µë³€ì— ì˜í•´ ì°¸ì¡°ë˜ì§€ ì•Šì•˜ë‹¤ë©´? (ì¦‰, ì•„ì§ ë‹µí•˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´)
                if last_user_transcript.question_id != last_ai_transcript.question_id:
                    logger.info(f"AI has already spoken up to stage '{last_stage_name}', but user just answered a previous question. Waiting for user to answer current question.")
                    return {"status": "waiting_for_user_to_catch_up"}

            # [ìˆ˜ì •] ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°œì„ : ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì •ë³´ë¥¼ í•¨ê»˜ ë¦¬í„´
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    logger.info(f"Next stage '{next_stage['stage']}' already exists. Re-triggering TTS/Broadcast.")
                    # TTS ë‹¤ì‹œ í•œ ë²ˆ ì°”ëŸ¬ì¤Œ (ì´ë¯¸ ìˆìœ¼ë©´ 1ì´ˆë„ ì•ˆ ê±¸ë¦¼)
                    synthesize_task.delay(last_ai_transcript.text, language="auto", question_id=last_ai_transcript.question_id)
                    return {
                        "status": "success", 
                        "stage": next_stage['stage'], 
                        "question": last_ai_transcript.text,
                        "question_id": last_ai_transcript.question_id
                    }
            # [ìˆ˜ì •] ê³µí†µ ì •ë³´ ì¶”ì¶œ (í…œí”Œë¦¿/AI/ê¼¬ë¦¬ì§ˆë¬¸ ëª¨ë‘ ì‚¬ìš©)
            candidate_name = "ì§€ì›ì"
            target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
            company_name = "ì €í¬ íšŒì‚¬"
            company_ideal = "ëˆ„êµ¬ë‚˜ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” ê¸°ìˆ ì„ í†µí•´ ì‚¬ìš©ìì˜ ì„¸ê³„ë¥¼ í™•ì¥í•˜ê³ , ìƒˆë¡œìš´ ê´€ì ê³¼ ì•„ì´ë””ì–´ë¡œ ì„¸ìƒì„ í’ìš”ë¡­ê²Œ í•˜ëŠ” ì¸ì¬" # ê¸°ë³¸ê°’

            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str): sd = json.loads(sd)
                header = sd.get("header", {})
                candidate_name = header.get("name") or header.get("candidate_name") or candidate_name
                target_role = header.get("target_role") or target_role
                company_name = header.get("target_company") or header.get("company") or company_name

            # DBì—ì„œ íšŒì‚¬ì˜ ì¸ì¬ìƒ(ideal) ì¡°íšŒ
            db_company = None
            if interview.company_id:
                db_company = session.get(Company, interview.company_id)
            if not db_company and company_name != "ì €í¬ íšŒì‚¬":
                stmt_co = select(Company).where(Company.company_name == company_name)
                db_company = session.exec(stmt_co).first()
            
            if db_company and db_company.ideal:
                company_ideal = db_company.ideal
                logger.info(f"ğŸ¢ Dynamic Talent Image Loaded: {company_ideal[:30]}...")

            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                cert_list = ""
                act_org, act_role = "ê´€ë ¨ ê¸°ê´€", "ë‹´ë‹¹ ì—…ë¬´"
                proj_org, proj_name = "í•´ë‹¹ ê¸°ê´€", "ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸"
                
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    # 1. ìê²©ì¦ ë¦¬ìŠ¤íŠ¸ì—…
                    certs = sd.get("certifications", [])
                    if certs:
                        cert_names = [c.get("title") or c.get("name") for c in certs if (c.get("title") or c.get("name"))]
                        cert_list = ", ".join(cert_names)
                    
                    # 4-1. ê²½ë ¥ (activities)
                    acts = sd.get("activities", [])
                    act_header_kws = ["ê¸°ê°„", "ì—­í• ", "ê¸°ê´€", "ì†Œì†", "ì¥ì†Œ", "ì œëª©", "ë‚´ìš©"]
                    for act in acts:
                        tmp_org = act.get("organization") or act.get("name") or ""
                        tmp_role = act.get("role") or act.get("position") or ""
                        if not any(kw in tmp_org for kw in act_header_kws) and not any(kw in tmp_role for kw in act_header_kws):
                            act_org = tmp_org or act_org
                            act_role = tmp_role or act_role
                            break
                    
                    # 4-2. í”„ë¡œì íŠ¸ (projects)
                    projs = sd.get("projects", [])
                    proj_header_kws = ["ê¸°ê°„", "ì œëª©", "ê³¼ì •ëª…", "ê¸°ê´€", "ì„¤ëª…", "ë‚´ìš©"]
                    for proj in projs:
                        tmp_name = proj.get("title") or proj.get("name") or ""
                        tmp_org = proj.get("organization") or ""
                        if not any(kw in tmp_name for kw in proj_header_kws) and not any(kw in tmp_org for kw in proj_header_kws):
                            proj_name = tmp_name or proj_name
                            proj_org = tmp_org or proj_org
                            break
                
                if not cert_list: cert_list = "ê´€ë ¨ ìê²©"

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "company_name": company_name,
                    "company_ideal": company_ideal,
                    "major": major or "í•´ë‹¹ ì „ê³µ",
                    "cert_list": cert_list,
                    "act_org": act_org,
                    "act_role": act_role,
                    "proj_org": proj_org,
                    "proj_name": proj_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except Exception as e:
                    logger.warning(f"Template formatting error: {e}")
                    for k, v in template_vars.items():
                        tpl = tpl.replace("{" + k + "}", str(v))
                    formatted = tpl

                intro_msg = next_stage.get("intro_sentence", "")
                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"Template stage '{next_stage['stage']}' â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ")

            else:
                category_raw = next_stage.get("category")
                
                # [í•µì‹¬ ìˆ˜ì •] narrative ì¹´í…Œê³ ë¦¬(9-14ë²ˆ)ëŠ” ì´ë ¥ì„œ RAGë¥¼ ê±´ë„ˆë›°ê³  ì¸ì¬ìƒì—ë§Œ ì§‘ì¤‘
                if next_stage.get("type") == "followup":
                    logger.info("ğŸ¯ Follow-up mode: Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                elif category_raw == "narrative":
                    if next_stage.get("stage") == "responsibility":
                        # [íŠ¹ìƒí™œìš©] 11ë²ˆ ì±…ì„ê°/ê°€ì¹˜ê´€ ì§ˆë¬¸ì€ ì´ë ¥ì„œ(ìê¸°ì†Œê°œì„œ) ê¸°ë°˜ìœ¼ë¡œ ìƒì„±
                        logger.info("âœ¨ Responsibility Stage (11): Prioritizing Self-Intro Question 1 for values.")
                        
                        # 1. êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ [ì§ˆë¬¸1] ì •ë°€ íƒìƒ‰
                        values_text = ""
                        try:
                            if interview.resume and interview.resume.structured_data:
                                s_data = interview.resume.structured_data
                                if isinstance(s_data, str): s_data = json.loads(s_data)
                                
                                self_intro_list = s_data.get("self_intro", [])
                                for item in self_intro_list:
                                    if "[ì§ˆë¬¸1]" in item.get("question", ""):
                                        values_text = f"[ì§€ì›ì ìê¸°ì†Œê°œì„œ ì§ˆë¬¸1 ë‹µë³€]: {item.get('answer', '')}"
                                        logger.info("ğŸ“ Found Question 1 in Self-Intro.")
                                        break
                        except Exception as e:
                            logger.error(f"Failed to extract self_intro values: {e}")

                        # 2. RAG ê²°ê³¼ì™€ ê²°í•©
                        rag_results = retrieve_context("ì§€ì›ìì˜ ê·¼ë³¸ì ì¸ ê°€ì¹˜ê´€, ìƒí™œ ì‹ ë…, ì§ì—… ìœ¤ë¦¬, ì •ì§í•¨", resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = f"{values_text}\n\n[ì¶”ê°€ ì°¸ê³  ì •ë³´]:\n{rag_context}".strip()
                        if not context_text: context_text = "íŠ¹ë³„í•œ ê°€ì¹˜ê´€ ì •ë³´ ì—†ìŒ"
                    else:
                        # [ê°œì„ ] 9-14ë²ˆ ì¸ì„± ë©´ì ‘: ê° ì—­ëŸ‰(í˜‘ì—…, ì„±ì¥, ì±…ì„ê°)ì— íŠ¹í™”ëœ RAG ìˆ˜í–‰
                        s_name = next_stage.get('stage', '')
                        behavioral_keywords = {
                            "communication": "í˜‘ì—… ì‚¬ë¡€, íŒ€ í”„ë¡œì íŠ¸ ì¤‘ ê°ˆë“± ì¡°ìœ¨, íŒ€ì›Œí¬ ë°œíœ˜, ì†Œí†µ ëŠ¥ë ¥",
                            "growth": "ìê¸°ê³„ë°œ ë…¸ë ¥, ìƒˆë¡œìš´ ê¸°ìˆ  í•™ìŠµ íƒœë„, ì‹¤íŒ¨ ê·¹ë³µ ë° ì„±ì¥ ì‚¬ë¡€",
                            "responsibility": "ì§ì—… ìœ¤ë¦¬, ì•½ì† ì´í–‰, ì •ì§í•¨ê³¼ ê´€ë ¨ëœ ê²½í—˜"
                        }
                        # í•´ë‹¹ ë‹¨ê³„ì— ë§ëŠ” ì¿¼ë¦¬ ì„ íƒ (ì—†ìœ¼ë©´ ê¸°ë³¸ ê°€ì¹˜ê´€ ê²½í—˜ ê²€ìƒ‰)
                        target_query = behavioral_keywords.get(s_name, "ë³¸ì¸ì˜ ê°•ì , ì„±ì·¨ê°, ë„ì „ì ì¸ ê²½í—˜ ì‚¬ë¡€")
                        
                        logger.info(f"âœ¨ Behavioral RAG ({s_name}): Searching for '{target_query}'")
                        rag_results = retrieve_context(target_query, resume_id=interview.resume_id, top_k=2)
                        rag_context = "\n".join([r['text'] for r in rag_results]) if rag_results else ""
                        
                        context_text = (
                            f"ì´ ë‹¨ê³„ëŠ” {next_stage['display_name']}ë¥¼ í™•ì¸í•˜ëŠ” ì¸ì„± ë©´ì ‘ì…ë‹ˆë‹¤.\n"
                            f"ì§€ì›ìì˜ ê¸°ìˆ ë ¥ ê²€ì¦ë³´ë‹¤ëŠ” **íƒœë„, ê°€ì¹˜ê´€, ì¡°ì§ ì ì‘ë ¥**ì„ íŒŒì•…í•˜ëŠ” ë° ì§‘ì¤‘í•˜ì‹­ì‹œì˜¤.\n"
                            f"ì•„ë˜ [ì§€ì›ì ê²½í—˜ ì •ë³´]ë¥¼ 'ë°°ê²½'ìœ¼ë¡œ í™œìš©í•˜ì—¬ êµ¬ì²´ì ì¸ ì§ˆë¬¸ì„ ìƒì„±í•˜ì‹­ì‹œì˜¤.\n\n"
                            f"[ì§€ì›ì ê²½í—˜ ì •ë³´]:\n{rag_context}"
                        )
                else:
                    # ì¼ë°˜ ê¸°ìˆ /ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸ (4, 5, 8ë²ˆ ë“± ìƒˆë¡œìš´ ì£¼ì œ ì‹œì‘ ì‹œ)
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(target_role=target_role, major=major or "")
                    except:
                        query = query_template

                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        # êµ¬ì¡°í™”ëœ ë°ì´í„°ì—ì„œ ìê²©ì¦ ì¶”ì¶œ ë¡œì§ (ìƒëµ ë°©ì§€ë¥¼ ìœ„í•œ ìœ ì§€)
                        context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + cert_list
                        rag_results = [{'text': f"ë³´ìœ  ìê²©: {cert_list}"}]
                    else:
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        # [ì „ëµ 4] ë¬´ì˜ë¯¸í•œ ë‹µë³€ì¼ ê²½ìš° ì´ì „ ì»¨í…ìŠ¤íŠ¸ë¥¼ ì‚­ì œí•˜ì—¬ í™˜ê° ë°©ì–´
                        if is_meaningless(last_user_transcript.text):
                             context_text = "[ì£¼ì˜: ì§€ì›ìì˜ ì´ì „ ë‹µë³€ì´ ë¬´ì˜ë¯¸í•˜ê±°ë‚˜ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤. ê³¼ê±° ì •ë³´ì— ì˜ì¡´í•˜ì§€ ë§ê³  ë‹¤ì‹œ ë¬¼ì–´ë³´ì‹­ì‹œì˜¤.]"
                             logger.warning("ğŸš« Meaningless input detected! Isolating context to prevent hallucination.")
                        
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                # ê°€ì´ë“œ ë‚´ ë³€ìˆ˜ ì¹˜í™˜
                guide_raw = next_stage.get('guide', '')
                try:
                    guide_formatted = guide_raw.format(company_ideal=company_ideal)
                except:
                    guide_formatted = guide_raw

                # [ì¶”ê°€] ë‹¨ê³„ë³„ ë§ì¶¤í˜• ì „ëµ ì§€ì¹¨ ê²°ì • (ì§€ì›ìë‹˜ ìš”ì²­ ë°˜ì˜)
                mode_instruction = "ì¼ë°˜ì ì¸ ë‹¨ì¼ ì§ˆë¬¸ ìƒì„±ì„ ìˆ˜í–‰í•˜ì‹­ì‹œì˜¤."
                mode_task_instruction = "ì œê³µëœ ì •ë³´ë¥¼ ë¶„ì„í•˜ì—¬ ê°€ì¥ ì˜ˆë¦¬í•œ ê¼¬ë¦¬ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ìƒì„±í•˜ì‹­ì‹œì˜¤. ì§€ì›ìì˜ ë§ˆì§€ë§‰ ë‹µë³€ ë‚´ìš©ì—ì„œ êµ¬ì²´ì ì¸ ì‚¬ì‹¤ ê´€ê³„ë¥¼ í™•ì¸í•˜ê³  ë…¼ë¦¬ì  í—ˆì ì„ ì°Œë¥´ëŠ” ì§ˆë¬¸ì„ í•˜ì‹­ì‹œì˜¤." # ê¸°ë³¸ê°’
                global_constraint = "ì˜¤ì§ ì§ˆë¬¸ë§Œì„ ìƒì„±í•˜ê³ , ê¸°ìˆ  ìŠ¤íƒê³¼ ìˆ˜ì¹˜ë¥¼ ì ì ˆíˆ ì¸ìš©í•˜ì‹­ì‹œì˜¤." # ê¸°ë³¸ ê¸°ìˆ  ì§€ì¹¨
                
                s_name = next_stage.get('stage', '')
                s_type = next_stage.get('type', '')
                
                # ì¸ì„± ë©´ì ‘ ë‹¨ê³„(9~14) ì—¬ë¶€ í™•ì¸
                is_narrative = (next_stage.get('category') == 'narrative') or (s_name in ['communication', 'communication_followup', 'responsibility', 'responsibility_followup', 'growth', 'growth_followup'])

                if is_narrative:
                    global_constraint = "ì¸ì„± ë‹¨ê³„ì…ë‹ˆë‹¤. **ì½”ë“œ, ì„¤ê³„, ê°œë°œê³¼ ê°™ì€ ì§ë¬´ ë‹¨ì–´ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ê³ **, íƒœë„ì™€ ê°€ì¹˜ê´€ì„ ì¸ìš©í•˜ì—¬ ì§§ê²Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤."
                
                if s_name == 'problem_solving':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 7ë²ˆ(ë¬¸ì œí•´ê²°ì§ˆë¬¸)ì…ë‹ˆë‹¤. ì§ˆë¬¸ ê³¼ì •ì—ì„œ 'ê·¸ëŸ°ë°' í˜¹ì€ 'ê·¸ë ‡ë‹¤ë©´'ê³¼ ê°™ì€ ì ‘ì†ì‚¬ë¥¼ í™œìš©í•˜ì—¬ ìì—°ìŠ¤ëŸ½ê²Œ ìƒí™©ì„ ì œì‹œí•˜ë˜, ë°˜ë“œì‹œ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ë§Œ ë˜ì§€ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility':
                    # 11ë²ˆ ê°€ì¹˜ê´€ ì§ˆë¬¸: ê¸°ìˆ  ì¤‘ì‹¬ ì¸ìš© ëŒ€ì‹  ê°€ì¹˜ ì¤‘ì‹¬ ì „í™˜ (ì „ì²´ ê¸¸ì´ 30% ì¶•ì†Œ)
                    mode_task_instruction = "ìê¸°ì†Œê°œì„œì—ì„œ ë‚˜íƒ€ë‚œ ì§€ì›ìì˜ í•µì‹¬ ê°€ì¹˜ê´€(ì •ì§, ì±…ì„ê° ë“±)ì„ íŒŒì•…í•˜ì—¬ ì¸ì¬ìƒê³¼ ì—°ê²°í•˜ì‹­ì‹œì˜¤. ì„œë¹„ìŠ¤ ì„¤ê³„ë‚˜ ì½”ë“œ ê°™ì€ ê¸°ìˆ  ë‚´ìš©ì€ ì¼ì ˆ ì–¸ê¸‰í•˜ì§€ ë§ê³  ì˜¤ì§ ì¸ì„±ì ì¸ ë©´ëª¨ë¥¼ 80ì ì´ë‚´ë¡œ ë¬¼ìœ¼ì‹­ì‹œì˜¤."
                    mode_instruction = "ì´ì „ ë‹µë³€ ìš”ì•½ì„ ìƒëµí•˜ê³ , 'ìê¸°ì†Œê°œì„œì—ì„œ ~í•œ ê°€ì¹˜ê´€ì´ ì¸ìƒì ì´ì—ˆìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´...'ê³¼ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”í•˜ì‹­ì‹œì˜¤. 30% ë” ì§§ê²Œ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                elif s_name == 'responsibility_followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” 12ë²ˆ(ê°€ì¹˜ê´€ ì‹¬ì¸µ)ì…ë‹ˆë‹¤. ì§€ì›ìì˜ ë‹µë³€ì— ì‹¤ì œ ë‚´ìš©ì´ ìˆì„ ê²½ìš°ì—ë§Œ ì•„ì£¼ ì§§ê²Œ ìš”ì•½í•˜ê³ , ê³§ë°”ë¡œ ê°€ì¹˜ê´€ì— ëŒ€í•œ ì§ˆë¬¸ í•˜ë‚˜ë¥¼ ë˜ì§€ì‹­ì‹œì˜¤. 60ì ì´ë‚´ë¡œ êµ¬ì„±í•˜ì‹­ì‹œì˜¤."
                elif s_name in ['communication', 'growth']:
                    # 9ë²ˆ, 13ë²ˆ ì¸ì„± ì§ˆë¬¸: íƒœë„ ê°•ì¡° ë° ê¸¸ì´ ì¶•ì†Œ
                    mode_task_instruction = "ì¸ì¬ìƒê³¼ ì´ë ¥ì„œë¥¼ ê²°í•©í•˜ë˜, ê¸°ìˆ ì  ì„±ì·¨ê°€ ì›ì¸ì´ ì•„ë‹Œ 'í˜‘ì—… íƒœë„'ì™€ 'ì„±ì¥ ì˜ì§€'ê°€ ì§ˆë¬¸ì˜ ì£¼ì¸ê³µì´ ë˜ê²Œ í•˜ì‹­ì‹œì˜¤. ëª¨ë“  ë¬¸ì¥ì€ í˜„ì¬ë³´ë‹¤ 30% ë” ì§§ê³  ê°„ëµí•˜ê²Œ êµ¬ì„±í•˜ì‹­ì‹œì˜¤."
                    mode_instruction = f"ì´ ë‹¨ê³„ëŠ” {s_name} ê²€ì¦ì…ë‹ˆë‹¤. ì½”ë“œ, ê°œë°œ, ìŠ¤íƒ ê°™ì€ ë‹¨ì–´ë¥¼ ë°°ì œí•˜ê³  ëŒ€í™”í•˜ë“¯ ë”± í•˜ë‚˜ì˜ ê°„ê²°í•œ í•œ ë¬¸ì¥ìœ¼ë¡œë§Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤."
                elif s_type == 'followup':
                    mode_instruction = "ì´ ë‹¨ê³„ëŠ” ê¼¬ë¦¬ì§ˆë¬¸ì…ë‹ˆë‹¤. ë‹µë³€ ìš”ì•½ê³¼ ì§ˆë¬¸ì„ í•˜ë‚˜ì˜ ë¬¸ì¥ìœ¼ë¡œ ê²°í•©í•˜ì—¬ ë”± í•˜ë‚˜ì˜ ì§ˆë¬¸ìœ¼ë¡œ ìƒì„±í•˜ì‹­ì‹œì˜¤."
                
                # [ì¶”ê°€] ì§€ì›ìì˜ ë¶€ì •ì  ë‹µë³€ ê°ì§€ ë° íŠ¹ìˆ˜ ì§€ì‹œ (ë¬´ì§€/íšŒí”¼ ëŒ€ì‘)
                if last_user_transcript:
                    u_text = last_user_transcript.text.strip()
                    # "ì‹«ë‹¤", "ëª°ë¼" ë“± í‚¤ì›Œë“œ ë³´ê°•
                    negative_keywords = ["ëª¨ë¥´ê² ìŠµë‹ˆë‹¤", "ëª¨ë¥´ê² ì–´ìš”", "ì•„ë‹ˆìš”", "ì—†ìŠµë‹ˆë‹¤", "ê¸°ì–µì´ ì•ˆ ë‚¨", "ì˜ ëª¨ë¦„", "ëª°ë¼ìš”", "ëª°ë¼", "ì‹«ì–´", "ì‹«ìŒ", "ì‹«ë‹¤"]
                    
                    # [ì „ëµ 3] ë¬´ì˜ë¯¸í•œ ì…ë ¥ì´ê±°ë‚˜ ëª…ì‹œì  ê±°ì ˆì¼ ë•Œ ì§€ì‹œì–´ ì „í™˜
                    if is_meaningless(u_text) or any(kw in u_text for kw in negative_keywords):
                        mode_task_instruction = "ì§€ì›ìê°€ ë‹µë³€ì„ í•˜ì§€ ëª»í•˜ê±°ë‚˜ ì˜ë¯¸ ì—†ëŠ” ì…ë ¥ì„ í–ˆìŠµë‹ˆë‹¤. ì´ì „ ë‚´ìš©ì— ëŒ€í•œ ìš”ì•½ì´ë‚˜ ì¶”ì¸¡ì„ 100% ìƒëµí•˜ê³ , ì •ì¤‘í•˜ê²Œ ë‹¤ì‹œ ì„¤ëª…ì„ ìš”ì²­í•˜ê±°ë‚˜ ë‹¤ë¥¸ ì£¼ì œë¡œ ì „í™˜í•˜ì‹­ì‹œì˜¤."
                        global_constraint = "ì´ì „ ë‹µë³€ ìš”ì•½ì„ **ì ˆëŒ€** í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë‹µë³€ì„ ì§€ì–´ë‚´ì§€ ë§ê³ , 'ì•Œê² ìŠµë‹ˆë‹¤. ê·¸ë ‡ë‹¤ë©´ ì´ë²ˆì—ëŠ”...'ê³¼ ê°™ì´ ìì—°ìŠ¤ëŸ½ê²Œ ëŒ€í™”ë¥¼ ì´ì–´ê°€ì‹­ì‹œì˜¤."
                        mode_instruction = "í™˜ê°(Hallucination) ì—†ì´ ë‹´ë°±í•˜ê²Œ ë‹¤ìŒ ì§ˆë¬¸ìœ¼ë¡œ ë„˜ì–´ê°€ê±°ë‚˜ ì¬ì„¤ëª…ì„ ìš”ì²­í•˜ì‹­ì‹œì˜¤."

                final_content = chain.invoke({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "company_ideal": company_ideal,
                    "guide": guide_formatted,
                    "mode_instruction": mode_instruction,
                    "mode_task_instruction": mode_task_instruction,
                    "global_constraint": global_constraint,
                    "target_role": target_role
                })

                # [ì •ì œ ê°€ì†í™” ë° ë¡œì§ ê°•í™”]
                final_content = final_content.strip()
                # ì„œë‘/ë§ë¯¸ ë”°ì˜´í‘œ ì œê±°
                final_content = re.sub(r'^["\'\sâ€œ]+|["\'\sâ€]+$', '', final_content)
                
                # 1. ë©”íƒ€ ì„¤ëª… ë° ê°€ì´ë“œ ë¬¸êµ¬ ê°•ì œ ì‚­ì œ (9ë²ˆ ì˜¤ë¥˜ í•´ê²° í•µì‹¬)
                # AIê°€ ê°€ì´ë“œ ë‚´ìš©ì„ ì§ˆë¬¸ ë’¤ì— ë¶™ì´ê±°ë‚˜ ê°€ì„¤ì„ ë˜ì§€ëŠ” ê²½ìš°ë¥¼ íŒ¨í„´ìœ¼ë¡œ ì œê±°
                meta_patterns = [
                    r'(ì´\s*ì§ˆë¬¸ì€|ì˜ë„ëŠ”|~ë¼ê³ \s*ë‹µë³€í–ˆë‹¤ë©´|ê²€ì¦í•©ë‹ˆë‹¤|ì˜ë„í•¨|í™•ì¸í•©ë‹ˆë‹¤|ìš”êµ¬í•˜ì—¬).*', 
                    r'ì§€ì›ìê°€\s*.*ë¼ê³ \s*ë§í–ˆë‹¤ë©´.*',
                    r'ìœ„\s*ì§ˆë¬¸ì€\s*.*',
                    r'ë”°ë¼ì„œ\s*.*',
                    r'ë³¸\s*ì§ˆë¬¸ì€\s*.*'
                ]
                for pattern in meta_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE | re.DOTALL)

                # 2. ì„œë‘ ë ˆì´ë¸” ì œê±° (í•œê¸€/ì˜ë¬¸/íŠ¹ìˆ˜ë¬¸ì í¬í•¨)
                label_patterns = [
                    r'^\**ì§€ì›ìì˜\s*ë‹µë³€\s*ìš”ì•½\s*ë°\s*ê¼¬ë¦¬ì§ˆë¬¸:\**\s*',
                    r'^\**í•µì‹¬\s*ìš”ì•½:\**\s*',
                    r'^\**ê¼¬ë¦¬ì§ˆë¬¸:\**\s*',
                    r'^\**ìš”ì•½:\**\s*',
                    r'^\**ì§ˆë¬¸:\**\s*',
                    r'^\**[QA]:\**\s*',
                    r'^\d+\.\s*',
                    r'^-\s*'
                ]
                for pattern in label_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE | re.MULTILINE)

                # 3. ë¬¸ì¥ ì¤‘ê°„ì— ì‚½ì…ë˜ëŠ” ì—°ê²° ë ˆì´ë¸” ì œê±°
                bridge_patterns = [
                    r'ì´ì—\s*ëŒ€í•œ\s*ì§ˆë¬¸ì…ë‹ˆë‹¤:?',
                    r'ë‹¤ìŒì€\s*ì§ˆë¬¸ì…ë‹ˆë‹¤:?',
                    r'ì§ˆë¬¸ë“œë¦½ë‹ˆë‹¤:?',
                    r'ì§ˆë¬¸ì€\s*ë‹¤ìŒê³¼\s*ê°™ìŠµë‹ˆë‹¤:?',
                    r'\*\*.*\*\*:\s*' # ë³¼íŠ¸ê°€ í¬í•¨ëœ ëª¨ë“  ë ˆì´ë¸” í˜•íƒœ ì œê±°
                ]
                for pattern in bridge_patterns:
                    final_content = re.sub(pattern, '', final_content, flags=re.IGNORECASE)

                # 4. Markdown ì œëª©(#) ë° ë¶ˆí•„ìš”í•œ íƒœê·¸ ì œê±° (## ì œëª©, [ì§ˆë¬¸ë ˆì´ë¸”] ë“±)
                final_content = re.sub(r'#+\s*.*?\n', '\n', final_content) # ## ì œëª© ì œê±°
                final_content = re.sub(r'#+\s*.*$', '', final_content)    # ì¤„ ëì˜ # ì œê±°
                final_content = re.sub(r'\[.*?ì§ˆë¬¸\]', '', final_content)   # [ì„±ì¥ê°€ëŠ¥ì„±ì§ˆë¬¸] ë“± ì œê±°
                
                # 5. [í•µì‹¬] ë§Œì•½ AIê°€ "..." ì²˜ëŸ¼ ë”°ì˜´í‘œ ì•ˆì— ì§ˆë¬¸ì„ ë„£ì—ˆë‹¤ë©´ ê·¸ê²ƒë§Œ ì¶”ì¶œ
                quote_match = re.search(r'["\'â€œ]([^"\'â€]*\?+)["\'â€]', final_content)
                if quote_match:
                    final_content = quote_match.group(1)

                # 5. [ì •ì œ ë¡œì§ ì™„í™”] ë¬¼ìŒí‘œ ìë¥´ê¸°ë¥¼ ì •êµí•˜ê²Œ ìˆ˜í–‰ (ë¬¸ë§¥ ë³´ì¡´)
                # ë‹¨ì¼ ë¬¸ì¥ë§Œ ë‚¨ê¸°ëŠ” ëŒ€ì‹ , ë§ˆì§€ë§‰ ë¬¼ìŒí‘œ ì´í›„ì˜ 'ë¶€ì—° ì„¤ëª…(ê°€ì´ë“œë¼ì¸)'ë§Œ ì œê±°
                # AIê°€ ê°€ë” ë§ëì— "ì´ ì§ˆë¬¸ì€ ~ë¥¼ ì˜ë„í•¨" ë“±ì„ ë¶™ì´ëŠ” ê²ƒ ë°©ì§€
                final_content = final_content.replace("**", "").strip()
                if '?' in final_content:
                    # íŒ¨í„´ ê¸°ë°˜: ì§ˆë¬¸ ì˜ë„ë‚˜ ì„¤ëª…ì´ ì‹œì‘ë˜ëŠ” í‚¤ì›Œë“œê°€ ìˆìœ¼ë©´ ê·¸ ì•ê¹Œì§€ë§Œ ìœ ì§€
                    cut_patterns = ["ì´ ì§ˆë¬¸ì€", "ì§ˆë¬¸ì˜ ì˜ë„", "ì˜ë„ëŠ”", "ë‹µë³€ì„ í†µí•´", "í™•ì¸í•˜ê³ ì í•¨", "ê²€ì¦í•˜ê³ ì í•˜ëŠ”"]
                    for pattern in cut_patterns:
                        if pattern in final_content:
                            final_content = final_content.split(pattern)[0].strip()
                    
                    # ë§Œì•½ ë¬¼ìŒí‘œê°€ ìˆê³  ê·¸ ë’¤ì— ì•„ì£¼ ì§§ì€ ë¬¸ì¥(ì„¤ëª…ì¡°)ì´ ë” ìˆë‹¤ë©´ ë§ˆì§€ë§‰ ë¬¼ìŒí‘œê¹Œì§€ë§Œ ìœ ì§€
                    q_last_idx = final_content.rfind('?') + 1
                    if q_last_idx < len(final_content) and len(final_content) - q_last_idx < 30:
                        final_content = final_content[:q_last_idx]

                # [ì™„í™”] ë¬´ì¡°ê±´ì ì¸ ë¬¼ìŒí‘œ 1ê°œ ì œí•œ ëŒ€ì‹ , ë„ˆë¬´ ì—¬ëŸ¬ ê°œ(3ê°œ ì´ìƒ)ì¸ ê²½ìš°ë§Œ ìƒìœ„ 2ê°œë¡œ ì œí•œ
                if final_content.count('?') > 2:
                    logger.warning(f"âš ï¸ Excessive questions detected. Truncating to first two.")
                    q_parts = final_content.split('?')
                    final_content = q_parts[0] + '?' + q_parts[1] + '?'
                
                final_content = final_content.strip()

                intro_tpl = next_stage.get("intro_sentence", "")
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                else:
                    intro_msg = ""

                if next_stage.get("type") == "followup":
                    intro_msg = "" 
                
                display_name = next_stage.get("display_name", "ì‹¬ì¸µ ë©´ì ‘")
                final_content = f"[{display_name}] {intro_msg} {final_content}".strip() if intro_msg else f"[{display_name}] {final_content}".strip()

            # 6. DB ì €ì¥ (Question ë° Transcript)

            # 6. DB ì €ì¥ (Question ë° Transcript)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                session=session
            )

            # 7. ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 8. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±° (ì¤‘ë³µ ë°©ì§€: íŒŒì¼ ì¡´ì¬ í™•ì¸)
            if q_id:
                import pathlib
                tts_file = pathlib.Path(f"/app/uploads/tts/q_{q_id}.wav")
                if not tts_file.exists():
                    # [ë‹¨ê³„] íƒœê·¸ ì œê±° (TTSê°€ ì½ëŠ” í´ë¦° í…ìŠ¤íŠ¸)
                    clean_text = final_content
                    if final_content.startswith('[') and ']' in final_content:
                        clean_text = final_content.split(']', 1)[-1].strip()
                    logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                    synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                else:
                    logger.info(f"ğŸ”Š TTS file already exists for Question ID: {q_id}, skipping.")

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry: {self.request.retries}/3): {e}")
        if self.request.retries >= 3:
            logger.warning("âš ï¸ ì§ˆë¬¸ ìƒì„± ìµœëŒ€ ì¬ì‹œë„ íšŸìˆ˜ ì´ˆê³¼. í´ë°±(Fallback) ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.")
            try:
                from db import save_generated_question
                from tasks.tts import synthesize_task
                with Session(engine) as session:
                    fallback_text = "[ì‹œìŠ¤í…œ ì§ˆë¬¸] AI ì‘ë‹µ ì§€ì—°ìœ¼ë¡œ ì¸í•´ ê¸°ë³¸ ì§ˆë¬¸ìœ¼ë¡œ ëŒ€ì²´í•©ë‹ˆë‹¤. ì´ ì§ë¬´ë¥¼ ì„±ê³µì ìœ¼ë¡œ ìˆ˜í–‰í•˜ê¸° ìœ„í•´ ë³¸ì¸ì´ ê°€ì§„ ê°€ì¥ ë›°ì–´ë‚œ ì ì€ ë¬´ì—‡ì´ë©°, ì´ë¥¼ ë°œíœ˜í•œ ì‹¤ì œ ê²½í—˜ì„ ë§ì”€í•´ ì£¼ì‹œê² ìŠµë‹ˆê¹Œ?"
                    q_id = save_generated_question(
                        interview_id=interview_id,
                        content=fallback_text,
                        category="behavioral",
                        stage="fallback",
                        guide="ì—ëŸ¬ ë° íƒ€ì„ì•„ì›ƒ ë°œìƒìœ¼ë¡œ ì¸í•œ í´ë°± ì§ˆë¬¸",
                        session=session
                    )
                    if q_id:
                        clean_text = fallback_text.split(']', 1)[-1].strip() if ']' in fallback_text else fallback_text
                        synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                    return {"status": "success", "stage": "fallback", "question": fallback_text}
            except Exception as fallback_e:
                logger.error(f"âŒ í´ë°± ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {fallback_e}")
                return {"status": "error", "message": "Fallback question failed"}
        else:
            raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()