import sys
import os
import re
import json
import gc 
import logging
import torch
from datetime import datetime, timezone
from celery import shared_task
from langchain_core.prompts import PromptTemplate
from langchain_core.output_parsers import StrOutputParser
import redis

# ==========================================
# 1. ì´ˆê¸° ì„¤ì • ë° ëª¨ë¸ ê²½ë¡œ ìµœì í™”
# ==========================================

if "/app" not in sys.path:
    sys.path.insert(0, "/app")

logger = logging.getLogger("AI-Worker-QuestionGen")

# ëª¨ë¸ ê²½ë¡œ ì„¤ì •
local_path = r"C:\big20\Big20_aI_interview_project\ai-worker\models\EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
docker_path = "/app/models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf"
model_path = docker_path if os.path.exists(docker_path) else local_path

# ==========================================
# 2. í˜ë¥´ì†Œë‚˜ ì„¤ì • (Prompt Engineering)
# ==========================================

PROMPT_TEMPLATE = """[|system|]ë‹¹ì‹ ì€ ì§€ì›ìì˜ ì—­ëŸ‰ì„ ì •ë°€í•˜ê²Œ ê²€ì¦í•˜ëŠ” ì „ë¬¸ ë©´ì ‘ê´€ì…ë‹ˆë‹¤.
ì œê³µëœ [ì´ë ¥ì„œ ë¬¸ë§¥]ê³¼ [ë©´ì ‘ ì§„í–‰ ìƒí™©]ì„ ë°”íƒ•ìœ¼ë¡œ, ì§€ì›ìì—ê²Œ ë˜ì§ˆ 'ë‹¤ìŒ ì§ˆë¬¸' 1ê°œë§Œ ìƒì„±í•˜ì‹­ì‹œì˜¤.

[ì ˆëŒ€ ê·œì¹™]
 1. ë°˜ë“œì‹œ í•œêµ­ì–´ë¡œ ë‹µë³€í•˜ì‹­ì‹œì˜¤.
 2. ì§ˆë¬¸ì€ ëª…í™•í•˜ê³  êµ¬ì²´ì ì´ì–´ì•¼ í•˜ë©°, 150ì ì´ë‚´ë¡œ ì‘ì„±í•˜ì‹­ì‹œì˜¤.
 3. íŠ¹ìˆ˜ë¬¸ì(JSON ê¸°í˜¸, ì—­ë”°ì˜´í‘œ, ì‘ì€ë”°ì˜´í‘œ ë“±)ë¥¼ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ì˜¤ì§ ìˆœìˆ˜ í…ìŠ¤íŠ¸ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.
 4. ì§ˆë¬¸ ì•ë¨¸ë¦¬ì— '1.', 'ì§ˆë¬¸:' ë˜ëŠ” ë”°ì˜´í‘œ(') ë“±ì„ ì ˆëŒ€ ë¶™ì´ì§€ ë§ˆì‹­ì‹œì˜¤. ë°”ë¡œ ë³¸ë¬¸ë§Œ ì‹œì‘í•˜ì‹­ì‹œì˜¤.
 5. ì´ì „ ì§ˆë¬¸ê³¼ ì¤‘ë³µë˜ì§€ ì•Šë„ë¡ í•˜ì‹­ì‹œì˜¤.
 6. **ì–´ì¡° ê·œì¹™**: ê¸°ë³¸ì ìœ¼ë¡œ ëª¨ë“  ì§ˆë¬¸ì€ '~ì£¼ì„¸ìš”.'ë¡œ ëë§ºìŒí•˜ê³  ë¬¼ìŒí‘œ(?)ë¥¼ ì‚¬ìš©í•˜ì§€ ë§ˆì‹­ì‹œì˜¤. ë‹¨, ë³„ë„ì˜ ì§€ì‹œê°€ ìˆëŠ” [ê°€ì´ë“œ]ê°€ ì œê³µë  ê²½ìš° í•´ë‹¹ ê°€ì´ë“œì˜ ì–´ì¡°(ì˜ˆ: '~ì¸ê°€ìš”?')ì™€ ë¬¼ìŒí‘œ ì‚¬ìš© ìœ ë¬´ë¥¼ ìµœìš°ì„ ìœ¼ë¡œ ë”°ë¥´ì‹­ì‹œì˜¤.
 7. **ê¼¬ë¦¬ì§ˆë¬¸(Follow-up) ê·œì¹™**: ì§€ì›ìì˜ ë‹µë³€ ì¤‘ í•µì‹¬ì ì¸ êµ¬ì ˆì„ ê³¨ë¼ ì‘ì€ë”°ì˜´í‘œ(' ') ì•ˆì— ë„£ì–´ "...ë¼ê³  í•˜ì…¨ëŠ”ë°,"ë¡œ ìš”ì•½í•˜ë©° ì‹œì‘í•˜ì‹­ì‹œì˜¤. (ì˜ˆ: 'RAG ì•„í‚¤í…ì²˜'ë¼ê³  ë§ì”€í•˜ì…¨ëŠ”ë°,)
 8. **ì‹¬ì¸µ ì§ˆë¬¸ ì „ê°œ**: ì§€ì›ìê°€ ë‹µë³€í•œ ë‚´ìš© ë‚´ì—ì„œë§Œ ì‹¬ë„ ìˆê²Œ ì§ˆë¬¸í•˜ì‹­ì‹œì˜¤. ì™¸ë¶€ ì§€ì‹ ì¸ìš©ì´ë‚˜ ê°€ì§œ ê²½í—˜ ì¡°ì‘ì€ ì ˆëŒ€ ê¸ˆì§€ì…ë‹ˆë‹¤. ê°€ì´ë“œì—ì„œ ìš”ì²­í•˜ëŠ” ê²½ìš° ì–´ì¡°ë¥¼ ìœ ì—°í•˜ê²Œ ë³€ê²½í•˜ì‹­ì‹œì˜¤.
 9. **ë¬¸ì¥ ê²€ì¦(Self-Correction)**: ì§ˆë¬¸ì„ ì¶œë ¥í•˜ê¸° ì „, ë¬¸ì¥ì´ ë¹„ë…¼ë¦¬ì ì´ê±°ë‚˜ ë„ì¤‘ì— ëŠê¸°ì§€ ì•Šì•˜ëŠ”ì§€, ê·¸ë¦¬ê³  ì§ˆë¬¸ì˜ ì˜ë„ê°€ ëª…í™•í•œì§€ ìŠ¤ìŠ¤ë¡œ ìµœì¢… í™•ì¸í•˜ì‹­ì‹œì˜¤. ì–´ìƒ‰í•œ ë¹„ë¬¸ì€ ìë™ìœ¼ë¡œ ìˆ˜ì •í•˜ì—¬ ì™„ê²°ëœ ë¬¸ì¥ë§Œ ì¶œë ¥í•˜ì‹­ì‹œì˜¤.

[ì´ë ¥ì„œ ë° ë‹µë³€ ë¬¸ë§¥]
{context}

[í˜„ì¬ ë©´ì ‘ ë‹¨ê³„ ì •ë³´]
- ë‹¨ê³„ëª…: {stage_name}
- ê°€ì´ë“œ: {guide}

[|user|]ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë©´ì ‘ ì§ˆë¬¸ì„ ìƒì„±í•´ ì£¼ì„¸ìš”.[|endofturn|]
[|assistant|]"""

# ==========================================
# 3. ë©”ì¸ ì‘ì—…: ì§ˆë¬¸ ìƒì„± íƒœìŠ¤í¬
# ==========================================

@shared_task(name="tasks.question_generation.preload_model")
def preload_model_task():
    """
    EXAONE ëª¨ë¸ì„ ë©”ëª¨ë¦¬ì— ë¯¸ë¦¬ ë¡œë“œí•´ë‘ëŠ” ì›œì—…(Warmup) íƒœìŠ¤í¬.
    ë©´ì ‘ ì„¸ì…˜ ìƒì„± ì‹œ ì¦‰ì‹œ ì‹¤í–‰í•˜ì—¬, AI ì§ˆë¬¸ì´ í•„ìš”í•œ ì‹œì ì— ëª¨ë¸ì´ ì´ë¯¸ ì¤€ë¹„ëœ ìƒíƒœê°€ ë˜ë„ë¡ í•©ë‹ˆë‹¤.
    """
    try:
        from utils.exaone_llm import get_exaone_llm
        logger.info("ğŸ”¥ [Preload] EXAONE ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹œì‘...")
        get_exaone_llm()  # ì‹±ê¸€í†¤ - í•œ ë²ˆ ë¡œë”©ë˜ë©´ ì´í›„ íƒœìŠ¤í¬ì—ì„œ ì¬ì‚¬ìš©
        logger.info("âœ… [Preload] EXAONE ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì™„ë£Œ. AI ì§ˆë¬¸ ìƒì„± ì¤€ë¹„ë¨.")
    except Exception as e:
        logger.warning(f"âš ï¸ [Preload] ëª¨ë¸ ì‚¬ì „ ë¡œë”© ì‹¤íŒ¨ (AI ì§ˆë¬¸ ìƒì„± ì‹œ ìë™ ì¬ì‹œë„): {e}")


@shared_task(bind=True, name="tasks.question_generation.generate_next_question")
def generate_next_question_task(self, interview_id: int):
    """
    ì¸í„°ë·° ì§„í–‰ ìƒí™©ì„ íŒŒì•…í•˜ê³  ë‹¤ìŒ ë‹¨ê³„ì˜ AI ì§ˆë¬¸ì„ ìƒì„±í•©ë‹ˆë‹¤.
    """
    from db import engine, Session, select, Interview, Transcript, Speaker, Question, save_generated_question
    from utils.exaone_llm import get_exaone_llm
    from tasks.tts import synthesize_task
    from utils.interview_helpers import check_if_transition
    from config.interview_scenario import get_next_stage as get_next_stage_normal
    from config.interview_scenario_transition import get_next_stage as get_next_stage_transition
    from tasks.rag_retrieval import retrieve_context, retrieve_similar_questions
    try:
        with Session(engine) as session:
            interview = session.get(Interview, interview_id)
            if not interview: 
                logger.error(f"Interview {interview_id} not found.")
                return {"status": "error", "message": "Interview not found"}

            # 2. ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ ë° Stage íŒë³„
            # [ìˆ˜ì •] ë§ˆì§€ë§‰ ë°œí™” í™•ì¸ (Order í•„ë“œ ëŒ€ì‹  ID/ì‹œê°„ìˆœìœ¼ë¡œ ë³€ê²½í•˜ì—¬ ì •í•©ì„± í™•ë³´)
            stmt_all = select(Transcript).where(Transcript.interview_id == interview_id).order_by(Transcript.id.desc())
            last_transcript = session.exec(stmt_all).first()

            stmt_ai = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.AI
            ).order_by(Transcript.id.desc())
            last_ai_transcript = session.exec(stmt_ai).first()

            stmt_user = select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == Speaker.USER
            ).order_by(Transcript.id.desc())
            last_user_transcript = session.exec(stmt_user).first()

            # [ì‚­ì œ] 10ì´ˆ ì´ë‚´ ìŠ¤í‚µ ë¡œì§ (Race Condition ë°©ì§€ ëª©ì ì´ì—ˆìœ¼ë‚˜ ì´ˆê¸° í…œí”Œë¦¿ ë¡œë“œ ì‹œ ë°©í•´ë¨)

            # [ìˆ˜ì •] 3. ì „ê³µ/ì§ë¬´ ê¸°ë°˜ ì‹œë‚˜ë¦¬ì˜¤ ê²°ì •
            major = ""
            if interview.resume and interview.resume.structured_data:
                sd = interview.resume.structured_data
                if isinstance(sd, str):
                    sd = json.loads(sd)
                edu = sd.get("education", [])
                major = next((e.get("major", "") for e in edu if e.get("major", "").strip()), "")

            is_transition = check_if_transition(major, interview.position)
            get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal

            # ë§ˆì§€ë§‰ AI ë°œí™”ì˜ question_typeìœ¼ë¡œ í˜„ì¬ stage íŒë³„
            if last_ai_transcript and last_ai_transcript.question_id:
                last_question = session.get(Question, last_ai_transcript.question_id)
                last_stage_name = last_question.question_type if last_question else "intro"
            else:
                last_stage_name = "intro"

            logger.info(f"Current stage determined: {last_stage_name} (is_transition={is_transition})")
            next_stage = get_next_stage_func(last_stage_name)

            if not next_stage:
                logger.info(f"Interview {interview_id} finished. Transitioning to COMPLETED.")
                interview.status = "COMPLETED"
                session.add(interview)
                session.commit()
                return {"status": "completed"}

            # [ìˆ˜ì •] ë™ê¸°í™” ë¡œì§: ì´ë¯¸ AIê°€ ë‹¤ìŒ ì§ˆë¬¸(ë“¤)ì„ ë˜ì¡ŒëŠ”ë° ì‚¬ìš©ìê°€ ì•„ì§ ì´ì „ ì§ˆë¬¸ì— ë‹µí•˜ëŠ” ì¤‘ì´ë¼ë©´ ëŒ€ê¸°
            if last_ai_transcript and last_user_transcript:
                # ë§ˆì§€ë§‰ AI ë°œí™”ê°€ ì•„ì§ ì‚¬ìš©ì ë‹µë³€ì— ì˜í•´ ì°¸ì¡°ë˜ì§€ ì•Šì•˜ë‹¤ë©´? (ì¦‰, ì•„ì§ ë‹µí•˜ì§€ ì•Šì€ ì§ˆë¬¸ì´ ìˆë‹¤ë©´)
                if last_user_transcript.question_id != last_ai_transcript.question_id:
                    logger.info(f"AI has already spoken up to stage '{last_stage_name}', but user just answered a previous question. Waiting for user to answer current question.")
                    return {"status": "waiting_for_user_to_catch_up"}

            # [ìˆ˜ì •] ì¤‘ë³µ ë°©ì§€ ë¡œì§ ê°œì„ : ì´ë¯¸ ìƒì„±ëœ ê²½ìš° ì •ë³´ë¥¼ í•¨ê»˜ ë¦¬í„´
            if last_ai_transcript:
                last_q_for_check = session.get(Question, last_ai_transcript.question_id) if last_ai_transcript.question_id else None
                if last_q_for_check and last_q_for_check.question_type == next_stage['stage']:
                    logger.info(f"Next stage '{next_stage['stage']}' already exists. Re-triggering TTS/Broadcast.")
                    # TTS ë‹¤ì‹œ í•œ ë²ˆ ì°”ëŸ¬ì¤Œ (ì´ë¯¸ ìˆìœ¼ë©´ 1ì´ˆë„ ì•ˆ ê±¸ë¦¼)
                    synthesize_task.delay(last_ai_transcript.text, language="auto", question_id=last_ai_transcript.question_id)
                    return {
                        "status": "success", 
                        "stage": next_stage['stage'], 
                        "question": last_ai_transcript.text,
                        "question_id": last_ai_transcript.question_id
                    }
            # 4. [ìµœì í™”] template stageëŠ” RAG/LLM ì—†ì´ ì¦‰ì‹œ í¬ë§·
            if next_stage.get("type") == "template":
                candidate_name = "ì§€ì›ì"
                target_role = interview.position or "í•´ë‹¹ ì§ë¬´"
                cert_list = ""
                
                act_org, act_role = "ê´€ë ¨ ê¸°ê´€", "ë‹´ë‹¹ ì—…ë¬´"
                proj_org, proj_name = "í•´ë‹¹ ê¸°ê´€", "ìˆ˜í–‰í•œ í”„ë¡œì íŠ¸"
                
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    
                    header = sd.get("header", {})
                    candidate_name = header.get("name") or header.get("candidate_name") or candidate_name
                    target_role = header.get("target_role") or target_role
                    company_name = header.get("target_company") or header.get("company") or "ì €í¬ íšŒì‚¬"

                    # 1. ìê²©ì¦ ë¦¬ìŠ¤íŠ¸ì—… (ëª¨ë‘ ì¶”ì¶œ)
                    certs = sd.get("certifications", [])
                    if certs:
                        cert_names = [c.get("title") or c.get("name") for c in certs if (c.get("title") or c.get("name"))]
                        cert_list = ", ".join(cert_names)
                    
                    # 4-1. ê²½ë ¥ (activities) - í—¤ë” ì œì™¸ ë¡œì§
                    acts = sd.get("activities", [])
                    act_header_kws = ["ê¸°ê°„", "ì—­í• ", "ê¸°ê´€", "ì†Œì†", "ì¥ì†Œ", "ì œëª©", "ë‚´ìš©"]
                    for act in acts:
                        tmp_org = act.get("organization") or act.get("name") or ""
                        tmp_role = act.get("role") or act.get("position") or ""
                        if not any(kw in tmp_org for kw in act_header_kws) and not any(kw in tmp_role for kw in act_header_kws):
                            act_org = tmp_org or act_org
                            act_role = tmp_role or act_role
                            break
                    
                    # 4-2. í”„ë¡œì íŠ¸ (projects) - í—¤ë” ì œì™¸ ë¡œì§
                    projs = sd.get("projects", [])
                    proj_header_kws = ["ê¸°ê°„", "ì œëª©", "ê³¼ì •ëª…", "ê¸°ê´€", "ì„¤ëª…", "ë‚´ìš©"]
                    for proj in projs:
                        tmp_name = proj.get("title") or proj.get("name") or ""
                        tmp_org = proj.get("organization") or ""
                        if not any(kw in tmp_name for kw in proj_header_kws) and not any(kw in tmp_org for kw in proj_header_kws):
                            proj_name = tmp_name or proj_name
                            proj_org = tmp_org or proj_org
                            break
                
                if not cert_list: cert_list = "ê´€ë ¨ ìê²©"

                template_vars = {
                    "candidate_name": candidate_name, 
                    "target_role": target_role, 
                    "company_name": company_name if 'company_name' in locals() else "ì €í¬ íšŒì‚¬",
                    "major": major or "í•´ë‹¹ ì „ê³µ",
                    "cert_list": cert_list,
                    "act_org": act_org,
                    "act_role": act_role,
                    "proj_org": proj_org,
                    "proj_name": proj_name
                }
                
                tpl = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ê³„ì†í•´ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl.format(**template_vars)
                except Exception as e:
                    logger.warning(f"Template formatting error: {e}")
                    # í´ë°±: ì§ì ‘ ë¬¸ìì—´ ì¹˜í™˜
                    for k, v in template_vars.items():
                        tpl = tpl.replace("{" + k + "}", str(v))
                    formatted = tpl

                intro_msg = next_stage.get("intro_sentence", "")
                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"Template stage '{next_stage['stage']}' (v2) â†’ ì¦‰ì‹œ í¬ë§· ì™„ë£Œ (Direct Extraction)")

            elif next_stage.get("type") == "template_quoted":
                # ==========================================
                # [template_quoted] RAG ë¬¸ì¥ ì¶”ì¶œ í›„ template ì§ì ‘ ì£¼ì… (hallucination ì°¨ë‹¨)
                # ==========================================
                query_template_tq = next_stage.get("query_template", interview.position)
                try:
                    query_tq = query_template_tq.format(
                        target_role=interview.position or "í•´ë‹¹ ì§ë¬´",
                        major=major or ""
                    )
                except (KeyError, ValueError):
                    query_tq = query_template_tq

                rag_results_tq = retrieve_context(query_tq, resume_id=interview.resume_id, top_k=5)
                raw_text = "\n".join([r['text'] for r in rag_results_tq]) if rag_results_tq else ""

                # í…ìŠ¤íŠ¸ ì •ê·œí™”: ê°œí–‰ì„ ê³µë°±ìœ¼ë¡œ ë³€í™˜
                normalized_text = re.sub(r'\n+', ' ', raw_text).strip()

                # í•œêµ­ì–´ ë¬¸ì¥ ë‹¨ìœ„ ë¶„ë¦¬ (í•˜ë‹¤. / ì…ë‹ˆë‹¤. / ê±°ë‹ˆë‹¤. ë“±)
                sentences = re.split(r'(?<=[\ub2e4\uc694])\. ?', normalized_text)

                extract_keywords = next_stage.get("extract_keywords", [])
                quote = ""

                if extract_keywords and sentences:
                    best_sentence = ""
                    best_score = 0
                    for sent in sentences:
                        sent = sent.strip()
                        if len(sent) < 10:
                            continue
                        score = sum(1 for kw in extract_keywords if kw in sent)
                        if score > best_score or (score == best_score and len(sent) > len(best_sentence)):
                            best_score = score
                            best_sentence = sent
                    if best_sentence and best_score > 0:
                        # ë¬¸ì¥ ë ë§ˆì¹¨í‘œ ë³µì›
                        quote = best_sentence.rstrip('.') + '.'

                # í´ë°±: í‚¤ì›Œë“œ ë§¤ì¹­ ì‹¤íŒ¨ ì‹œ ì²« ë²ˆì§¸ ì˜ë¯¸ìˆëŠ” ë¬¸ì¥ ì‚¬ìš©
                if not quote:
                    fallback_sents = [s.strip() for s in sentences if len(s.strip()) > 20]
                    quote = fallback_sents[0].rstrip('.') + '.' if fallback_sents else "ìê¸°ì†Œê°œì„œì— ê¸°ì¬í•˜ì‹  ë‚´ìš©"

                # template ë³€ìˆ˜ ì¤€ë¹„
                candidate_name_tq = "ì§€ì›ì"
                target_role_tq = interview.position or "í•´ë‹¹ ì§ë¬´"
                if interview.resume and interview.resume.structured_data:
                    sd_tq = interview.resume.structured_data
                    if isinstance(sd_tq, str): sd_tq = json.loads(sd_tq)
                    candidate_name_tq = sd_tq.get("header", {}).get("name", "ì§€ì›ì")

                tpl_tq = next_stage.get("template", "{candidate_name} ì§€ì›ìë‹˜, ìê¸°ì†Œê°œì„œì— '{quote}'ë¼ê³  ì“°ì…¨ëŠ”ë°, ì´ì— ëŒ€í•´ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ ì£¼ì„¸ìš”.")
                try:
                    formatted = tpl_tq.format(
                        candidate_name=candidate_name_tq,
                        quote=quote,
                        target_role=target_role_tq
                    )
                except Exception as fmt_err:
                    logger.warning(f"template_quoted formatting error: {fmt_err}")
                    formatted = tpl_tq.replace("{candidate_name}", candidate_name_tq).replace("{quote}", quote).replace("{target_role}", target_role_tq)

                display_name = next_stage.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
                intro_msg = next_stage.get("intro_sentence", "")
                final_content = f"[{display_name}] {intro_msg} {formatted}".strip() if intro_msg else f"[{display_name}] {formatted}"
                logger.info(f"template_quoted stage '{next_stage['stage']}' â†’ ì¸ìš©ë¬¸ ì¶”ì¶œ ì„±ê³µ: '{quote[:60]}...'")

            else:
                # [ë¡œì§ ë‹¨ìˆœí™˜] ê¼¬ë¦¬ì§ˆë¬¸ê³¼ ì¼ë°˜ ì§ˆë¬¸ì˜ ì»¨í…ìŠ¤íŠ¸ ë¶„ë¦¬
                if next_stage.get("type") == "followup":
                    # ê¼¬ë¦¬ì§ˆë¬¸: RAG/ì§ˆë¬¸ì€í–‰ ëª¨ë‘ ìŠ¤í‚µí•˜ê³  ì˜¤ì§ 'ì§ˆë¬¸-ë‹µë³€' ë§¥ë½ë§Œ ì‚¬ìš© (í™˜ê° 0%)
                    logger.info("ğŸ¯ Follow-up mode: RAG & Question Bank disabled. Focusing purely on conversation context.")
                    context_text = f"ì´ì „ ì§ˆë¬¸: {last_ai_transcript.text if last_ai_transcript else 'ì—†ìŒ'}\n"
                    if last_user_transcript:
                        context_text += f"[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"
                    rag_results = []
                else:
                    # ì¼ë°˜ AI ì§ˆë¬¸ (ê²½í—˜/ë¬¸ì œí•´ê²° ë“±): ì´ë ¥ì„œ RAG ê²€ìƒ‰ ìˆ˜í–‰
                    query_template = next_stage.get("query_template", interview.position)
                    try:
                        query = query_template.format(
                            target_role=interview.position or "í•´ë‹¹ ì§ë¬´",
                            major=major or ""
                        )
                    except (KeyError, ValueError):
                        query = query_template

                    category_raw = next_stage.get("category")
                    rag_results = []
                    context_text = ""

                    if category_raw == "certification" and interview.resume and interview.resume.structured_data:
                        sd = interview.resume.structured_data
                        if isinstance(sd, str): sd = json.loads(sd)
                        certs = sd.get("certifications", [])
                        important_certs = [c for c in certs if any(kw in c.get('title', '') for kw in ["ë°ì´í„°", "ë¶„ì„", "RAG", "AI", "í´ë¼ìš°ë“œ", "SQL", "ADSP", "ì •ë³´ì²˜ë¦¬"])]
                        final_certs = important_certs if important_certs else certs
                        if final_certs:
                            logger.info(f"âœ… RAG ê±´ë„ˆëœ€ (êµ¬ì¡°í™” ë°ì´í„° í™œìš©)")
                            context_text = "ì§€ì›ìê°€ ë³´ìœ í•œ ìê²©ì¦ ëª©ë¡:\n" + "\n".join([f"- {c.get('title')}" for c in final_certs])
                            rag_results = [{'text': f"ìê²©ëª…: {final_certs[0].get('title')}"}]
                        else:
                            rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3)
                            context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                    else:
                        filter_type = None
                        if category_raw == "certification": filter_type = "certifications"
                        rag_results = retrieve_context(query, resume_id=interview.resume_id, top_k=3, filter_type=filter_type)
                        context_text = "\n".join([r['text'] for r in rag_results]) if rag_results else "íŠ¹ë³„í•œ ì •ë³´ ì—†ìŒ"
                        
                    if last_user_transcript:
                        context_text += f"\n[ì§€ì›ìì˜ ìµœê·¼ ë‹µë³€]: {last_user_transcript.text}"

                llm = get_exaone_llm()
                prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
                chain = prompt | llm | StrOutputParser()

                # Redis ì„¤ì • (ìŠ¤íŠ¸ë¦¬ë° ì „ì†¡ìš©)
                redis_host = os.getenv("REDIS_HOST", "redis")
                r = redis.Redis(host=redis_host, port=6379, db=0)
                channel = f"interview_{interview_id}_stream"

                logger.info(f"ğŸš€ Starting streaming generation for Interview {interview_id}")
                
                full_tokens = []
                # stream()ì„ ì‚¬ìš©í•˜ì—¬ í† í° ë‹¨ìœ„ë¡œ ì‹¤ì‹œê°„ ìˆ˜ì‹ 
                for chunk in chain.stream({
                    "context": context_text,
                    "stage_name": next_stage['display_name'],
                    "guide": next_stage.get('guide', ''),
                    "target_role": interview.position or "ì§€ì› ì§ë¬´"
                }):
                    if chunk:
                        full_tokens.append(chunk)
                        # Redis Pub/Subìœ¼ë¡œ í† í° ë°œí–‰ (ì‹¤ì‹œê°„ ìŠ¤íŠ¸ë¦¬ë°)
                        try:
                            r.publish(channel, chunk)
                        except Exception as pub_err:
                            logger.error(f"Redis publish failed: {pub_err}")

                final_content = "".join(full_tokens)

                # [ì¶”ê°€] AI ì‘ë‹µ ì •ì œ: ë”°ì˜´í‘œ, ìˆ«ì, 'ì§ˆë¬¸:' ë“± ë¶ˆí•„ìš”í•œ ì¥ì‹ ì œê±°
                final_content = final_content.strip()
                # 1. ì•ë’¤ ë”°ì˜´í‘œ ì œê±°
                final_content = re.sub(r'^["\'\s]+|["\'\s]+$', '', final_content)
                # 2. ì•ì¤„ ë²ˆí˜¸ë‚˜ 'ì§ˆë¬¸:' ë“±ì˜ íƒœê·¸ ì œê±° (ì˜ˆ: '1.', 'ì§ˆë¬¸:', "'1.")
                final_content = re.sub(r'^(\'?\d+\.|\'?ì§ˆë¬¸:|\'?Q:|\'?-\s*)\s*', '', final_content)
                # 3. ì¤‘ë³µ ê³µë°± ì œê±° ë° ë‹¤ì‹œ í•œë²ˆ ë‹¤ë“¬ê¸°
                final_content = final_content.strip()

                # ì¸íŠ¸ë¡œ ë©”ì‹œì§€ ì¡°í•© (3ë²ˆ ì§ˆë¬¸ ì „ìš© ë¡œì§ í¬í•¨)
                candidate_name = "ì§€ì›ì"
                if interview.resume and interview.resume.structured_data:
                    sd = interview.resume.structured_data
                    if isinstance(sd, str): sd = json.loads(sd)
                    candidate_name = sd.get("header", {}).get("name", "ì§€ì›ì")

                intro_tpl = next_stage.get("intro_sentence", "")
                if next_stage['stage'] == 'skill' and 'cert_name' in intro_tpl:
                    # RAG ê²°ê³¼ì—ì„œ ì²« ë²ˆì§¸ ìê²©ì¦ ì´ë¦„ ì¶”ì¶œ ì‹œë„
                    cert_name = "ìë£Œì— ëª…ì‹œëœ"
                    if rag_results:
                        # "[ìê²©ì¦] ìê²©ëª…: XXX" í˜•íƒœì—ì„œ ì´ë¦„ ì¶”ì¶œ
                        match = re.search(r'ìê²©ëª…:\s*([^,\(]+)', rag_results[0]['text'])
                        if match: cert_name = match.group(1).strip()
                    intro_msg = intro_tpl.format(candidate_name=candidate_name, cert_name=cert_name)
                elif intro_tpl:
                    try:
                        intro_msg = intro_tpl.format(candidate_name=candidate_name)
                    except:
                        intro_msg = intro_tpl
                else:
                    intro_msg = ""

                if next_stage.get("type") == "followup":
                    intro_msg = "" # í”„ë¡¬í”„íŠ¸ì—ì„œ ì´ë¯¸ ìƒì„±í•˜ë¯€ë¡œ ì¤‘ë³µ ë°©ì§€ë¥¼ ìœ„í•´ ë¹„ì›€
                
                display_name = next_stage.get("display_name", "ì‹¬ì¸µ ë©´ì ‘")
                final_content = f"[{display_name}] {intro_msg} {final_content}".strip() if intro_msg else f"[{display_name}] {final_content}".strip()

            # 6. DB ì €ì¥ (Question ë° Transcript)

            # 6. DB ì €ì¥ (Question ë° Transcript)
            category_raw = next_stage.get("category", "technical")
            category_map = {"certification": "technical", "project": "technical", "narrative": "behavioral", "problem_solving": "situational"}
            db_category = category_map.get(category_raw, "technical")

            logger.info(f"ğŸ’¾ Saving generated question to DB for Interview {interview_id} (Stage: {next_stage['stage']})")
            q_id = save_generated_question(
                interview_id=interview_id,
                content=final_content,
                category=db_category,
                stage=next_stage['stage'],
                guide=next_stage.get('guide', ''),
                rubric_json=next_stage.get('rubric'),  # stageë³„ ë£¨ë¸Œë¦­ ì£¼ì…
                session=session
            )

            # 7. ë©”ëª¨ë¦¬ ì •ë¦¬
            gc.collect()
            if torch.cuda.is_available():
                torch.cuda.empty_cache()

            # 8. TTS ìƒì„± íƒœìŠ¤í¬ ì¦‰ì‹œ íŠ¸ë¦¬ê±° (ì¤‘ë³µ ë°©ì§€: íŒŒì¼ ì¡´ì¬ í™•ì¸)
            if q_id:
                import pathlib
                tts_file = pathlib.Path(f"/app/uploads/tts/q_{q_id}.wav")
                if not tts_file.exists():
                    # [ë‹¨ê³„] íƒœê·¸ ì œê±° (TTSê°€ ì½ëŠ” í´ë¦° í…ìŠ¤íŠ¸)
                    clean_text = final_content
                    if final_content.startswith('[') and ']' in final_content:
                        clean_text = final_content.split(']', 1)[-1].strip()
                    logger.info(f"ğŸ”Š Triggering TTS synthesis for Question ID: {q_id}")
                    synthesize_task.delay(clean_text, language="ko", question_id=q_id)
                else:
                    logger.info(f"ğŸ”Š TTS file already exists for Question ID: {q_id}, skipping.")

            return {"status": "success", "stage": next_stage['stage'], "question": final_content}
    except Exception as e:
        logger.error(f"âŒ ì‹¤ì‹œê°„ ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨ (Retry ì‹œë„): {e}")
        raise self.retry(exc=e, countdown=3)
    finally:
        gc.collect()