# 당당 : 김린
# 산출물1 : Final_Project_VectorDB_설계서
# 산출물2 : Final_Project_RAG_설계서
# 산출물3 : Final_Project_프롬프트_설계서

# 산출물1 : Final_Project_VectorDB_설계서

## 1. 문서 개요
### 1.1 문서 목적
본 문서는 멀티모달 생성형 AI 면접 시스템에서 활용되는 VectorDB의 설계 기준을 정의한다.  
질문·답변·평가 기준 등 비정형 데이터를 벡터화하여 검색 및 생성(RAG)에 활용하기 위한 구조와 전략을 명확히 하는 것을 목적으로 한다.

### 1.2 적용 범위
- 텍스트 기반 면접 질문 및 답변 데이터
- 평가 루브릭 및 피드백 데이터
- RAG 기반 LLM 응답 생성 파이프라인

---

## 2. 전체 아키텍처 개요
### 2.1 VectorDB 역할
VectorDB는 LLM 응답 생성을 위한 외부 지식 저장소로서,  
유사도 기반 검색을 통해 적절한 문맥(Context)을 제공하는 역할을 수행한다.

### 2.2 시스템 연계 구조
- 입력 데이터 → 임베딩 생성 → VectorDB 저장
- 사용자 질의 → 벡터 검색 → RAG Context 구성 → LLM 응답 생성

---

## 3. 벡터화 대상 정의
### 3.1 벡터화 대상 데이터
| 구분 | 설명 |
|---|---|
| 면접 질문 | 직무별·유형별 질문 텍스트 |
| 모범답안 | 평가 기준에 부합하는 예시 답변 |
| 평가 루브릭 | 논리성, 직무이해도, 태도 등 평가 기준 |
| 피드백 문장 | 개선점·강점 설명용 텍스트 |

### 3.2 벡터화 제외 대상
- 단순 메타 정보 (ID, 날짜 등)
- 통계 수치, 점수 값

---

## 4. 메타데이터 설계
### 4.1 메타데이터 구성 항목
| 필드명 | 설명 |
|---|---|
| doc_type | question / answer / rubric / feedback |
| job_category | 개발 / 데이터 / 인프라 / 기획 |
| job_role | 세부 직무명 |
| company_type | 공통 / 기업별 |
| difficulty | 하 / 중 / 상 |
| source | 데이터 출처 |

### 4.2 메타데이터 활용 목적
- 검색 필터링
- 직무 및 기업별 Context 제어
- RAG 결과 품질 향상

---

## 5. 임베딩 전략 설계
### 5.1 임베딩 대상
- 문장 단위 또는 의미 단위 Chunk
- 질문·답변·루브릭 분리 임베딩

### 5.2 임베딩 방식
- Sentence-level Embedding 적용
- 의미 손실을 최소화하기 위한 Chunk 길이 제한

### 5.3 임베딩 모델 선택 기준
- 한국어 문맥 이해 성능
- 문장 유사도 표현 정확성
- 추론 속도 및 확장성

---

## 6. 컬렉션(인덱스) 분리 설계
### 6.1 컬렉션 분리 기준
| 컬렉션명 | 저장 데이터 |
|---|---|
| interview_questions | 면접 질문 |
| sample_answers | 모범답안 |
| evaluation_rubrics | 평가 기준 |
| feedback_templates | 피드백 문장 |

### 6.2 분리 설계 목적
- 검색 정확도 향상
- Context 혼합 방지
- 유지보수 및 확장 용이성 확보

---

## 7. 검색(Retrieval) 방식 정의
### 7.1 검색 방식
- Vector Similarity Search 기반
- Top-K 검색 결과 활용

### 7.2 검색 조건
- 메타데이터 필터 적용
- 직무·기업·난이도 기반 제한

### 7.3 검색 결과 처리
- 중복 제거
- 중요도 기준 정렬
- LLM 입력 길이 제한 고려

---

## 8. RAG 파이프라인 연결 설계
### 8.1 RAG 처리 흐름
1. 사용자 답변 입력
2. 질의 임베딩 생성
3. VectorDB 유사도 검색
4. Context 구성
5. LLM 응답 생성

### 8.2 RAG 적용 목적
- LLM 환각(Hallucination) 최소화
- 면접 맥락에 맞는 답변 생성
- 일관된 평가 및 피드백 제공

---

## 9. 품질 및 운영 고려사항
### 9.1 데이터 품질 관리
- 벡터화 대상 정기 점검
- 오래된 데이터 갱신 정책

### 9.2 성능 고려
- 검색 응답 시간
- 임베딩 생성 비용
- 동시 요청 처리 가능성

---

## 10. 기대 효과
- 면접 질문·평가의 일관성 확보
- 실전 면접 기준에 부합하는 RAG 응답 제공
- AI 면접 시스템의 신뢰성 및 활용도 향상

# __________________________________

# 산출물2 : Final_Project_RAG_설계서

## 1. 문서 개요
### 1.1 문서 목적
본 문서는 멀티모달 생성형 AI 면접 시스템에서 활용되는  
RAG(Retrieval-Augmented Generation) 구조의 설계 기준을 정의한다.  
LLM 응답의 신뢰성과 일관성을 확보하기 위해 참조 지식 범위, 검색 전략,  
프롬프트 주입 구조 및 실패 대응 방안을 명확히 하는 것을 목적으로 한다.

### 1.2 적용 범위
- 면접 질문 생성
- 답변 평가 및 피드백 생성
- 실전 면접 기준 반영 응답 생성

---

## 2. RAG 적용 배경 및 목적
### 2.1 RAG 도입 필요성
- LLM 단독 응답 시 발생 가능한 환각(Hallucination) 문제
- 면접 기준의 일관성 부족
- 기업·직무별 맥락 반영 한계

### 2.2 RAG 설계 목표
- 신뢰 가능한 면접 기준 기반 응답 생성
- 실무 면접관 관점의 평가 반영
- 사용자 답변 맥락에 맞는 컨텍스트 제공

---

## 3. 참조 지식 범위 정의
### 3.1 참조 지식 유형
| 구분 | 설명 |
|---|---|
| 면접 질문 데이터 | 직무·유형별 질문 |
| 모범답안 | 실전 면접 기준에 부합하는 답변 |
| 평가 루브릭 | 논리성, 직무이해도, 태도 등 |
| 기업 인재상 | 기업별 핵심 가치 |
| 피드백 템플릿 | 개선점·강점 설명 문장 |

### 3.2 참조 지식 범위 제한 원칙
- 일반 상식성 지식 제외
- 최신성·신뢰성 확보된 데이터만 활용
- 면접 목적과 직접 관련 없는 정보 배제

---

## 4. 문서 구조화 및 Chunk 전략
### 4.1 문서 구조화 기준
- 질문 / 답변 / 평가 기준 문서 분리
- 의미 단위 중심 구조화

### 4.2 Chunk 분할 전략
- 문장 또는 의미 블록 단위 Chunk
- 과도한 길이 방지로 의미 손실 최소화
- 질문–답변–평가 기준 혼합 방지

### 4.3 Chunk 설계 목적
- 검색 정확도 향상
- 불필요한 컨텍스트 유입 방지
- LLM 입력 길이 효율화

---

## 5. 컨텍스트 정제(Context Filtering)
### 5.1 정제 필요성
- 검색 결과 중 중복·저품질 문서 제거
- LLM 입력 토큰 낭비 방지

### 5.2 정제 기준
- 유사도 점수 기준 필터링
- 메타데이터 기반 필터링
- 동일 의미 문서 중복 제거

### 5.3 컨텍스트 구성 원칙
- 핵심 정보 우선 배치
- 평가 기준 → 참고 예시 순 구성

---

## 6. Retrieval 전략 설계
### 6.1 검색 방식
- Vector Similarity Search 기반
- Top-K 검색 방식 적용

### 6.2 Retrieval 전략
| 전략 | 설명 |
|---|---|
| 직무 필터링 | 지원 직무 기반 검색 |
| 기업 필터링 | 기업 인재상 반영 |
| 단계별 검색 | 질문 생성 / 평가 / 피드백 분리 |

### 6.3 Retrieval 실패 조건 정의
- 유사도 기준 미달
- 적합 문서 미존재

---

## 7. 프롬프트 주입 구조 설계
### 7.1 프롬프트 구성 요소
- System Prompt: 면접관 역할 및 평가 기준 정의
- Context Prompt: RAG 검색 결과 주입
- User Prompt: 사용자 입력 답변

### 7.2 주입 구조 원칙
- 컨텍스트와 사용자 발화 명확 분리
- 참조 정보 외 내용 생성 제한
- 평가 기준 우선 반영

### 7.3 프롬프트 주입 흐름
1. 검색 결과 Context 정제
2. Context Prompt 구성
3. System Prompt와 결합
4. LLM 응답 생성

---

## 8. 실패 및 Fallback 설계
### 8.1 RAG 실패 유형
| 유형 | 설명 |
|---|---|
| 검색 실패 | 적절한 문서 미검색 |
| 컨텍스트 부족 | 정보 불충분 |
| 응답 불확실 | 판단 근거 부족 |

### 8.2 Fallback 전략
- 일반 평가 기준 기반 응답 전환
- LLM 단독 응답 모드 제한적 허용
- 사용자에게 추가 질문 요청

### 8.3 실패 대응 원칙
- 추측성 답변 생성 금지
- 불확실성 명시
- 보수적 평가 유지

---

## 9. 품질 및 운영 고려사항
### 9.1 품질 관리
- RAG 응답 결과 정기 검증
- Retrieval 정확도 모니터링

### 9.2 운영 고려
- 검색 속도
- 동시 요청 처리
- 데이터 업데이트 정책

---

## 10. 기대 효과
- 실전 면접 기준에 부합하는 응답 생성
- 평가 결과의 일관성 확보
- AI 면접 시스템 신뢰도 향상

# __________________________________

# 산출물3 : Final_Project_프롬프트_설계서

---

## 1. 문서 개요

### 1.1 목적
본 문서는 생성형 AI 기반 멀티모달 면접 서비스에서 사용되는 LLM 프롬프트 및  
RAG(Retrieval-Augmented Generation) 연계 구조를 정의한다.  
질문 생성, 답변 평가, 후속 질문 생성, 상태(State) 제어를 일관되고 재현 가능하게 수행하는 것을 목표로 한다.

### 1.2 적용 범위
- RAG 기반 지식 검색 및 컨텍스트 주입
- LLM 기반 질문 생성 및 답변 평가
- 프롬프트 템플릿 설계
- 출력 파싱 및 상태(State) 연동
- 서비스(API/화면) 연계

---

## 2. 전체 프롬프트 아키텍처

### 2.1 처리 흐름

사용자 입력  
 → 입력 전처리  
 → Retrieval 검색 (RAG)  
 → 컨텍스트 정제  
 → 프롬프트 템플릿 구성  
 → LLM 호출  
 → 출력 파싱  
 → State 갱신  
 → 서비스 연동(API / UI)

---

## 3. RAG 지식 적재 파이프라인 설계

### 3.1 지식 소스
- 직무별 면접 질문 데이터
- 기업 인재상 및 평가 기준
- 직무·인성 평가 루브릭
- 프로젝트 산출물(SAD, WBS, 설계 문서)

### 3.2 지식 적재 절차
1. 원천 데이터 수집(JSON, CSV, 문서)
2. 문서 분할(Chunking)
3. 텍스트 정규화 및 불필요 정보 제거
4. 임베딩 벡터 생성
5. 벡터 데이터베이스 저장

### 3.3 Chunk 전략
- Chunk 크기: 300~800 토큰
- Overlap: 10~20%
- 의미 단위 기준 분할

---

## 4. Retrieval 검색 함수 설계

### 4.1 검색 방식
- 벡터 유사도 기반 검색
- Cosine Similarity 사용

### 4.2 Top-K 설정
- 기본값: K = 3~5
- 질문 생성 단계: K 증가
- 답변 평가 단계: K 감소

### 4.3 Threshold 기준
- 유사도 임계값: 0.7 이상
- 임계값 미달 시 Fallback 로직 수행

---

## 5. 컨텍스트 정제 규칙 모듈

### 5.1 목적
- LLM 환각(Hallucination) 방지
- 프롬프트 길이 관리
- 질문 목적에 맞는 정보 선별

### 5.2 정제 규칙
- 중복 문장 제거
- 질문과 무관한 산업·직무 정보 제거
- 최신 정보 우선 정렬
- 토큰 초과 시 요약 적용

---

## 6. 프롬프트 템플릿 설계

### 6.1 기본 프롬프트 구조
- System: AI 역할, 출력 형식, 언어 규칙 정의
- Context: RAG 검색 결과 컨텍스트
- State: scenario, stage, intent, evaluation, retry_count
- User Input: 사용자 답변 또는 요청
- Instruction: 질문 생성 또는 평가 지시

---

## 7. 프롬프트 유형별 설계

### 7.1 질문 생성 프롬프트
- 직무·산업 맥락 반영
- 이전 질문과 중복 금지
- Stage 기반 난이도 조절

### 7.2 답변 평가 프롬프트
- 루브릭 기준 명시
- 점수 산출 기준 고정
- 부족 사유 명확화

---

## 8. LLM 호출 및 출력 파싱 모듈

### 8.1 LLM 호출 방식
- Chat Completion 기반
- System / User 메시지 분리

### 8.2 출력 데이터 구조
- intent
- evaluation.status
- evaluation.score
- evaluation.lack_reason
- next_action

### 8.3 파싱 실패 대응
- JSON 파싱 실패 시 재요청
- 출력 규칙 재강조 프롬프트 적용

---

## 9. 실패 및 Fallback 로직 설계

### 9.1 Retrieval 실패
- Threshold 미달 시 컨텍스트 없이 기본 프롬프트 사용

### 9.2 평가 불가 처리
- 답변 길이 부족
- 질문과 무관한 응답
- 재질문 또는 보조 질문 생성

### 9.3 반복 실패 제어
- retry_count 증가
- 최대 재시도 초과 시 단계 종료

---

## 10. State 기반 서비스 연동 설계

### 10.1 State 구성 요소
- scenario: 입사지원 | 직무평가 | 인성평가
- stage: 3 | 3-1 | 4 | 4-1
- intent
- evaluation
- next_action
- retry_count
- history

### 10.2 서비스 연동
- State 기반 API 응답 구성
- 화면 렌더링 제어
- 다음 질문 자동 트리거

---

## 11. 기대 효과
- 프롬프트 구조 표준화
- 평가 기준의 객관성 확보
- 직무·산업 확장 용이
- LLM 응답 품질 안정화
