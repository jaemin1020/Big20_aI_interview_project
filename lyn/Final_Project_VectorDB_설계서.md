# [산출물 3] Final_Project_VectorDB_설계서

## 1. 문서 개요

### 1.1 문서 목적

본 문서는 멀티모달 생성형 AI 면접 시스템에서 활용되는 VectorDB의 설계 기준을 정의합니다. 특히 지원자의 이력서, 면접 질문, 평가지표 등 비정형 데이터를 벡터화하여 검색 및 생성(RAG)에 활용하기 위한 데이터 구조, 임베딩 전략, 그리고 효율적인 검색 체계를 명확히 하는 것을 목적으로 합니다.

### 1.2 적용 범위

* **지원자 데이터**: 이력서 텍스트 기반 성과 및 역량 데이터
* **평가 지식 기반**: 직무별 면접 질문 예시 및 평가 루브릭
* **RAG 파이프라인**: LangChain `Retriever` 인터페이스를 통한 벡터 검색 엔진 (`tasks/rag_retrieval.py`)
* **저장 거점**: LangChain `PGVector` 기반의 벡터 저장소 (`tasks/pgvector_store.py`)

---

## 2. 전체 아키텍처 개요

### 2.1 VectorDB 역할

VectorDB는 LLM 응답 생성을 위한 **'외부 지식 저장소(Knowledge Base)'**로서 작동합니다.

* **문맥 제공**: 단순 키워드 매칭이 아닌 의미론적 유사도(Semantic Similarity)를 기반으로 질문 의도에 가장 부합하는 이력서 구절을 찾아냅니다.
* **신속한 참조**: 대규모 비정형 데이터 속에서 필요한 정보만을 수 밀리초(ms) 단위로 추출하여 LLM 프롬프트에 주입합니다.

### 2.2 시스템 연계 구조

1. **데이터 수집**: PDF 및 텍스트 기반 이력서 파싱 (`tasks/parse_resume.py`).
2. **임베딩 생성**: 한국어 특화 모델(`KURE-v1`)을 통한 고차원 벡터 변환 (`tasks/embedding.py`).
3. **저장**: PostgreSQL의 `pgvector` 확장을 사용하여 벡터 및 메타데이터 동시 저장.
4. **검색 & 생성**: 사용자의 답변이나 질문 생성 요청 시 유사도 검색 수행 후 LLM 응답 생성.

---

## 3. 벡터화 대상 정의

### 3.1 벡터화 대상 데이터

실시간 면접관이 참조할 수 있는 모든 정보를 벡터화 대상으로 산정합니다.

| 구분                     | 설명                                       | 활용 목적                                  |
| :----------------------- | :----------------------------------------- | :----------------------------------------- |
| **이력서 청크**    | 프로젝트 상세 설명, 활동 내역, 자소서 본문 | 실시간 개인화 질문 생성 근거               |
| **면접 질문 예시** | 직무별 표준 질문 및 모범 답변              | 질문 생성 실패 시 폴백(Fallback) 및 가이드 |
| **평가 루브릭**    | 논리성, 직무이해, 기술 숙련도 기준         | 답변 평가 시 정답 유무 및 수준 판별        |
| **피드백 문구**    | 강점 및 약점 설명용 텍스트 뱅크            | 최종 리포트의 피드백 문구 자동화           |

### 3.2 벡터화 제외 대상

* **정형 데이터**: ID, 지원 일자, 단순 합계 점수 등 (RDBMS의 일반 컬럼으로 관리).
* **단순 메타 정보**: 파일 경로, 생성자 정보 등 의미론적 검색이 불필요한 항목.

---

## 4. 메타데이터 및 청킹(Chunking) 상세 설계

단순 텍스트 검색의 한계를 극복하고 LLM이 문맥을 정확히 파악할 수 있도록 고도화된 청킹 및 메타데이터 전략을 적용합니다.

### 4.1 청킹(Chunking) 가이드라인 (`tasks/chunking.py`)

이력서의 방대한 데이터를 의미 단위로 쪼개어 검색 효율을 극대화합니다.

* **Chunk Size**: **200** (텍스트를 약 200자 내외의 작은 단위로 분할하여 검색의 정밀도를 높입니다.)
* **Chunk Overlap**: **70** (청크 사이의 문맥 단절을 방지하기 위해 약 35%의 텍스트를 중속시켜 문장의 연속성을 확보합니다.)
* **Recursive Split**: `\n\n` > `\n` > `.` >  순의 계층적 구분자를 사용하여 문장이나 단어가 중간에 잘리는 것을 최소화합니다.

### 4.2 카테고리별 메타데이터 구성 (`metadata` 필드)

각 데이터의 출처와 성격을 세분화하여 **하이브리드 필터링**이 가능하도록 설계합니다. `chunking.py`에서 정의된 실제 메타데이터 구조는 다음과 같습니다.

| 분류 (Type)             | 메타데이터 구조 (`JSONB`)                                                                   | 특징 및 포함 필드                                          |
| :---------------------- | :-------------------------------------------------------------------------------------------- | :--------------------------------------------------------- |
| **Header**        | `{"source": "resume", "category": "profile"}`                                               | 이름, 지원 직무, 지원 회사 정보를 포함한 프로필 요약       |
| **Education**     | `{"source": "resume", "category": "education", "school": "학교명"}`                         | 학교명 기반 필터링 지원, 전공 및 학점 정보 포함            |
| **Activity**      | `{"source": "resume", "category": "activity", "org": "단체명"}`                             | 대외활동 기획 및 수행 내용, 단체명 정보 포함               |
| **Award**         | `{"source": "resume", "category": "award"}`                                                 | 수상 실적, 수여 기관, 수상 일자 요약                       |
| **Project**       | `{"source": "resume", "category": "project"}`                                               | 프로젝트명, 기술 스택, 성과 지표 중심의 상세 설명          |
| **Certification** | `{"source": "resume", "category": "certification"}`                                         | 자격증 명칭, 취득일, 발급 기관 정보                        |
| **Narrative (Q)** | `{"source": "resume", "category": "narrative", "subtype": "question"}`                      | 자기소개서 질문 원문 독립 보관 (검색용)                    |
| **Narrative (A)** | `{"source": "resume", "category": "narrative", "subtype": "answer", "question_ref": "..."}` | 답변 본문 분할 적재,`question_ref`를 통한 원문 질문 추적 |

---

## 5. 임베딩 엔진 및 비동기 파이프라인 설계

임베딩 과정은 핵심 연산을 담당하는 **'엔진(Engine)'**과 전체 공정을 관리하는 **'오케스트레이터(Orchestrator)'**로 이중 구조화되어 있습니다.

### 5.1 임베딩 핵심 엔진 (`tasks/embedding.py`)

이 모듈은 AI 모델을 메모리에 로드하고 텍스트를 수학적 벡터로 변환하는 순수 연산 로직을 담당합니다.

* **모델 기동**: `langchain_huggingface`를 통해 `KURE-v1` 모델을 로드하며, GPU 가용 시 `cuda` 장치를 우선 할당합니다.
* **벡터 변환**: LangChain의 `Embeddings` 인터페이스를 구현하여, 체인 내부에서 투명하게 벡터 변환을 수행합니다.
* **정규화(Normalization)**: `normalize_embeddings=True` 설정을 통해 코사인 유사도 연산에 최적화된 결과물을 산출합니다.

### 5.2 비동기 오케스트레이터 (`tasks/resume_embedding.py`)

이 모듈은 핵심 엔진을 활용하여 이력서 처리의 전 과정을 관리하는 **Celery 기반의 비동기 태스크**입니다.

* **파이프라인 관리**: DB에서 이력서 조회 → 청킹 호출 → 임베딩 엔진 호출 → 벡터 DB 저장까지의 워크플로우를 제어합니다.
* **대표 벡터(Representative Vector)**: 전체 청크 중 첫 번째 청크(보통 헤더 및 요약)를 추출하여 `Resumes` 테이블의 `embedding` 컬럼에 별도로 저장, 빠른 필터링에 활용합니다.
* **상태 추적 (Status Tracking)**: 작업의 시작과 성공/실패 여부를 `processing_status` 컬럼에 실시간 업데이트하여 시스템 안정성을 확보합니다.

변환된 결과값은 LangChain 전용 테이블 스키마에 영속화됩니다.

```sql
-- LangChain PGVector 자동 생성 테이블 구조
CREATE TABLE langchain_pg_embedding (
    id uuid PRIMARY KEY,
    collection_id uuid REFERENCES langchain_pg_collection(uuid),
    embedding vector(1024),
    document text, -- 원본 청크 텍스트
    metadata jsonb -- resume_id, category 등 포함
);
```

* **동기화 원칙**: 새로운 이력서 처리 요청 시 기존의 모든 벡터 데이터를 제거하고 최신본으로 교체(Delete-then-Insert)하여 데이터 무결성을 유지합니다.

---

## 6. 컬렉션 및 인덱스 설계

### 6.1 테이블 및 컬렉션 분리 기준

데이터의 성격과 활용 시점(Context)에 따라 테이블을 물리적으로 분리하거나, 단일 테이블 내에서 **'논리적 파티셔닝(Logical Partitioning)'**을 수행하여 검색 정확도를 제어합니다.

#### **1) `resume_embeddings` 내의 논리적 파티셔닝**

동일한 이력서 데이터라도 면접 단계에 따라 참조해야 할 정보가 다르므로, `metadata->>'category'`를 인덱싱하여 논리적으로 분리 관리합니다.

| 논리 카테고리        | 대상 데이터           | 활용 시점           | 분리 목적                            |
| :------------------- | :-------------------- | :------------------ | :----------------------------------- |
| **Profile**    | 이름, 직무, 학력 요약 | 면접 도입부 (Intro) | 지원자의 기본 정보 확인 및 인사      |
| **Experience** | 프로젝트, 경력, 활동  | 기술/경험 면접      | 구체적인 성과 및 역량 검증 질문 생성 |
| **Narrative**  | 자기소개서 질문/답변  | 심층 인성 면접      | 서류 기반 진위 확인 및 가치관 평가   |
| **Skill**      | 자격증, 기술 스택     | 역량/기술 면접      | 전문 도구 및 지식 수준 확인          |

#### **2) 물리적 테이블 분리 및 확장 계획**

이력서 이외에 시스템 전체가 공유하는 '지식 기반(Knowledge Base)' 데이터는 별도의 컬렉션으로 관리하여 전역적인 참조 성능을 확보합니다.

| 컬렉션/테이블명              | 물리적 역할              | 상세 데이터                       | 비고                                   |
| :--------------------------- | :----------------------- | :-------------------------------- | :------------------------------------- |
| **resume_embeddings**  | **개인화 데이터**  | 개별 지원자의 이력서 파편         | 지원자별 `resume_id`로 필터링        |
| **standard_questions** | **전역 지식 기반** | 1,000개 이상의 직무별 표준 질문   | 전 직무 공통 검색 (`予定`)           |
| **evaluation_rubrics** | **평가 기준 기반** | 면접관 가이드 및 모범 답안 루브릭 | 질문 생성 및 답변 평가 참조 (`予定`) |

#### **3) 분리 설계의 기대 효과**

* **검색 노이즈 제거 (Precision Filtering)**:
  - **전략**: 면접 단계별 `Retriever` 생성 시 `filter` 파라미터를 동적으로 구성하여 필요한 카테고리만 검색 범위로 한정합니다.
  - **이유**: 자기소개서 등의 추상적 표현이 기술적 성취 쿼리에 간섭하는 것을 방지하여 질문의 예리함을 유지합니다.
  - **결과**: `LCEL` 체인 내에서 고순도 컨텍스트가 주입되어 할루시네이션 방지 및 초개인화 면접이 실현됩니다.
* **멀티 테넌시 지원 (Multi-tenancy Isolation)**:
  - `resume_id` 기반의 물리/논리적 격리를 통해 수천 명의 지원자가 동시에 면접을 진행하더라도 데이터 유출이나 간섭 없이 독립적인 검색 컨텍스트를 보장합니다.

### 6.2 검색 효율 극대화 (Indexing)

* **HNSW 인덱스**: 대규모 데이터셋 발생 시, 단순 Linear Search가 아닌 HNSW(Hierarchical Navigable Small World) 인덱스를 신설하여 검색 속도를 O(log N) 수준으로 유지합니다.
* **Distance Metric**: 코사인 거리(Cosine Distance, `<=>`)를 기본 연산자로 사용하여 방향성 유사도를 정밀하게 측정합니다.

---

## 7. 결론

본 VectorDB 설계는 PostgreSQL pgvector의 강력한 관계형 기능과 벡터 연산 기능을 결합하여, **'정확한 근거 기반의 AI 면접'**을 가능케 합니다. 체계적인 메타데이터 관리와 한국어 특화 임베딩 모델의 조화를 통해 지원자의 역량을 가장 객관적으로 평가할 수 있는 지식 기반을 제공합니다.
