# 2026-02-11 AI Interview 시스템 오류 수정 내역

## 1. AI-Worker 문법 오류 수정 (SyntaxError)

- **대상 파일**: `ai-worker/tasks/stt.py`
- **오류 현황**: Git 머지 충돌 기호(`<<<<<<<`, `=======`, `>>>>>>>`)가 코드 내에 남아서 Celery 워커가 실행되지 않고 즉시 종료되는 문제 발생.
- **수정 내용**: 충돌 기호를 제거하고 `stt_model` 전역 변수를 사용하는 올바른 코드로 정리 완료.

## 2. RAG 파이프라인 데이터 저장 로직 연결

- **대상 파일**: `ai-worker/tasks/resume_embedding.py`
- **오류 현황**: 이력서 파싱 및 청킹은 수행되나, 생성된 청크 벡터(Embedding)들이 실제 벡터 DB 테이블(`resume_embeddings`)에 저장되지 않고 누락되는 현상 확인. (RAG 검색 불가 원인)
- **수정 내용**: `pgvector_store.py`의 `store_embeddings` 함수를 연결하여, 모든 이력서 청크 데이터가 PostgreSQL 벡터 테이블에 정상적으로 적재되도록 로직 수정.

## 3. DB 초기화 스크립트 오류 수정

- **대상 파일**: `infra/postgres/init.sql`
- **오류 현황**: `evaluation_reports` 테이블이 아직 생성되지 않은 상태에서 트리거를 생성하려 시도하여 DB 컨테이너가 에러(Code 3)와 함께 종료됨.
- **수정 내용**: 테이블 존재 여부를 체크하여 안전하게 트리거를 생성하거나, 백엔드에서 생성하도록 로직 분리 검토 (현재는 스크립트 실패를 방지하도록 주석 처리 또는 조건문 추가).

---

**상태**: 수정 및 연결 작업 완료 (정상 작동 확인 대기)

## 4. LLM 아키텍처 구조 분리 이유 (기술적 배경)
현재 `utils/exaone_llm.py`(엔진)와 `tasks/question_generator.py`(작업자)가 분리된 핵심 이유는 다음과 같습니다.

1. **GPU 메모리(VRAM) 효율성**: EXAONE 같은 거대 모델은 로딩 시 수 GB의 메모리를 사용합니다. `exaone_llm.py`에서 **싱글톤(Singleton)** 패턴을 사용함으로써, 시스템 전체에서 모델을 딱 한 번만 메모리에 올리고 여러 작업(질문 생성, 답변 평가)이 이 모델을 공유하여 메모리 폭발을 방지합니다.
2. **다목적 재사용성**: 현재 모델은 질문 생성뿐만 아니라 답변 평가(`evaluator.py`)에서도 동일하게 사용됩니다. 공통 유틸리티로 분리함으로써 코드 중복을 막고 통합 관리가 가능해집니다.
3. **관심사 분리 (Separation of Concerns)**:
    - `question_generator.py`: 면접의 **비즈니스 로직**(순서, 이력서 데이터 추출, 시나리오 단계)에 집중합니다.
    - `exaone_llm.py`: **AI 엔진 설정**(모델 경로, GPU 레이어 설정, 토큰 생성 파라미터)에 집중합니다.

## 5. 프롬프트 제어권 단일화 (Authority Consolidation)
- **문제**: `question_generator.py`와 `exaone_llm.py` 양쪽에 프롬프트가 흩어져 있어 수정 사항이 제대로 반영되지 않던 문제 해결.
- **수정**: `exaone_llm.py` 내부의 하드코딩된 프롬프트를 제거하고, `question_generator.py` 상단의 **`PROMPT_TEMPLATE`**이 모든 질문 생성의 유일한 권한을 갖도록 통합 완료.
- **효과**: 이제 `question_generator.py` 파일 하나만 수정하면 면접관의 말투, 페르소나, 질문 스타일을 즉시 제어 가능.
