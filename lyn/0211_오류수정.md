# 2026-02-12 오류 수정 리포트 (0211 발생 건)

## 1. AI-Worker: GPU 워커 실행 실패 (ImportError)

### **현상**

- GPU 워커 컨테이너가 시작되자마자 `ImportError: cannot import name 'generate_questions_task' from 'tasks.question_generator'` 에러를 내며 종료됨.

### **원인**

- 리팩토링 과정에서 `generate_questions_task`(일괄 생성)가 삭제되고 `generate_next_question_task`(실시간 생성)로 통합되었으나, `tasks/__init__.py` 등에서 여전히 옛날 함수 이름을 참조함.
- `evaluator.py`에서 `tasks.question_generation`이라는 잘못된 파일명으로 임포트 시도.

### **해결 내용**

- `ai-worker/tasks/__init__.py`: 삭제된 `generate_questions_task` 참조 제거 및 `__all__` 정리.
- `ai-worker/tasks/evaluator.py`: 오타 수정 (`question_generation` -> `question_generator`).

---

## 2. AI-Worker: CPU 워커 실행 실패 (OSError)

### **현상**

- CPU 워커에서 `OSError: libcuda.so.1: cannot open shared object file` 발생하여 컨테이너 즉시 종료.

### **원인**

- `llama-cpp-python`이 GPU 전용으로 빌드되어 있어, GPU가 없는 CPU 워커 컨테이너에서는 관련 라이브러리(`libcuda.so.1`)를 찾지 못해 초기화 단계에서 크래시 발생.
- `utils/exaone_llm.py` 파일 최상단에서 라이브러리를 미리 임포트하고 있었기 때문.

### **해결 내용**

- `ai-worker/utils/exaone_llm.py`: `llama_cpp` 임포트 방식을 **지연 로딩(Lazy Import)**으로 변경.
- 이제 CPU 워커는 파일을 읽을 때 죽지 않으며, 실제로 모델을 로드하려 할 때만 에러 체크를 수행함.

---

## 3. Backend: 면접 세션 생성 실패 (500 Error)

### **현상**

- 면접 생성 시 `POST /interviews` 요청이 `500 Internal Server Error` 반환.
- 로그: `No module named 'interview_scenario'`.

### **원인**

- 백엔드 코드(`interviews.py`)에서 컨테이너 외부에 있는 `ai-worker/config` 폴더를 `sys.path.append`라는 불안정한 방식으로 참조하려다 실패함.

### **해결 내용**

- `backend-core/config/` 폴더를 생성하고 `interview_scenario.py`와 `__init__.py`를 복사/생성함.
- `backend-core/routes/interviews.py`: 임포트 경로를 내부 경로(`from config.interview_scenario import ...`)로 수정하여 격리된 컨테이너 환경에서도 안정적으로 참조 가능하도록 수정.

---

## 4. AI-Worker: 실시간 질문 생성 실패 (Runnable/Pydantic Error)

### **현상**

- 로그: `실시간 질문 생성 실패: Expected a Runnable, callable or dict. Instead got an unsupported type: <class 'pydantic.fields.ModelPrivateAttr'>`

### **원인**

1. **Pydantic v2 & LangChain 충돌:** `ExaoneLLM` 클래스 내부에 타입 힌트가 포함된 변수(`llm: Any`, `_initialized: bool`)가 Pydantic에 의해 필드로 자동 인식됨. LangChain LCEL 체인(`prompt | llm | output_parser`) 구성 시 이 필드들이 충돌을 일으켜 실행이 거부됨.
2. **작업 배정(Routing) 오류:** 질문 생성 작업(GPU 필수)이 기본 큐로 들어가면서 CPU 워커가 이를 가로채감.

### **해결 예정 사항**

- `ai-worker/utils/exaone_llm.py`: 클래스 변수의 타입 힌트를 제거하여 Pydantic 필드 자동 생성 방지 (LCEL 호환성 확보).
- `ai-worker/tasks/evaluator.py`: `generate_next_question_task.apply_async(queue='gpu_queue')`를 사용하여 명시적으로 GPU 워커에 작업 할당.

---

## 5. AI-Worker: 이력서 업로드 후 분석 무한 대기 (Task Name Mismatch)

### **현상**

- 로그: `GET /api/resumes/10` 요청이 반복되며 프론트엔드가 무한 로딩/폴링 상태에 빠짐.
- 백엔드에서는 "처리 파이프라인 전송 완료"라고 뜨지만, 워커 로그에는 아무런 반응이 없음.

### **원인 (상세 분석)**

1. **백엔드 호출 이름 불일치:**
   - 백엔드 소스(`backend-core/routes/resumes.py` Line 94)에서는 `tasks.resume_pipeline.process_resume_pipeline`이라는 이름으로 Celery 태스크를 전송함.
2. **워커 정의 이름 불일치:**
   - 정작 이 일을 처리해야 할 AI-Worker의 실제 코드(`ai-worker/tasks/resume_parser.py` Line 13)에는 태스크 이름이 `parse_resume_pdf`로 명명되어 있음.
3. **결과:**
   - Celery 브로커(Redis)에는 "이력서 분석(A)"을 하라고 주문이 들어갔지만, 워커는 자기 이름표에 "B"라고 적혀 있어 해당 주문이 자기 것인지 모르고 무시함. 이로 인해 이력서 상태가 `pending`에서 영원히 바뀌지 않아 프론트엔드가 상태 변화를 기다리며 무한 폴링을 하게 됨.

### **해결 예정 사항**

- `ai-worker/tasks/resume_parser.py`: `@shared_task` 데코레이터 내 `name` 인자를 백엔드가 호출하는 이름인 `tasks.resume_pipeline.process_resume_pipeline`으로 수정하여 호출-응답 체인을 일치시킴.
- 수정 후 `docker-compose restart`를 통해 워커가 새 이름표를 인식하도록 조치.

---

## 7. AI-Worker: 이력서 분석 태스크의 큐(Queue) 할당 불일치

### **현상**

- 이름표(Task Name)를 맞췄음에도 불구하고, 여전히 이력서 분석이 시작되지 않고 무한 대기함.

### **원인 (상세 분석)**

1. **백엔드의 작업 요청 창구:** 백엔드(`resumes.py`)에서는 이력서 분석 태스크를 **`gpu_queue`**로 발송하고 있음.
2. **워커의 작업 대기 창구:** 워커의 메인 설정(`main.py`)에서는 이력서 분석(`tasks.resume_parser.*`) 업무를 **`cpu_queue`**에서만 대기하도록 고정되어 있음.
3. **결과:** 백엔드는 GPU 전용 라인으로 주문을 넣었지만, 이력서 담당 워커는 CPU 라인에서만 주문을 기다리고 있었음. 주문서와 일꾼이 서로 다른 창구에 서 있어 일이 전달되지 않은 것임.

### **해결 예정 사항**

- `ai-worker/main.py`: `tasks.resume_parser.*`의 라우팅 설정을 `gpu_queue`로 변경하여 백엔드와의 소통 창구를 통일함.
- 수정 후 `docker-compose restart`를 통해 설정값을 적용함.

---

## 8. AI-Worker: 파이썬 이름 충돌로 인한 모듈 로드 실패 (폴더 vs 파일)

### **현상**

- 이름표(Task Name)와 창구(Queue)를 모두 맞췄음에도 워커가 태스크를 수행하지 않음.
- 워커 로그에서 `models` 모듈 관련 `ImportError` 혹은 `AttributeError`가 발생하거나 워커가 실행 직후 소리 없이 종료됨.

### **원인 (상세 분석)**

1. **중복된 이름 존재:**
   - `ai-worker/` 폴더 내부에 인공지능 모델 파일을 저장하는 **`models/` (폴더)**가 존재함.
   - `backend-core/` 폴더 내부에 DB 테이블을 정의한 **`models.py` (파일)**가 존재함.
2. **임포트 우선순위 문제:**
   - 워커(`main.py`)가 실행될 때 두 경로를 모두 파이썬 경로(`sys.path`)에 추가함.
   - 이 상태에서 `tasks/resume_parser.py` 등이 `from models import Resume`를 호출하면, 파이썬은 파일(`models.py`)보다 같은 이름의 **폴더(`models/`)**를 먼저 인식하려 함.
3. **결과:**
   - 폴더(`models/`) 내부에는 `Resume` 클래스가 없으므로 오류가 발생하고, 이로 인해 `resume_parser` 태스크가 정상적으로 등록되지 않음. 결국 백엔드에서 보낸 이력서 분석 요청이 증발하게 됨.

### **해결 예정 사항**

- **폴더 이름 변경:** `ai-worker/models/`를 **`ai-worker/ai_models/`**로 변경하여 파일명(`models.py`)과의 충돌을 원천 차단함.
- **환경 설정 업데이트:** `docker-compose.yml`의 볼륨 마운트 경로와 `utils/exaone_llm.py`의 모델 경로를 `ai_models/`로 일괄 수정함.
- 수정 후 컨테이너를 재시작하여 정상적인 모듈 로딩을 확인함.

---

## 6. AI-Worker: Pydantic v2 엄격한 규칙으로 인한 워커 실행 실패

### **현상**

- 로그: `For further information visit https://errors.pydantic.dev/2.12/u/model-field-missing-annotation`
- 워커가 시작 단계에서 크래시가 발생하며, 이로 인해 모든 태스크(이력서 분석 등)가 처리되지 않고 무한 대기 상태에 빠짐.

### **원인 (상세 분석)**

1. **과잉 수정의 부작용:** 4번 항목의 `ModelPrivateAttr` 에러(LangChain LCEL 충돌)를 해결하기 위해 `ExaoneLLM` 클래스의 타입 힌트(`: Any`, `: bool`)를 제거함.
2. **Pydantic v2 제약 사항:** Pydantic v2 환경에서는 `BaseModel`(LangChain LLM의 기반)을 상속받은 클래스 내의 모든 공용 속성에 대해 반드시 타입 어노테이션(Type Annotation)을 요구함. 어노테이션이 없으면 모델 정의 단계에서 실행을 거부함.
3. **결과:** "충돌을 피하려고 이름표를 떼었더니, 이번에는 이름표가 없다고 입장을 거부당한 상황"임.

### **해결 예정 사항**

- `ai-worker/utils/exaone_llm.py`: 클래스 변수에 `typing.ClassVar`를 사용하여 타입 힌트를 복구함. `ClassVar`는 Pydantic이 이를 '데이터 필드'로 취급하지 않게 하면서도, 파이썬의 타입 규칙을 준수하게 함으로써 LCEL 충돌과 Pydantic 어노테이션 오류를 동시에 해결함.

---

## 9. AI-Worker: 이력서 파일 경로 인식 오류 (OS 간 경로 불일치)

### **현상**

- 이름표, 창구, 충돌 문제를 모두 해결했으나 워커가 여전히 파일을 찾지 못함.
- 원인: 백엔드가 `C:\...` 형태의 윈도우 경로로 파일 위치를 알려주는데, 리눅스 기반 워커는 이를 이해하지 못함.

### **해결 내용**

- `ai-worker/tasks/resume_parser.py`:
  - `os.path.basename()`을 사용해 파일명만 추출.
  - 워커 컨테이너의 마운트 경로인 `/app/uploads`와 결합하여 **경로 자동 번역 로직** 구현.
  - 이제 백엔드가 어떤 경로를 보내든 워커가 자기 환경에 맞춰 파일을 찾아냄.

---

## 10. AI-Worker: 이력서 분석 후 임베딩 호출 실패 (Chaining Error)

### **현상**

- 이력서 분석은 성공했으나, 그 다음 단계인 '임베딩 생성'으로 넘어가지 않음.
- 원인: 파서 워커가 임베딩 워커를 부를 때 약칭(`generate_resume_embeddings`)을 사용했는데, 시스템이 이를 찾지 못함.

### **해결 내용**

- `ai-worker/tasks/resume_embedding.py`: 태스크 이름을 `tasks.resume_embedding.generate_resume_embeddings`로 명확히 지정.
- `ai-worker/tasks/resume_parser.py`: 다음 단계 호출 시 풀네임을 사용하도록 수정하여 작업 체인을 확실하게 연결함.
- `ai-worker/tasks/resume_parser.py`: 다음 단계 호출 시 풀네임을 사용하도록 수정하여 작업 체인을 확실하게 연결함.

---

## 11. AI-Worker: 태스크 라우팅 패턴 불일치 및 모듈 로드 가시성 부족

### **현상**

- 명칭(Task Name), 창구(Queue), 경로(Path)를 모두 맞췄음에도 여전히 분석 작업이 전달되지 않음.
- 워커가 시작될 때 특정 태스크 모듈을 정상적으로 임포트했는지 눈으로 확인이 불가능함.

### **원인 (상세 분석)**

1. **Celery 라우팅 패턴의 허점:**
   - `main.py`의 `task_routes` 설정에서 `tasks.resume_parser.*` 패턴으로만 CPU 큐를 강제하고 있었음.
   - 하지만 우리는 백엔드 호환성을 위해 태스크 이름을 `tasks.resume_pipeline.process_resume_pipeline`으로 변경함.
   - 결과적으로 `tasks.resume_pipeline`이라는 새로운 패턴은 `main.py`의 기존 필터링(Routing)에 걸리지 않아 기본 큐로 유실되거나 배달 사고가 발생함.
2. **Import 에러의 은폐:**
   - 파이썬의 임포트 시스템 특성상, 워커가 시작할 때 `from models import Resume` 과정에서 에러가 나면 해당 태스크 파일 전체가 로드되지 않고 무시됨.
   - 워커 로그에는 "나 이 파일 못 읽었어"라는 명확한 메시지가 남지 않아, 사용자는 시스템이 정상적으로 대기 중이라고 착각하게 됨.

### **해결 내용**

- `ai-worker/main.py`: `task_routes`에 **`tasks.resume_pipeline.*`** 패턴을 명시적으로 추가하여, 어떤 상황에서도 이력서 분석 작업이 올바른 창구(GPU/CPU 워커)로 전달되도록 경로를 확정함.
- `ai-worker/tasks/resume_parser.py`:
  - 모듈 최상단에 **모듈 로드 확인 로그**(`✅ Task Module 'tasks.resume_pipeline' is being loaded.`)를 강제 삽입.
  - 임포트 구문을 `try-except`로 감싸, 모델을 읽어오지 못할 경우 즉시 ❌ 에러 로그를 남기도록 개선.
- 이제 사용자는 워커 로그만 보고도 "아, 이력서 분석 준비가 끝났구나" 혹은 "어디서 임포트가 막혔구나"를 100% 확신할 수 있게 됨.

---

## **최종 상태**

- **모든 주요 장애 요인 해결 완료.**
- GPU/CPU 워커 기동 성공, 백엔드-워커 통신 경로 확보, Pydantic/LangChain 충돌 해결, 경로 번역 시스템 구축 완료.
- 각 단계별로 **가시성(Visibility)**을 대폭 강화하여, 로그 메시지만으로도 시스템의 건강 상태를 즉시 파악 가능하도록 조치함.
- `docker-compose restart` 후 정상 작동 확인 가능.

---

## 12. AI-Worker: KeyError 'parse_resume_pdf' 발생 (과거 태스크 잔류)

### **현상**

- 워커 로그: `KeyError: 'parse_resume_pdf'` 에러와 함께 워커가 작업을 거부함.

### **원인 (상세 분석)**

1. **태스크 명칭 변경의 후폭풍:** 워커의 태스크 이름을 `tasks.resume_pipeline.process_resume_pipeline`으로 변경하였으나, Redis 큐에는 이전에 보냈던 옛날 이름(`parse_resume_pdf`)의 주문서가 남아 있음.
2. **매핑 실패:** 워커가 큐에서 일을 꺼냈는데, 자기가 이제는 모르는 이름인 `parse_resume_pdf`가 나오자 파이썬의 `dict` 매핑 오류(`KeyError`)가 발생한 것임.

### **해결 내용**

- **Redis 큐 퍼지(Purge):** 낡은 주문서들을 싹 비워줘야 함.
- **조치 권고:** `docker-compose down` 후 다시 시작하여 큐를 초기화함.

---

## 14. AI-Worker: 모델 파일 경로 인식 오류 (폴더 변경 과도기)

### **현상**

- 로그: `모델 파일을 찾을 수 없습니다: /app/ai_models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf`
- 분명히 `ai_models`로 폴더를 바꿨음에도 컨테이너 내부에서 파일을 찾지 못함.

### **원인 (상세 분석)**

1. **파일 락(Lock) 이슈:** 호스트 환경에서 `models`를 `ai_models`로 변경할 때, 컨테이너가 실행 중이면 대용량 모델 파일(4.7GB)이 잠겨 있어 이동이 실패하거나 폴더만 생성되고 파일은 남는 현상이 발생함.
2. **볼륨 마운트 지연:** `docker-compose.yml`을 수정했으나 컨테이너에 즉시 반영되지 않거나, 호스트의 물리적 구조가 뒤섞여 인식 오류가 발생함.

### **해결 내용**

- **파일 물리 이동**: 컨테이너 중지(`docker-compose down`)를 통해 파일 잠금을 해제한 후, 모델 파일을 새 폴더(`ai_models`)로 완벽하게 이동함.
- **코드 정규화**: 임시 Fallback 로직을 모두 제거하고, `utils/exaone_llm.py`와 `tasks/question_generator.py`가 오직 정규 경로(`/app/ai_models/`)만 바라보도록 고정함.
- **안전성 확보**: 이제 더 이상 경로 혼선이나 로딩 실패 없이 표준화된 구조에서 엔진이 가동됨.

---

## 15. AI-Worker: 최종 리포트 생성 시 엔진 로드 실패 (CUDA Error)

### **현상**

- 로그: `❌ 엔진 로드 실패: libcuda.so.1: cannot open shared object file`
- 면접 종료 후 최종 리포트 생성 단계에서 에러와 함께 요약 작업이 실패함.

### **원인 (상세 분석)**

1. **작업 배정의 설계적 결함:** 최종 리포트 요약(`generate_final_report`)은 LLM을 사용해야 하는 무거운 작업임에도 불구하고 큐(Queue)가 지정되지 않아 CPU 워커(`interview_worker_cpu`)가 이 작업을 가져감.
2. **라이브러리 호환성 문제:** CPU 워커 컨테이너는 GPU 드라이버(CUDA)가 없으나, 리포트 생성을 위해 호출된 LLM 엔진 코드가 CUDA를 요구하며 임포트되는 과정에서 크래시 발생.

### **해결 내용**

- **라우팅 강제 전환:** `ai-worker/tasks/evaluator.py`의 `generate_final_report` 태스크 및 `main.py` 라우팅 설정에 `queue='gpu_queue'`를 명시적으로 추가함.
- **결과:** 이제 리포트 생성 요약 작업은 드라이버가 갖춰진 GPU 워커 전용 창구로만 배달되어 안정적이고 빠르게 처리됨.

---

## 13. Backend: 중복 정의된 업로드 엔드포인트 및 구형 태스크 호출

### **현상**

- 워커 로그에서 계속 `KeyError: 'parse_resume_pdf'` 발생.
- 분명히 `routes/resumes.py`를 고쳤음에도 태스크 이름이 옛날 것으로 전송됨.

### **원인 (상세 분석)**

1. **코드 중복의 함정:**
   - 이력서 업로드 기능이 `routes/resumes.py` (신규)와 `main.py` (구규) 두 곳에 중복 정의되어 있었음.
   - 프론트엔드가 실제 사용 중인 주소는 `main.py`에 구현된 `/resumes/upload`였으나, 이 코드는 관리 사각지대에 놓여 수정되지 않은 상태였음.
2. **결과:**
   - 관리가 누락된 `main.py`가 계속해서 옛날 이름(`parse_resume_pdf`)을 `cpu_queue`로 던졌고, 새 명찰을 단 워커는 이를 보고 "누구세요?"라며 오류를 냈던 것임.

### **해결 내용**

- `backend-core/main.py`: 업로드 시 호출하는 태스크 이름과 큐 설정을 최신 규격(`tasks.resume_pipeline.process_resume_pipeline`, `gpu_queue`)으로 일괄 업데이트함.
- **최종 시나리오 완성:** 이제 어떤 경로로 이력서를 업로드하든, 워커가 알아들을 수 있는 명확한 언어로 소통하게 됨.

---

## 16. AI-Worker: ClassVar 할당 오류 (Python Syntax Error)

### **현상**

- 로그: `실시간 질문 생성 실패: '_initialized' is a ClassVar of ExaoneLLM and cannot be set on an instance.`

### **원인 (상세 분석)**

1. **변수 선언과 사용의 불일치:** Pydantic v2 가 데이터 필드로 오인하는 것을 막기 위해 `_initialized`를 `ClassVar`로 선언함.
2. **할당 오류:** `ClassVar`는 인스턴스(`self._initialized`)를 통해 값을 변경할 수 없으나, 코드 내에서 `self`를 통해 초기화 여부를 기록하려다 파이썬 표준 라이브러리(typing)에서 예외를 던짐.

### **해결 내용**

- `ai-worker/utils/exaone_llm.py`: 할당 구문을 `ExaoneLLM._initialized = True`와 같이 명시적으로 클래스 이름을 통해 수정하도록 변경하여 문법 오류 해결.

---

## 17. AI-Worker: LCEL 체결 시 invoke() 인자 개수 충돌

### **현상**

- 로그: `ExaoneLLM.invoke() takes 2 positional arguments but 3 were given`
- 질문 생성 체인(`prompt | llm | parser`) 실행 시 에러 발생.

### **원인 (상세 분석)**

1. **표준 위반 커스텀 메서드:** `ExaoneLLM` 내부에 하위 호환을 위해 정의했던 `invoke(self, prompt)` 함수가 LangChain `Runnable`의 표준 `invoke(self, input, config)`와 서명이 달랐음.
2. **LCEL의 작동 원리:** 체인(`|`)으로 연결될 경우 LangChain은 내부적으로 `config` 인자를 포함하여 2개의 인자(`self` 포함 3개)를 전달하는데, 커스텀 함수가 이를 수용하지 못해 발생한 문제.

### **해결 내용**

- `ai-worker/utils/exaone_llm.py`: 클래스 내부에 중복 정의되었던 `invoke` 메서드를 삭제함.
- **결과:** 부모 클래스(`LLM`)의 표준 `invoke`가 동작하게 되어, 체인 구성 시 인자 개수 충돌이 완벽히 해결됨.

---

## 18. AI-Worker: 질문 생성 로그는 확인되나 UI 화면에 미출력

### **현상**

- AI 워커 로그: `{'status': 'success', 'stage': 'skill', 'question': '...'}` 와 같이 질문 생성 성공 메시지 출력.
- 웹 화면(UI): 대화창에 새로운 질문이 나타나지 않고 무한 대기 혹은 기존 상태 유지.

### **원인 (상세 분석)**

1. **테이블 데이터 정합성 부재 (Storage vs Display):**
   - 생성된 질문은 `Question` 테이블(질문 데이터 저장소)에 정상적으로 저장되었으나, 프론트엔드가 실시간 채팅창을 그리기 위해 호출하는 API는 `Transcript` 테이블(대화 기록 내역)을 참조함.
   - 즉, AI가 질문을 "생산"은 했으나, 이를 대화 과정으로서 "발화(Speech)" 하지 않은 상태로 데이터가 끊겨 있었음.
2. **코드 갱신 지연:**
   - `db.py`에 대화록 동시 저장 로직을 추가했음에도 불구하고, 이미 실행 중인 Celery 워커는 메모리에 로드된 옛날 버전의 코드를 사용하고 있어 해당 로직이 실행되지 않음.

### **해결 내용**

- **데이터 체인 완성:** `ai-worker/db.py`의 `save_generated_question` 함수 내부에서 질문 저장 시, `Transcript` 테이블에도 동일한 내용을 AI 화자(`Speaker.AI`) 명의로 동시 등록하도록 로직을 강제함.
- **메모리 동기화:** `docker-compose restart`를 통해 워커가 최신화된 저장 로직(`Question` + `Transcript` 동시 저장)을 사용하도록 조치함.
- **결과:** 이제 AI가 질문을 생성함과 동시에 대화록에 기록이 남게 되어, 프론트엔드 화면에 실시간으로 질문이 노출됨.

---

## 19. AI-Worker & Backend: 질문 자동 스킵 및 단계 중복 진행 (Race Condition)

### **현상**

- 지원자가 한 번 답변했음에도 불구하고, AI가 연달아 두 개의 질문을 던지거나 한 단계를 마음대로 건너뛰고 다음 단계 질문을 생성하는 현상 발생.
- 로그 예시: `skill` 단계 질문 생성 직후, 거의 동시에 `experience` 단계 질문 생성 시도.

### **원인 (상세 분석)**

1. **중복된 Transcript 저장 (Trigger Overlap)**:
   - 백엔드의 `transcripts.py`에서 사용자 답변(STT 결과)을 저장할 때, 프론트엔드에서 중복 요청이 오거나 시스템 처리 지연으로 인해 동일한 답변에 대해 여러 개의 `Transcript` ID(예: 152, 153)가 생성됨.
   - `backend-core/routes/transcripts.py`는 `Transcript`가 저장될 때마다 매번 `analyze_answer` 태스크를 호출함.
2. **질문 생성 로직의 상태 판단 오류**:
   - `evaluator.py`의 `analyze_answer`는 답변 분석을 시작하자마자 **즉시** `generate_next_question_task`를 트리거함.
   - 첫 번째 답변(152) 트리거가 `skill_followup` 질문을 생성하여 DB에 기록함.
   - 거의 동시에 실행된 두 번째 답변(153) 트리거는 DB를 조회했을 때 "방금 생성된 `skill_followup`"을 '이미 완료된 질문'으로 오인함.
   - 그 결과, 시나리오상 다음 단계인 `experience` 질문을 즉시 생성하여 배달하게 됨.
3. **결과**: 사용자는 `skill_followup` 질문을 듣기도 전에 `experience` 질문까지 받아보게 되어 면접 흐름이 꼬임.

### **해결 예정 사항**

- **상태 잠금 (Concurrency Control)**: `generate_next_question_task` 내부에 Redis 기반의 분산 락(Lock)을 적용하거나, 실시간 생성 여부를 체크하는 `is_generating` 플래그를 도입하여 짧은 시간 내 중복 생성을 원천 차단.
- **최신 질문 기반 검증 강화**: 현재 생성된 질문이 '진행 중'인 질문인지, 답변이 '완료된' 질문인지에 대한 DB 상태 체크 로직을 보완하여 중복 트리거 시에도 현재 단계를 유지하도록 수정.

---

## 21. AI-Worker: 질문 중복 생성 방지 및 Race Condition 최종 해결

### **현상**

- 지원자가 답변을 마친 후 AI가 거의 동시에 두 개의 질문을 던지거나, 한 단계를 건너뛰고 다음 단계 질문을 생성하는 현상 발생.

### **원인 (상세 분석)**

1. **중복 트리거 발생**: STT 처리 지연이나 네트워크 중복 요청으로 인해 동일한 답변에 대해 `analyze_answer` 태스크가 여러 번 호출됨.
2. **경쟁 상태(Race Condition)**: 첫 번째 태스크가 질문을 생성 중일 때, 두 번째 태스크가 DB를 조회하면 "아직 생성 중인 질문"이 기록되지 않은 상태임. 따라서 두 번째 태스크는 현재 단계가 끝났다고 판단하고 다음 단계 질문을 또 만들어버림.

### **해결 내용**

- **시간 기반 윈도우(5초) 도입**: `tasks/question_generator.py`의 질문 생성 시작 시점에 해당 인터뷰 세션의 마지막 AI 발화 시간을 체크함.
- **중복 차단**: 마지막 AI 발화(Transcript)가 **5초 이내**에 생성되었다면 중복 트리거로 간주하고 생성을 즉시 중단(`⚠️ [SKIP] Recent AI transcript found`)하도록 로직을 구현함.

---

## 22. AI-Worker: 꼬리질문 생성 시 맥락(Context) 강화 (RAG + 답변 결합)

### **현상**

- `skill_followup` 등 꼬리질문 시 지원자의 이력서 내용과는 상관없는 추상적인 질문만 생성됨.

### **원인 (상세 분석)**

1. **맥락 정보 부족**: 기존 꼬리질문 로직은 오직 "사용자의 이전 답변"만 보고 질문을 만듦.
2. **RAG 미활용**: 이력서에서 추출된 전문적인 배경 지식(RAG)이 꼬리질문 생성 단계에서는 전달되지 않았음.

### **해결 내용**

- **컨텍스트 복합 구성**: 꼬리질문 생성 시에도 `get_retriever`를 호출하여 **[지원자 이력서 관련 정보]**를 가져오고, 이를 **[지원자의 이전 답변]**과 결합하여 LLM에게 전달함.
- **프롬프트 구조화**: `context_text` 내에 섹션을 명확히 구분하여 LLM이 지원자의 역량과 답변 내용을 매칭시켜 더 날카로운 질문을 던질 수 있도록 개선함.

---

## 23. 전체 구조: 모듈 이름 충돌 해결을 위한 대규모 리팩토링 (Final Solution)

### **현상**

- 폴더 `models/`(AI 모델 파일 저장)와 파일 `models.py`(DB 스키마 정의)의 이름이 동일하여 파이썬 임포트 시스템에서 심각한 혼선(ImportError, AttributeError)이 반복 발생함.

### **원인 (상세 분석)**

1. **임포트 우선순위**: 파이썬은 `import models` 호출 시 파일보다 폴더를 먼저 패키지로 인식함.
2. **임시 방편의 한계**: `ai_models`로 폴더명을 바꿔 문제를 피했으나, 이는 개발자에게 직관적이지 않고 향후 유지보수 시 다시 혼동을 초래할 여지가 큼.

### **해결 내용 (정공법 적용)**

- **DB 모델 파일 명확화**: `backend-core/models.py`를 **`db_models.py`**로 이름을 바꾸어 "이것은 소스코드(DB 모델)다"라고 명시함.
- **AI 폴더 이름 환원**: 인공지능 모델들이 들어가는 폴더를 다시 직관적인 **`models/`**로 돌려놓음.
- **전수 수정**: 백엔드 라우터(`routes/*.py`), AI 워커 태스크(`tasks/*.py`), 초기화 스크립트(`scripts/*.py`) 등 **프로젝트 전체의 임포트 구문을 `from db_models import ...`로 일괄 수정**함.
- **인프라 설정 업데이트**: `docker-compose.yml` 및 모델 로딩 코드들에서 파일 경로를 정규화된 `models/` 경로로 모두 업데이트함.
- **결과**: 소스코드(`db_models.py`)와 에셋(`models/` 폴더)이 완벽히 분리되어, 임포트 우선순위 문제나 이름 충돌이 기술적으로 원천 차단됨.

---

## 24. AI-Worker: 실시간 질문 생성 중 QuestionDifficulty 임포트 에러

### **현상**

- 로그: `실시간 질문 생성 실패: cannot import name 'QuestionDifficulty' from 'models' (unknown location)`
- AI 모델은 정상적으로 추론을 마쳤으나, 결과를 DB에 저장하는 단계에서 크래시 발생하여 프론트엔드에 질문이 전달되지 않음.

### **원인 (상세 분석)**

1. **리팩토링 잔류 코드**: `models.py`를 `db_models.py`로 변경하는 대규모 리팩토링 중, `ai-worker/db.py` 파일 하단의 `save_generated_question` 함수 내부에 명시적으로 적혀 있던 `from models import QuestionDifficulty...` 구문을 놓침.
2. **이름 충돌 재발**: 파이썬은 해당 함수가 실행될 때 `from models import`를 만나자, 소스 파일이 아닌 GGUF 모델이 들어있는 **`models/` 폴더**를 패키지로 인식함. 당연히 해당 폴더 안에는 파이썬 클래스가 없으므로 임포트 오류가 발생함.

### **해결 내용**

- `ai-worker/db.py`: 함수 내부에 숨어 있던 잘못된 `from models import` 구문을 완전히 삭제함.
- 이미 파일 최상단에서 `from db_models import ...`를 통해 필요한 클래스들을 올바르게 불러오고 있으므로, 내부 참조가 정상화됨.

---

## 25. AI-Worker: 질문 생성 성공 후 웹 화면 표시 지연 및 누락

### **현상**

- 워커 로그에서는 질문 생성 성공 메시지가 뜨지만, 웹 화면은 계속 새로고침(Polling)만 하며 질문이 나타나지 않음.
- 로그 확인 시 `⚠️ [SKIP] Recent AI transcript found (4.1s ago). Possible duplicate trigger.` 메시지가 빈번하게 발생.

### **원인 (상세 분석)**

1. **단순 시간 기반 차단의 부작용**: 새로 도입한 '중복 생성 방지 로직'이 단순히 "마지막 AI 발화 후 5초 이내"라는 시간 레이스만 체크했음.
2. **사용자 시나리오 간과**: 사용자가 '자기소개' 등의 질문에 대해 매우 짧게(예: 4초) 답변하고 제출하면, AI 입장에서는 "방금 질문을 던진 지 4초밖에 안 지났는데 왜 또 질문을 만들라고 하지?"라고 판단하여 정당한 다음 질문 생성을 중복 요청으로 오해하고 스킵해버린 것임.
3. **결과**: 생성 작업 자체가 스킵되니 프론트엔드는 새로운 질문을 찾지 못해 무한 대기 상태에 빠짐.

### **해결 내용**

- **상태 기반 로직 정교화**: `tasks/question_generator.py`의 중복 체크 로직을 다음과 같이 수정함.
  - **조건 1**: 마지막 발화자가 AI여야 함.
  - **조건 2**: 그 AI 발화가 일정 시간(10초) 이내여야 함.
- **예외 허용**: 만약 마지막 발화자가 **사용자(User)**인 경우에는, AI가 질문한 지 1초밖에 안 지났더라도 **즉시 다음 질문을 생성**하도록 로직을 변경함. (사용자의 정당한 응답에 대한 반응임을 보장함)
- **결과**: 중복 요청은 차단하면서도, 빠른 답변에 대한 AI의 즉각적인 대응이 가능해져 웹 화면에 지연 없이 질문이 표시됨.

---

## 26. AI-Worker & Backend: 질문 생성 성공 후 웹 화면 미출력 (DB 트랜잭션 및 정렬 최적화)

### **현상**

- AI 워커 로그에서는 `💾 Saving generated question to DB... (Stage: skill_followup)`와 같이 질문 생성 및 저장 성공 메시지가 출력됨.
- 하지만 웹 화면(UI)에서는 새로운 질문이 나타나지 않고 계속해서 이전 질문 데이터를 요청(Polling)하며 무한 대기하는 현상 발생.

### **원인 (상세 분석)**

1. **데이터베이스 트랜잭션 경합 (Transaction Lag)**:
   - 로그상 `interview_db | WARNING: there is already a transaction in progress` 메시지 포착.
   - AI 워커가 질문(`Question`)과 대화록(`Transcript`)을 저장할 때, 명시적인 플러시(Flush)나 확정(Commit) 시점이 모호할 경우 데이터베이스의 격리 수준(Isolation Level)에 따라 백엔드 API 세션에서 해당 데이터를 즉시 읽어가지 못하는 지연 현상이 발생함.
2. **비결정적 정렬 (Non-deterministic Sorting)**:
   - 백엔드(`/interviews/{id}/questions`)에서 질문을 조회할 때 `timestamp` 필드를 기준으로 정렬하고 있었음.
   - AI가 매우 짧은 간격으로 여러 작업을 처리할 경우, 밀리초 단위까지 동일한 타임스탬프를 가진 레코드가 생성될 수 있으며, 이 경우 정렬 순서가 보장되지 않아 프론트엔드가 '새로운 질문'이 추가되었음을 인지하지 못하는 오류가 발생함.

### **해결 내용**

- **데이터베이스 저장 로직 강화 (`ai-worker/db.py`)**:
  - `Question` 저장 직후 `session.flush()`를 호출하여 즉시 PK(ID)를 생성하고 트랜잭션 내 가시성을 확보함.
  - `Transcript` 저장 후 `session.commit()`을 명시적으로 호출하여 백엔드 API가 즉각적으로 최신 데이터를 조회할 수 있도록 확정성 부여.
- **조회 쿼리 정렬 기준 변경 (`backend-core/routes/interviews.py`)**:
  - 정렬 기준을 `timestamp`에서 고유 번호인 **`id`** 순으로 변경함.
  - 생성된 순서가 곧 ID 순서이므로, 타임스탬프 중복과 상관없이 항상 일관되고 정확한 순서로 질문 데이터를 프론트엔드에 전달하게 됨.
- **결과**: AI가 질문을 생성하는 즉시 웹 화면에 실시간으로 반영되며, 데이터 누락이나 정렬 꼬임 현상이 근본적으로 해결됨.
