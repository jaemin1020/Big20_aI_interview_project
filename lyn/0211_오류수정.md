# 2026-02-12 오류 수정 리포트 (0211 발생 건)

## 1. AI-Worker: GPU 워커 실행 실패 (ImportError)

### **현상**

- GPU 워커 컨테이너가 시작되자마자 `ImportError: cannot import name 'generate_questions_task' from 'tasks.question_generator'` 에러를 내며 종료됨.

### **원인**

- 리팩토링 과정에서 `generate_questions_task`(일괄 생성)가 삭제되고 `generate_next_question_task`(실시간 생성)로 통합되었으나, `tasks/__init__.py` 등에서 여전히 옛날 함수 이름을 참조함.
- `evaluator.py`에서 `tasks.question_generation`이라는 잘못된 파일명으로 임포트 시도.

### **해결 내용**

- `ai-worker/tasks/__init__.py`: 삭제된 `generate_questions_task` 참조 제거 및 `__all__` 정리.
- `ai-worker/tasks/evaluator.py`: 오타 수정 (`question_generation` -> `question_generator`).

---

## 2. AI-Worker: CPU 워커 실행 실패 (OSError)

### **현상**

- CPU 워커에서 `OSError: libcuda.so.1: cannot open shared object file` 발생하여 컨테이너 즉시 종료.

### **원인**

- `llama-cpp-python`이 GPU 전용으로 빌드되어 있어, GPU가 없는 CPU 워커 컨테이너에서는 관련 라이브러리(`libcuda.so.1`)를 찾지 못해 초기화 단계에서 크래시 발생.
- `utils/exaone_llm.py` 파일 최상단에서 라이브러리를 미리 임포트하고 있었기 때문.

### **해결 내용**

- `ai-worker/utils/exaone_llm.py`: `llama_cpp` 임포트 방식을 **지연 로딩(Lazy Import)**으로 변경.
- 이제 CPU 워커는 파일을 읽을 때 죽지 않으며, 실제로 모델을 로드하려 할 때만 에러 체크를 수행함.

---

## 3. Backend: 면접 세션 생성 실패 (500 Error)

### **현상**

- 면접 생성 시 `POST /interviews` 요청이 `500 Internal Server Error` 반환.
- 로그: `No module named 'interview_scenario'`.

### **원인**

- 백엔드 코드(`interviews.py`)에서 컨테이너 외부에 있는 `ai-worker/config` 폴더를 `sys.path.append`라는 불안정한 방식으로 참조하려다 실패함.

### **해결 내용**

- `backend-core/config/` 폴더를 생성하고 `interview_scenario.py`와 `__init__.py`를 복사/생성함.
- `backend-core/routes/interviews.py`: 임포트 경로를 내부 경로(`from config.interview_scenario import ...`)로 수정하여 격리된 컨테이너 환경에서도 안정적으로 참조 가능하도록 수정.

---

## 4. AI-Worker: 실시간 질문 생성 실패 (Runnable/Pydantic Error)

### **현상**

- 로그: `실시간 질문 생성 실패: Expected a Runnable, callable or dict. Instead got an unsupported type: <class 'pydantic.fields.ModelPrivateAttr'>`

### **원인**

1. **Pydantic v2 & LangChain 충돌:** `ExaoneLLM` 클래스 내부에 타입 힌트가 포함된 변수(`llm: Any`, `_initialized: bool`)가 Pydantic에 의해 필드로 자동 인식됨. LangChain LCEL 체인(`prompt | llm | output_parser`) 구성 시 이 필드들이 충돌을 일으켜 실행이 거부됨.
2. **작업 배정(Routing) 오류:** 질문 생성 작업(GPU 필수)이 기본 큐로 들어가면서 CPU 워커가 이를 가로채감.

### **해결 예정 사항**

- `ai-worker/utils/exaone_llm.py`: 클래스 변수의 타입 힌트를 제거하여 Pydantic 필드 자동 생성 방지 (LCEL 호환성 확보).
- `ai-worker/tasks/evaluator.py`: `generate_next_question_task.apply_async(queue='gpu_queue')`를 사용하여 명시적으로 GPU 워커에 작업 할당.

---

## 5. AI-Worker: 이력서 업로드 후 분석 무한 대기 (Task Name Mismatch)

### **현상**

- 로그: `GET /api/resumes/10` 요청이 반복되며 프론트엔드가 무한 로딩/폴링 상태에 빠짐.
- 백엔드에서는 "처리 파이프라인 전송 완료"라고 뜨지만, 워커 로그에는 아무런 반응이 없음.

### **원인 (상세 분석)**

1. **백엔드 호출 이름 불일치:**
   - 백엔드 소스(`backend-core/routes/resumes.py` Line 94)에서는 `tasks.resume_pipeline.process_resume_pipeline`이라는 이름으로 Celery 태스크를 전송함.
2. **워커 정의 이름 불일치:**
   - 정작 이 일을 처리해야 할 AI-Worker의 실제 코드(`ai-worker/tasks/resume_parser.py` Line 13)에는 태스크 이름이 `parse_resume_pdf`로 명명되어 있음.
3. **결과:**
   - Celery 브로커(Redis)에는 "이력서 분석(A)"을 하라고 주문이 들어갔지만, 워커는 자기 이름표에 "B"라고 적혀 있어 해당 주문이 자기 것인지 모르고 무시함. 이로 인해 이력서 상태가 `pending`에서 영원히 바뀌지 않아 프론트엔드가 상태 변화를 기다리며 무한 폴링을 하게 됨.

### **해결 예정 사항**

- `ai-worker/tasks/resume_parser.py`: `@shared_task` 데코레이터 내 `name` 인자를 백엔드가 호출하는 이름인 `tasks.resume_pipeline.process_resume_pipeline`으로 수정하여 호출-응답 체인을 일치시킴.
- 수정 후 `docker-compose restart`를 통해 워커가 새 이름표를 인식하도록 조치.

---

## 7. AI-Worker: 이력서 분석 태스크의 큐(Queue) 할당 불일치

### **현상**

- 이름표(Task Name)를 맞췄음에도 불구하고, 여전히 이력서 분석이 시작되지 않고 무한 대기함.

### **원인 (상세 분석)**

1. **백엔드의 작업 요청 창구:** 백엔드(`resumes.py`)에서는 이력서 분석 태스크를 **`gpu_queue`**로 발송하고 있음.
2. **워커의 작업 대기 창구:** 워커의 메인 설정(`main.py`)에서는 이력서 분석(`tasks.resume_parser.*`) 업무를 **`cpu_queue`**에서만 대기하도록 고정되어 있음.
3. **결과:** 백엔드는 GPU 전용 라인으로 주문을 넣었지만, 이력서 담당 워커는 CPU 라인에서만 주문을 기다리고 있었음. 주문서와 일꾼이 서로 다른 창구에 서 있어 일이 전달되지 않은 것임.

### **해결 예정 사항**

- `ai-worker/main.py`: `tasks.resume_parser.*`의 라우팅 설정을 `gpu_queue`로 변경하여 백엔드와의 소통 창구를 통일함.
- 수정 후 `docker-compose restart`를 통해 설정값을 적용함.

---

## 8. AI-Worker: 파이썬 이름 충돌로 인한 모듈 로드 실패 (폴더 vs 파일)

### **현상**

- 이름표(Task Name)와 창구(Queue)를 모두 맞췄음에도 워커가 태스크를 수행하지 않음.
- 워커 로그에서 `models` 모듈 관련 `ImportError` 혹은 `AttributeError`가 발생하거나 워커가 실행 직후 소리 없이 종료됨.

### **원인 (상세 분석)**

1. **중복된 이름 존재:**
   - `ai-worker/` 폴더 내부에 인공지능 모델 파일을 저장하는 **`models/` (폴더)**가 존재함.
   - `backend-core/` 폴더 내부에 DB 테이블을 정의한 **`models.py` (파일)**가 존재함.
2. **임포트 우선순위 문제:**
   - 워커(`main.py`)가 실행될 때 두 경로를 모두 파이썬 경로(`sys.path`)에 추가함.
   - 이 상태에서 `tasks/resume_parser.py` 등이 `from models import Resume`를 호출하면, 파이썬은 파일(`models.py`)보다 같은 이름의 **폴더(`models/`)**를 먼저 인식하려 함.
3. **결과:**
   - 폴더(`models/`) 내부에는 `Resume` 클래스가 없으므로 오류가 발생하고, 이로 인해 `resume_parser` 태스크가 정상적으로 등록되지 않음. 결국 백엔드에서 보낸 이력서 분석 요청이 증발하게 됨.

### **해결 예정 사항**

- **폴더 이름 변경:** `ai-worker/models/`를 **`ai-worker/ai_models/`**로 변경하여 파일명(`models.py`)과의 충돌을 원천 차단함.
- **환경 설정 업데이트:** `docker-compose.yml`의 볼륨 마운트 경로와 `utils/exaone_llm.py`의 모델 경로를 `ai_models/`로 일괄 수정함.
- 수정 후 컨테이너를 재시작하여 정상적인 모듈 로딩을 확인함.

---

## 6. AI-Worker: Pydantic v2 엄격한 규칙으로 인한 워커 실행 실패

### **현상**

- 로그: `For further information visit https://errors.pydantic.dev/2.12/u/model-field-missing-annotation`
- 워커가 시작 단계에서 크래시가 발생하며, 이로 인해 모든 태스크(이력서 분석 등)가 처리되지 않고 무한 대기 상태에 빠짐.

### **원인 (상세 분석)**

1. **과잉 수정의 부작용:** 4번 항목의 `ModelPrivateAttr` 에러(LangChain LCEL 충돌)를 해결하기 위해 `ExaoneLLM` 클래스의 타입 힌트(`: Any`, `: bool`)를 제거함.
2. **Pydantic v2 제약 사항:** Pydantic v2 환경에서는 `BaseModel`(LangChain LLM의 기반)을 상속받은 클래스 내의 모든 공용 속성에 대해 반드시 타입 어노테이션(Type Annotation)을 요구함. 어노테이션이 없으면 모델 정의 단계에서 실행을 거부함.
3. **결과:** "충돌을 피하려고 이름표를 떼었더니, 이번에는 이름표가 없다고 입장을 거부당한 상황"임.

### **해결 예정 사항**

- `ai-worker/utils/exaone_llm.py`: 클래스 변수에 `typing.ClassVar`를 사용하여 타입 힌트를 복구함. `ClassVar`는 Pydantic이 이를 '데이터 필드'로 취급하지 않게 하면서도, 파이썬의 타입 규칙을 준수하게 함으로써 LCEL 충돌과 Pydantic 어노테이션 오류를 동시에 해결함.

---

## 9. AI-Worker: 이력서 파일 경로 인식 오류 (OS 간 경로 불일치)

### **현상**

- 이름표, 창구, 충돌 문제를 모두 해결했으나 워커가 여전히 파일을 찾지 못함.
- 원인: 백엔드가 `C:\...` 형태의 윈도우 경로로 파일 위치를 알려주는데, 리눅스 기반 워커는 이를 이해하지 못함.

### **해결 내용**

- `ai-worker/tasks/resume_parser.py`:
  - `os.path.basename()`을 사용해 파일명만 추출.
  - 워커 컨테이너의 마운트 경로인 `/app/uploads`와 결합하여 **경로 자동 번역 로직** 구현.
  - 이제 백엔드가 어떤 경로를 보내든 워커가 자기 환경에 맞춰 파일을 찾아냄.

---

## 10. AI-Worker: 이력서 분석 후 임베딩 호출 실패 (Chaining Error)

### **현상**

- 이력서 분석은 성공했으나, 그 다음 단계인 '임베딩 생성'으로 넘어가지 않음.
- 원인: 파서 워커가 임베딩 워커를 부를 때 약칭(`generate_resume_embeddings`)을 사용했는데, 시스템이 이를 찾지 못함.

### **해결 내용**

- `ai-worker/tasks/resume_embedding.py`: 태스크 이름을 `tasks.resume_embedding.generate_resume_embeddings`로 명확히 지정.
- `ai-worker/tasks/resume_parser.py`: 다음 단계 호출 시 풀네임을 사용하도록 수정하여 작업 체인을 확실하게 연결함.
- `ai-worker/tasks/resume_parser.py`: 다음 단계 호출 시 풀네임을 사용하도록 수정하여 작업 체인을 확실하게 연결함.

---

## 11. AI-Worker: 태스크 라우팅 패턴 불일치 및 모듈 로드 가시성 부족

### **현상**

- 명칭(Task Name), 창구(Queue), 경로(Path)를 모두 맞췄음에도 여전히 분석 작업이 전달되지 않음.
- 워커가 시작될 때 특정 태스크 모듈을 정상적으로 임포트했는지 눈으로 확인이 불가능함.

### **원인 (상세 분석)**

1. **Celery 라우팅 패턴의 허점:**
   - `main.py`의 `task_routes` 설정에서 `tasks.resume_parser.*` 패턴으로만 CPU 큐를 강제하고 있었음.
   - 하지만 우리는 백엔드 호환성을 위해 태스크 이름을 `tasks.resume_pipeline.process_resume_pipeline`으로 변경함.
   - 결과적으로 `tasks.resume_pipeline`이라는 새로운 패턴은 `main.py`의 기존 필터링(Routing)에 걸리지 않아 기본 큐로 유실되거나 배달 사고가 발생함.
2. **Import 에러의 은폐:**
   - 파이썬의 임포트 시스템 특성상, 워커가 시작할 때 `from models import Resume` 과정에서 에러가 나면 해당 태스크 파일 전체가 로드되지 않고 무시됨.
   - 워커 로그에는 "나 이 파일 못 읽었어"라는 명확한 메시지가 남지 않아, 사용자는 시스템이 정상적으로 대기 중이라고 착각하게 됨.

### **해결 내용**

- `ai-worker/main.py`: `task_routes`에 **`tasks.resume_pipeline.*`** 패턴을 명시적으로 추가하여, 어떤 상황에서도 이력서 분석 작업이 올바른 창구(GPU/CPU 워커)로 전달되도록 경로를 확정함.
- `ai-worker/tasks/resume_parser.py`:
  - 모듈 최상단에 **모듈 로드 확인 로그**(`✅ Task Module 'tasks.resume_pipeline' is being loaded.`)를 강제 삽입.
  - 임포트 구문을 `try-except`로 감싸, 모델을 읽어오지 못할 경우 즉시 ❌ 에러 로그를 남기도록 개선.
- 이제 사용자는 워커 로그만 보고도 "아, 이력서 분석 준비가 끝났구나" 혹은 "어디서 임포트가 막혔구나"를 100% 확신할 수 있게 됨.

---

## **최종 상태**

- **모든 주요 장애 요인 해결 완료.**
- GPU/CPU 워커 기동 성공, 백엔드-워커 통신 경로 확보, Pydantic/LangChain 충돌 해결, 경로 번역 시스템 구축 완료.
- 각 단계별로 **가시성(Visibility)**을 대폭 강화하여, 로그 메시지만으로도 시스템의 건강 상태를 즉시 파악 가능하도록 조치함.
- `docker-compose restart` 후 정상 작동 확인 가능.

---

## 12. AI-Worker: KeyError 'parse_resume_pdf' 발생 (과거 태스크 잔류)

### **현상**

- 워커 로그: `KeyError: 'parse_resume_pdf'` 에러와 함께 워커가 작업을 거부함.

### **원인 (상세 분석)**

1. **태스크 명칭 변경의 후폭풍:** 워커의 태스크 이름을 `tasks.resume_pipeline.process_resume_pipeline`으로 변경하였으나, Redis 큐에는 이전에 보냈던 옛날 이름(`parse_resume_pdf`)의 주문서가 남아 있음.
2. **매핑 실패:** 워커가 큐에서 일을 꺼냈는데, 자기가 이제는 모르는 이름인 `parse_resume_pdf`가 나오자 파이썬의 `dict` 매핑 오류(`KeyError`)가 발생한 것임.

### **해결 내용**

- **Redis 큐 퍼지(Purge):** 낡은 주문서들을 싹 비워줘야 함.
- **조치 권고:** `docker-compose down` 후 다시 시작하여 큐를 초기화함.

---

## 14. AI-Worker: 모델 파일 경로 인식 오류 (폴더 변경 과도기)

### **현상**

- 로그: `모델 파일을 찾을 수 없습니다: /app/ai_models/EXAONE-3.5-7.8B-Instruct-Q4_K_M.gguf`
- 분명히 `ai_models`로 폴더를 바꿨음에도 컨테이너 내부에서 파일을 찾지 못함.

### **원인 (상세 분석)**

1. **파일 락(Lock) 이슈:** 호스트 환경에서 `models`를 `ai_models`로 변경할 때, 컨테이너가 실행 중이면 대용량 모델 파일(4.7GB)이 잠겨 있어 이동이 실패하거나 폴더만 생성되고 파일은 남는 현상이 발생함.
2. **볼륨 마운트 지연:** `docker-compose.yml`을 수정했으나 컨테이너에 즉시 반영되지 않거나, 호스트의 물리적 구조가 뒤섞여 인식 오류가 발생함.

### **해결 내용**

- **파일 물리 이동**: 컨테이너 중지(`docker-compose down`)를 통해 파일 잠금을 해제한 후, 모델 파일을 새 폴더(`ai_models`)로 완벽하게 이동함.
- **코드 정규화**: 임시 Fallback 로직을 모두 제거하고, `utils/exaone_llm.py`와 `tasks/question_generator.py`가 오직 정규 경로(`/app/ai_models/`)만 바라보도록 고정함.
- **안전성 확보**: 이제 더 이상 경로 혼선이나 로딩 실패 없이 표준화된 구조에서 엔진이 가동됨.

---

## 15. AI-Worker: 최종 리포트 생성 시 엔진 로드 실패 (CUDA Error)

### **현상**

- 로그: `❌ 엔진 로드 실패: libcuda.so.1: cannot open shared object file`
- 면접 종료 후 최종 리포트 생성 단계에서 에러와 함께 요약 작업이 실패함.

### **원인 (상세 분석)**

1. **작업 배정의 설계적 결함:** 최종 리포트 요약(`generate_final_report`)은 LLM을 사용해야 하는 무거운 작업임에도 불구하고 큐(Queue)가 지정되지 않아 CPU 워커(`interview_worker_cpu`)가 이 작업을 가져감.
2. **라이브러리 호환성 문제:** CPU 워커 컨테이너는 GPU 드라이버(CUDA)가 없으나, 리포트 생성을 위해 호출된 LLM 엔진 코드가 CUDA를 요구하며 임포트되는 과정에서 크래시 발생.

### **해결 내용**

- **라우팅 강제 전환:** `ai-worker/tasks/evaluator.py`의 `generate_final_report` 태스크 및 `main.py` 라우팅 설정에 `queue='gpu_queue'`를 명시적으로 추가함.
- **결과:** 이제 리포트 생성 요약 작업은 드라이버가 갖춰진 GPU 워커 전용 창구로만 배달되어 안정적이고 빠르게 처리됨.

---

## 13. Backend: 중복 정의된 업로드 엔드포인트 및 구형 태스크 호출

### **현상**

- 워커 로그에서 계속 `KeyError: 'parse_resume_pdf'` 발생.
- 분명히 `routes/resumes.py`를 고쳤음에도 태스크 이름이 옛날 것으로 전송됨.

### **원인 (상세 분석)**

1. **코드 중복의 함정:**
   - 이력서 업로드 기능이 `routes/resumes.py` (신규)와 `main.py` (구규) 두 곳에 중복 정의되어 있었음.
   - 프론트엔드가 실제 사용 중인 주소는 `main.py`에 구현된 `/resumes/upload`였으나, 이 코드는 관리 사각지대에 놓여 수정되지 않은 상태였음.
2. **결과:**
   - 관리가 누락된 `main.py`가 계속해서 옛날 이름(`parse_resume_pdf`)을 `cpu_queue`로 던졌고, 새 명찰을 단 워커는 이를 보고 "누구세요?"라며 오류를 냈던 것임.

### **해결 내용**

- `backend-core/main.py`: 업로드 시 호출하는 태스크 이름과 큐 설정을 최신 규격(`tasks.resume_pipeline.process_resume_pipeline`, `gpu_queue`)으로 일괄 업데이트함.
- **최종 시나리오 완성:** 이제 어떤 경로로 이력서를 업로드하든, 워커가 알아들을 수 있는 명확한 언어로 소통하게 됨.
