# 면접 시스템 마이크 권한 및 실시간 인식 오류 분석 보고서 (02/11)

## 1. 현상 요약

* **상황**: 환경 테스트(음성 인식 성공) 완료 후 첫 번째 질문에서 "답변 시작" 버튼 클릭 시 오류 발생.
* **오류 메시지**: "녹음을 시작할 수 없습니다. 마이크 권한을 확인해주세요."
* **특이사항**: 환경 테스트에서는 정상 작동했으나 본 면접 진입 직후에만 발생함.

---

## 2. 근본 원인 분석

### A. 미디어 스트림 할당 레이스 컨디션 (Race Condition)

* `App.jsx`의 `setupWebRTC` 함수는 비동기로 마이크/카메라 권한을 요청하고 스트림을 가져옵니다.
* 사용자가 `FinalGuidePage`에서 "지금 면접 시작하기"를 누르면 `InterviewPage`로 이동하며 즉시 버튼이 렌더링됩니다.
* **문제**: 브라우저가 장치 권한을 초기화하고 `videoRef.current.srcObject`에 스트림을 할당하는 속도보다 사용자가 "답변 시작"을 누르는 속도가 더 빠를 경우, `toggleRecording` 함수는 `srcObject`가 `null`인 상태로 실행되어 "권한 오류"를 띄웁니다.

### B. 오디오 전용(Fallback) 모드 시 할당 누락 버그

* `App.jsx`의 `setupWebRTC` 내 330~340번 라인 부근의 로직 오류입니다.
* 카메라 접근이 실패하여 오디오 전용(`getUserMedia({ audio: true })`)으로 전환될 때, 가져온 `audioStream`을 WebRTC 연결에는 사용하지만 **`videoRef.current.srcObject`에는 할당하지 않고 있습니다.**
* 이로 인해 실제 마이크 권한은 있으나, 녹음 엔진(`MediaRecorder`)이 참조할 소스가 없어 오류가 발생합니다.

### C. 하드웨어 점유 및 해제 지연 (Hardware Latency)

* `EnvTestPage` 종료 시 `track.stop()`을 호출하여 마이크를 끕니다.
* 면접 페이지 진입 시 다시 마이크를 켭니다.
* 일부 OS 및 브라우저 환경에서 하드웨어 장치를 끄고 바로 다시 켜는 과정에서 "장치가 사용 중"이거나 "준비되지 않음" 상태가 일시적으로 지속될 수 있으며, 이 찰나에 요청이 들어가면 무시되거나 지연됩니다.

### D. 실시간 인식 로직과 녹음 로직의 충돌

* 현재 코드는 **고전적인 녹음 방식(MediaRecorder + 완료 후 전송)**과 **실시간 방식(WebRTC + WebSocket)**이 혼재되어 있습니다.
* 사용자는 "실시간"을 기대하지만, 현재 `toggleRecording`은 녹음이 모두 끝나야만 서버로 음성을 보냅니다. 실시간으로 음성이 전달되지 않으니 사용자는 시스템이 멈춘 것처럼 느끼거나 성급하게 버튼을 다시 누르게 되어 오류를 유발합니다.

---

## 3. 해결 방안 (Action Plan)

### 1단계: 장비 준비 상태(Media Readiness) 관리

* `isMediaReady` 상태값을 `InterviewPage`에 도입합니다.
* `setupWebRTC`가 완료되어 스트림 할당이 확정된 후 버튼을 활성화시켜, 불완전한 상태에서의 클릭을 원천 차단합니다.

### 2단계: Fallback 로직 보완

* 카메라가 없거나 실패하더라도 오디오 스트림을 반드시 `videoRef`에 할당하도록 코드를 수정합니다.

### 3단계: 실시간 STT 전환

* `toggleRecording` 시 직접 오디오 바이너리를 `MediaRecorder`로 쪼개서 보내는 대신, 이미 연결된 `WebSocket`을 통해 **"인식 시작(Start Translation)"** 신호만 보냅니다.
* 서버는 이미 WebRTC로 받고 있는 오디오 스트림을 변환하여 즉시 클라이언트로 텍스트를 던져주도록 통신 프로토콜을 정렬합니다.

### 4단계: 초기화 지연 시간 확보

* 면접 진입 전 0.5~1초 정도의 "준비 중..." 오버레이를 유지하여 하드웨어 안정화 시간을 확보합니다.

---

## 4. 프론트엔드 빌드 syntax 오류 분석 (02/13)

### 🔴 문제 현상

* **오류**: `[plugin:vite:react-babel] Missing semicolon. (385:3)`
* **증상**: 빌드 시 `App.jsx`에서 세미콜론이 누락되었다는 에러와 함께 빌드 실패. 에러 위치가 `start_recording` 등 엉뚱한 곳을 가리킴.

### 🔍 원인 분석

* **코드 구조 붕괴**: `toggleRecording` 함수 내에서 `if` 조건문의 중괄호(`}`) 닫기 위치가 잘못되어 논리 구조가 파손됨.
* **Orphaned Else**: 376행에서 `if` 블록이 너무 일찍 닫히면서, 385행의 `else` 문이 짝이 맞는 `if` 없이 단독으로 남게 됨.
* **파서 오작동**: 자바스크립트 엔진이 짝 없는 `else`를 만나면서 문법 해석에 실패했고, 이를 "이전 문장에 세미콜론이 없다"는 식의 엉뚱한 에러로 보고함.

### ✅ 조치 사항

* **구조 복원**: 잘못된 중괄호를 제거하여 `if` 블록이 정상적인 범위(384행까지)를 포함하도록 수정.
* **논리 정합성 확보**: `if (녹음 중)` - `else (녹음 중 아님)` 구조를 명확히 하여 바벨 파서가 정상적으로 코드를 해석할 수 있도록 교정 완료.

---

## 5. 실시간 자막 미출력 및 DB 저장 현상 분석 (02/13)

### 🔴 문제 현상

* **증상**: 실시간 면접 중 자막(Subtitle)이 화면에 표시되지 않음.
* **특이사항**: 실시간 자막은 안 나오지만, 답변 종료 후 `transcripts` 테이블에는 내가 말한 텍스트가 정상적으로 저장되어 있음.

### 🔍 상세 분석 (Data Flow Trace)

#### A. STT 데이터 전송 경로의 이원화

현재 시스템은 두 가지 경로로 STT 데이터를 처리합니다.

1. **경로 A (실시간)**: `Media Server` -> `WebSocket` -> `Frontend (App.jsx)` -> `UI (Subtitle)`
2. **경로 B (녹음 종료 후 배치)**: `Frontend (App.jsx)` -> `STT API (recognizeAudio)` -> `DB (createTranscript)`

**"DB에는 저장된다"**는 사실은 **경로 B**가 정상 작동하고 있음을 의미합니다. 즉, 녹음이 끝난 뒤 파일로 묶어서 보내는 방식은 성공했으나, 실시간으로 한 단어씩 뿌려주는 **경로 A**가 끊겨 있습니다.

#### B. WebSocket 수신 및 필터 로직 결함 가능성 (`App.jsx`)

```javascript
// App.jsx 분석
ws.onmessage = (event) => {
  const data = JSON.parse(event.data);
  if (data.type === 'stt_result' && data.text) { 
    setTranscript(prev => prev + ' ' + data.text);
  }
};
```

* **원인 1**: `Media Server`에서 전송하는 JSON의 `type` 필드명이 `stt_result`가 아니거나, 텍스트 필드명이 `text`가 아닐 가능성.
* **원인 2**: `isRecordingRef.current` 참조값이 활성화되지 않아 상태 업데이트가 무시될 가능성.

#### C. 배치가 실시간을 덮어쓰는 구조 (`App.jsx`)

```javascript
// App.jsx 444행 부근
setTranscript(prev => {
  if (prev.trim().length > recognizedText.length) return prev;
  return recognizedText; 
});
```

* 이 코드는 녹음 **종료** 시점에 작동하여 실시간 결과를 배치 결과로 보정합니다. 하지만 실시간 데이터가 아예 오지 않는다면 종료 전까지 화면은 빈 칸으로 유지됩니다.

#### D. 세션 ID (Interview ID) 매칭 오류

* WebRTC 오디오 세션과 WebSocket 메시징 세션 간의 ID가 서버 단에서 일치하지 않을 경우, 서버는 음성을 텍스트로 변환했음에도 어느 클라이언트에게 보내야 할지 몰라 메시지 전송에 실패할 수 있습니다.

### 💡 최종 분석 결과

사용자가 확인한 DB 데이터는 실시간 결과가 아니라, **녹음 종료 후 프론트엔드가 서버에 보낸 배치(Batch) 처리 결과**입니다. 결과적으로 현재 **실시간 STT 경로(WebSocket 경로)는 아예 작동하지 않고 있는 상태**로 분석됩니다.

### 🛠 향후 점검 포인트 (코드 수정 전 확인 사항)

1. **Media Server 로그**: Deepgram 서버로부터 받은 결과를 클라이언트로 전송하는 로그가 있는지 확인.
2. **Browser Console**: `[STT Received]: ...` 로그가 찍히는지 확인.
3. **WebSocket Protocol**: 서버와 클라이언트 간의 메시지 규격(`type`, `key`) 재검토.
