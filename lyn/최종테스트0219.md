# 2026-02-19 AI 면접 시스템 오류 분석 및 개선 리포트

본 문서는 실무 면접 대비 최종 테스트 과정에서 발생한 주요 기술적 이슈들에 대한 원인 분석과 해결 방안, 그리고 시스템 성능 향상을 위한 개선 계획을 정리한 문서입니다.

---

## 1. 미디어 서버(interview_media) 모듈 오류 분석

### **[이슈 1] ModuleNotFoundError: No module named 'mediapipe'**

* **현상**: `interview_media` 서비스 시작 시 `mediapipe` 라이브러리를 찾지 못해 컨테이너가 중단됨.
* **원인**: `requirements.txt`에 명시되어 있었으나, Docker 빌드 과정에서 캐시 문제 또는 의존성 패키지(`protobuf`) 버전 충돌로 인해 정상적으로 설치되지 않음.
* **해결**:
  1. `media-server/requirements.txt`에 `protobuf<5.0.0`을 명시하여 `mediapipe`와의 호환성 확보.
  2. `Dockerfile`에서 `pip`, `setuptools`, `wheel`을 업그레이드하여 빌드 안정성 강화.
  3. `--no-cache` 옵션으로 이미지를 재빌드하여 패키지 설치 완료.

### **[이슈 2] GPU 지원 불가 경고 (eglGetDisplay error 0x300c)**

* **현상**: 로그에 `GPU support is not available` 및 `eglGetDisplay() returned error 0x300c` 발생.
* **분석**: Docker 컨테이너(서버 환경) 인스턴스에 물리적 디스플레이가 연결되어 있지 않아 발생하는 MediaPipe의 표준 경고임.
* **결과**: 시스템이 자동으로 CPU 기반 추론(XNNPACK)으로 전환하여 정상 작동함. 영상 분석 기능(표정, 자세 등) 수행에 지장 없음이 확인됨.

---

## 2. 이력서 분석(Resume Parsing) 실패 분석

### **[현상] 이력서 업로드 후 분석 로그가 나타나지 않음**

* **원인 분석**:
  1. **경로 불일치**: 백엔드는 `./uploads/resumes/`에 저장하나, 워커(`resume_parser.py`)는 `/app/uploads/` 직하단에서 파일을 찾으려 함. (디렉토리 구조 불일치)
  2. **큐(Queue) 비효율**: 단순 텍스트 추출 작업임에도 불구하고 `gpu_queue`를 사용하도록 설정되어 GPU 워커의 병목 현상을 유발할 가능성이 있었음.
* **해결 내용**:
  1. `tasks/resume_parser.py`의 경로 탐색 로직에 `resumes` 하위 디렉토리 포함.
  2. 이력서 파싱 태스크를 `cpu_queue`로 이동하여 리소스 분산 및 처리 속도 향상.

---

## 3. 면접 세션 생성 및 시나리오 임포트 오류

### **[현상] "No module named 'config.interview_scenario_transition'" 에러 발생**

* **원인 분석**:
  1. **파일 누락**: `ai-worker` 폴더에는 직무 전환 시나리오 파일이 존재했으나, `backend-core/config/` 폴더에는 해당 파일이 복사되지 않아 백엔드에서 초기 질문 생성 시 실패함.
  2. **파일명 규칙 위반**: 초기 파일명이 `interview-scenario-transition.py`와 같이 하이픈(`-`)을 포함하고 있어 파이썬 모듈로 인식되지 못함.
* **해결 내용**:
  1. `backend-core/config/`에 시나리오 설정 파일 복사 및 생성.
  2. 모든 관련 파일명과 임포트문을 언더바(`_`) 기반의 파이썬 표준 명칭으로 통일.
  3. `sys.path` 설정을 보강하여 컨테이너 환경 내 가시성 확보.

---

## 4. 면접 질문 생성 지연(Latency) 이슈 및 개선안

### **[현상] 사용자 답변 후 다음 질문이 나올 때까지 40~60초가량 소요됨**

* **지연 원인 분석 (Bottleneck)**:
  1. **순차적 태스크 구조**: 답변 저장 -> 답변 평가(LLM) -> 다음 질문 생성(LLM) 순으로 진행됨. `solo` 워커 특성상 평가가 끝나야만 질문 생성이 시작됨.
  2. **LLM 2단계 추론**: 질문을 하나 만들 때 '생성' 후 '정제(Refine)' 과정을 거치며 LLM을 두 번 호출함. 1회 추론에 15~20초가 소요되어 총 30~40초가 질문 생성에만 소진됨.

### **[개선 방안 - 속도 2배 향상 계획]**

#### **1) 비동기 병렬 트리거 (Parallel Processing)**

* **내용**: 백엔드에서 사용자 답변 저장 즉시 '답변 평가'와 '다음 질문 생성' 태스크를 동시에 요청.
* **효과**: 답변 평가(분석)가 진행되는 동안 다음 질문 생성이 즉시 시작되어, 사용자는 평가 완료를 기다릴 필요 없이 바로 다음 면접 단계로 진행 가능.

#### **2) 프롬프트 통합 및 단일 추론 (One-Shot Generation)**

* **내용**: 기존의 2단계(생성+정제) 레이아웃을 하나로 통합. 질문 생성 프롬프트 자체에 '사족 제거', '특수문자 금지', '깔끔한 문장' 규칙을 강력하게 포함.
* **효과**: LLM 호출 횟수를 2회에서 1회로 단축하여 질문 생성 속도를 약 15~20초 이상 단축.

#### **3) 큐(Queue) 우선순위 최적화**

* **내용**: 실시간 흐름에 필수적인 `question_generation` 태스크에 높은 우선순위를 부여하고, 비실시간 분석인 `evaluation` 태스크는 뒤에서 처리되도록 조정.

### **수정 요약 (성능 최적화)**

1. **비동기 병렬 처리 적용 (transcripts.py)** :

   * 사용자가 답변을 마치는 순간, **답변 분석(평가)**과 **다음 질문 생성**을 동시에 Celery 큐에 넣습니다.
   * 이전에는 평가가 완전히 끝나야 질문 생성이 시작되었으나, 이제는 두 작업이 병렬로 실행되어 사용자의 체감 대기 시간이 대폭 줄어듭니다.
2. **질문 생성 단계 단일화 (One-Shot Generation)** :

* 질문을 만들고 다시 다듬던 2단계 추론 과정을 **1단계**로 통합했습니다.
* 프롬프트에 정제 규칙(특수문자 제거, 사족 금지 등)을 강력하게 포함하여 한 번의 LLM 실행으로 고품질의 질문이 나오도록 개선했습니다. 이로 인해 질문 생성 시간이 기존 대비 **약 15~20초 추가 단축**됩니다.

1. **불필요한 트리거 제거 (evaluator.py)** :

   * 백엔드에서 직접 질문 생성을 요청하게 됨에 따라, 평가 태스크 내부에서 중복으로 질문 생성을 요청하던 로직을 제거하여 리소스 낭비를 막았습니다.

---

## 5. 향후 계획

위 개선안을 적용하여 면접 시 대기 시간을 **15초 내외**로 단축하는 것을 목표로 하며, 수정 작업 후 성능 테스트 결과를 별도로 보고할 예정임.

---

## 6. 실시간 STT(Speech-to-Text) 미작동 및 지연 분석

### **[현상] 사용자가 말할 때 실시간 자막이 나오지 않고, 답변 완료 후에만 한꺼번에 나타남**

* **원인 분석 (Structural Flaw)**:
  1. **데이터 전송 이중화 및 병목**:
     - 로그 분석 결과, `media-server`는 3초 단위(64KB)로 오디오 청크를 쪼개서 `ai-worker`로 실시간 전송하고 있음(A 방식).
     - 하지만 프론트엔드(`App.jsx`)는 답변이 끝나는 시점에 전체 녹음 파일(예: 688KB)을 한꺼번에 백엔드로 POST 요청함(B 방식).
     - 결과적으로 네트워크 대역폭을 이중으로 낭비하고 있으며, 대용량 파일 전송 및 처리로 인해 지연이 발생함.
  2. **끊어진 파이프라인 (Relay Logic Missing)**:
     - `media-server`가 워커로부터 실시간 STT 결과를 받아도, 이를 웹소켓(WebSocket)을 통해 브라우저로 다시 보내주는 '중계 로직'이 설계상 누락되어 있음.
     - 이로 인해 서버 내부에서는 실시간 분석이 일어나고 있으나, 사용자는 결과를 볼 수 없는 상태임.
  3. **동기식 대기 구조**:
     - 현재 프론트엔드는 `/stt/recognize` API의 응답이 올 때까지 '무한 대기'하는 동기적 방식을 사용함. 모델 로딩이나 파일 처리가 길어지면 브라우저가 응답을 멈춘 것처럼 보임.

### **[해결 방안 - 실시간성 확보 계획]**

#### **1) 웹소켓 중계 기능 활성화 (WebSocket Relay)**

* **내용**: `media-server`가 `ai-worker`로부터 받은 실시간 STT 결과를 즉시 해당 세션의 웹소켓으로 브라우저에 전송하도록 수정.
* **효과**: 답변이 끝나기 전에도 사용자가 말하는 대로 즉시 화면에 자막(Subtitle)이 표시됨.

#### **2) 스트리밍 방식 단일화**

* **내용**: 답변 완료 후 대용량 파일을 다시 보내는 방식을 제거하고, 실시간으로 누적된 텍스트 데이터만을 활용하도록 변경.
* **효과**: 수백 KB의 중복 오디오 데이터 전송을 없애 네트워크 부하를 줄이고 처리 속도를 극대화함.

#### **3) VAD(Voice Activity Detection) 최적화**

* **내용**: 3초 시간 기반 분할 대신, 사용자의 목소리가 들릴 때만 워커에 요청을 보내도록 효율화하여 CPU 자원 낭비를 방지 (현재 2초 고정 분할로 1차 최적화 완료).

### **수정 요약 (실시간성 확보 및 최적화 완료)**

1. **미디어 서버 실시간 중계 로직 추가 (media-server/main.py)**:

   - 미디어 서버가 2초 단위로 음성 조각을 워커에 보내고, 분석 결과가 나오는 즉시 웹소켓을 통해 브라우저로 중계하도록 로직 개선.
   - 답변 완료 전에도 사용자가 말하는 내용이 실시간 자막(Subtitle)으로 화면에 표시됨.
2. **프론트엔드 중복 작업 제거 및 최적화 (App.jsx)**:

   - 실시간 자막이 충분히 확보(50자 이상)된 경우, 답변 완료 후 대용량 녹음 파일을 다시 서버로 보내는 무거운 작업을 생략하도록 개선.
   - 전체 파일 전송은 실시간 STT 실패 시에만 폴백(Fallback)으로 작동하도록 하여 네트워크 부하 감소.
3. **워커 큐 라우팅 및 리로딩 최적화 (ai-worker/main.py)**:

   - STT 작업을 전용 CPU 큐로 정확히 배분하여 질문 생성(GPU)과 자막 변환(CPU)이 병렬로 지장 없이 수행되도록 설정.
   - 워커 시작 시 STT 모델을 미리 메모리에 로드(Preload)하여 첫 질문의 응답 지연 시간 제거.

---

## 7. STT 결과 중계 타임아웃 및 오류 분석 (추가)

### **[현상] `STT 결과 중계 실패: The operation timed out` 또는 `I/O operation on closed file` 발생**

* **원인 분석**:
  1. **CPU 워커 병목 (Worker Bottleneck)**:
     - 기존 CPU 워커가 `solo` 풀(한 번에 1개 작업 처리)을 사용하여 STT 요청이 밀릴 경우 10초 내에 처리를 완료하지 못함.
     - `large-v3-turbo` 모델의 CPU 연산 부하와 빔 서치(beam_size=5) 설정으로 인해 2초 음성 처리가 2초 이상 걸려 큐가 누적됨.
  2. **동시성 오류 (Thread Safety)**:
     - `media-server`에서 비대기(Non-blocking)로 `task.get()`을 호출할 때 Redis 결과 백엔드와의 통신에서 예기치 않은 핸들 종료가 발생할 수 있음.

### **[해결 방안 - 안정성 강화 계획]**

#### **1) CPU 워커 대역폭 확대**

- **내용**: `ai-worker-cpu`의 풀 방식을 `solo`에서 `threads`로 변경하고, **concurrency=4**로 설정하여 4개의 STT 작업을 동시에 처리 가능하도록 확장.
- **효과**: 동시에 들어오는 음성 청크를 지연 없이 처리하여 타임아웃 발생 억제.

#### **2) STT 엔진 추론 속도 최적화**

- **내용**: 실시간성을 위해 `beam_size`를 5에서 **1**로 변경.
- **효과**: 정확도를 소폭 양보하되, 추론 속도를 2~3배 향상시켜 2초 음성 조각을 1초 내에 처리 완료.

#### **3) 타임아웃 임계치 조정 및 예외 처리 강화**

- **내용**: `media-server`의 대기 시간을 10초에서 **20초**로 상향하고, 타임아웃 발생 시 에러 대신 경고 로그로 처리하여 전체 프로세스 중단 방지.
