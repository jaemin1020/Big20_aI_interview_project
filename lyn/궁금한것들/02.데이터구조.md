면접용 RAG 시스템에서는 보통 **두 가지** 저장 구조를 씁니다: (1) 일반 DB(관계형/NoSQL) 스키마, (2) 벡터DB(임베딩+텍스트 chunk).[[pass4sure](https://www.pass4sure.com/blog/top-30-rag-interview-questions-and-answers-for-2025/)]

## 1. 어떤 데이터를 저장할지

면접/직무 RAG에서 주요 엔티티는 대략 다음입니다.[[arxiv](https://arxiv.org/html/2504.02870v1)]

* 직무(Job/Role)
  * id, 이름, 레벨(주니어/시니어), 설명, 실제 JD 텍스트 등
* 직무별 지식/문서(Document)
  * JD 원문, 역량 모델, 직무 가이드, 예시 질문/답변, 회사 인터뷰 매뉴얼 등 원본 텍스트
* 문서 조각(Chunk)
  * RAG 검색 단위가 되는 작은 텍스트 블록
* 지원자(Resume/Candidate)
  * 이력서 파일 메타데이터, 파싱 결과(경력/기술 리스트/자기소개 요약 등)

이 중 “RAG 검색용”은 주로 **문서·문서 조각**이고, 나머지는 일반 DB에 구조화해서 두면 좋습니다.[[linkedin](https://www.linkedin.com/posts/v-chandra-sekhar_top-30-rag-interview-questions-activity-7398192717069086720-3GaU)]

## 2. 일반 DB에 저장하는 구조 예시

RDB 기준 예시입니다(이름만 참고용).[[mercity](https://www.mercity.ai/blog-post/build-an-llm-based-resume-analyzer)]

* `jobs` 테이블
  * `id` (PK)
  * `title` (예: Backend Engineer)
  * `level` (예: junior, senior)
  * `description` (직무 개요)
  * `created_at` …
* `job_documents` 테이블 (직무 관련 원본 문서)
  * `id` (PK)
  * `job_id` (FK → jobs.id)
  * `doc_type` (예: JD, competency_model, interview_guide)
  * `title`
  * `raw_text` (전체 텍스트)
  * `source` (파일명/URL 등)
* `candidates` / `resumes` 테이블
  * `id`
  * `candidate_name`
  * `email` …
  * `raw_resume_text`
  * `parsed_skills` (JSON 배열)
  * `parsed_experiences` (JSON)

이렇게 “정형 정보”는 RDB/NoSQL에 둬서 관리·조회·로그용으로 쓰고, RAG 검색은 아래 벡터DB 구조로 갑니다.[[arxiv](https://arxiv.org/html/2504.02870v1)]

## 3. 벡터 DB에 저장하는 구조

벡터DB는 기본적으로 “임베딩 벡터 + 메타데이터 + 원문” 구조입니다.[[weaviate](https://weaviate.io/blog/chunking-strategies-for-rag)]

예를 들어 `job_knowledge` 컬렉션(또는 index)을 만든다고 하면:

* 필수 필드
  * `id`: chunk 식별자
  * `vector`: 임베딩 배열 (예: 1536차원 float[])
* 메타데이터(검색/필터용)
  * `job_id`: 어떤 직무에 관련된 chunk인지
  * `doc_id`: 어떤 원본 문서에서 온 chunk인지
  * `doc_type`: JD/guide/question_bank 등
  * `language`: ko/en 등
  * `difficulty`: junior/senior 레벨 태그 등
* 컨텐츠
  * `text`: 실제 chunk 텍스트

벡터DB마다 JSON 메타데이터 컬럼 하나에 위 필드를 넣거나, 스키마 필드를 따로 두는 식으로 저장합니다.[[linkedin](https://www.linkedin.com/posts/anshuizme_vectordb-ai-rag-activity-7378417667742826496-erlT)]

## 4. chunk를 만들 때 구조

문서를 그냥 통째로 넣지 않고 **chunking** 해서 넣는 게 RAG 성능에 중요합니다.[[unstructured](https://unstructured.io/blog/chunking-for-rag-best-practices)]

* chunk 전략 예
  * 200~800 토큰 단위로 문단 기준으로 자르기 (문단/제목 경계를 최대한 유지).[[latenode](https://latenode.com/blog/ai-frameworks-technical-infrastructure/rag-retrieval-augmented-generation/rag-chunking-strategies-complete-guide-to-document-splitting-for-better-retrieval)]
  * JD의 “필수 요건”, “우대사항”, “주요 업무” 같은 섹션별로 쪼갠 뒤, 섹션 안에서 길면 추가로 자르기.
* 각 chunk에 들어가는 것
  * `text`: “이 직무에서 OO를 할 때 고려해야 하는 시스템 설계 포인트…” 같은 실제 내용
  * `metadata`: `job_id`, `section="requirements"`, `skill_tag=["Java","Spring","SQL"]` 등

이렇게 해두면 쿼리할 때 `job_id=백엔드` 필터 + 임베딩 유사도로 찾을 수 있습니다.[[weaviate](https://weaviate.io/blog/chunking-strategies-for-rag)]

## 5. “데이터를 가져올 때” 플로우 예시

지원자가 “백엔드 개발자” 선택 + 이력서 업로드 했다고 가정하면:[[mercity](https://www.mercity.ai/blog-post/build-an-llm-based-resume-analyzer)]

1. 이력서 파싱 → 스킬/경력 요약 추출 (일반 DB에 JSON으로 저장).
2. LLM이나 룰 기반으로 “질문을 만들고 싶은 핵심 토픽”을 쿼리 텍스트로 생성.
   * 예: “Spring 기반 트랜잭션 처리 경험 검증”, “대규모 트래픽 핸들링 경험” 등.
3. 이 쿼리를 임베딩으로 바꿔서 벡터DB `job_knowledge`에서 검색:
   * 필터: `job_id = 백엔드`, 필요하면 `difficulty = junior` 등.
4. 상위 N개의 chunk(`text` + `metadata`)를 가져와서 LLM 프롬프트에 넣고 질문 생성.

여기서 “가져오는 구조”는

* 쿼리: `embedding(query_text) + filter(job_id)`
* 응답: `[ {id, text, metadata{job_id, doc_type, ...}}, ... ]` 형태가 일반적입니다.[[pass4sure](https://www.pass4sure.com/blog/top-30-rag-interview-questions-and-answers-for-2025/)]

## 6. 지원자 이력서도 RAG에 쓸지 여부

이력서를 질문 생성용 RAG에도 쓰고 싶다면:[[arxiv](https://arxiv.org/html/2504.02870v1)]

* `resume_chunks` 같은 별도 컬렉션
  * `id`
  * `candidate_id`
  * `vector`
  * `text` (경력/프로젝트 내용)
* 쿼리 시
  * 직무 지식 컬렉션(`job_knowledge`)에서 “뭘 물어볼지” 관련 컨텍스트
  * 이력서 컬렉션(`resume_chunks`)에서 “어디를 파고들지” 관련 컨텍스트

    둘 다 검색해서 한 프롬프트에 넣는 식의 구조도 가능합니다.[[arxiv](https://arxiv.org/html/2504.02870v1)]

---

요약하면:

* 일반 DB에는 “직무, 문서, 이력서, 관계”를 **정형 구조**로 저장.
* 벡터DB에는 문서/이력서를 적절히 **chunk** 해서 `vector + text + metadata(job_id, section, skill_tag…)` 형태로 저장.
* 가져올 때는 “임베딩 + 메타데이터 필터”로 chunk 리스트를 가져와 LLM 프롬프트에 끼워 넣는 구조로 설계하는 게 일반적인 패턴입니다.[[pass4sure](https://www.pass4sure.com/blog/top-30-rag-interview-questions-and-answers-for-2025/)]
