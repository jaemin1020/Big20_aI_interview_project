# 담당 : 엄재민
#  산출물1 : Final_Project_시스템아키텍처_설계서_SAD

## 1. 시스템 아키텍처 개요 (Overview)
* **설계 목적:** 실시간 멀티모달(음성, 영상, 텍스트) 데이터를 분석하여 사용자에게 개인화된 면접 경험과 정교한 피드백 리포트 제공.
* **적용 범위:** 웹 기반 AI 모의면접 플랫폼 및 결과 분석 관리 시스템.
* **시스템 목표:** 저지연(Low Latency) 데이터 처리, 평가 객관성 확보, 마이크로서비스 기반의 높은 확장성.
* **설계 전제 조건:** 안정적인 STT 전송을 위한 비동기 처리 및 LLM 토큰 관리 최적화.

> **📌 아키텍처 선택 근거:** LLM의 추론 시간과 멀티모달 분석 부하를 고려하여, 응답 속도를 최적화하고 장애 격리가 용이한 **비동기 이벤트 기반 마이크로서비스 아키텍처(EDA)**를 채택함.

---

## 2. 전체 시스템 구성도 (Architecture Diagram)


* **User (Client):** React/Next.js 기반 웹 UI.
* **API Server (Backend):** 세션 관리, 인증 및 비즈니스 로직 처리.
* **AI Processing Layer:** * **STT:** Deepgram API (음성-텍스트 변환)
    * **LLM:** OpenAI GPT-4o 또는 오픈소스 모델 (Llama 3 등)
    * **Vision:** OpenCV/MediaPipe (표정 및 시선 분석)
* **DB / Storage:**
    * **PostgreSQL:** 세션 및 사용자 결과 데이터 저장.
    * **Pinecone/Chroma:** RAG를 위한 벡터 데이터베이스.
* **Message Broker:** Redis/RabbitMQ를 통한 작업 큐 관리.

---

## 3. 데이터 흐름 설계 (End-to-End Flow)
1. **Input:** 사용자의 음성/영상 스트림 수집.
2. **STT Pipeline:** 실시간 오디오 데이터를 텍스트로 변환.
3. **Question Logic:** 이전 답변과 자소서 맥락을 기반으로 후속 질문(Follow-up) 생성.
4. **Evaluation:** 답변 내용 및 비언어적 데이터를 루브릭에 따라 정량적 평가.
5. **Output:** 평가 결과를 JSON 구조화하여 DB 저장 및 사용자 리포트 제공.

---

## 4. 멀티모달 처리 파이프라인 설계
* **음성(STT):** WebSocket을 활용한 실시간 스트리밍 처리.
* **영상(Vision):** 프레임별 감정 분석 및 시선 추적 (비동기 처리).
* **텍스트:** 자연어 처리(NLP)를 통한 핵심 키워드 및 논리 구조 추출.
* **병렬성:** 각 파이프라인은 독립적인 워커에서 실행되어 실시간성 확보.

---

## 5. AI 기능 모듈 구조 설계
* **질문 생성 모듈:** 지원 직무 및 자소서 기반 맞춤형 질문 추출.
* **평가 모듈:** 답변의 일관성 및 전문성 평가.
* **꼬리 질문 모듈:** 답변의 모호함을 감지하여 심층 질문 유도.
* **감정 분석 워커:** 면접 중 긴장도 및 비언어적 표현 수치화.

---

## 6. LLM 기반 평가·질문 생성 구조
* **프롬프트 전략:** System(면접관 페르소나), Context(직무 정보), User(답변)로 구분.
* **출력 구조:** 시스템 연동을 위해 **JSON 포맷** 응답 강제.
* **로직 연결:** 평가 점수가 임계치 미달 시 보충 질문을 생성하는 상태 전이 로직 포함.

---

## 7. RAG / VectorDB 설계
* **RAG 사용 이유:** 최신 기술 동향 및 특정 기업 인재상 등 학습 데이터 외 지식 참조.
* **VectorDB:** 직무별 도메인 지식 및 모범 답변 사례 임베딩 저장.
* **Fallback:** 검색 결과가 부적절할 경우 기본 역량 질문 세트로 전환.

---

## 8. 상태(State) 기반 흐름 설계

* **State 정의:** `START` → `QUESTIONING` → `EVALUATING` → `FOLLOW_UP` → `END`
* **Stage:** 현재 면접의 단계(공통질문/심화질문 등).
* **Next Action:** 평가 결과(`status`)에 따라 다음 질문 혹은 종료 결정.

---

## 9. 데이터 저장 구조 (DB Schema)
* **Session Table:** 면접 고유 ID, 사용자 정보, 총평.
* **Turn Table:** 각 문답의 쌍, 오디오 파일 경로, 개별 평가 점수.
* **Evaluation Table:** 항목별 점수 및 LLM이 생성한 평가 근거 로그.

---

## 10. 서버·서비스 분리 설계
* **Main API Server:** 경량 비즈니스 로직 및 사용자 인터페이스 통신.
* **AI Model Server:** 고부하 AI 추론(LLM/Vision) 전용 서버(GPU 자원 할당).
* **Worker Server:** 리포트 생성 및 데이터 분석용 백그라운드 서버.

---

## 11. 실행 환경 및 인프라 구성
* **Local:** Docker Compose를 이용한 개발 환경 통일.
* **Server:** GPU 가속이 가능한 클라우드 인스턴스 (AWS G4dn 등).
* **Environment:** Python 3.10+, Virtualenv/Poetry 기반 의존성 관리.

---

## 12. 컨테이너 및 배포 구조
* **Docker:** 서비스별 이미지를 컨테이너화하여 독립성 확보.
* **CI/CD:** GitHub Actions를 이용한 자동 빌드 및 배포 파이프라인.

---

## 13. 성능·확장성 고려 설계
* **병목 현상 방지:** LLM 응답 지연을 가리기 위해 STT 스트리밍과 UI 피드백 최적화.
* **확장 전략:** 동시 접속자 증가 시 워커 노드를 수평 확장(Auto-scaling).

---

## 14. 평가 기준(Rubric) 설계
* **평가 항목:** 직무 적합성, 논리력, 전달력, 비언어적 태도.
* **산출 방식:** 가중치 합산 방식 (직무 역량 중심).
* **신뢰성:** 평가 점수와 함께 그 근거가 되는 원본 로그를 매칭하여 저장.

---

## 15. 로그 및 추적 설계 (加算點)
* **Rationale Log:** AI가 특정 점수를 부여한 텍스트 근거 기록.
* **RAG Trace:** 질문 생성 시 어떤 문서를 참조했는지 ID 기록.
* **Error Log:** API 장애 발생 시 재시도 로직 및 원인 추적.

---

## 16. 한계 및 향후 확장
* **한계:** 실시간 영상 분석의 높은 연산 비용으로 인한 하드웨어 의존성.
* **확장:** 향후 사용자 맞춤형 표정 훈련 기능 및 다국어(English) 면접 모드 추가.

