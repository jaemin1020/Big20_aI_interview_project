import { useState, useRef, useEffect } from 'react';
import { 
  createInterview, 
  getInterviewQuestions, 
  createTranscript,
  completeInterview,
  getEvaluationReport,
  uploadResume,
  getAllInterviews,
  login as apiLogin, 
  register as apiRegister, 
  logout as apiLogout, 
  getCurrentUser 
} from './api/interview';
import { createClient } from "@deepgram/sdk";

// Layout & UI
import Header from './components/layout/Header';
import MainPage from './pages/main/MainPage';
import AuthPage from './pages/auth/AuthPage';
import LandingPage from './pages/landing/LandingPage';
import ResumePage from './pages/landing/ResumePage';
import EnvTestPage from './pages/setup/EnvTestPage';
import FinalGuidePage from './pages/landing/FinalGuidePage';
import InterviewPage from './pages/interview/InterviewPage';
import ResultPage from './pages/result/ResultPage';

function App() {
  const [step, setStep] = useState('main');
  const [user, setUser] = useState(null);
  const [authMode, setAuthMode] = useState('login');
  const [authError, setAuthError] = useState('');
  
  const [isDarkMode, setIsDarkMode] = useState(false); // ê¸°ë³¸: ë¼ì´íŠ¸ëª¨ë“œ

  useEffect(() => {
    console.log("Theme changed to:", isDarkMode ? "DARK" : "LIGHT");
    if (isDarkMode) {
      document.body.classList.add('dark-theme');
    } else {
      document.body.classList.remove('dark-theme');
    }
  }, [isDarkMode]);
  
  const [account, setAccount] = useState({ 
    email: '', 
    username: '',
    password: '', 
    passwordConfirm: '',
    fullName: '', 
    birthDate: '',
    profileImage: null,
    termsAgreed: false
  });
  const [interview, setInterview] = useState(null);
  const [questions, setQuestions] = useState([]);
  const [currentIdx, setCurrentIdx] = useState(0);
  const [report, setReport] = useState(null);
  
  const [transcript, setTranscript] = useState('');
  const [isRecording, setIsRecording] = useState(false);
  const [userName, setUserName] = useState('');
  const [position, setPosition] = useState('');
  const [resumeFile, setResumeFile] = useState(null);
  const [parsedResumeData, setParsedResumeData] = useState(null);

  // Recruiter State
  const [allInterviews, setAllInterviews] = useState([]);
  const [selectedInterviewForReview, setSelectedInterviewForReview] = useState(null);
  
  const videoRef = useRef(null);
  const pcRef = useRef(null);
  const wsRef = useRef(null);
  const mediaRecorderRef = useRef(null);
  const deepgramConnectionRef = useRef(null);
  const isRecordingRef = useRef(false);

  useEffect(() => {
    const token = localStorage.getItem('token');
    if (token) {
      getCurrentUser()
        .then(u => {
          setUser(u);
          setStep('landing');
        })
        .catch(() => {
          localStorage.removeItem('token');
          setStep('main');
        });
    }
  }, []);

  const handleAuth = async () => {
    setAuthError('');
    
    // í´ë¼ì´ì–¸íŠ¸ ì‚¬ì´ë“œ ìœ íš¨ì„± ê²€ì‚¬
    if (authMode === 'register') {
        const usernameRegex = /^[a-z0-9_]{4,12}$/;
        const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;

        if (!usernameRegex.test(account.username)) {
            setAuthError("ì•„ì´ë””ëŠ” 4~12ìì˜ ì˜ë¬¸ ì†Œë¬¸ì, ìˆ«ì, ë°‘ì¤„(_)ë§Œ ê°€ëŠ¥í•©ë‹ˆë‹¤.");
            return;
        }
        if (!emailRegex.test(account.email)) {
            setAuthError("ìœ íš¨í•œ ì´ë©”ì¼ ì£¼ì†Œë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”.");
            return;
        }
    }

    try {
      if (authMode === 'login') {
        // ë¡œê·¸ì¸ ì‹œì—ëŠ” username ì‚¬ìš©
        await apiLogin(account.username, account.password);
        const u = await getCurrentUser();
        setUser(u);
        setStep('landing');
      } else {
        // íšŒì›ê°€ì… ê²€ì¦
        const emailRegex = /^[^\s@]+@[^\s@]+\.[^\s@]+$/;
        if (!emailRegex.test(account.email)) {
          setAuthError('ì˜¬ë°”ë¥¸ ì´ë©”ì¼ í˜•ì‹ì´ ì•„ë‹™ë‹ˆë‹¤.');
          return;
        }

        if (account.password !== account.passwordConfirm) {
          setAuthError('ë¹„ë°€ë²ˆí˜¸ê°€ ì¼ì¹˜í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤.');
          return;
        }
        if (!account.termsAgreed) {
          setAuthError('ì´ìš©ì•½ê´€ì— ë™ì˜í•´ì•¼ í•©ë‹ˆë‹¤.');
          return;
        }

        // ì‹¤ì œ API í˜¸ì¶œ
        await apiRegister(account.email, account.username, account.password, account.fullName);
        alert('íšŒì›ê°€ì… ì„±ê³µ! ë¡œê·¸ì¸í•´ì£¼ì„¸ìš”.');
        setAuthMode('login');
      }
    } catch (err) {
      // FastAPI validation error (422) ì²˜ë¦¬
      if (err.response?.data?.detail) {
        const detail = err.response.data.detail;
        if (Array.isArray(detail)) {
          // Validation error ë°°ì—´
          setAuthError(detail.map(e => e.msg).join(', '));
        } else if (typeof detail === 'string') {
          setAuthError(detail);
        } else {
          setAuthError('ì¸ì¦ ì‹¤íŒ¨');
        }
      } else {
        setAuthError(err.message || 'ì¸ì¦ ì‹¤íŒ¨');
      }
    }
  };

  const handleLogout = () => {
    apiLogout();
    setUser(null);
    setStep('auth');
  };

  const startInterviewFlow = () => {
    setStep('resume');
  };

  const initInterviewSession = async () => {
    try {
      // 1. Create Interview with Parsed Position & User Name
      const interviewPosition = parsedResumeData?.position || position || 'General';
      const interviewUser = user?.full_name || user?.username || userName || 'Candidate';
      
      console.log("Creating interview with:", { interviewUser, interviewPosition });

      const newInterview = await createInterview(interviewPosition, null, null); // user name usually handled by backend via token, or if API needed it? 
      // Checking api/interview.js: createInterview(position, jobPostingId, scheduledTime). 
      // It does NOT take username. Backend likely uses the token's user.
      
      setInterview(newInterview);

      // 2. Upload Resume - Already done in ResumePage? 
      // If ResumePage uploads it to get parsed data, we often just need that data.
      // But if the backend *needs* the file attached to the *interview ID*, we might need to re-upload or link it?
      // Based on api/interview.js, uploadResume(file) returns data and takes no ID.
      // So it strictly parses. It does not attach to an interview explicitly unless backend tracks user's last upload.
      // We will assume the parsing was enough for now, or if we need to store the file content in the interview context, 
      // the backend implementation of createInterview might need to know about the resume.
      // But for now, user request is "Start session with parsed position". We have that.

      // 3. Get Questions
      const qs = await getInterviewQuestions(newInterview.id);
      
      if (!qs || qs.length === 0) {
         console.log("Questions not ready, retrying in 3s...");
         setTimeout(async () => {
             const retryQs = await getInterviewQuestions(newInterview.id);
             setQuestions(retryQs);
             setStep('interview');
         }, 3000);
         return;
      }

      setQuestions(qs);
      setStep('interview');
    } catch (err) {
      console.error("Session init error:", err);
      // alert("ë©´ì ‘ ì„¸ì…˜ ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤."); // Removed for smoother UX if fails silent
    }
  };

  const setupWebSocket = (sessionId) => {
    const ws = new WebSocket(`ws://localhost:8080/ws/${sessionId}`);
    wsRef.current = ws;
    ws.onmessage = (event) => {
      try {
        const data = JSON.parse(event.data);
        if (data.type === 'stt_result' && data.text) {
          console.log('[STT Received]:', data.text, '| Recording:', isRecordingRef.current);
          
          setTranscript(prev => prev + ' ' + data.text);
        }
      } catch (err) {
        console.error('[WebSocket] Parse error:', err);
      }
    };

    ws.onerror = (error) => console.error('[WebSocket] Error:', error);
    ws.onclose = () => console.log('[WebSocket] Closed');
  };

  const setupDeepgram = (stream) => {
    const apiKey = import.meta.env.VITE_DEEPGRAM_API_KEY;
    if (!apiKey) {
      console.warn("Deepgram API Key not found");
      return;
    }

    const deepgram = createClient(apiKey);
    const connection = deepgram.listen.live({
      model: "nova-2",
      language: "ko",
      smart_format: true,
      encoding: "linear16", 
      sample_rate: 16000,
    });

    connection.on("Open", () => {
      console.log("Deepgram WebSocket Connected");
      
      const mediaRecorder = new MediaRecorder(stream, { mimeType: 'audio/webm' });
      mediaRecorder.addEventListener('dataavailable', (event) => {
        if (event.data.size > 0 && connection.getReadyState() === 1) {
          connection.send(event.data);
        }
      });
      mediaRecorder.start(250);
      mediaRecorderRef.current = mediaRecorder;
    });

    connection.on("Results", (result) => {
      const channel = result.channel;
      if (channel && channel.alternatives && channel.alternatives[0]) {
        const transcriptText = channel.alternatives[0].transcript;
        const isFinal = result.is_final;
        
        if (transcriptText) {
          if (isFinal) {
             setTranscript(prev => prev + ' ' + transcriptText);
             setSubtitle(''); 
          } else {
             setSubtitle(transcriptText);
          }
        }
      }
    });

    connection.on("Error", (err) => {
      console.error("Deepgram Error:", err);
    });

    deepgramConnectionRef.current = connection;
  };

  const setupWebRTC = async (interviewId) => {
    console.log('[WebRTC] Starting setup for interview:', interviewId);
    const pc = new RTCPeerConnection();
    pcRef.current = pc;
    try {
      const stream = await navigator.mediaDevices.getUserMedia({ 
        video: true, 
        audio: true 
      });
      console.log('[WebRTC] Media stream obtained:', stream.getTracks().map(t => t.kind));
      videoRef.current.srcObject = stream;
      
      setupDeepgram(stream);

      stream.getTracks().forEach(track => {
        pc.addTrack(track, stream);
        console.log('[WebRTC] Added track:', track.kind, track.label);
      });
    } catch (err) {
      console.warn('[WebRTC] Camera failed, trying audio-only:', err);
      try {
        const audioStream = await navigator.mediaDevices.getUserMedia({ audio: true });
        audioStream.getTracks().forEach(track => pc.addTrack(track, audioStream));
        alert('ì¹´ë©”ë¼ ì ‘ê·¼ ê±°ë¶€ë¨. ìŒì„±ë§Œ ì‚¬ìš©í•©ë‹ˆë‹¤.');
      } catch (audioErr) {
        alert('ë§ˆì´í¬ ì ‘ê·¼ ì‹¤íŒ¨');
        throw audioErr;
      }
    }

    const offer = await pc.createOffer();
    await pc.setLocalDescription(offer);
    console.log('[WebRTC] Sending offer to server...');

    const response = await fetch('http://localhost:8080/offer', {
      method: 'POST',
      body: JSON.stringify({
        sdp: pc.localDescription.sdp,
        type: pc.localDescription.type,
        session_id: interviewId
      }),
      headers: { 'Content-Type': 'application/json' }
    });

    if (!response.ok) {
      throw new Error(`WebRTC offer failed: ${response.status}`);
    }

    const answer = await response.json();
    await pc.setRemoteDescription(new RTCSessionDescription(answer));
    console.log('[WebRTC] Connection established successfully');
  };

  const toggleRecording = () => {
    if (isRecording) {
      setIsRecording(false);
      isRecordingRef.current = false;
    } else {
      setTranscript('');
      setIsRecording(true);
      isRecordingRef.current = true;
    }
  };

  const nextQuestion = async () => {
    const answerText = transcript.trim() || "ë‹µë³€ ì—†ìŒ";
    
    try {
      // Transcript ì €ì¥ (ì‚¬ìš©ì ë‹µë³€)
      await createTranscript(
        interview.id,
        'User',
        answerText,
        questions[currentIdx].id
      );
      
      if (currentIdx < questions.length - 1) {
        setCurrentIdx(currentIdx + 1);
        setTranscript('');
        setIsRecording(false);
      } else {
        setStep('loading');
        
        if (wsRef.current) wsRef.current.close();
        if (pcRef.current) pcRef.current.close();
        
        // ë©´ì ‘ ì™„ë£Œ ì²˜ë¦¬
        await completeInterview(interview.id);
        
        // í‰ê°€ ë¦¬í¬íŠ¸ ëŒ€ê¸°
        setTimeout(async () => {
          try {
            const finalReport = await getEvaluationReport(interview.id);
            setReport(finalReport);
            setStep('result');
          } catch (err) {
            alert('í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ì…ë‹ˆë‹¤. ì ì‹œ í›„ ë‹¤ì‹œ í™•ì¸í•´ì£¼ì„¸ìš”.');
            setStep('landing');
          }
        }, 10000);
      }
    } catch (err) {
      console.error('[Submit Error]:', err);
      alert('ë‹µë³€ ì œì¶œ ì‹¤íŒ¨');
    }
  };

  useEffect(() => {
    if (step === 'interview' && interview && videoRef.current && !pcRef.current) {
      const initMedia = async () => {
        try {
          await setupWebRTC(interview.id);
          setupWebSocket(interview.id);
        } catch (err) {
          console.error("Media init error:", err);
        }
      };
      initMedia();
    }
  }, [step, interview]);

  useEffect(() => {
    return () => {
      if (wsRef.current) wsRef.current.close();
      if (pcRef.current) pcRef.current.close();
      if (mediaRecorderRef.current) mediaRecorderRef.current.stop();
      if (deepgramConnectionRef.current) deepgramConnectionRef.current.finish();
    };
  }, []);

  return (
    <div className="container">
      {/* Header - Visible in Most Steps */}
      {step !== 'main' && step !== 'auth' && (
        <Header 
          onLogout={handleLogout} 
          showLogout={!!user} 
          onLogoClick={() => setStep('main')} 
        />
      )}

      {/* Theme Toggle Button */}
      <div style={{ position: 'fixed', bottom: '2rem', right: '2rem', zIndex: 1000 }}>
        <button 
          onClick={() => setIsDarkMode(!isDarkMode)}
          style={{ 
            width: '50px', 
            height: '50px', 
            borderRadius: '50%', 
            background: 'var(--glass-bg)',
            backdropFilter: 'blur(10px)',
            border: '1px solid var(--glass-border)',
            boxShadow: '0 4px 15px rgba(0,0,0,0.1)',
            cursor: 'pointer',
            fontSize: '1.5rem',
            display: 'flex',
            alignItems: 'center',
            justifyContent: 'center',
            transition: 'all 0.3s ease'
          }}
        >
          {isDarkMode ? 'â˜€ï¸' : 'ğŸŒ™'}
        </button>
      </div>

      <div style={{ flex: 1, width: '100%', display: 'flex', flexDirection: 'column' }}>
        {step === 'main' && (
          <MainPage 
            onStartInterview={() => setStep('landing')}
            onLogin={() => { setAuthMode('login'); setStep('auth'); }}
            onRegister={() => { setAuthMode('register'); setStep('auth'); }}
            user={user}
            onLogout={handleLogout}
          />
        )}

      {step === 'auth' && (
        <AuthPage 
          authMode={authMode} setAuthMode={setAuthMode}
          account={account} setAccount={setAccount}
          handleAuth={handleAuth} authError={authError}
        />
      )}

      {step === 'landing' && (
        <LandingPage 
          startInterview={startInterviewFlow} 
          handleLogout={handleLogout}
        />
      )}

      {step === 'resume' && (
        <ResumePage 
          onNext={() => setStep('env_test')} 
          onFileSelect={setResumeFile} 
          onParsedData={setParsedResumeData} // Pass this to save parsed info
        />
      )}
      
      {step === 'env_test' && <EnvTestPage onNext={() => setStep('final_guide')} />}
      
      {step === 'final_guide' && <FinalGuidePage onNext={initInterviewSession} onPrev={() => setStep('env_test')} />}

      {step === 'interview' && (
        <InterviewPage 
          currentIdx={currentIdx}
          totalQuestions={questions.length}
          question={questions[currentIdx]?.question_text}
          isRecording={isRecording}
          transcript={transcript}
          toggleRecording={toggleRecording}
          nextQuestion={nextQuestion}
          videoRef={videoRef}
        />
      )}

      {step === 'loading' && (
        <div className="card animate-fade-in" style={{ textAlign: 'center' }}>
          <h2 className="text-gradient">AI ë¶„ì„ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...</h2>
          <div className="spinner" style={{ width: '60px', height: '60px', borderTopColor: 'var(--primary)' }}></div>
          <p style={{ color: 'var(--text-muted)' }}>ë‹µë³€ ë‚´ìš©ì„ ë°”íƒ•ìœ¼ë¡œ ì •ë°€í•œ ê²°ê³¼ë¥¼ ë„ì¶œí•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ì£¼ì„¸ìš”.</p>
        </div>
      )}

      {step === 'result' && (
        <ResultPage 
          results={report || []} 
          onReset={() => {
            setStep('landing');
            setCurrentIdx(0);
            setReport(null);
          }} 
        />
      )}
      </div>
    </div>
  );
}

export default App;