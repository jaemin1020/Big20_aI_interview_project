# 🎯 하이브리드 질문 생성 및 선순환 평가 시스템 분석

기존의 복잡한 계층적(회사/산업별) 탐색 대신, **실질적인 성능과 UX에 집중한 재작성된 로직**에 대한 분석입니다.

---

## 1. 하이브리드 질문 생성기 (`QuestionGenerator`)

### 🛠️ 핵심 전략: **Reuse & Create (R&C)**

질문 생성 시 단일 소스에 의존하지 않고, **DB의 검증된 질문**과 **LLM의 창의성**을 4:6 비율로 혼합합니다.

#### A. 재활용 (Reuse, 40%)
- **Target**: `get_best_questions_by_position(position)`
- **Logic**: 
  - 과거 면접에서 **평균 점수(`avg_score`)가 높았던 질문**을 우선 선택합니다.
  - 너무 자주 사용된 질문(`usage_count` 과다)은 배제하여 신선함을 유지합니다.
- **Benefit**:
  - 검증된 고품질 질문 보장
  - 빠른 응답 속도 (DB 조회만 수행)

#### B. 생성 (Create, 60%) - Few-Shot Learning
- **Target**: `LLM.invoke(prompt)`
- **Logic**:
  - 위에서 조회한 DB 질문 3개를 **"좋은 질문의 예시"**로 프롬프트에 포함합니다.
  - LLM에게 "이런 스타일과 난이도의 새로운 질문을 만들어줘"라고 지시합니다.
- **Benefit**:
  - 기존 질문의 톤앤매너(Tone & Manner) 유지
  - 매번 새로운 질문 생성 (다양성 확보)
  - 할루시네이션(엉뚱한 질문) 방지

---

## 2. 선순환 평가 시스템 (`Evaluator`)

### 🔄 핵심 전략: **Feedback Loop**

단순히 지원자의 답변만 채점하는 것이 아니라, **그 질문의 가치**도 함께 평가하여 시스템을 진화시킵니다.

#### A. 답변 평가
- **Score**: 기술(Technical) + 소통(Communication) 점수 (1-5)
- **Sentiment**: 긍정/부정 감정 점수 (-1.0 ~ 1.0) 계산하여 `transcript`에 저장

#### B. 질문 가치 평가 (선순환)
- **Logic**: 
  - 지원자가 답변을 잘 할 수 있었던 질문(=변별력이 있고 명확한 질문)이라고 가정합니다.
  - 답변 품질 점수를 해당 질문의 `avg_score`에 반영(업데이트)합니다.
- **Effect**:
  - 좋은 답변을 이끌어낸 질문은 `avg_score`가 상승합니다.
  - 다음 면접 생성 시 **재활용(Reuse) 후보로 선택될 확률**이 높아집니다.
  - 반대로 답변이 부실하거나 에러가 많은 질문은 자연스럽게 도태됩니다.

---

## 3. 데이터 흐름 요약

1. **[면접 시작]** `generate_questions(position="Backend")` 호출
2. **[DB 조회]** 평점 높은 질문 2개 선택 ("REST API...", "DB Sharding...")
3. **[LLM 생성]** 위 2개를 예시로 3개 신규 생성 ("GraphQL 경험...", "MSA 트랜잭션...")
4. **[면접 진행]** 사용자 답변 제출
5. **[평가 수행]** 답변 점수 4.5점 (우수)
6. **[DB 업데이트]** "REST API..." 질문의 평점 상승 (4.2 -> 4.3)
   -> 다음 면접에서 더 자주 선택됨!

---

## ✅ 결론

이 시스템은 초기 데이터가 적을 때도 LLM의 힘으로 잘 동작하며, 데이터가 쌓일수록 **자정 작용(Self-Correction)**을 통해 질문의 품질이 점점 좋아지는 구조입니다. 복잡한 분류 체계 없이도 직무(Position) 하나만으로 강력한 맞춤형 면접을 제공할 수 있습니다.
