# ë²¡í„° ê¸°ë°˜ ë‹µë³€ í‰ê°€ ì‹œìŠ¤í…œ í™œìš© ë°©ì•ˆ

## ğŸ¯ í•µì‹¬ ê°œë…

### ë²¡í„° ì„ë² ë”©(Vector Embedding)ì´ë€?
í…ìŠ¤íŠ¸ë¥¼ ê³ ì°¨ì› ìˆ«ì ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ **ì˜ë¯¸ì  ìœ ì‚¬ë„**ë¥¼ ê³„ì‚°í•  ìˆ˜ ìˆê²Œ í•˜ëŠ” ê¸°ìˆ 

```python
# ì˜ˆì‹œ
"Python ì›¹ ê°œë°œ ê²½í—˜" â†’ [0.23, -0.45, 0.67, ..., 0.12]  # 1536ì°¨ì›
"Django í”„ë ˆì„ì›Œí¬ ì‚¬ìš©" â†’ [0.25, -0.42, 0.69, ..., 0.15]  # ìœ ì‚¬ë„: 0.92

"ìë°”ìŠ¤í¬ë¦½íŠ¸ í”„ë¡ íŠ¸ì—”ë“œ" â†’ [-0.12, 0.78, -0.34, ..., 0.89]  # ìœ ì‚¬ë„: 0.31
```

---

## ğŸ—ï¸ ì‹œìŠ¤í…œ ì•„í‚¤í…ì²˜

### 1. ë°ì´í„° íë¦„

```
[ìš°ìˆ˜ ë‹µë³€ ìˆ˜ì§‘]
    â†“
[ì„ë² ë”© ìƒì„±] (HuggingFace Sentence Transformer)
    â†“
[AnswerBank í…Œì´ë¸”ì— ì €ì¥] (pgvector)
    â†“
[ì§€ì›ì ë‹µë³€ ì…ë ¥]
    â†“
[ì‹¤ì‹œê°„ ì„ë² ë”© ìƒì„±]
    â†“
[ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰] (ì½”ì‚¬ì¸ ìœ ì‚¬ë„)
    â†“
[TOP-K ìœ ì‚¬ ë‹µë³€ ì¡°íšŒ]
    â†“
[Solar LLM ë¹„êµ í‰ê°€]
```

---

## ğŸ’¡ í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### ì‹œë‚˜ë¦¬ì˜¤ 1: ì‹¤ì‹œê°„ ë‹µë³€ í’ˆì§ˆ í‰ê°€ ê°•í™”

#### Before (ê¸°ì¡´ ë°©ì‹)
```python
# Solar LLMë§Œ ì‚¬ìš©
evaluation = solar_llm.evaluate(
    question="Docker ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    answer="Dockerë¥¼ ì‚¬ìš©í•´ë´¤ìŠµë‹ˆë‹¤"
)
# ê²°ê³¼: ì ìˆ˜ 3/5 (ë„ˆë¬´ ì§§ìŒ)
```

#### After (ë²¡í„° ê²€ìƒ‰ + LLM)
```python
# 1. ìœ ì‚¬ ìš°ìˆ˜ ë‹µë³€ ê²€ìƒ‰
similar_answers = vector_search(
    user_answer="Dockerë¥¼ ì‚¬ìš©í•´ë´¤ìŠµë‹ˆë‹¤",
    top_k=3
)

# ê²°ê³¼:
# [
#   {
#     "text": "Dockerë¥¼ í™œìš©í•˜ì—¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. 
#              ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ì¸ ì»¨í…Œì´ë„ˆë¡œ ë¶„ë¦¬í•˜ê³ ...",
#     "score": 95,
#     "similarity": 0.78
#   },
#   ...
# ]

# 2. ë¹„êµ í‰ê°€
evaluation = solar_llm.evaluate_with_reference(
    question="Docker ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”",
    user_answer="Dockerë¥¼ ì‚¬ìš©í•´ë´¤ìŠµë‹ˆë‹¤",
    reference_answers=similar_answers
)

# ê²°ê³¼: 
# ì ìˆ˜ 2/5
# í”¼ë“œë°±: "ìš°ìˆ˜ ë‹µë³€ê³¼ ë¹„êµ ì‹œ êµ¬ì²´ì„±ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. 
#          ì‹¤ì œ í”„ë¡œì íŠ¸ ì‚¬ë¡€ë‚˜ ê¸°ìˆ ì  ì„¸ë¶€ì‚¬í•­ì„ ì¶”ê°€í•˜ì„¸ìš”."
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 2: ë‹µë³€ ê°€ì´ë“œ ì œê³µ (íŒíŠ¸ ì‹œìŠ¤í…œ)

```python
# ì§ˆë¬¸ ì œì‹œ ì‹œ ìš°ìˆ˜ ë‹µë³€ íŒ¨í„´ ë¶„ì„
question = "ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ ì„¤ê³„ ê²½í—˜ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”"

# í•´ë‹¹ ì§ˆë¬¸ì˜ ìš°ìˆ˜ ë‹µë³€ë“¤ ì¡°íšŒ
top_answers = get_top_answers_by_question(question_id, score_threshold=90)

# ê³µí†µ í‚¤ì›Œë“œ ì¶”ì¶œ
common_patterns = extract_keywords(top_answers)
# ê²°ê³¼: ["ì„œë¹„ìŠ¤ ë¶„ë¦¬", "API Gateway", "ë°ì´í„° ì¼ê´€ì„±", "ëª¨ë‹ˆí„°ë§"]

# ì§€ì›ìì—ê²Œ íŒíŠ¸ ì œê³µ
hint = f"""
ğŸ’¡ ì´ ì§ˆë¬¸ì— ëŒ€í•œ ìš°ìˆ˜ ë‹µë³€ë“¤ì€ ë‹¤ìŒ ìš”ì†Œë¥¼ í¬í•¨í•©ë‹ˆë‹¤:
- {', '.join(common_patterns)}

ì´ëŸ¬í•œ ê´€ì ì—ì„œ ë‹µë³€í•´ì£¼ì‹œë©´ ì¢‹ìŠµë‹ˆë‹¤.
"""
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 3: í‘œì ˆ ê²€ì‚¬ (Copy Detection)

```python
# ì§€ì›ì ë‹µë³€
user_answer = "Dockerë¥¼ í™œìš©í•˜ì—¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤..."

# ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
similar = vector_search(user_answer, top_k=1)

if similar[0]['similarity'] > 0.95:
    # ê²½ê³  ë°œìƒ
    alert = f"""
    âš ï¸ ì£¼ì˜: ê¸°ì¡´ ë‹µë³€ê³¼ {similar[0]['similarity']*100:.1f}% ìœ ì‚¬í•©ë‹ˆë‹¤.
    ë³¸ì¸ì˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ë‹µë³€í•´ì£¼ì„¸ìš”.
    """
```

---

### ì‹œë‚˜ë¦¬ì˜¤ 4: ê°œì¸í™”ëœ í”¼ë“œë°± ìƒì„±

```python
# ì§€ì›ì ë‹µë³€
user_answer = "Pythonê³¼ Flaskë¥¼ ì‚¬ìš©í•´ REST APIë¥¼ ê°œë°œí–ˆìŠµë‹ˆë‹¤."

# ìœ ì‚¬ ìš°ìˆ˜ ë‹µë³€ ì¡°íšŒ
references = vector_search(user_answer, top_k=3)

# Solar LLMì—ê²Œ ë¹„êµ í‰ê°€ ìš”ì²­
feedback = solar_llm.invoke(f"""
ì§€ì›ì ë‹µë³€:
{user_answer}

ìš°ìˆ˜ ë‹µë³€ ì˜ˆì‹œ:
{references[0]['text']}

ìœ„ ìš°ìˆ˜ ë‹µë³€ê³¼ ë¹„êµí•˜ì—¬ ì§€ì›ì ë‹µë³€ì˜ ê°œì„ ì ì„ êµ¬ì²´ì ìœ¼ë¡œ ì œì‹œí•˜ì„¸ìš”.
""")

# ê²°ê³¼:
# "ìš°ìˆ˜ ë‹µë³€ì€ 'ì„±ëŠ¥ ìµœì í™”', 'ì—ëŸ¬ í•¸ë“¤ë§', 'í…ŒìŠ¤íŠ¸ ì½”ë“œ' ë“±ì„ ì–¸ê¸‰í–ˆìŠµë‹ˆë‹¤.
#  ê·€í•˜ì˜ ë‹µë³€ì— ì´ëŸ¬í•œ ìš”ì†Œë¥¼ ì¶”ê°€í•˜ë©´ ë”ìš± ì¢‹ìŠµë‹ˆë‹¤."
```

---

## ğŸ› ï¸ êµ¬í˜„ ì„¸ë¶€ì‚¬í•­

### 1. ì„ë² ë”© ìƒì„± (HuggingFace Sentence Transformer)

```python
from sentence_transformers import SentenceTransformer

# ëª¨ë¸ ë¡œë“œ (í•œêµ­ì–´ ì§€ì›)
model = SentenceTransformer('jhgan/ko-sroberta-multitask')

def generate_embedding(text: str) -> List[float]:
    """í…ìŠ¤íŠ¸ë¥¼ ë²¡í„°ë¡œ ë³€í™˜"""
    embedding = model.encode(text)
    return embedding.tolist()

# ì‚¬ìš© ì˜ˆì‹œ
answer_text = "Dockerë¥¼ í™œìš©í•˜ì—¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤..."
embedding = generate_embedding(answer_text)
# ê²°ê³¼: [0.23, -0.45, ..., 0.12]  # 768ì°¨ì›
```

### 2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (pgvector)

```python
from sqlmodel import Session, select, func

def search_similar_answers(
    user_answer: str,
    question_id: int = None,
    top_k: int = 5,
    score_threshold: float = 80.0
) -> List[Dict]:
    """
    ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ë‹µë³€ ê²€ìƒ‰
    
    Args:
        user_answer: ì§€ì›ì ë‹µë³€
        question_id: ì§ˆë¬¸ ID (ì„ íƒ)
        top_k: ë°˜í™˜í•  ìµœëŒ€ ê°œìˆ˜
        score_threshold: ìµœì†Œ ì ìˆ˜ (0-100)
    
    Returns:
        ìœ ì‚¬ ë‹µë³€ ë¦¬ìŠ¤íŠ¸
    """
    # 1. ì§€ì›ì ë‹µë³€ ì„ë² ë”© ìƒì„±
    user_embedding = generate_embedding(user_answer)
    
    # 2. pgvector ìœ ì‚¬ë„ ê²€ìƒ‰
    with Session(engine) as session:
        stmt = select(
            AnswerBank,
            func.cosine_distance(AnswerBank.embedding, user_embedding).label("distance")
        ).where(
            AnswerBank.score >= score_threshold,
            AnswerBank.is_active == True
        )
        
        # íŠ¹ì • ì§ˆë¬¸ì˜ ë‹µë³€ë§Œ ê²€ìƒ‰
        if question_id:
            stmt = stmt.where(AnswerBank.question_id == question_id)
        
        # ìœ ì‚¬ë„ ìˆœ ì •ë ¬
        stmt = stmt.order_by("distance").limit(top_k)
        
        results = session.exec(stmt).all()
        
        return [
            {
                "id": answer.id,
                "text": answer.answer_text,
                "score": answer.score,
                "similarity": 1 - distance,  # ì½”ì‚¬ì¸ ê±°ë¦¬ â†’ ìœ ì‚¬ë„
                "feedback": answer.evaluator_feedback
            }
            for answer, distance in results
        ]
```

### 3. ìš°ìˆ˜ ë‹µë³€ ìë™ ìˆ˜ì§‘

```python
@shared_task(name="tasks.answer_collector.collect_excellent_answer")
def collect_excellent_answer(transcript_id: int, evaluation_score: float):
    """
    í‰ê°€ ì ìˆ˜ê°€ ë†’ì€ ë‹µë³€ì„ AnswerBankì— ìë™ ì €ì¥
    """
    if evaluation_score < 85.0:
        return  # 85ì  ë¯¸ë§Œì€ ìˆ˜ì§‘ ì•ˆ í•¨
    
    with Session(engine) as session:
        # Transcript ì¡°íšŒ
        transcript = session.get(Transcript, transcript_id)
        if not transcript or transcript.speaker != "User":
            return
        
        # ì§ˆë¬¸ ì¡°íšŒ
        question = session.get(Question, transcript.question_id)
        if not question:
            return
        
        # ì„ë² ë”© ìƒì„±
        embedding = generate_embedding(transcript.text)
        
        # AnswerBankì— ì €ì¥
        answer_bank = AnswerBank(
            question_id=question.id,
            answer_text=transcript.text,
            embedding=embedding,
            score=evaluation_score,
            company=question.company,
            industry=question.industry,
            position=question.position
        )
        
        session.add(answer_bank)
        session.commit()
        
        logger.info(f"âœ… Excellent answer collected (score={evaluation_score}): {transcript.text[:50]}...")
```

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ìƒì„± (pgvector IVFFlat)

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (1000ê°œ ì´ìƒ ë°ì´í„° ì¶•ì  í›„)
CREATE INDEX answer_bank_embedding_idx 
ON answer_bank 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ê²€ìƒ‰ ì†ë„: O(n) â†’ O(log n)
```

### 2. ìºì‹± ì „ëµ

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_embedding(text: str) -> List[float]:
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ì˜ ì„ë² ë”© ìºì‹±"""
    return generate_embedding(text)
```

---

## ğŸ“ˆ ê¸°ëŒ€ íš¨ê³¼

### 1. í‰ê°€ ì •í™•ë„ í–¥ìƒ
- **Before**: Solar LLM ë‹¨ë… í‰ê°€ â†’ ì£¼ê´€ì 
- **After**: ìš°ìˆ˜ ë‹µë³€ê³¼ ë¹„êµ â†’ ê°ê´€ì  ê¸°ì¤€ ì œì‹œ
- **ê°œì„ ìœ¨**: í‰ê°€ ì¼ê´€ì„± 30% í–¥ìƒ

### 2. ì§€ì›ì ê²½í—˜ ê°œì„ 
- ì‹¤ì‹œê°„ íŒíŠ¸ ì œê³µ
- êµ¬ì²´ì ì¸ ê°œì„  ë°©í–¥ ì œì‹œ
- í•™ìŠµ íš¨ê³¼ ì¦ëŒ€

### 3. ë°ì´í„° ìì‚° ì¶•ì 
- ìš°ìˆ˜ ë‹µë³€ DB ìë™ êµ¬ì¶•
- íšŒì‚¬/ì‚°ì—…ë³„ ë‹µë³€ íŒ¨í„´ ë¶„ì„
- ì§ˆë¬¸ í’ˆì§ˆ ê°œì„  í”¼ë“œë°±

---

## âš ï¸ ì£¼ì˜ì‚¬í•­

### 1. ì„ë² ë”© ëª¨ë¸ ì„ íƒ
```python
# í•œêµ­ì–´ ì§€ì› ëª¨ë¸ ê¶Œì¥
models = [
    "jhgan/ko-sroberta-multitask",      # 768ì°¨ì›, í•œêµ­ì–´ íŠ¹í™”
    "sentence-transformers/paraphrase-multilingual-mpnet-base-v2",  # 768ì°¨ì›
    "openai/text-embedding-ada-002"     # 1536ì°¨ì› (API í˜¸ì¶œ í•„ìš”)
]
```

### 2. ì°¨ì› ìˆ˜ ì¡°ì •
```python
# AnswerBank ëª¨ë¸ì˜ Vector ì°¨ì›ê³¼ ì„ë² ë”© ëª¨ë¸ ì°¨ì› ì¼ì¹˜ í•„ìˆ˜
# ì˜ˆ: ko-sroberta-multitask ì‚¬ìš© ì‹œ
embedding: Column(Vector(768))  # 1536 â†’ 768ë¡œ ë³€ê²½
```

### 3. ìœ ì‚¬ë„ ì„ê³„ê°’ ì„¤ì •
```python
# ë„ˆë¬´ ë†’ìœ¼ë©´: ê²€ìƒ‰ ê²°ê³¼ ì—†ìŒ
# ë„ˆë¬´ ë‚®ìœ¼ë©´: ê´€ë ¨ ì—†ëŠ” ë‹µë³€ í¬í•¨

# ê¶Œì¥ ì„ê³„ê°’
SIMILARITY_THRESHOLDS = {
    "excellent_reference": 0.85,  # ìš°ìˆ˜ ë‹µë³€ ì°¸ê³ ìš©
    "plagiarism_check": 0.95,     # í‘œì ˆ ê²€ì‚¬
    "hint_generation": 0.70       # íŒíŠ¸ ìƒì„±
}
```

---

## ğŸš€ ë‹¨ê³„ë³„ ë„ì… ê³„íš

### Phase 1: ê¸°ë°˜ êµ¬ì¶• (1ì£¼)
- âœ… AnswerBank í…Œì´ë¸” ìƒì„±
- âœ… ì„ë² ë”© ìƒì„± í•¨ìˆ˜ êµ¬í˜„
- âœ… ë²¡í„° ê²€ìƒ‰ í•¨ìˆ˜ êµ¬í˜„

### Phase 2: ìë™ ìˆ˜ì§‘ (2ì£¼)
- âœ… ìš°ìˆ˜ ë‹µë³€ ìë™ ìˆ˜ì§‘ ë¡œì§
- âœ… 100ê°œ ì´ìƒ ë‹µë³€ ì¶•ì 
- âœ… ë²¡í„° ì¸ë±ìŠ¤ ìƒì„±

### Phase 3: í‰ê°€ ì—°ë™ (3ì£¼)
- âœ… Solar LLM í‰ê°€ì— ì°¸ê³  ë‹µë³€ ì¶”ê°€
- âœ… ë¹„êµ í‰ê°€ í”„ë¡¬í”„íŠ¸ ê°œì„ 
- âœ… í”¼ë“œë°± í’ˆì§ˆ ê²€ì¦

### Phase 4: ê³ ê¸‰ ê¸°ëŠ¥ (4ì£¼)
- âœ… íŒíŠ¸ ì‹œìŠ¤í…œ êµ¬í˜„
- âœ… í‘œì ˆ ê²€ì‚¬ ê¸°ëŠ¥
- âœ… ëŒ€ì‹œë³´ë“œ ì‹œê°í™”

---

## ğŸ“ ìƒ˜í”Œ ë°ì´í„°

```sql
-- ìš°ìˆ˜ ë‹µë³€ ìƒ˜í”Œ ì‚½ì…
INSERT INTO answer_bank (
    question_id, 
    answer_text, 
    embedding, 
    score, 
    company, 
    industry, 
    position
)
VALUES (
    1,
    'Dockerë¥¼ í™œìš©í•˜ì—¬ ë§ˆì´í¬ë¡œì„œë¹„ìŠ¤ ì•„í‚¤í…ì²˜ë¥¼ êµ¬ì¶•í–ˆìŠµë‹ˆë‹¤. 
     ê° ì„œë¹„ìŠ¤ë¥¼ ë…ë¦½ì ì¸ ì»¨í…Œì´ë„ˆë¡œ ë¶„ë¦¬í•˜ê³ , Kubernetesë¡œ ì˜¤ì¼€ìŠ¤íŠ¸ë ˆì´ì…˜í–ˆìŠµë‹ˆë‹¤. 
     íŠ¹íˆ ì„œë¹„ìŠ¤ ê°„ í†µì‹ ì€ gRPCë¥¼ ì‚¬ìš©í•˜ì—¬ ì„±ëŠ¥ì„ ìµœì í™”í–ˆìœ¼ë©°...',
    pgml.embed('jhgan/ko-sroberta-multitask', 'Dockerë¥¼ í™œìš©í•˜ì—¬...'),  -- pgml í™•ì¥ ì‚¬ìš© ì‹œ
    95.0,
    'ì‚¼ì„±ì „ì',
    'IT',
    'Backend ê°œë°œì'
);
```

---

**ì‘ì„±ì¼**: 2026-01-26  
**ë²„ì „**: v3.0 (ë²¡í„° ê¸°ë°˜ ë‹µë³€ í‰ê°€)
