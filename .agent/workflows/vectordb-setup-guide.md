---
description: VectorDBì™€ ìì—°ì–´DB êµ¬ì¶• ì™„ë²½ ê°€ì´ë“œ
---

# ğŸ—„ï¸ VectorDBì™€ ìì—°ì–´DB êµ¬ì¶• ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ê°œìš”](#ê°œìš”)
2. [VectorDBë€?](#vectordbë€)
3. [í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°](#í˜„ì¬-í”„ë¡œì íŠ¸-êµ¬ì¡°)
4. [êµ¬ì¶• ë‹¨ê³„](#êµ¬ì¶•-ë‹¨ê³„)
5. [ì„ë² ë”© ìƒì„± ë°©ë²•](#ì„ë² ë”©-ìƒì„±-ë°©ë²•)
6. [ë²¡í„° ê²€ìƒ‰ êµ¬í˜„](#ë²¡í„°-ê²€ìƒ‰-êµ¬í˜„)
7. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

---

## ê°œìš”

ì´ í”„ë¡œì íŠ¸ëŠ” **PostgreSQL + pgvector**ë¥¼ ì‚¬ìš©í•˜ì—¬ ê´€ê³„í˜• DBì™€ VectorDBë¥¼ í†µí•© ìš´ì˜í•©ë‹ˆë‹¤.

### ì£¼ìš” íŠ¹ì§•
- âœ… í•˜ë‚˜ì˜ DBì—ì„œ ê´€ê³„í˜• ë°ì´í„°ì™€ ë²¡í„° ë°ì´í„° ëª¨ë‘ ê´€ë¦¬
- âœ… 768ì°¨ì› ì„ë² ë”© ë²¡í„° ì €ì¥ (HuggingFace ëª¨ë¸ ì‚¬ìš©)
- âœ… ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê¸°ë°˜ ê²€ìƒ‰
- âœ… ì§ˆë¬¸-ë‹µë³€ ë§¤ì¹­ ë° ìœ ì‚¬ ì§ˆë¬¸ ì¶”ì²œ

---

## VectorDBë€?

### 1. ì •ì˜
**VectorDB**ëŠ” í…ìŠ¤íŠ¸, ì´ë¯¸ì§€ ë“±ì„ ê³ ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜í•˜ì—¬ ì €ì¥í•˜ê³ , ìœ ì‚¬ë„ ê²€ìƒ‰ì„ ìˆ˜í–‰í•˜ëŠ” ë°ì´í„°ë² ì´ìŠ¤ì…ë‹ˆë‹¤.

### 2. ì‘ë™ ì›ë¦¬
```
í…ìŠ¤íŠ¸ ì…ë ¥ â†’ ì„ë² ë”© ëª¨ë¸ â†’ ë²¡í„°(ìˆ«ì ë°°ì—´) â†’ DB ì €ì¥ â†’ ìœ ì‚¬ë„ ê²€ìƒ‰
```

**ì˜ˆì‹œ:**
```python
"Python ê°œë°œì ë©´ì ‘ ì§ˆë¬¸" â†’ [0.234, -0.567, 0.891, ...] (768ê°œ ìˆ«ì)
"íŒŒì´ì¬ ë°±ì—”ë“œ ì§ˆë¬¸"     â†’ [0.221, -0.543, 0.876, ...] (768ê°œ ìˆ«ì)
# ë‘ ë²¡í„°ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ = 0.95 (ë§¤ìš° ìœ ì‚¬!)
```

### 3. ìì—°ì–´DB vs VectorDB

| êµ¬ë¶„ | ìì—°ì–´DB (ê´€ê³„í˜•) | VectorDB |
|------|------------------|----------|
| ì €ì¥ í˜•ì‹ | í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ | ìˆ«ì ë²¡í„° |
| ê²€ìƒ‰ ë°©ì‹ | í‚¤ì›Œë“œ ë§¤ì¹­ (LIKE, ILIKE) | ì˜ë¯¸ ê¸°ë°˜ ìœ ì‚¬ë„ |
| ì˜ˆì‹œ ì¿¼ë¦¬ | `WHERE content LIKE '%Python%'` | `ORDER BY embedding <=> query_vector` |
| ì¥ì  | ì •í™•í•œ ë§¤ì¹­ | ì˜ë¯¸ì  ìœ ì‚¬ì„± íŒŒì•… |

**ìš°ë¦¬ í”„ë¡œì íŠ¸ëŠ” ë‘˜ ë‹¤ ì‚¬ìš©í•©ë‹ˆë‹¤!**
- ìì—°ì–´DB: ì‚¬ìš©ì ì •ë³´, ë©´ì ‘ ê¸°ë¡, ëŒ€í™” ë‚´ìš© ì €ì¥
- VectorDB: ì§ˆë¬¸ ìœ ì‚¬ë„ ê²€ìƒ‰, ìš°ìˆ˜ ë‹µë³€ ë§¤ì¹­

---

## í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°

### 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •
```yaml
# docker-compose.yml
db:
  image: pgvector/pgvector:pg18  # PostgreSQL + pgvector í™•ì¥
  environment:
    POSTGRES_USER: admin
    POSTGRES_PASSWORD: 1234
    POSTGRES_DB: interview_db
```

### 2. ë²¡í„° í…Œì´ë¸” êµ¬ì¡°

#### **Question í…Œì´ë¸”** (ì§ˆë¬¸ ì€í–‰)
```python
class Question(SQLModel, table=True):
    id: int
    content: str                    # ìì—°ì–´ ì§ˆë¬¸ í…ìŠ¤íŠ¸
    category: QuestionCategory      # technical, behavioral ë“±
    difficulty: QuestionDifficulty  # easy, medium, hard

    # ğŸ”¥ ë²¡í„° ì»¬ëŸ¼ (768ì°¨ì›)
    embedding: List[float] = Field(sa_column=Column(Vector(768)))

    # ê³„ì¸µì  ë¶„ë¥˜ (í•„í„°ë§ìš©)
    company: str   # "ì‚¼ì„±ì „ì", "ì¹´ì¹´ì˜¤"
    industry: str  # "IT", "ê¸ˆìœµ"
    position: str  # "Backend ê°œë°œì"
```

#### **AnswerBank í…Œì´ë¸”** (ìš°ìˆ˜ ë‹µë³€ ì€í–‰)
```python
class AnswerBank(SQLModel, table=True):
    id: int
    question_id: int
    answer_text: str                # ìì—°ì–´ ë‹µë³€ í…ìŠ¤íŠ¸

    # ğŸ”¥ ë²¡í„° ì»¬ëŸ¼ (768ì°¨ì›)
    embedding: List[float] = Field(sa_column=Column(Vector(768)))

    score: float                    # ë‹µë³€ ì ìˆ˜ (0-100)
    evaluator_feedback: str         # í‰ê°€ì í”¼ë“œë°±
```

---

## êµ¬ì¶• ë‹¨ê³„

### Step 1: pgvector í™•ì¥ í™œì„±í™” âœ…

**ì´ë¯¸ ì™„ë£Œë¨!** `infra/postgres/init.sql`ì— ì„¤ì •ë˜ì–´ ìˆìŠµë‹ˆë‹¤:
```sql
CREATE EXTENSION IF NOT EXISTS vector;
```

Docker Composeë¡œ DBë¥¼ ì‹œì‘í•˜ë©´ ìë™ìœ¼ë¡œ í™œì„±í™”ë©ë‹ˆë‹¤.

### Step 2: ì„ë² ë”© ëª¨ë¸ ì¤€ë¹„

#### ì¶”ì²œ ëª¨ë¸ (HuggingFace)

1. **sentence-transformers/all-MiniLM-L6-v2** (ê¶Œì¥)
   - ì°¨ì›: 384
   - ì†ë„: ë¹ ë¦„
   - ìš©ë„: ì¼ë°˜ì ì¸ ë¬¸ì¥ ì„ë² ë”©

2. **jhgan/ko-sroberta-multitask** (í•œêµ­ì–´ íŠ¹í™”)
   - ì°¨ì›: 768 â­ (í˜„ì¬ í”„ë¡œì íŠ¸ ì„¤ì •)
   - ì†ë„: ì¤‘ê°„
   - ìš©ë„: í•œêµ­ì–´ ë©´ì ‘ ì§ˆë¬¸/ë‹µë³€

3. **intfloat/multilingual-e5-large**
   - ì°¨ì›: 1024
   - ì†ë„: ëŠë¦¼
   - ìš©ë„: ê³ í’ˆì§ˆ ë‹¤êµ­ì–´ ì§€ì›

#### ëª¨ë¸ ì„¤ì¹˜ ì˜ˆì‹œ
```python
from sentence_transformers import SentenceTransformer

# í•œêµ­ì–´ ëª¨ë¸ ë‹¤ìš´ë¡œë“œ
model = SentenceTransformer('jhgan/ko-sroberta-multitask')

# ì„ë² ë”© ìƒì„±
text = "Python FastAPI ê²½í—˜ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”"
embedding = model.encode(text)  # [768ê°œ ìˆ«ì]
```

### Step 3: ë°ì´í„° ì‚½ì… ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±

ì•„ë˜ ìŠ¤í¬ë¦½íŠ¸ë¥¼ `backend-core/scripts/populate_vectordb.py`ë¡œ ì €ì¥í•˜ì„¸ìš”:

```python
import sys
import os
sys.path.append(os.path.dirname(os.path.dirname(__file__)))

from sentence_transformers import SentenceTransformer
from sqlmodel import Session, select
from database import engine
from models import Question, AnswerBank, QuestionCategory, QuestionDifficulty

# ì„ë² ë”© ëª¨ë¸ ë¡œë“œ
print("ğŸ”„ ì„ë² ë”© ëª¨ë¸ ë¡œë”© ì¤‘...")
model = SentenceTransformer('jhgan/ko-sroberta-multitask')
print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

def add_question_with_embedding(
    session: Session,
    content: str,
    category: QuestionCategory,
    difficulty: QuestionDifficulty,
    company: str = None,
    industry: str = None,
    position: str = None,
    rubric: dict = None
):
    """ì§ˆë¬¸ê³¼ ì„ë² ë”©ì„ í•¨ê»˜ ì €ì¥"""

    # 1. ì„ë² ë”© ìƒì„±
    embedding = model.encode(content).tolist()

    # 2. Question ê°ì²´ ìƒì„±
    question = Question(
        content=content,
        category=category,
        difficulty=difficulty,
        embedding=embedding,
        company=company,
        industry=industry,
        position=position,
        rubric_json=rubric or {}
    )

    # 3. DB ì €ì¥
    session.add(question)
    session.commit()
    session.refresh(question)

    print(f"âœ… ì§ˆë¬¸ ì €ì¥ ì™„ë£Œ: {content[:50]}... (ID: {question.id})")
    return question

def add_answer_with_embedding(
    session: Session,
    question_id: int,
    answer_text: str,
    score: float,
    feedback: str = None
):
    """ë‹µë³€ê³¼ ì„ë² ë”©ì„ í•¨ê»˜ ì €ì¥"""

    # 1. ì„ë² ë”© ìƒì„±
    embedding = model.encode(answer_text).tolist()

    # 2. AnswerBank ê°ì²´ ìƒì„±
    answer = AnswerBank(
        question_id=question_id,
        answer_text=answer_text,
        embedding=embedding,
        score=score,
        evaluator_feedback=feedback
    )

    # 3. DB ì €ì¥
    session.add(answer)
    session.commit()
    session.refresh(answer)

    print(f"âœ… ë‹µë³€ ì €ì¥ ì™„ë£Œ: {answer_text[:50]}... (ì ìˆ˜: {score})")
    return answer

def populate_sample_data():
    """ìƒ˜í”Œ ë°ì´í„° ì‚½ì…"""

    with Session(engine) as session:
        # ì˜ˆì‹œ ì§ˆë¬¸ 1
        q1 = add_question_with_embedding(
            session,
            content="Pythonì—ì„œ GIL(Global Interpreter Lock)ì´ ë¬´ì—‡ì¸ì§€ ì„¤ëª…í•˜ê³ , ë©€í‹°ìŠ¤ë ˆë”© ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            category=QuestionCategory.TECHNICAL,
            difficulty=QuestionDifficulty.HARD,
            company="ì¹´ì¹´ì˜¤",
            industry="IT",
            position="Backend ê°œë°œì",
            rubric={
                "ì •í™•ì„±": 30,
                "ê¹Šì´": 30,
                "ì‹¤ë¬´ ì ìš©": 40
            }
        )

        # ì˜ˆì‹œ ë‹µë³€ 1
        add_answer_with_embedding(
            session,
            question_id=q1.id,
            answer_text="""
            GILì€ Python ì¸í„°í”„ë¦¬í„°ê°€ í•œ ë²ˆì— í•˜ë‚˜ì˜ ìŠ¤ë ˆë“œë§Œ Python ë°”ì´íŠ¸ì½”ë“œë¥¼ ì‹¤í–‰í•˜ë„ë¡
            ì œí•œí•˜ëŠ” ë®¤í…ìŠ¤ì…ë‹ˆë‹¤. ì´ëŠ” ë©”ëª¨ë¦¬ ê´€ë¦¬ì˜ ì•ˆì „ì„±ì„ ë³´ì¥í•˜ì§€ë§Œ, CPU-bound ì‘ì—…ì—ì„œëŠ”
            ë©€í‹°ìŠ¤ë ˆë”©ì˜ ì´ì ì„ ì œí•œí•©ë‹ˆë‹¤. ì‹¤ë¬´ì—ì„œëŠ” multiprocessing ëª¨ë“ˆì´ë‚˜ asyncioë¥¼
            ì‚¬ìš©í•˜ì—¬ ì´ë¥¼ ìš°íšŒí•©ë‹ˆë‹¤.
            """,
            score=95.0,
            feedback="GILì˜ ê°œë…ê³¼ ì˜í–¥, í•´ê²° ë°©ë²•ì„ ëª¨ë‘ ì •í™•íˆ ì„¤ëª…í•¨"
        )

        # ì˜ˆì‹œ ì§ˆë¬¸ 2
        q2 = add_question_with_embedding(
            session,
            content="íŒ€ì—ì„œ ì˜ê²¬ ì¶©ëŒì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì…¨ë‚˜ìš”?",
            category=QuestionCategory.BEHAVIORAL,
            difficulty=QuestionDifficulty.MEDIUM,
            industry="IT",
            position="Backend ê°œë°œì"
        )

        # ì˜ˆì‹œ ë‹µë³€ 2
        add_answer_with_embedding(
            session,
            question_id=q2.id,
            answer_text="""
            ì´ì „ í”„ë¡œì íŠ¸ì—ì„œ API ì„¤ê³„ ë°©ì‹ì— ëŒ€í•´ íŒ€ì›ê³¼ ì˜ê²¬ì´ ë‹¬ëìŠµë‹ˆë‹¤.
            ì €ëŠ” ê°ìì˜ ë°©ì‹ì„ í”„ë¡œí† íƒ€ì…ìœ¼ë¡œ êµ¬í˜„í•˜ì—¬ ì„±ëŠ¥ê³¼ ìœ ì§€ë³´ìˆ˜ì„±ì„ ë¹„êµí–ˆê³ ,
            ë°ì´í„°ë¥¼ ê¸°ë°˜ìœ¼ë¡œ ë…¼ì˜í•œ ê²°ê³¼ í•©ì˜ì ì„ ì°¾ì„ ìˆ˜ ìˆì—ˆìŠµë‹ˆë‹¤.
            """,
            score=88.0,
            feedback="êµ¬ì²´ì ì¸ ìƒí™©ê³¼ í•´ê²° ê³¼ì •ì„ STAR ê¸°ë²•ìœ¼ë¡œ ì˜ ì„¤ëª…í•¨"
        )

        print("\nğŸ‰ ìƒ˜í”Œ ë°ì´í„° ì‚½ì… ì™„ë£Œ!")

if __name__ == "__main__":
    populate_sample_data()
```

### Step 4: ë²¡í„° ì¸ë±ìŠ¤ ìƒì„± (ì„±ëŠ¥ ìµœì í™”)

ë°ì´í„°ê°€ 1000ê°œ ì´ìƒì¼ ë•Œ ì¸ë±ìŠ¤ë¥¼ ìƒì„±í•˜ì„¸ìš”:

```sql
-- IVFFlat ì¸ë±ìŠ¤ (ë¹ ë¥¸ ê·¼ì‚¬ ê²€ìƒ‰)
CREATE INDEX idx_questions_embedding
ON questions
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

CREATE INDEX idx_answer_bank_embedding
ON answer_bank
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);
```

**ì¸ë±ìŠ¤ ìƒì„± ì‹œì :**
- ë°ì´í„° < 1000ê°œ: ì¸ë±ìŠ¤ ë¶ˆí•„ìš” (ìˆœì°¨ ê²€ìƒ‰ì´ ë” ë¹ ë¦„)
- ë°ì´í„° > 1000ê°œ: IVFFlat ì¸ë±ìŠ¤ ìƒì„±
- ë°ì´í„° > 10000ê°œ: HNSW ì¸ë±ìŠ¤ ê³ ë ¤

---

## ì„ë² ë”© ìƒì„± ë°©ë²•

### ë°©ë²• 1: Pythonì—ì„œ ì§ì ‘ ìƒì„± (ê¶Œì¥)

```python
from sentence_transformers import SentenceTransformer

model = SentenceTransformer('jhgan/ko-sroberta-multitask')

# ë‹¨ì¼ í…ìŠ¤íŠ¸
embedding = model.encode("ì§ˆë¬¸ í…ìŠ¤íŠ¸")

# ë°°ì¹˜ ì²˜ë¦¬ (íš¨ìœ¨ì )
texts = ["ì§ˆë¬¸1", "ì§ˆë¬¸2", "ì§ˆë¬¸3"]
embeddings = model.encode(texts, batch_size=32)
```

### ë°©ë²• 2: HuggingFace API ì‚¬ìš©

```python
import requests

API_URL = "https://api-inference.huggingface.co/models/jhgan/ko-sroberta-multitask"
headers = {"Authorization": f"Bearer {HUGGINGFACE_API_KEY}"}

def get_embedding(text):
    response = requests.post(API_URL, headers=headers, json={"inputs": text})
    return response.json()
```

### ë°©ë²• 3: OpenAI Embeddings (ìœ ë£Œ)

```python
from openai import OpenAI

client = OpenAI(api_key="your-api-key")

response = client.embeddings.create(
    model="text-embedding-3-small",  # 1536ì°¨ì›
    input="ì§ˆë¬¸ í…ìŠ¤íŠ¸"
)

embedding = response.data[0].embedding
```

---

## ë²¡í„° ê²€ìƒ‰ êµ¬í˜„

### 1. ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰

```python
from sqlmodel import Session, select, text
from database import engine
from models import Question

def find_similar_questions(query_text: str, top_k: int = 5):
    """ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ìœ ì‚¬í•œ ì§ˆë¬¸ ê²€ìƒ‰"""

    # 1. ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±
    query_embedding = model.encode(query_text).tolist()

    # 2. ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ (ì½”ì‚¬ì¸ ê±°ë¦¬)
    with Session(engine) as session:
        # pgvectorì˜ <=> ì—°ì‚°ì: ì½”ì‚¬ì¸ ê±°ë¦¬ (ì‘ì„ìˆ˜ë¡ ìœ ì‚¬)
        stmt = select(
            Question,
            text(f"embedding <=> '{query_embedding}' AS distance")
        ).order_by(text("distance")).limit(top_k)

        results = session.exec(stmt).all()

        return [
            {
                "question": result[0],
                "similarity": 1 - result[1]  # ê±°ë¦¬ â†’ ìœ ì‚¬ë„ ë³€í™˜
            }
            for result in results
        ]

# ì‚¬ìš© ì˜ˆì‹œ
similar = find_similar_questions("íŒŒì´ì¬ ë©€í‹°ìŠ¤ë ˆë”©ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”")
for item in similar:
    print(f"ìœ ì‚¬ë„: {item['similarity']:.2f} - {item['question'].content}")
```

### 2. í•„í„°ë§ê³¼ ë²¡í„° ê²€ìƒ‰ ê²°í•©

```python
def find_questions_by_position(
    query_text: str,
    position: str,
    difficulty: str = None,
    top_k: int = 5
):
    """ì§ë¬´ë³„ + ë‚œì´ë„ë³„ + ìœ ì‚¬ë„ ê²€ìƒ‰"""

    query_embedding = model.encode(query_text).tolist()

    with Session(engine) as session:
        stmt = select(
            Question,
            text(f"embedding <=> '{query_embedding}' AS distance")
        ).where(
            Question.position == position
        )

        if difficulty:
            stmt = stmt.where(Question.difficulty == difficulty)

        stmt = stmt.order_by(text("distance")).limit(top_k)

        return session.exec(stmt).all()

# ì‚¬ìš© ì˜ˆì‹œ
results = find_questions_by_position(
    query_text="ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”",
    position="Backend ê°œë°œì",
    difficulty="hard"
)
```

### 3. ë‹µë³€ í‰ê°€ (ìš°ìˆ˜ ë‹µë³€ê³¼ ë¹„êµ)

```python
def evaluate_answer(question_id: int, user_answer: str):
    """ì‚¬ìš©ì ë‹µë³€ì„ ìš°ìˆ˜ ë‹µë³€ê³¼ ë¹„êµ"""

    # 1. ì‚¬ìš©ì ë‹µë³€ ì„ë² ë”©
    user_embedding = model.encode(user_answer).tolist()

    # 2. í•´ë‹¹ ì§ˆë¬¸ì˜ ìš°ìˆ˜ ë‹µë³€ë“¤ ê°€ì ¸ì˜¤ê¸°
    with Session(engine) as session:
        stmt = select(
            AnswerBank,
            text(f"embedding <=> '{user_embedding}' AS distance")
        ).where(
            AnswerBank.question_id == question_id
        ).order_by(text("distance")).limit(3)

        similar_answers = session.exec(stmt).all()

        if not similar_answers:
            return {"score": 0, "feedback": "ì°¸ê³ í•  ë‹µë³€ì´ ì—†ìŠµë‹ˆë‹¤."}

        # 3. ê°€ì¥ ìœ ì‚¬í•œ ë‹µë³€ ê¸°ì¤€ìœ¼ë¡œ ì ìˆ˜ ê³„ì‚°
        best_match = similar_answers[0]
        similarity = 1 - best_match[1]

        return {
            "score": similarity * best_match[0].score,
            "reference_answer": best_match[0].answer_text,
            "reference_score": best_match[0].score,
            "similarity": similarity,
            "feedback": best_match[0].evaluator_feedback
        }
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ì „ëµ

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ (ë°ì´í„° 1000ê°œ ì´ìƒì¼ ë•Œ)
CREATE INDEX idx_questions_embedding
ON questions
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- ë³µí•© ì¸ë±ìŠ¤ (í•„í„°ë§ + ê²€ìƒ‰)
CREATE INDEX idx_questions_position_category
ON questions (position, category);
```

### 2. ë°°ì¹˜ ì„ë² ë”© ìƒì„±

```python
# âŒ ëŠë¦¼: í•˜ë‚˜ì”© ì²˜ë¦¬
for text in texts:
    embedding = model.encode(text)
    save_to_db(embedding)

# âœ… ë¹ ë¦„: ë°°ì¹˜ ì²˜ë¦¬
embeddings = model.encode(texts, batch_size=32, show_progress_bar=True)
for text, embedding in zip(texts, embeddings):
    save_to_db(embedding)
```

### 3. ìºì‹± ì „ëµ

```python
from functools import lru_cache

@lru_cache(maxsize=1000)
def get_cached_embedding(text: str):
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ëŠ” ìºì‹±"""
    return model.encode(text).tolist()
```

### 4. ê·¼ì‚¬ ê²€ìƒ‰ vs ì •í™• ê²€ìƒ‰

```python
# ì •í™• ê²€ìƒ‰ (ëŠë¦¼, ë°ì´í„° < 1000ê°œ)
SELECT * FROM questions
ORDER BY embedding <=> query_vector
LIMIT 10;

# ê·¼ì‚¬ ê²€ìƒ‰ (ë¹ ë¦„, ì¸ë±ìŠ¤ ì‚¬ìš©)
SET ivfflat.probes = 10;  -- ì •í™•ë„ ì¡°ì ˆ (1-lists)
SELECT * FROM questions
ORDER BY embedding <=> query_vector
LIMIT 10;
```

---

## ì‹¤ì „ í™œìš© ì˜ˆì‹œ

### 1. ë©´ì ‘ ì§ˆë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ

```python
def recommend_questions(
    user_id: int,
    position: str,
    num_questions: int = 5
):
    """ì‚¬ìš©ì ì´ë ¥ì„œ ê¸°ë°˜ ì§ˆë¬¸ ì¶”ì²œ"""

    # 1. ì‚¬ìš©ì ì´ë ¥ì„œ/ê²½ë ¥ ê°€ì ¸ì˜¤ê¸°
    user_profile = get_user_profile(user_id)

    # 2. í”„ë¡œí•„ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
    profile_text = f"{user_profile.skills} {user_profile.experience}"

    # 3. ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
    questions = find_questions_by_position(
        query_text=profile_text,
        position=position,
        top_k=num_questions
    )

    return questions
```

### 2. ì‹¤ì‹œê°„ ë‹µë³€ í”¼ë“œë°±

```python
async def provide_realtime_feedback(
    interview_id: int,
    question_id: int,
    user_answer: str
):
    """ì‹¤ì‹œê°„ ë‹µë³€ í‰ê°€"""

    # 1. ë‹µë³€ í‰ê°€
    evaluation = evaluate_answer(question_id, user_answer)

    # 2. í”¼ë“œë°± ìƒì„±
    if evaluation["similarity"] > 0.8:
        feedback = "âœ… ìš°ìˆ˜í•œ ë‹µë³€ì…ë‹ˆë‹¤!"
    elif evaluation["similarity"] > 0.6:
        feedback = "âš ï¸ ì¢‹ì€ ë‹µë³€ì´ì§€ë§Œ ê°œì„  ì—¬ì§€ê°€ ìˆìŠµë‹ˆë‹¤."
    else:
        feedback = "âŒ ë‹µë³€ì„ ë³´ì™„í•´ì£¼ì„¸ìš”."

    # 3. ì°¸ê³  ë‹µë³€ ì œê³µ
    return {
        "feedback": feedback,
        "score": evaluation["score"],
        "reference": evaluation["reference_answer"]
    }
```

---

## ë‹¤ìŒ ë‹¨ê³„

1. âœ… `backend-core/scripts/populate_vectordb.py` ìŠ¤í¬ë¦½íŠ¸ ì‘ì„±
2. âœ… ì„ë² ë”© ëª¨ë¸ ë‹¤ìš´ë¡œë“œ ë° í…ŒìŠ¤íŠ¸
3. âœ… ìƒ˜í”Œ ë°ì´í„° ì‚½ì…
4. âœ… ë²¡í„° ê²€ìƒ‰ API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
5. âœ… í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ì¶”ì²œ ê¸°ëŠ¥ êµ¬í˜„

---

## ì°¸ê³  ìë£Œ

- [pgvector ê³µì‹ ë¬¸ì„œ](https://github.com/pgvector/pgvector)
- [Sentence Transformers](https://www.sbert.net/)
- [HuggingFace í•œêµ­ì–´ ëª¨ë¸](https://huggingface.co/jhgan/ko-sroberta-multitask)
