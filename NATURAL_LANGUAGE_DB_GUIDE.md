# ğŸ—£ï¸ ìì—°ì–´DB êµ¬ì¶• ë° í™œìš© ê°€ì´ë“œ

## ğŸ“‹ ëª©ì°¨
1. [ìì—°ì–´DBë€?](#ìì—°ì–´dbë€)
2. [í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ìì—°ì–´DB êµ¬ì¡°](#í˜„ì¬-í”„ë¡œì íŠ¸ì˜-ìì—°ì–´db-êµ¬ì¡°)
3. [ìì—°ì–´ ê²€ìƒ‰ êµ¬í˜„](#ìì—°ì–´-ê²€ìƒ‰-êµ¬í˜„)
4. [ì „ë¬¸ ê²€ìƒ‰(Full-Text Search) ì„¤ì •](#ì „ë¬¸-ê²€ìƒ‰-ì„¤ì •)
5. [ì‹¤ì „ í™œìš© ì˜ˆì‹œ](#ì‹¤ì „-í™œìš©-ì˜ˆì‹œ)
6. [ì„±ëŠ¥ ìµœì í™”](#ì„±ëŠ¥-ìµœì í™”)

---

## ìì—°ì–´DBë€?

**ìì—°ì–´DB**ëŠ” ì¼ë°˜ì ì¸ ê´€ê³„í˜• ë°ì´í„°ë² ì´ìŠ¤ì—ì„œ **ìì—°ì–´ í…ìŠ¤íŠ¸**ë¥¼ ì €ì¥í•˜ê³  ê²€ìƒ‰í•˜ëŠ” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### VectorDBì™€ì˜ ì°¨ì´ì 

| êµ¬ë¶„ | ìì—°ì–´DB | VectorDB |
|------|----------|----------|
| **ì €ì¥ ë°©ì‹** | í…ìŠ¤íŠ¸ ê·¸ëŒ€ë¡œ | ìˆ«ì ë²¡í„° (ì„ë² ë”©) |
| **ê²€ìƒ‰ ë°©ì‹** | í‚¤ì›Œë“œ ë§¤ì¹­, íŒ¨í„´ ë§¤ì¹­ | ì˜ë¯¸ì  ìœ ì‚¬ë„ |
| **ê²€ìƒ‰ ì˜ˆì‹œ** | `LIKE '%Python%'` | ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚° |
| **ì¥ì ** | ì •í™•í•œ ë§¤ì¹­, ë¹ ë¥¸ ì†ë„ | ì˜ë¯¸ íŒŒì•…, ìœ ì—°í•œ ê²€ìƒ‰ |
| **ë‹¨ì ** | ë™ì˜ì–´/ìœ ì‚¬ì–´ ê²€ìƒ‰ ì–´ë ¤ì›€ | ê³„ì‚° ë¹„ìš© ë†’ìŒ |

### ì–¸ì œ ì‚¬ìš©í•˜ë‚˜ìš”?

âœ… **ìì—°ì–´DB ì‚¬ìš© ì¼€ì´ìŠ¤:**
- ì‚¬ìš©ì ì´ë¦„, ì´ë©”ì¼ ê²€ìƒ‰
- ë©´ì ‘ ê¸°ë¡, ëŒ€í™” ë‚´ìš© ì¡°íšŒ
- í‚¤ì›Œë“œ ê¸°ë°˜ í•„í„°ë§
- ì •í™•í•œ í…ìŠ¤íŠ¸ ë§¤ì¹­

âœ… **VectorDB ì‚¬ìš© ì¼€ì´ìŠ¤:**
- ìœ ì‚¬í•œ ì§ˆë¬¸ ì°¾ê¸°
- ì˜ë¯¸ ê¸°ë°˜ ë‹µë³€ í‰ê°€
- ì¶”ì²œ ì‹œìŠ¤í…œ

---

## í˜„ì¬ í”„ë¡œì íŠ¸ì˜ ìì—°ì–´DB êµ¬ì¡°

### 1. ë°ì´í„°ë² ì´ìŠ¤ ì„¤ì •

```yaml
# docker-compose.yml
db:
  image: pgvector/pgvector:pg18
  environment:
    POSTGRES_USER: admin
    POSTGRES_PASSWORD: 1234
    POSTGRES_DB: interview_db
```

### 2. ìì—°ì–´ í…ìŠ¤íŠ¸ë¥¼ ì €ì¥í•˜ëŠ” í…Œì´ë¸”

#### **Users í…Œì´ë¸”** (ì‚¬ìš©ì ì •ë³´)
```python
class User(SQLModel, table=True):
    id: int
    email: str              # ì´ë©”ì¼ (ìì—°ì–´)
    username: str           # ì‚¬ìš©ìëª… (ìì—°ì–´)
    full_name: str          # ì „ì²´ ì´ë¦„ (ìì—°ì–´)
    role: UserRole
```

**ê²€ìƒ‰ ì˜ˆì‹œ:**
```sql
-- ì´ë¦„ìœ¼ë¡œ ì‚¬ìš©ì ê²€ìƒ‰
SELECT * FROM users WHERE full_name ILIKE '%ê¹€ì² ìˆ˜%';

-- ì´ë©”ì¼ë¡œ ê²€ìƒ‰
SELECT * FROM users WHERE email = 'user@example.com';
```

#### **Interviews í…Œì´ë¸”** (ë©´ì ‘ ì„¸ì…˜)
```python
class Interview(SQLModel, table=True):
    id: int
    candidate_id: int
    position: str           # ì§€ì› ì§ë¬´ (ìì—°ì–´)
    status: InterviewStatus
    emotion_summary: Dict   # ê°ì • ë¶„ì„ ìš”ì•½ (JSON)
```

**ê²€ìƒ‰ ì˜ˆì‹œ:**
```sql
-- íŠ¹ì • ì§ë¬´ì˜ ë©´ì ‘ ì¡°íšŒ
SELECT * FROM interviews WHERE position = 'Backend ê°œë°œì';

-- ì™„ë£Œëœ ë©´ì ‘ë§Œ ì¡°íšŒ
SELECT * FROM interviews WHERE status = 'completed';
```

#### **Transcripts í…Œì´ë¸”** (ëŒ€í™” ê¸°ë¡) â­ í•µì‹¬!
```python
class Transcript(SQLModel, table=True):
    id: int
    interview_id: int
    speaker: Speaker        # AI ë˜ëŠ” User
    text: str              # ëŒ€í™” ë‚´ìš© (ìì—°ì–´) â­
    timestamp: datetime
    sentiment_score: float
    emotion: str
```

**ê²€ìƒ‰ ì˜ˆì‹œ:**
```sql
-- íŠ¹ì • ë©´ì ‘ì˜ ëª¨ë“  ëŒ€í™” ì¡°íšŒ
SELECT * FROM transcripts
WHERE interview_id = 1
ORDER BY timestamp;

-- íŠ¹ì • í‚¤ì›Œë“œê°€ í¬í•¨ëœ ëŒ€í™” ê²€ìƒ‰
SELECT * FROM transcripts
WHERE text ILIKE '%Python%' OR text ILIKE '%FastAPI%';

-- ì‚¬ìš©ì ë‹µë³€ë§Œ ì¡°íšŒ
SELECT * FROM transcripts
WHERE speaker = 'User' AND interview_id = 1;
```

#### **Questions í…Œì´ë¸”** (ì§ˆë¬¸ ì€í–‰)
```python
class Question(SQLModel, table=True):
    id: int
    content: str           # ì§ˆë¬¸ ë‚´ìš© (ìì—°ì–´) â­
    category: QuestionCategory
    difficulty: QuestionDifficulty
    company: str           # íšŒì‚¬ëª… (ìì—°ì–´)
    position: str          # ì§ë¬´ (ìì—°ì–´)
```

**ê²€ìƒ‰ ì˜ˆì‹œ:**
```sql
-- í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ ê²€ìƒ‰
SELECT * FROM questions WHERE content ILIKE '%ë°ì´í„°ë² ì´ìŠ¤%';

-- íšŒì‚¬ë³„ ì§ˆë¬¸ ì¡°íšŒ
SELECT * FROM questions WHERE company = 'ì¹´ì¹´ì˜¤';

-- ë‚œì´ë„ë³„ í•„í„°ë§
SELECT * FROM questions
WHERE difficulty = 'hard' AND category = 'technical';
```

#### **EvaluationReports í…Œì´ë¸”** (í‰ê°€ ë¦¬í¬íŠ¸)
```python
class EvaluationReport(SQLModel, table=True):
    id: int
    interview_id: int
    summary_text: str      # ì¢…í•© í‰ê°€ (ìì—°ì–´) â­
    details_json: Dict     # ìƒì„¸ í‰ê°€ (JSON)
```

---

## ìì—°ì–´ ê²€ìƒ‰ êµ¬í˜„

### 1. ê¸°ë³¸ í‚¤ì›Œë“œ ê²€ìƒ‰ (LIKE, ILIKE)

```python
from sqlmodel import Session, select
from database import engine
from models import Transcript, Question

def search_transcripts_by_keyword(interview_id: int, keyword: str):
    """ëŒ€í™” ê¸°ë¡ì—ì„œ í‚¤ì›Œë“œ ê²€ìƒ‰"""
    with Session(engine) as session:
        # ILIKE: ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ ê²€ìƒ‰
        stmt = select(Transcript).where(
            Transcript.interview_id == interview_id,
            Transcript.text.ilike(f"%{keyword}%")
        )
        results = session.exec(stmt).all()
        return results

# ì‚¬ìš© ì˜ˆì‹œ
transcripts = search_transcripts_by_keyword(1, "Python")
for t in transcripts:
    print(f"[{t.speaker}] {t.text}")
```

### 2. ë‹¤ì¤‘ í‚¤ì›Œë“œ ê²€ìƒ‰ (OR ì¡°ê±´)

```python
from sqlalchemy import or_

def search_questions_multi_keyword(keywords: list[str]):
    """ì—¬ëŸ¬ í‚¤ì›Œë“œë¡œ ì§ˆë¬¸ ê²€ìƒ‰ (OR ì¡°ê±´)"""
    with Session(engine) as session:
        # í‚¤ì›Œë“œ ì¤‘ í•˜ë‚˜ë¼ë„ í¬í•¨ë˜ë©´ ê²€ìƒ‰
        conditions = [Question.content.ilike(f"%{kw}%") for kw in keywords]
        stmt = select(Question).where(or_(*conditions))
        results = session.exec(stmt).all()
        return results

# ì‚¬ìš© ì˜ˆì‹œ
questions = search_questions_multi_keyword(["Python", "FastAPI", "Django"])
```

### 3. ì •ê·œì‹ ê²€ìƒ‰ (ê³ ê¸‰)

```python
from sqlmodel import text

def search_with_regex(pattern: str):
    """ì •ê·œì‹ì„ ì‚¬ìš©í•œ ê³ ê¸‰ ê²€ìƒ‰"""
    with Session(engine) as session:
        # PostgreSQLì˜ ì •ê·œì‹ ì—°ì‚°ì ~*
        stmt = text(f"""
            SELECT * FROM questions
            WHERE content ~* :pattern
        """)
        results = session.exec(stmt, {"pattern": pattern}).all()
        return results

# ì‚¬ìš© ì˜ˆì‹œ
# "Python" ë˜ëŠ” "íŒŒì´ì¬"ì´ í¬í•¨ëœ ì§ˆë¬¸ ê²€ìƒ‰
questions = search_with_regex("Python|íŒŒì´ì¬")
```

---

## ì „ë¬¸ ê²€ìƒ‰(Full-Text Search) ì„¤ì •

PostgreSQLì˜ **ì „ë¬¸ ê²€ìƒ‰(Full-Text Search)**ì„ ì‚¬ìš©í•˜ë©´ ë” ê°•ë ¥í•œ ìì—°ì–´ ê²€ìƒ‰ì´ ê°€ëŠ¥í•©ë‹ˆë‹¤.

### 1. í•œêµ­ì–´ ì „ë¬¸ ê²€ìƒ‰ ì„¤ì •

```sql
-- PostgreSQLì— ì ‘ì†
docker exec -it interview_db psql -U admin -d interview_db

-- 1. í•œêµ­ì–´ ì‚¬ì „ í™•ì¸
SELECT * FROM pg_ts_config WHERE cfgname = 'korean';

-- 2. ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„± (Questions í…Œì´ë¸”)
CREATE INDEX idx_questions_content_fts
ON questions
USING gin(to_tsvector('korean', content));

-- 3. ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„± (Transcripts í…Œì´ë¸”)
CREATE INDEX idx_transcripts_text_fts
ON transcripts
USING gin(to_tsvector('korean', text));
```

### 2. ì „ë¬¸ ê²€ìƒ‰ ì¿¼ë¦¬

```python
from sqlmodel import text

def fulltext_search_questions(query: str, limit: int = 10):
    """ì „ë¬¸ ê²€ìƒ‰ì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ê²€ìƒ‰"""
    with Session(engine) as session:
        stmt = text("""
            SELECT
                id,
                content,
                category,
                difficulty,
                ts_rank(to_tsvector('korean', content), query) AS rank
            FROM questions,
                 plainto_tsquery('korean', :query) query
            WHERE to_tsvector('korean', content) @@ query
            ORDER BY rank DESC
            LIMIT :limit
        """)

        results = session.exec(
            stmt,
            {"query": query, "limit": limit}
        ).all()

        return results

# ì‚¬ìš© ì˜ˆì‹œ
results = fulltext_search_questions("ë°ì´í„°ë² ì´ìŠ¤ ìµœì í™”")
for r in results:
    print(f"[ìˆœìœ„: {r[4]:.4f}] {r[1]}")
```

### 3. ì „ë¬¸ ê²€ìƒ‰ + í•„í„°ë§ ê²°í•©

```python
def advanced_search(
    query: str,
    position: str = None,
    difficulty: str = None,
    limit: int = 10
):
    """ì „ë¬¸ ê²€ìƒ‰ + í•„í„°ë§"""
    with Session(engine) as session:
        sql = """
            SELECT
                id, content, category, difficulty,
                ts_rank(to_tsvector('korean', content), plainto_tsquery('korean', :query)) AS rank
            FROM questions
            WHERE to_tsvector('korean', content) @@ plainto_tsquery('korean', :query)
        """

        params = {"query": query, "limit": limit}

        if position:
            sql += " AND position = :position"
            params["position"] = position

        if difficulty:
            sql += " AND difficulty = :difficulty"
            params["difficulty"] = difficulty

        sql += " ORDER BY rank DESC LIMIT :limit"

        results = session.exec(text(sql), params).all()
        return results

# ì‚¬ìš© ì˜ˆì‹œ
results = advanced_search(
    query="ë°ì´í„°ë² ì´ìŠ¤",
    position="Backend ê°œë°œì",
    difficulty="hard"
)
```

---

## ì‹¤ì „ í™œìš© ì˜ˆì‹œ

### 1. ë©´ì ‘ ëŒ€í™” ë¶„ì„

```python
def analyze_interview_conversation(interview_id: int):
    """ë©´ì ‘ ëŒ€í™” ë‚´ìš© ë¶„ì„"""
    with Session(engine) as session:
        # ëª¨ë“  ëŒ€í™” ì¡°íšŒ
        stmt = select(Transcript).where(
            Transcript.interview_id == interview_id
        ).order_by(Transcript.timestamp)

        transcripts = session.exec(stmt).all()

        # í†µê³„ ê³„ì‚°
        total_words = sum(len(t.text.split()) for t in transcripts)
        user_responses = [t for t in transcripts if t.speaker == "User"]
        avg_response_length = sum(len(t.text.split()) for t in user_responses) / len(user_responses)

        # í‚¤ì›Œë“œ ë¹ˆë„ ë¶„ì„
        from collections import Counter
        all_words = " ".join(t.text for t in user_responses).split()
        keyword_freq = Counter(all_words).most_common(10)

        return {
            "total_messages": len(transcripts),
            "total_words": total_words,
            "avg_response_length": avg_response_length,
            "top_keywords": keyword_freq
        }

# ì‚¬ìš© ì˜ˆì‹œ
analysis = analyze_interview_conversation(1)
print(f"ì´ ëŒ€í™”: {analysis['total_messages']}ê°œ")
print(f"í‰ê·  ë‹µë³€ ê¸¸ì´: {analysis['avg_response_length']:.1f}ë‹¨ì–´")
print(f"ì£¼ìš” í‚¤ì›Œë“œ: {analysis['top_keywords']}")
```

### 2. ì‚¬ìš©ì ê²€ìƒ‰ (ìë™ì™„ì„±)

```python
def autocomplete_users(query: str, limit: int = 5):
    """ì‚¬ìš©ì ì´ë¦„ ìë™ì™„ì„±"""
    with Session(engine) as session:
        stmt = select(User).where(
            or_(
                User.username.ilike(f"{query}%"),
                User.full_name.ilike(f"%{query}%"),
                User.email.ilike(f"{query}%")
            )
        ).limit(limit)

        results = session.exec(stmt).all()
        return [
            {
                "id": u.id,
                "username": u.username,
                "full_name": u.full_name,
                "email": u.email
            }
            for u in results
        ]

# ì‚¬ìš© ì˜ˆì‹œ
suggestions = autocomplete_users("ê¹€")
# ê²°ê³¼: [{"username": "kim123", "full_name": "ê¹€ì² ìˆ˜", ...}, ...]
```

### 3. ì§ˆë¬¸ í•„í„°ë§ ë° ì •ë ¬

```python
def filter_questions(
    category: str = None,
    difficulty: str = None,
    company: str = None,
    position: str = None,
    keyword: str = None,
    sort_by: str = "created_at",
    order: str = "desc",
    limit: int = 20
):
    """ë‹¤ì–‘í•œ ì¡°ê±´ìœ¼ë¡œ ì§ˆë¬¸ í•„í„°ë§"""
    with Session(engine) as session:
        stmt = select(Question)

        # í•„í„° ì¡°ê±´ ì¶”ê°€
        conditions = []
        if category:
            conditions.append(Question.category == category)
        if difficulty:
            conditions.append(Question.difficulty == difficulty)
        if company:
            conditions.append(Question.company == company)
        if position:
            conditions.append(Question.position == position)
        if keyword:
            conditions.append(Question.content.ilike(f"%{keyword}%"))

        if conditions:
            stmt = stmt.where(and_(*conditions))

        # ì •ë ¬
        if order == "desc":
            stmt = stmt.order_by(getattr(Question, sort_by).desc())
        else:
            stmt = stmt.order_by(getattr(Question, sort_by))

        stmt = stmt.limit(limit)

        results = session.exec(stmt).all()
        return results

# ì‚¬ìš© ì˜ˆì‹œ
questions = filter_questions(
    category="technical",
    difficulty="hard",
    position="Backend ê°œë°œì",
    keyword="ë°ì´í„°ë² ì´ìŠ¤",
    sort_by="usage_count",
    order="desc"
)
```

### 4. ëŒ€í™” ë‚´ìš© í•˜ì´ë¼ì´íŠ¸

```python
def highlight_keywords_in_transcript(interview_id: int, keywords: list[str]):
    """ëŒ€í™” ë‚´ìš©ì—ì„œ í‚¤ì›Œë“œ í•˜ì´ë¼ì´íŠ¸"""
    with Session(engine) as session:
        stmt = select(Transcript).where(
            Transcript.interview_id == interview_id
        ).order_by(Transcript.timestamp)

        transcripts = session.exec(stmt).all()

        highlighted = []
        for t in transcripts:
            text = t.text
            for keyword in keywords:
                # ëŒ€ì†Œë¬¸ì êµ¬ë¶„ ì—†ì´ í•˜ì´ë¼ì´íŠ¸
                import re
                pattern = re.compile(re.escape(keyword), re.IGNORECASE)
                text = pattern.sub(f"**{keyword}**", text)

            highlighted.append({
                "speaker": t.speaker,
                "text": text,
                "timestamp": t.timestamp,
                "emotion": t.emotion
            })

        return highlighted

# ì‚¬ìš© ì˜ˆì‹œ
highlighted = highlight_keywords_in_transcript(1, ["Python", "FastAPI", "ë°ì´í„°ë² ì´ìŠ¤"])
```

---

## ì„±ëŠ¥ ìµœì í™”

### 1. ì¸ë±ìŠ¤ ìƒì„±

```sql
-- ìì£¼ ê²€ìƒ‰í•˜ëŠ” ì»¬ëŸ¼ì— ì¸ë±ìŠ¤ ìƒì„±
CREATE INDEX idx_users_username ON users(username);
CREATE INDEX idx_users_email ON users(email);
CREATE INDEX idx_interviews_position ON interviews(position);
CREATE INDEX idx_interviews_status ON interviews(status);
CREATE INDEX idx_questions_category ON questions(category);
CREATE INDEX idx_questions_difficulty ON questions(difficulty);
CREATE INDEX idx_questions_position ON questions(position);
CREATE INDEX idx_transcripts_interview_id ON transcripts(interview_id);

-- ë³µí•© ì¸ë±ìŠ¤ (ìì£¼ í•¨ê»˜ ì‚¬ìš©ë˜ëŠ” ì»¬ëŸ¼)
CREATE INDEX idx_questions_pos_cat_diff
ON questions(position, category, difficulty);

-- ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ (GIN)
CREATE INDEX idx_questions_content_gin
ON questions USING gin(to_tsvector('korean', content));

CREATE INDEX idx_transcripts_text_gin
ON transcripts USING gin(to_tsvector('korean', text));
```

### 2. ì¿¼ë¦¬ ìµœì í™”

```python
# âŒ ë¹„íš¨ìœ¨ì : N+1 ì¿¼ë¦¬ ë¬¸ì œ
def get_interviews_with_transcripts_bad(user_id: int):
    with Session(engine) as session:
        interviews = session.exec(
            select(Interview).where(Interview.candidate_id == user_id)
        ).all()

        for interview in interviews:
            # ê° ë©´ì ‘ë§ˆë‹¤ ë³„ë„ ì¿¼ë¦¬ ì‹¤í–‰ (N+1 ë¬¸ì œ!)
            transcripts = session.exec(
                select(Transcript).where(Transcript.interview_id == interview.id)
            ).all()
            interview.transcripts = transcripts

        return interviews

# âœ… íš¨ìœ¨ì : JOIN ì‚¬ìš©
def get_interviews_with_transcripts_good(user_id: int):
    with Session(engine) as session:
        # SQLModelì˜ Relationshipì„ í™œìš©í•œ ìë™ JOIN
        stmt = select(Interview).where(
            Interview.candidate_id == user_id
        )
        interviews = session.exec(stmt).all()

        # Relationshipì´ ì •ì˜ë˜ì–´ ìˆìœ¼ë©´ ìë™ìœ¼ë¡œ ë¡œë“œë¨
        return interviews
```

### 3. í˜ì´ì§€ë„¤ì´ì…˜

```python
def get_questions_paginated(page: int = 1, page_size: int = 20):
    """í˜ì´ì§€ë„¤ì´ì…˜ì„ ì‚¬ìš©í•œ ì§ˆë¬¸ ì¡°íšŒ"""
    with Session(engine) as session:
        offset = (page - 1) * page_size

        # ì „ì²´ ê°œìˆ˜ ì¡°íšŒ
        total_count = session.exec(
            select(func.count(Question.id))
        ).one()

        # í˜ì´ì§€ ë°ì´í„° ì¡°íšŒ
        stmt = select(Question).offset(offset).limit(page_size)
        questions = session.exec(stmt).all()

        return {
            "total": total_count,
            "page": page,
            "page_size": page_size,
            "total_pages": (total_count + page_size - 1) // page_size,
            "data": questions
        }
```

### 4. ìºì‹± ì „ëµ

```python
from functools import lru_cache
from datetime import datetime, timedelta

# ë©”ëª¨ë¦¬ ìºì‹± (ìì£¼ ì¡°íšŒë˜ëŠ” ë°ì´í„°)
@lru_cache(maxsize=100)
def get_question_by_id_cached(question_id: int):
    """ì§ˆë¬¸ ì¡°íšŒ (ìºì‹±)"""
    with Session(engine) as session:
        return session.get(Question, question_id)

# Redis ìºì‹± (ë¶„ì‚° í™˜ê²½)
import redis
import json

redis_client = redis.from_url("redis://redis:6379/0")

def get_interview_cached(interview_id: int):
    """ë©´ì ‘ ì¡°íšŒ (Redis ìºì‹±)"""
    cache_key = f"interview:{interview_id}"

    # ìºì‹œ í™•ì¸
    cached = redis_client.get(cache_key)
    if cached:
        return json.loads(cached)

    # DB ì¡°íšŒ
    with Session(engine) as session:
        interview = session.get(Interview, interview_id)

        # ìºì‹œ ì €ì¥ (5ë¶„ TTL)
        redis_client.setex(
            cache_key,
            300,
            json.dumps(interview.dict())
        )

        return interview
```

---

## ì‹¤ì „ API ì—”ë“œí¬ì¸íŠ¸ ì˜ˆì‹œ

```python
# backend-core/main.py

from fastapi import FastAPI, Query
from typing import Optional

app = FastAPI()

@app.get("/api/search/questions")
async def search_questions(
    keyword: str = Query(..., description="ê²€ìƒ‰ í‚¤ì›Œë“œ"),
    category: Optional[str] = None,
    difficulty: Optional[str] = None,
    position: Optional[str] = None,
    page: int = Query(1, ge=1),
    page_size: int = Query(20, ge=1, le=100)
):
    """ì§ˆë¬¸ ê²€ìƒ‰ API"""
    results = filter_questions(
        category=category,
        difficulty=difficulty,
        position=position,
        keyword=keyword,
        limit=page_size
    )

    return {
        "keyword": keyword,
        "results": [
            {
                "id": q.id,
                "content": q.content,
                "category": q.category,
                "difficulty": q.difficulty
            }
            for q in results
        ]
    }

@app.get("/api/interviews/{interview_id}/transcripts")
async def get_interview_transcripts(
    interview_id: int,
    keyword: Optional[str] = None
):
    """ë©´ì ‘ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    if keyword:
        transcripts = search_transcripts_by_keyword(interview_id, keyword)
    else:
        with Session(engine) as session:
            stmt = select(Transcript).where(
                Transcript.interview_id == interview_id
            ).order_by(Transcript.timestamp)
            transcripts = session.exec(stmt).all()

    return {
        "interview_id": interview_id,
        "total": len(transcripts),
        "transcripts": [
            {
                "speaker": t.speaker,
                "text": t.text,
                "timestamp": t.timestamp,
                "emotion": t.emotion
            }
            for t in transcripts
        ]
    }

@app.get("/api/users/search")
async def search_users(
    query: str = Query(..., min_length=1),
    limit: int = Query(5, ge=1, le=20)
):
    """ì‚¬ìš©ì ê²€ìƒ‰ (ìë™ì™„ì„±)"""
    results = autocomplete_users(query, limit)
    return {"suggestions": results}
```

---

## ë‹¤ìŒ ë‹¨ê³„

âœ… **ìì—°ì–´DB êµ¬ì¶• ì™„ë£Œ!**

ì´ì œ ë‹¤ìŒì„ ì‹œë„í•´ë³´ì„¸ìš”:
1. âœ… ì „ë¬¸ ê²€ìƒ‰ ì¸ë±ìŠ¤ ìƒì„±
2. âœ… API ì—”ë“œí¬ì¸íŠ¸ ì¶”ê°€
3. âœ… í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ê²€ìƒ‰ ê¸°ëŠ¥ êµ¬í˜„
4. âœ… ìºì‹± ì „ëµ ì ìš©

---

## ì°¸ê³  ìë£Œ

- [PostgreSQL Full-Text Search](https://www.postgresql.org/docs/current/textsearch.html)
- [SQLModel ê³µì‹ ë¬¸ì„œ](https://sqlmodel.tiangolo.com/)
- [FastAPI ê³µì‹ ë¬¸ì„œ](https://fastapi.tiangolo.com/)
