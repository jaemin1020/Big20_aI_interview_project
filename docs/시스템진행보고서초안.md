# Big20 AI 면접 프로젝트 시스템 진행 보고서 (초안)

> **작성일**: 2026-02-27
> **문서 버전**: 1.0 (초안)
>
> **프로젝트 기간**: 2026-01-20 ~ 2026-03-11

## 1. 프로젝트 개요

### 1.1 프로젝트 목적

Big20 AI 면접 프로젝트(A4 프로젝트)는 최신 AI 기술(LLM, Vision AI, STT)과 실시간 웹 통신 기술(WebRTC)을 결합하여, 실제 면접과 유사한 환경을 제공하는 온프레미스 기반 통합 아키텍처를 구축하는 것을 목적으로 합니다. 면접자의 답변 내용과 비언어적 태도를 종합적으로 분석하여 객관적이고 심도 있는 피드백을 제공합니다.

### 1.2 시스템 아키텍처 부서의 역할 및 관리 범위

시스템 아키텍처는 단순 서버 구성뿐만 아니라 서비스가 안정적으로 동작하기 위한 전체 구조와 기술적 경계를 책임집니다.

- **인프라 아키텍처**: 서버 구성, GPU/CPU 워커 분리, Docker 컨테이너 전략, 네트워크 및 포트 설계 등
- **애플리케이션 설계**: 백엔드 API 레이어, 비동기 큐, RAG 파이프라인 흐름 정의
- **데이터 구조**: PostgreSQL/pgvector 기반 ERD 구조, 벡터 검색 및 세션 저장 전략
- **보안 및 운영 전략**: 모니터링, 역할 기반 인가(JWT), 스케일아웃 시나리오 등

---

## 2. 초기 아키텍처 설계안

프로젝트 기획 초기에는 단일 인스턴스 중심의 구조와 제한적인 상태 관리를 가정했습니다.

- **초기 인프라 구조**: 단일 Docker Compose 환경 내에서 백엔드, 프론트엔드, DB를 모두 구동하는 모놀리식에 가까운 컨테이너 구조.
- **AI 처리 구조**: 단일 워커(Worker)에서 비동기 구분 없이 LLM과 STT 등 모든 무거운 처리를 순차적으로 할당.
- **상태 관리 체계**: 세션 상태 대부분을 메모리에서 단기적으로 관리, DB는 최종 결과 저장용으로만 활용 계획.
- **동기 LLM 호출**: 사용자 요청마다 동기(Synchronous) 방식으로 언어 모델을 직접 호출하여 답변 대기 발생 예상.

이러한 초기 구조는 개발의 용이성을 주었지만, 예측된 트래픽이나 복합적인 AI 추론 환경 하에서 병목 및 확장성에 대한 한계를 드러냈습니다.

---

## 3. 설계 진행 과정

시스템 구축이 본격화되면서 여러 문제와 성능 이슈에 대응하기 위해 아키텍처를 진화시켰습니다.

### 3.1 인프라 진행 과정

- **자원 격리 적용**: GPU 집약적 작업(LLM 추론, 면접관/꼬리질문 생성)과 CPU 집약적 작업(STT, 이력서 문서 파싱, Vision AI 프레임 추출)을 수행하는 Celery Worker 컨테이너 분리.
- **Docker Compose 네트워크 최적화**: WebRTC 영상 스트리밍과 NAT 우회를 위해 Host IP 마스킹 적용(50000-50050/udp 확장)으로 포트 및 컨테이너 네트워크 충돌 제거.

### 3.2 애플리케이션 구조 변화

- **비동기 큐 도입**: 동기식 AI 호출을 전면 개편. Redis 기반 메세지 브로커와 Celery Task Queue를 도입하여, `cpu_queue`와 `gpu_queue`로 트래픽을 분리 제어.
- **상태 관리 고도화**: Redis를 통한 단기 세션의 빠른 Caching 및 PostgreSQL을 통한 상태 트랜잭션의 명확한 분리.

### 3.3 데이터 구조 변화

- **RAG/Vector 검색 통합**: 단일 DB 전략으로 관리를 일원화하기 위해 PostgreSQL 내 `pgvector` Extension을 도입, 1024차원 고정 벡터 검색 기능 탑재. 이력서 및 기업 인재상의 벡터 임베딩 통합 서치 설계 반영.
- **인덱스 전략 수정**: 데이터베이스 관계(Foreign Key) 및 구조적 무결성 확보 개선. (실시간 기록되는 Transcripts와 Questions 연동 구조 개선 등)

---

## 4. 아키텍처 변경 이력

주요 구조적 전환 내역은 다음과 같습니다.

| 변경 항목               | 변경 전                      | 변경 후                              | 변경 이유 및 영향도                                                                                                     |
| ----------------------- | ---------------------------- | ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| **Worker 구성**   | 단일 AI Worker               | GPU / CPU 분리 Worker                | **이유**: 컨테이너 간 리소스 경합 방지 `<br>`**영향**: GPU 메모리 분산 및 처리 응답성 극대화              |
| **LLM 호출 방식** | 동기식(Synchronous) API 호출 | Celery 비동기 처리                   | **이유**: 요청 대기 시간으로 인한 Time-out 방지 `<br>`**영향**: 응답 안정성 및 시스템 로드 감소 효과 확보 |
| **STT 처리**      | 서버 내 로컬 Whisper 혼용    | Client-Side Audio / Celery 원격 처리 | **이유**: 실시간성 보강 및 서버 부하 이전 `<br>`**영향**: 발화 즉시 텍스트화 달성 및 2초 이내 변환 완성   |
| **DB 운영**       | 일반 RDBMS + 별도 Vector DB  | PostgreSQL + pgvector 통합           | **이유**: 아키텍처 복잡도 축소 방안 `<br>`**영향**: 트랜잭션 관리와 RAG 파이프라인의 통합으로 정합성 향상 |

---

## 5. 기술 이슈 및 리스크 대응

- **PostgreSQL 볼륨 마운트 에러**: PostgreSQL 18 버전 업그레이드로 인한 Data 디렉토리 경로 충돌 문제. `docker-compose.yml` 볼륨 설정을 `/var/lib/postgresql`로 변경하여 해결함.
- **Celery Task 모듈 참조 오류**: 백엔드와 워커 간 컨테이너 분리로 인해 Task Class 직참조 불가 이슈. Task 이름을 직접 호출하는 `send_task` 패턴으로 전환하여 의존성을 디커플링함.
- **파일 볼륨 공유 부재**: 백엔드에서 업로드한 PDF(이력서)를 AI Worker가 접근하지 못하는 이슈 대응. `uploads` 디렉토리를 공용 Docker 마운트로 매핑 처리하여 문제 해소.
- **동적 자바스크립트 빌드 및 구문 오류**: 프론트엔드 환경에서 WebRTC Recording 로직 충돌 및 바벨(Babel) 분석 에러가 있었으나, 문법 스크립트 블록 및 DOM 라이프사이클을 교정하여 해결.
- **비전 AI 모델 병목**: 초당 프레임 추출로 인한 Media-Server 부하. OpenCV를 활용해 5FPS/2초 간격 프레임 추출로 샘플링 레이트를 조절하여 서버 안정성을 확보.

---

## 6. 성능 검증 결과

실제 온프레미스 인스턴스 구축 결과 달성한 주요 성능 스펙입니다.

1. **실시간성(WebRTC)**: P2P 환경 기준 미디어 응답 레이턴시 500ms 미만 유지 (UDP 50000 포트 트래버스 최적화).
2. **LLM 처리 속도(EXAONE 3.5)**: 꼬리질문 및 답변 종합 평가 요청 처리 시 Task 큐 딜레이 포함 API 평균 질문 생성 5초 이내 완료 달성.
3. **음성인식(STT) 속도**: 사용자 발화 종료(Silence) 감지 후 2초 이내 Text Transcript 변환 완료.
4. **시각 분석(Vision)**: 200ms 미만의 Latency로 얼굴 랜드마크 분석 및 감정(Dominant Emotion) 스코어 산출 달성.

*설계된 아키텍처는 이론적 모델을 넘어 요구사항을 만족하는 실시간 반응성을 확보했습니다.*

---

## 7. 산출물 목록

진행 과정에서 다음과 같은 산출물을 도출하여 관리하고 있습니다.

1. `시스템_아키텍처_디자인(SAD).docx` (전반 시스템 개요 정의)
2. `SYSTEM_SPECIFICATION.md` (시스템 명세서)
3. `TROUBLESHOOTING.md` (기술 오류 및 해결 가이드)
4. `docker-compose.yml` (통합 인프라 배포 파일 최종 버전)
5. `QUALITY_INSPECTION_REPORT.md` (품질 검사 및 보안 개선 리포트)

---

## 8. 최종 확정 아키텍처

- **최종 인프라 구조**: Docker Compose 기반 가상 네트워크 격리망. Backend(FastAPI), React Client, Media-Server, AI Worker(CPU/GPU 독립), DB(PostgreSQL), Broker(Redis).
- **최종 AI 모델 패치**: 단일 거대언어모델 적용 (질문 생성 및 답변 평가 통합: EXAONE-3.5-7.8B), 시각분석(DeepFace/MediaPipe).
- **데이터 구조 통합**: pgvector로 구성된 RDBMS 스키마. 사용자, 이력서 벡터, 질문 벡터, 회사 인재상을 통합 연결하여 관리.

최종 확정된 이 구조는 On-premise 환경 기준 수십 명 규모의 동시 면접 시나리오를 효과적으로 방어하며, 운영 가능한 실증 단위에 도달했습니다.

---

## 9. 운영 준비 상태

본 시스템은 실제 운영 투입을 위한 기반이 갖춰져 있습니다.

- **권한 철저 분리**: JWT Stateless Token 및 API EndPoint 마다 `Candidate / Recruiter` 별 RBAC (Role-Based Access Control) 권한 제어 적용 완료.
- **민감정보 보호**: 외부 통신망(DB, Broker) 외부 공개 차단 설정 및 환경변수 주입을 통해 컨테이너 레벨 보안 정책수립.
- **장애 모니터링 체계 준비**: Docker log 및 Celery Task 추적 로그 확인 환경을 제공하며, 장애 발생 시 원인을 빠르게 트래킹할 수 있는 기초 환경(Troubleshooting Guide) 구성.

---

## 10. 향후 고도화 계획

- **모델 경량화 전략(Quantization)**: VRAM 비용 절감 및 속도 개선을 위해 EXAONE의 GGUF 기반 양자화 추론기 고도화 및 최적화 추진.
- **분산 스케일아웃 확장(Scale-out)**: 동시 접속 증가 대응을 위한 Celery 워커 클러스터 물리 확충 방안 모색 및 대규모 Kafka 브로커 전환 검토.
- **서비스 분리 및 고가용성 확보(Docker Swarm)**: 현재의 단일 노드 Compose 환경에서 벗어나 Frontend, Backend, DB 노드를 물리적으로 분리하고, Docker Swarm 기반의 오케스트레이션을 구축하여 부하 분산 및 고가용성(HA) 환경 확보 예정.
- **LLM 품질 파이프라인**: LangSmith 등 Observability 도구 연동을 통한 면접 응답 품질(QnA) 트레이싱 대시보드 구축 진행.
