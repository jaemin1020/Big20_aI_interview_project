# Big20 AI 면접 프로젝트 시스템 진행 보고서

> **작성일**: 2026-02-27
> **문서 버전**: 1.1
> **작성자**: 엄재민
> **프로젝트 기간**: 2026-01-20 ~ 2026-03-11

## 1. 프로젝트 개요

### 1.1 프로젝트 목적

Big20 AI 면접 프로젝트(A4 프로젝트)는 최신 AI 기술(LLM, Vision AI, STT)과 실시간 웹 통신 기술(WebRTC)을 결합하여, 실제 면접과 유사한 환경을 제공하는 온프레미스 기반 통합 아키텍처를 구축하는 것을 목적으로 합니다. 대규모 클라우드 자원에 의존하지 않고 로컬 서버 및 통제된 네트워크 내에서 독립적으로 구동 가능한 B2B/B2C 면접 솔루션을 목표로 하며, 면접자의 답변 내용과 비언어적 태도, 이력서 문맥을 종합적으로 분석하여 객관적이고 심도 있는 피드백을 제공합니다.

### 1.2 시스템 아키텍처 부서의 역할 및 관리 범위

시스템 아키텍처는 단순한 컨테이너 배포를 넘어, 무거운 AI 추론 작업을 지연 없이 처리하고 서비스가 365일 안정적으로 동작하기 위한 전체 구조와 기술적 경계를 책임집니다.

- **인프라 아키텍처 (Infrastructure)**: 온프레미스 서버 환경 구성, GPU 구동 환경 최적화(NVIDIA Container Toolkit), GPU/CPU 워커 역할 물리적 분리, Docker Compose 기반 오케스트레이션 전략, VNet(가상 네트워크) 및 포트 할당 정책.
- **애플리케이션 설계 (Application)**: FastAPI 기반의 비동기 백엔드 API 레이어, Celery와 Redis 기반의 메시지 큐 시스템, RAG(Retrieval-Augmented Generation) 파이프라인 흐름 정의.
- **데이터 구조 (Data)**: PostgreSQL 및 pgvector 확장 기능(Extension)을 기반으로 한 1024차원 벡터 검색 구조, ERD 상세 설계, 세션 트랜잭션과 Redis 임시 저장 전략의 분리.
- **보안 및 운영 전략 (Security & Ops)**: 시스템 모니터링 체계, JWT 기반의 Stateless Auth 및 Role-Based Access Control(RBAC), 데이터베이스 외부 노출 차단 정책 설정 등.

---

## 2. 초기 아키텍처 설계안

프로젝트 기획 초기에는 빠른 프로토타이핑을 위해 단일 인스턴스 중심의 모놀리식 구조와 제한적인 상태 관리를 가정했습니다.

- **초기 인프라 구조**: 단일 Docker Compose 환경 내에서 Backend(FastAPI), Frontend(React), DB(PostgreSQL), Media-Server를 모두 구동하는 구조.
- **AI 처리 구조**: 단일 AI Worker를 할당하여 비동기 구분 없이 대형 언어모델 예측(LLM), 음성 인식(STT), 비전 프레임 분석(Vision) 등 이질적인 무거운 작업들을 순차적으로 처리하도록 계획.
- **상태 관리 체계**: 면접 세션의 진행 상태(질문 순서, 현재 발화 등)를 메모리(Variable) 수준에서 단기적으로 관리하고, DB는 최종 결과 통보 및 단순 로그 저장용으로만 활용할 계획이었습니다.
- **동기 LLM 호출**: Frontend에서 질문을 요청할 때마다 백엔드가 동기(Synchronous) 방식으로 블로킹된 상태에서 API 언어 모델을 호출, 사용자에게 답변을 내려주기까지 장시간 대기가 발생할 것으로 예상되는 구조였습니다.

**문제점 도출**: 이러한 초기 구조는 개발의 용이성을 제공했지만, 본격적인 스트레스 테스트와 복합적인 AI 추론 환경 하에서 심각한 병목을 일으켰습니다. 특히 GPU 연산과 CPU 연산이 한정된 자형 안에서 경합을 벌이면서 STT 변환 주기가 길어지거나, LLM의 텍스트 생성이 멈추는 확장성 한계를 뚜렷이 드러냈습니다.

---

## 3. 설계 진행 과정

시스템 구축이 본격화되면서 발견된 병목 현상과 성능 이슈에 적극적으로 대응하기 위해 아키텍처를 대폭 진화시켰습니다.

### 3.1 인프라 진행 과정 (Resource Isolation & Network)

- **자원 격리 적용 (GPU vs CPU)**: AI 연산의 특징적 차이를 분석하여, VRAM 집약적인 작업(EXAONE-3.5 LLM 프롬프트 추론, TTS 변환)과 코어 연산 집약적인 작업(Whisper/Browser 기반 STT 전처리, PDF 이력서 파싱, Face 랜드마크 추출)을 수행하는 Celery Worker 컨테이너를 물리적으로 2개(`gpu_worker`, `cpu_worker`) 분리했습니다. 이를 통해 서로 간의 리소스 경합(Lock)을 방지했습니다.
- **WebRTC 네트워크 최적화**: 화상 면접에 필수적인 WebRTC 영상 스트리밍을 안정적으로 연결하기 위해 NAT 우회 로직을 구성했습니다. Media-Server 컴포넌트 내에 Host IP 마스킹 기법을 적용하고, 데이터 채널 소켓용 광역 포트(`50000-50050/udp`)를 명시적으로 열어 내부망 컨테이너 네트워크 충돌을 완전히 제거했습니다.
- **DB 초기 인프라 및 핵심 테이블 자동 구축**: 전체 시스템이 동작할 기반을 마련하기 위해, PostgreSQL 컨테이너 가동 시점에 채용자(`Recruiter`) 및 지원자(`Candidate`) 기본 계정과 `Interview`, `Transcript` 등의 뼈대 테이블이 ORM 모델을 통해 자동으로 삽입/초기화되도록 DB Init 파이프라인을 완비했습니다.
- **React 기반 초기 화면 구조(UI/UX) 설계**: 실시간 면접 사용자 경험 향상을 위해 Vite + React 통합 프론트엔드 인프라를 우선 세팅하고, 로그인 직후 접근 가능한 관리자 대시보드 화면 및 미디어 스트림(웹캠/마이크) 권한을 획득하는 면접장(Room) 레이아웃 뼈대를 초기에 선제적으로 그려냈습니다.

### 3.2 애플리케이션 구조 변화 (Async Message Broker)

- **비동기 큐 전면 도입**: 동기식 AI 호출의 치명적인 타임아웃 문제를 해결하기 위해 백엔드를 Event-Driven 방식으로 개편했습니다. Redis 기반의 메모리형 메세지 브로커와 Celery Task Queue를 병합 적용하여, 수신된 API 요청을 Queue에 밀어넣고 클라이언트는 즉각 응답을 받은 뒤 필요 시점에 결괏값만 폴링/웹소켓으로 받아가도록 비동기 파이프라인을 확립했습니다.
- **상태 관리 고도화**: 휘발성 메모리에 의존하던 면접 세션을 변경하여, Redis로는 단기 연결상태(Connection Caching)만 유지하고, 질문 번호 추적, 진행률 등 지속적인 상태 트랜잭션은 모두 PostgreSQL 로 격리하여 데이터 영속성 상실(Data Loss)을 차단했습니다.

### 3.3 데이터 구조 변화 (PostgreSQL & Vector Search)

- **RAG/Vector 검색 통합**: LLM이 이력서와 기업 인재상에 맞춰 정교하게 질문하려면 벡터 검색이 필수였습니다. 덩치가 큰 외부 Vector DB(Milvus 등)를 별도 설치하는 대신, 단일 DB 전략으로 아키텍처를 일원화하고자 기존 PostgreSQL 18 인스턴스에 `pgvector` 확장을 직접 이식했습니다. 이로써 정형 RDBMS 데이터와 1024차원의 AI 임베딩 벡터 데이터를 Join 쿼리하여 속도 지연 없이 통합 서치할 수 있게 되었습니다.
- **인덱스 전략 수정**: 데이터베이스 관계 무결성을 지키기 위해 엔티티 간 Foreign Key 연결을 강화했습니다. 실시간 기록되는 사용자 대화(`Transcripts`)와 AI의 특정 `Question` ID를 상호 매핑하는 형태로 ERD 구조를 튜닝, 추후 종합 채점 파이프라인에서 완벽하게 문맥을 연결할 수 있도록 개선했습니다.

### 3.4 협업 및 형상 관리 환경 구축

- **Git 기반 형상 관리 확립**: 초기 단계에서의 무작위한 파일 복사 시스템 한계를 극복하기 위해, Git 원격 저장소를 전면 도입했습니다. 커밋 이력(History Tracking)과 브랜치(Branching) 전략을 통해 프론트엔드와 백엔드 간 API 동기화 문제를 제거했습니다.
- **.gitignore 상세 정책 적용**: 보안에 민감한 API Key 관련 환경 변수(`.env`), 크기가 5GB에 달하는 막대한 GGUF/PT 모델 가중치 파일들, 그리고 운영 체제별 충돌을 유발하는 파이썬/노드 종속성 캐시(`__pycache__`, `node_modules`) 등을 강력히 배제하여 저장소를 깃허브 등 원격 서버에 올리기 적합하도록 슬림화했습니다.
- **멀티 컴포넌트 모노레포 관리**: `frontend` (React), `backend-core` (FastAPI), `ai-worker` (DL 환경), `media-server` (aiortc) 등 각기 다른 언어와 실행 환경을 가진 복잡한 MSA 모듈들을 하나의 최상위 레포지토리 하위에 단일 트리로 분산 배치하여 코드 관리를 일원화했습니다.
### 3.5 시스템 아키텍트(jaemin1020) 주요 개발 및 기여 내역

전체 저장소(Git) 로그 리서치를 거쳐 식별된 `jaemin1020` 계정의 주요 개발 변경 이력입니다. 이 기여는 프로젝트의 뼈대가 되는 초기 인프라 설계부터, 각 핵심 단위 모듈들(LLM, DB, STT/TTS)의 통합 최적화, 그리고 문서화 레거시 전반을 아우릅니다.

- **초기 통합 인프라 환경 및 프로젝트 뼈대 구축**:
  - `backend-core`, `frontend`, `ai-worker`, `media-server` 등 복합 MSA 구조의 **단일 최상위 디렉토리(모노레포)를 최초 생성**하고, 통합 `docker-compose.yml` 리팩토링 및 세부 환경별 `.gitignore` 설정을 배포하여 팀 원격 협업 체계를 마련했습니다.
- **음성/시각 미디어 파이프라인(STT/TTS/Vision) 코어 연동**:
  - Deepgram/Whisper 기반 **STT 인식 시 발생하는 타임아웃 에러 및 라이브러리 종속성 충돌을 밀착 수정** 설계하여, 면접 중 사용자 발화가 끊기지 않도록 인식 구조를 개편했습니다.
  - 면접관 음성 산출 속도를 위해 **TTS 생성 레이턴시 축소 및 재생 스레드 최적화**를 달성했으며, DeepFace 얼굴 인식 모델 연동을 수행하여 서비스 코어를 완성했습니다.
- **RAG 데이터 파이프라인 및 백엔드/DB 최적화**:
  - PostgreSQL 테이블 구조와 pgvector ERD를 지속해서 개편 조율했으며, 언어 모델 사양에 맞춘 **1024차원 데이터 벡터 생성 및 사용자 이력서(PDF) 자동 파싱 로직 구현**을 주도했습니다.
  - 프로세스 병렬 처리 및 동기화 병목을 해소하기 위해 **Redis Cache 기반의 Celery Task 큐 구조 도입을 기획**했으며, 무한 응답 대기 오류 발생 시 **강제로 기본 질문을 뱉어내는 폴백(Fallback) 방어 트리거 로직**을 추가 이식하여 시스템 커널 붕괴를 억제했습니다.
- **핵심 기술 및 개발 산출물(QA) 총괄 작성**:
  - 프로젝트 전체의 아키텍트이자 관리자 역할을 수행하며, 시스템 설계서(SAD), 데이터베이스 연동 기준서, 기술 최적화 리포트, 품질 개선 사항 및 검증서 등 **대형 Technical Documentation 작성을 전담 및 유지보수**하여 프로젝트 노하우의 유산화에 크게 기여했습니다.
---

## 4. 아키텍처 변경 이력

주요 구조적 전환 내역은 다음과 같습니다.

| 변경 항목               | 변경 전                      | 변경 후                              | 변경 이유 및 영향도                                                                                                     |
| ----------------------- | ---------------------------- | ------------------------------------ | ----------------------------------------------------------------------------------------------------------------------- |
| **Worker 구성**   | 단일 AI Worker               | GPU / CPU 분리 Worker                | **이유**: 컨테이너 간 리소스 경합 방지 `<br>`**영향**: GPU 메모리 분산 및 처리 응답성 극대화              |
| **LLM 호출 방식** | 동기식(Synchronous) API 호출 | Celery 비동기 처리                   | **이유**: 요청 대기 시간으로 인한 Time-out 방지 `<br>`**영향**: 응답 안정성 및 시스템 로드 감소 효과 확보 |
| **STT 처리**      | 서버 내 로컬 Whisper 혼용    | Client-Side Audio / Celery 원격 처리 | **이유**: 실시간성 보강 및 서버 부하 이전 `<br>`**영향**: 발화 즉시 텍스트화 달성 및 2초 이내 변환 완성   |
| **DB 운영**       | 일반 RDBMS + 별도 Vector DB  | PostgreSQL + pgvector 통합           | **이유**: 아키텍처 복잡도 축소 방안 `<br>`**영향**: 트랜잭션 관리와 RAG 파이프라인의 통합으로 정합성 향상 |
| **예외 처리 구조** | AI 타임아웃/에러 시 무한 대기 | 3회 Retry 초과 시 자동 폴백(Fallback) | **이유**: LLM 응답 실패로 인한 클라이언트 동맥경화 방지 `<br>`**영향**: 예외 상황에서도 끊김 없는 면접 진행 보장 |

---

## 5. 기술 이슈 및 리스크 대응

과정 중 직면했던 주요 엔지니어링 병목과 해결 기법을 요약합니다.
1. **PostgreSQL 볼륨 마운트 에러**
   - **발생 문제**: DB 엔진을 PostgreSQL v18로 업그레이드한 직후, 기존 `pg17`에서 할당되던 `/var/lib/postgresql/data` 디렉토리 경로 스펙이 변경되며 컨테이너 구동(Init)이 크래시(Crash)되는 현상 발생.
   - **해결 방법**: 공식 도큐먼트 확인 후 `docker-compose.yml` 파일 내부의 볼륨 마운트 설정을 새 버전에 맞춘 `/var/lib/postgresql` 경로로 조정하고 기존 볼륨 캐시를 삭제 후 재생성함.
   - **현 상황**: 데이터 무결성을 유지하며 pgvector가 포함된 최신 버전의 DB 인스턴스가 5432 포트에서 안정적으로 구동 중임.

2. **Celery Task 모듈 참조 오류 (Namespace Isolation)**
   - **발생 문제**: 단일 모놀리식 구조에서 백엔드 컨테이너와 AI 워커(Celery) 컨테이너를 물리적으로 쪼개는 과정에서, 백엔드가 워커의 Task Class 코드를 직접 `import`하려다 패키지 참조 에러(ModuleNotFoundError) 발생.
   - **해결 방법**: 두 컨테이너 간의 하드 코딩 의존성을 완전히 디커플링하기 위해, Task의 고유 식별자(String)만을 Redis 브로커로 넘겨 호출하는 `celery_app.send_task("task_name")` 패턴으로 전체 비동기 라우터를 전면 리팩토링함.
   - **현 상황**: 컴포넌트 간 코드 참조 없이도 Redis를 매개로 초당 수십 건 이상의 비동기 Task가 유연하게 통신 및 큐 데이터 교환 중.

3. **Docker 분산 컨테이너 간 파일 볼륨 공유 부재**
   - **발생 문제**: 지원자가 Frontend-Backend 단을 통해 정상적으로 이력서(PDF)를 업로드했으나, 이를 넘겨받아 RAG 파싱을 수행해야 할 별도의 AI-Worker 컨테이너에서는 해당 파일 시스템 디렉토리에 접근하지 못해 파싱 오류 발생.
   - **해결 방법**: `docker-compose`의 Volume 바인딩 설정을 수정하여, 서버 호스트 시스템의 특정 디렉토리를 `backend-core`와 `ai-worker` 컨테이너 양쪽의 `/app/uploads` 공동 마운트 지점으로 설정해 읽기/쓰기 환경을 브릿지함.
   - **현 상황**: I/O 딜레이 및 복사 자원 낭비 없이, 업로드 즉시 AI가 파싱 및 1024차원 벡터화 작업을 원활하게 수행 가능.

4. **비전 AI 모델의 연산 병목 현상 (CPU/Overload)**
   - **발생 문제**: Media-Server가 지원자의 캠 스트리밍 프레임을 무제한(30FPS 등)으로 모두 DeepFace 및 MediaPipe에 넘겨 분석하려 시도하면서, 서버 CPU 로드가 100%를 치고 컨테이너가 뻗어버리는 현상 발생.
   - **해결 방법**: 백그라운드 분석 Loop 체인에 5FPS(1초당 5장) 또는 2초당 1장 단위의 **강제 샘플링 타이머 레이트 제한(Rate Limit) 로직을 이식**하여 무의미한 프레임 연산을 쳐냄.
   - **현 상황**: 200ms 단위 실시간성을 일부 양보하는 대신 끊김 없는 화상 서버 및 CPU 안정성을 동시 확보함.

5. **AI 질문 생성 지연 무한 루프**
   - **발생 문제**: 간헐적으로 로컬 LLM(EXAONE) 엔진에 메모리 피크가 와서 생성이 지연되거나 먹통이 될 때, React 프론트엔드단이 2분 이상 무한 로딩 상태에 빠지며 면접이 완전히 중단되는 UI 동맥경화 발생.
   - **해결 방법**: Task Queue에서 180초 타임아웃 또는 3회 이상 Retry가 넘어가면 뻗어버리는 대신 기존 예외처리(Exception) 블록에서 강제로 **기본 폴백(Fallback) 답변**('[시스템 질문] ... 뛰어나신 역량은?')을 `db_session`에 Insert 하고 반환토록 방어 코드를 트리거함.
   - **현 상황**: 시스템 내부적으로 AI 에러가 발생해도, 지원자 입장에서는 지체 없이 곧바로 다음 예비 면접 질문을 받게 되어 사용자 경험(UX) 붕괴를 완전히 차단함.

6. **프론트엔드 API 키 탈취 위험 (보안 취약점)**
   - **발생 문제**: React 프론트엔드 코드(App.jsx) 상에 Deepgram STT 등 외부 유료 API Key가 평문 환경변수(`VITE_DEEPGRAM_API_KEY`)로 하드코딩되어 네트워크 탭 등을 통해 클라이언트에 그대로 유출될 위험 식별.
   - **해결 방법**: 백엔드 코어에 임시 토큰 발행 프록시 라우터(`/stt/token`)를 신설. 프론트엔드가 자체 JWT 인증을 거쳐 백엔드에 요청하면, 백엔드가 발급해준 일회용 단기 토큰만 받아 프론트엔드가 STT 서버통신을 하도록 아키텍처 개량.
   - **현 상황**: 최종 빌드된 웹페이지에서는 어떤 외부 자격의 Root Key도 역추적할 수 없는 완벽한 보안망 구축 완료.

7. **데이터베이스 드라이버 호환성 충돌**
   - **발생 문제**: 파이썬 환경의 Backend와 AI-Worker 컨테이너 간, 구형 `psycopg2-binary`와 비동기 전용인 `psycopg[binary]>=3.2.0` 드라이버 풀이 혼용 설치되며 쿼리 요청 시 접속이 간헐적으로 차단되거나 병목 속도 저하됨.
   - **해결 방법**: 두 컴포넌트 패키지의 추상화 드라이버 요건을 최신 기술인 `psycopg v3` 규격으로 강제 통일하여 덮어씌움 구성 적용.
   - **현 상황**: 모든 서비스 레이어에서 Connection Pool 이 균일하게 매니지먼트되며 DB 응답 속도가 최적화됨.

8. **브라우저 메인 스레드 점유 지연 (Audio Node)**
   - **발생 문제**: 오디오 캡처를 위해 초기 개발한 구형 `ScriptProcessorNode` 방식이 브라우저의 메인 JS 스레드를 점유해버리면서, 사용자의 UI 화면 렌더링이 뚝뚝 끊기고 음성 전송이 딜레이되는 현상 발생.
   - **해결 방법**: 브라우저의 백그라운드 스레드에서 오디오 PCM 렌더링과 버퍼링을 독립적으로 구동하는 최신 웹 스펙인 `AudioWorkletNode` 아키텍처로 컴포넌트 프로세서를 마이그레이션함.
   - **현 상황**: 브라우저 로딩 없이 오디오를 쾌적하게 수집하여 Deepgram 서버로 라이브 스트리밍 중.

9. **WebRTC 미디어 거부 예외 대처 (Fallback)**
   - **발생 문제**: 특정 지원자의 데스크톱 환경(웹캠 부재)이거나, 권한이 거부된 경우 비디오 스트림이 `null`로 반환되면서 연이은 WebRTC 연결 라인이 몽땅 크래시되는 Exception 발생.
   - **해결 방법**: 예외처리 `Catch` 구문에 로직을 짜넣어, 둘 중 비디오 권한 구득에 실패하더라도 오디오(마이크) 단일 스트림만 예비로 획득하여 면접 환경이 강제 종료되지 않고 유지되도록 하위 폴백(Fallback) 시나리오 구현.
   - **현 상황**: 화면이 안 나오더라도 음성만으로 질문/답변의 사이클이 정상 작동하여 테스트 탄력성이 극대화됨.

---

## 6. 성능 검증 결과

실제 온프레미스 인스턴스 구축 결과 달성한 주요 성능 스펙입니다.

1. **실시간성(WebRTC)**: P2P 환경 기준 미디어 응답 레이턴시 500ms 미만 유지 (UDP 50000 포트 트래버스 최적화).
2. **LLM 처리 속도(EXAONE 3.5)**: 꼬리질문 및 답변 종합 평가 요청 처리 시 Task 큐 딜레이 포함 API 평균 질문 생성 10초 이내 완료 달성.
3. **음성인식(STT) 속도**: 사용자 발화 종료(Silence) 감지 후 10초 이내 Text Transcript 변환 완료.
4. **시각 분석(Vision)**: 200ms 미만의 Latency로 얼굴 랜드마크 분석 및 감정(Dominant Emotion) 스코어 산출 달성.

---

## 7. 산출물 목록

진행 과정에서 다음과 같은 산출물을 도출하여 관리하고 있습니다.

1. `시스템_아키텍처_디자인(SAD).docx` (전반 시스템 개요 정의)
2. `SYSTEM_SPECIFICATION.md` (시스템 명세서)
3. `TROUBLESHOOTING.md` (기술 오류 및 해결 가이드)
4. `docker-compose.yml` (통합 인프라 배포 파일 최종 버전)
5. `QUALITY_INSPECTION_REPORT.md` (품질 검사 및 보안 개선 레거시 리포트)
6. `.agent/QUALITY_REPORT_*.md` (A.I 기반 최신 시스템 아키텍처 정밀 분석 및 보안/구조 종합 점검 리포트)
7. `.agent/workflows/quality-fixes.md` (품질 검사 기반 발견 문제 수정 및 시스템 보안 하드닝 워크플로우 가이드)
8. `.agent/QUALITY_CHECK_FINAL.md` (로컬 인프라/컨테이너 구동 상태 최종 검증 상세 보고서)
9. `.agent/DEPENDENCY_CHECK_REPORT.md` (MSA 컴포넌트 간 패키지 의존성 및 라이브러리 버전 일치 추적 보고서)

---

## 8. 최종 확정 아키텍처

거듭된 리팩토링을 통해 확정된 최종 컴포넌트 간 통합 배치도입니다.

- **최종 인프라 구조**: Docker Compose 기반 가상 멀티 컨테이너 네트워크(DNS).
  - Web Server: React Client (Node.js)
  - Core API API: FastAPI (Python)
  - RTC Streaming: Media-Server (aiortc 기반 P2P Relay)
  - ML Operations: AI Worker (CPU와 GPU로 이원화된 Task 큐 처리반)
  - Data Layer: PostgreSQL, Redis 브로커.
- **최종 AI 모델 구동 현황**:
  - LLM: `EXAONE-3.5-7.8B-Instruct (GGUF)` 단일 모델로 사용자 답변 꼬리질문 생성, 이력서 스캔, 문장 요약, 최종 종합 평가 점수 부여 역할 완전 통합수행.
  - Vision/Face: `DeepFace`, `MediaPipe` 기반의 표정 분석. 
- **데이터 구조 통합 완료**: `pgvector` 플러그인 설정이 완료된 RDBMS 모델 생성기. 사용자 메타데이터, 파싱된 이력서의 1024차원 벡터 수, 그리고 사전에 정의된 회사 인재상 객체들이 Foreign Key를 매개로 견고하게 연계 됨.

최종 확정된 이 구조는 On-premise 환경 기준 수십 명 규모의 동시 면접 시나리오를 효과적으로 방어하며, 안정적으로 실서비스 투입 가능한 검증 단계에 도달했습니다.

---

## 9. 운영 준비 상태

본 시스템은 실제 운영 투입을 위한 기반이 갖춰져 있습니다.

- **권한 철저 분리**: JWT Stateless Token 및 API EndPoint 마다 `Candidate / Recruiter` 별 RBAC (Role-Based Access Control) 권한 제어 적용 완료.
- **민감정보 보호**: 외부 통신망(DB, Broker) 외부 공개 차단 설정 및 환경변수 주입을 통해 컨테이너 레벨 보안 정책수립.
- **장애 모니터링 체계 준비**: Docker log 및 Celery Task 추적 로그 확인 환경을 제공하며, 장애 발생 시 원인을 빠르게 트래킹할 수 있는 기초 환경(Troubleshooting Guide) 구성.

---

## 10. 향후 고도화 계획

- **모델 경량화 전략(Quantization)**: VRAM 비용 절감 및 속도 개선을 위해 EXAONE의 GGUF 기반 양자화 추론기 고도화 및 최적화 추진.
- **분산 스케일아웃 확장(Scale-out)**: 동시 접속 증가 대응을 위한 Celery 워커 클러스터 물리 확충 방안 모색 및 대규모 Kafka 브로커 전환 검토.
- **서비스 분리 및 고가용성 확보(Docker Swarm)**: 현재의 단일 노드 Compose 환경에서 벗어나 Frontend, Backend, DB 노드를 물리적으로 분리하고, Docker Swarm 기반의 오케스트레이션을 구축하여 부하 분산 및 고가용성(HA) 환경 확보 예정.
- **테스트 파이프라인 및 CI/CD 전면 도입**: 수동 품질 검사 체계를 보완하여, 백엔드 API(Pytest)와 프론트엔드 E2E 모듈(Jest)의 통합 테스트 커버리지를 확보하고, GitHub Actions 환경과 통합 파이프라인 구축 고려.
- **운영 트래픽 보안(Rate Limiting)**: 무차별 API 조회를 방지하기 위한 엔드포인트 요청 제한 장벽 도입.
- **LLM 품질 분석 도구 연동**: LangSmith 등 Observability 도구 연동을 통한 면접 응답 품질(QnA) 트레이싱 대시보드 구조화 진행.
- **폴백(Fallback) 질문 생성 로직 고도화(Retriever 도입)**: 현재 고정된 질문으로 응답하는 3회 에러 초과 시의 폴백 로직을 발전시켜, 데이터베이스(pgvector) 내 기존에 생성/저장된 **유사 직무의 우수 대화(질문) 데이터셋을 Retriever로 검색하여 대치하는 구조**로 개선함으로써 면접 흐름의 단절과 문맥 붕괴를 최소화.
