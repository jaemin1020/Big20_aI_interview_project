# ğŸ¯ PDF ì´ë ¥ì„œ ì„ë² ë”© ì‹œìŠ¤í…œ êµ¬í˜„ ì™„ë£Œ ë³´ê³ ì„œ

> **ì‘ì„±ì¼**: 2026-02-04
> **ìƒíƒœ**: âœ… **Phase 1 ì™„ë£Œ (ì„ë² ë”© ìƒì„±ê¹Œì§€)**
> **ëª©ì **: PDF ì´ë ¥ì„œ ì—…ë¡œë“œ ë° KURE-v1 ëª¨ë¸ì„ ì´ìš©í•œ ì„ë² ë”© ê¸°ëŠ¥ êµ¬í˜„

---

## ğŸ“Š êµ¬í˜„ ì™„ë£Œ í˜„í™©

### âœ… **Phase 1: ì„ë² ë”© ìƒì„± ì‹œìŠ¤í…œ (ì™„ë£Œ)**

#### **1. ë°ì´í„°ë² ì´ìŠ¤ ìŠ¤í‚¤ë§ˆ**

**íŒŒì¼**: `backend-core/models.py`

##### Resume í…Œì´ë¸”

```python
class Resume(SQLModel, table=True):
    __tablename__ = "resumes"
  
    id: Optional[int] = Field(default=None, primary_key=True)
    candidate_id: int = Field(foreign_key="users.id", index=True)
  
    # íŒŒì¼ ì •ë³´
    file_name: str
    file_path: str
    file_size: int
  
    # ì²˜ë¦¬ ìƒíƒœ
    processing_status: str = Field(default="pending")  # pending, processing, completed, failed
    uploaded_at: datetime = Field(default_factory=datetime.utcnow)
    processed_at: Optional[datetime] = None
  
    # êµ¬ì¡°í™”ëœ ë°ì´í„° (JSON)
    structured_data: Optional[dict] = Field(default=None, sa_column=Column(JSON))
  
    # Relationships
    candidate: User = Relationship(back_populates="resumes")
    chunks: List["ResumeChunk"] = Relationship(back_populates="resume")
```

##### ResumeChunk í…Œì´ë¸” (RAG êµ¬ì¡°)

```python
class ResumeChunk(SQLModel, table=True):
    """ì´ë ¥ì„œ ì²­í¬ í…Œì´ë¸” - RAG ê¸°ë°˜ ì •ë°€ ê²€ìƒ‰ìš©"""
    __tablename__ = "resume_chunks"
  
    id: Optional[int] = Field(default=None, primary_key=True)
    resume_id: int = Field(foreign_key="resumes.id", index=True)
  
    # ì²­í¬ ë‚´ìš©
    content: str = Field(description="ì˜ê²Œ ìª¼ê°œì§„ ì´ë ¥ì„œ í…ìŠ¤íŠ¸ ì¡°ê°")
    chunk_index: int = Field(description="ì²­í¬ ìˆœì„œ (0ë¶€í„° ì‹œì‘)")
  
    # ë²¡í„° ì„ë² ë”© (1024ì°¨ì› - KURE-v1)
    embedding: Any = Field(
        default=None,
        sa_column=Column(Vector(1024)),
        description="ì²­í¬ì˜ ë²¡í„° ì„ë² ë”© (ìœ ì‚¬ë„ ê²€ìƒ‰ìš©)"
    )
  
    created_at: datetime = Field(default_factory=datetime.utcnow)
  
    # Relationship
    resume: Resume = Relationship(back_populates="chunks")
```

**íŠ¹ì§•**:

- âœ… 1:N ê´€ê³„ (Resume â†’ ResumeChunk)
- âœ… ì²­í¬ë³„ ì„ë² ë”© ì €ì¥ (1024ì°¨ì›)
- âœ… pgvector í™œìš© ê°€ëŠ¥

---

#### **2. ë°±ì—”ë“œ API**

**íŒŒì¼**: `backend-core/main.py`

##### í…ŒìŠ¤íŠ¸ ì—…ë¡œë“œ ì—”ë“œí¬ì¸íŠ¸

```python
@app.post("/test/upload-resume")
async def test_upload_resume(
    file: UploadFile = File(...),
    db: Session = Depends(get_session)
):
    """
    í…ŒìŠ¤íŠ¸ìš© ì´ë ¥ì„œ ì—…ë¡œë“œ (ì¸ì¦ ë¶ˆí•„ìš”)
    - ìë™ìœ¼ë¡œ test_user ìƒì„±
    - PDF íŒŒì¼ ì €ì¥
    - Celery task ì‹¤í–‰
    """
```

##### í…ŒìŠ¤íŠ¸ ìƒíƒœ ì¡°íšŒ ì—”ë“œí¬ì¸íŠ¸

```python
@app.get("/test/resumes/{resume_id}")
async def test_get_resume_status(
    resume_id: int,
    db: Session = Depends(get_session)
):
    """
    ì´ë ¥ì„œ ì²˜ë¦¬ ìƒíƒœ ì¡°íšŒ (ì¸ì¦ ë¶ˆí•„ìš”)
    - processing_status í™•ì¸
    - chunks_count í™•ì¸
    - embedding ì •ë³´ í™•ì¸
    """
```

**ì‘ë‹µ ì˜ˆì‹œ**:

```json
{
  "resume_id": 9,
  "file_name": "ì´ë ¥ì„œ.pdf",
  "processing_status": "completed",
  "chunks_count": 1,
  "chunks_info": [
    {
      "chunk_index": 0,
      "content_length": 1121,
      "has_embedding": true,
      "embedding_dimension": 1024,
      "content_preview": "ê¹€ì§€ì›ì ë„ì‹œ ë„ë¡œëª… 123..."
    }
  ]
}
```

---

#### **3. Celery Task (ë¹„ë™ê¸° ì²˜ë¦¬)**

**íŒŒì¼**: `ai-worker/tasks/resume_parser.py`

##### Task ë“±ë¡

```python
@shared_task(bind=True, name="parse_resume_pdf")
def parse_resume_pdf_task(self, resume_id: int, file_path: str):
    """
    ì´ë ¥ì„œ PDF íŒŒì‹± ë° ì„ë² ë”© ìƒì„± Task
  
    ì²˜ë¦¬ ë‹¨ê³„:
    1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
    2. í…ìŠ¤íŠ¸ ì •ì œ
    3. êµ¬ì¡°í™” (ì´ë¦„, ê²½ë ¥, í•™ë ¥ ë“±)
    4. LangChain ì²­í‚¹ (chunk_size=1500, overlap=300)
    5. ê° ì²­í¬ ì„ë² ë”© ìƒì„± (KURE-v1, 1024ì°¨ì›)
    6. ResumeChunk í…Œì´ë¸”ì— ì €ì¥
    7. Resume ìƒíƒœ ì—…ë°ì´íŠ¸ (completed)
    """
```

**ì²­í‚¹ ì„¤ì •**:

```python
text_splitter = RecursiveCharacterTextSplitter(
    chunk_size=1500,        # ì•½ 1500ì
    chunk_overlap=300,      # 20% ì¤‘ì²©ìœ¼ë¡œ ë¬¸ë§¥ ìœ ì§€
    length_function=len,
    separators=["\n\n", "\n", " ", ""]
)
```

---

#### **4. PDF íŒŒì„œ**

**íŒŒì¼**: `ai-worker/utils/pdf_parser.py`

```python
class ResumePDFParser:
    @staticmethod
    def extract_text(file_path: str) -> str:
        """
        PDFì—ì„œ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        - 1ì°¨: pdfplumber (ë ˆì´ì•„ì›ƒ ìœ ì§€)
        - 2ì°¨: PyPDF2 (fallback)
        """
```

---

#### **5. ì„ë² ë”© ìƒì„±ê¸°**

**íŒŒì¼**: `ai-worker/utils/vector_utils.py`

```python
class EmbeddingGenerator:
    def __init__(self):
        self.model = SentenceTransformer("nlpai-lab/KURE-v1")
  
    def encode_passage(self, text: str) -> List[float]:
        """
        í…ìŠ¤íŠ¸ë¥¼ 1024ì°¨ì› ë²¡í„°ë¡œ ë³€í™˜
        - ëª¨ë¸: KURE-v1 (í•œêµ­ì–´ ìµœì í™”)
        - ì¶œë ¥: 1024ì°¨ì› ë²¡í„°
        - ìµœëŒ€ ê¸¸ì´: 8192 í† í°
        """
```

**KURE-v1 ëª¨ë¸ ì •ë³´**:

- **ì¶œë ¥ ì°¨ì›**: 1024
- **ê¸°ë°˜ ëª¨ë¸**: BAAI/bge-m3
- **íŠ¹í™”**: í•œêµ­ì–´ ë¬¸ì„œ ê²€ìƒ‰
- **ìµœëŒ€ ì‹œí€€ìŠ¤**: 8192 í† í°

---

#### **6. ì´ë ¥ì„œ êµ¬ì¡°í™”**

**íŒŒì¼**: `ai-worker/utils/resume_structurer.py`

```python
class ResumeStructurer:
    @staticmethod
    def structure_with_rules(text: str) -> dict:
        """
        ê·œì¹™ ê¸°ë°˜ ì´ë ¥ì„œ ì •ë³´ ì¶”ì¶œ
        - personal_info: ì´ë¦„, ì´ë©”ì¼, ì „í™”ë²ˆí˜¸, ì£¼ì†Œ
        - experience: ê²½ë ¥
        - education: í•™ë ¥
        - skills: í”„ë¡œê·¸ë˜ë° ì–¸ì–´, í”„ë ˆì„ì›Œí¬, ë„êµ¬
        - projects: í”„ë¡œì íŠ¸
        - certifications: ìê²©ì¦
        """
```

---

## ğŸ”„ ì „ì²´ ì²˜ë¦¬ í”Œë¡œìš°

```mermaid
graph TD
    A[ì‚¬ìš©ì PDF ì—…ë¡œë“œ] -->|POST /test/upload-resume| B[Backend ì²˜ë¦¬]
    B --> C[íŒŒì¼ ì €ì¥<br/>./uploads/resumes/]
    B --> D[Resume ë ˆì½”ë“œ ìƒì„±<br/>status: pending]
    D --> E[Celery Task ì „ì†¡<br/>parse_resume_pdf]
    E --> F[Celery Worker ë¹„ë™ê¸° ì²˜ë¦¬]
    F --> G[1. PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ<br/>pdfplumber/PyPDF2]
    G --> H[2. í…ìŠ¤íŠ¸ ì •ì œ]
    H --> I[3. êµ¬ì¡°í™”<br/>ì´ë¦„, ê²½ë ¥, í•™ë ¥, ìŠ¤í‚¬]
    I --> J[4. LangChain ì²­í‚¹<br/>chunk_size=1500, overlap=300]
    J --> K[5. ê° ì²­í¬ ì„ë² ë”©<br/>KURE-v1, 1024ì°¨ì›]
    K --> L[6. ResumeChunk í…Œì´ë¸”ì— ì €ì¥<br/>chunkë³„ ì„ë² ë”©]
    L --> M[7. Resume ìƒíƒœ ì—…ë°ì´íŠ¸<br/>status: completed]
    M --> N[Frontend ìƒíƒœ í™•ì¸<br/>GET /test/resumes/:id]
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ê²°ê³¼

### **í…ŒìŠ¤íŠ¸ ì¼€ì´ìŠ¤ #1**

**ì…ë ¥**:

- íŒŒì¼: `ì´ë ¥ì„œ.pdf` (134,131 bytes)
- ë‚´ìš©: ë°±ì—”ë“œ ê°œë°œì ì´ë ¥ì„œ

**ê²°ê³¼**:

```json
{
  "resume_id": 9,
  "file_name": "ì´ë ¥ì„œ (1).pdf",
  "file_size": 134131,
  "processing_status": "completed",
  "uploaded_at": "2026-02-04T06:59:04.841865",
  "processed_at": "2026-02-04T06:59:05.568266",
  "chunks_count": 1,
  "chunks_info": [
    {
      "chunk_index": 0,
      "content_length": 1121,
      "has_embedding": true,
      "embedding_dimension": 1024,
      "content_preview": "ê¹€ì§€ì›ì ë„ì‹œ ë„ë¡œëª… 123, ë„ì‹œ, ìœ„ì¹˜ 12345..."
    }
  ],
  "structured_data": {
    "skills": {
      "programming_languages": ["Python"]
    },
    "personal_info": {
      "email": "no_reply@example.com",
      "phone": "+82 000-0000"
    }
  }
}
```

**ì²˜ë¦¬ ì‹œê°„**: ì•½ 0.7ì´ˆ

**ê²€ì¦ í•­ëª©**:

- âœ… PDF ì—…ë¡œë“œ ì„±ê³µ
- âœ… í…ìŠ¤íŠ¸ ì¶”ì¶œ ì„±ê³µ (1,121ì)
- âœ… ì²­í‚¹ ì™„ë£Œ (1ê°œ ì²­í¬)
- âœ… **ì„ë² ë”© ìƒì„± ì„±ê³µ (1024ì°¨ì›)**
- âœ… ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì™„ë£Œ
- âœ… êµ¬ì¡°í™”ëœ ë°ì´í„° ì¶”ì¶œ (ë¶€ë¶„ì )

---

## ğŸ“¦ Docker êµ¬ì„±

### **docker-compose.yml ìˆ˜ì • ì‚¬í•­**

```yaml
ai-worker:
  volumes:
    - ./ai-worker:/app
    - ./ai-worker/models:/app/models
    - ./backend-core:/backend-core
    - ./backend-core/uploads:/app/uploads  # âœ… ì¶”ê°€: íŒŒì¼ ê³µìœ 
```

**ì´ìœ **: ai-workerê°€ backendì—ì„œ ì—…ë¡œë“œí•œ PDF íŒŒì¼ì— ì ‘ê·¼í•  ìˆ˜ ìˆë„ë¡ ë³¼ë¥¨ ê³µìœ 

---

## ğŸ”§ ì£¼ìš” ìˆ˜ì • ì‚¬í•­

### **1. LangChain import ê²½ë¡œ ìˆ˜ì •**

**íŒŒì¼**: `ai-worker/tasks/resume_parser.py`

```python
# ìˆ˜ì • ì „
from langchain.text_splitter import RecursiveCharacterTextSplitter  # âŒ

# ìˆ˜ì • í›„
from langchain_text_splitters import RecursiveCharacterTextSplitter  # âœ…
```

**ì´ìœ **: LangChain ìµœì‹  ë²„ì „ì—ì„œ import ê²½ë¡œ ë³€ê²½

---

### **2. Celery Task ì´ë¦„ ìˆ˜ì •**

**íŒŒì¼**: `backend-core/main.py`

```python
# ìˆ˜ì • ì „
task = celery_app.send_task(
    "tasks.resume_parser.parse_resume_pdf_task",  # âŒ
    args=[resume.id, str(file_path)]
)

# ìˆ˜ì • í›„
task = celery_app.send_task(
    "parse_resume_pdf",  # âœ… Workerì— ë“±ë¡ëœ ì‹¤ì œ task ì´ë¦„
    args=[resume.id, str(file_path)]
)
```

**ì´ìœ **: Workerì— ë“±ë¡ëœ task ì´ë¦„ê³¼ ì¼ì¹˜ì‹œì¼œì•¼ í•¨

---

### **3. numpy array ì²´í¬ ë¡œì§ ìˆ˜ì •**

**íŒŒì¼**: `backend-core/main.py`

```python
# ìˆ˜ì • ì „
"embedding_dimension": len(chunk.embedding) if chunk.embedding else 0  # âŒ

# ìˆ˜ì • í›„
"embedding_dimension": len(chunk.embedding) if chunk.embedding is not None else 0  # âœ…
```

**ì´ìœ **: numpy arrayëŠ” `if array` ì²´í¬ ì‹œ ambiguous error ë°œìƒ

---

### **4. í…ŒìŠ¤íŠ¸ ì‚¬ìš©ì ìë™ ìƒì„±**

**íŒŒì¼**: `backend-core/main.py`

```python
# test_userê°€ ì—†ìœ¼ë©´ ìë™ ìƒì„±
test_user = session.exec(
    select(User).where(User.username == "test_user")
).first()

if not test_user:
    test_user = User(
        username="test_user",
        email="test@example.com",
        password_hash="test_hash",
        full_name="Test User",
        role=UserRole.CANDIDATE
    )
    session.add(test_user)
    session.commit()
    session.refresh(test_user)
```

**ì´ìœ **: ì™¸ë˜í‚¤ ì œì•½ ì¡°ê±´ í•´ê²° (candidate_id í•„ìˆ˜)

---

## â³ Phase 2: ë²¡í„° ê²€ìƒ‰ (ë‹¤ìŒ ë‹¨ê³„)

### **êµ¬í˜„ ì˜ˆì • ê¸°ëŠ¥**

#### **1. ì´ë ¥ì„œ ê²€ìƒ‰ API**

```python
@app.post("/resumes/search")
async def search_resumes(
    query: str,
    top_k: int = 10,
    db: Session = Depends(get_session)
):
    """
    ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì´ë ¥ì„œ ê²€ìƒ‰
    - ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    - pgvectorë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰
    - ìƒìœ„ Kê°œ ì´ë ¥ì„œ ë°˜í™˜
    """
```

#### **2. ë©´ì ‘ ì§ˆë¬¸ ìƒì„±**

```python
@app.post("/interviews/{interview_id}/generate-questions")
async def generate_questions(
    interview_id: int,
    resume_id: int,
    question_count: int = 5
):
    """
    ì´ë ¥ì„œ ë‚´ìš© ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
    - ì´ë ¥ì„œ ì²­í¬ë¥¼ ì»¨í…ìŠ¤íŠ¸ë¡œ LLMì— ì „ë‹¬
    - ê°œì¸í™”ëœ ì§ˆë¬¸ ìƒì„±
    """
```

#### **3. ë‹µë³€ í‰ê°€ (RAG)**

```python
@app.post("/interviews/{interview_id}/evaluate-answer")
async def evaluate_answer(
    interview_id: int,
    question: str,
    answer: str,
    resume_id: int
):
    """
    ë‹µë³€ì„ ì´ë ¥ì„œ ë‚´ìš©ê³¼ ë¹„êµ
    - ë‹µë³€ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    - ì´ë ¥ì„œ ì²­í¬ì™€ ìœ ì‚¬ë„ ë¹„êµ
    - ì¼ê´€ì„± ì ìˆ˜ ì‚°ì¶œ
    """
```

---

## ğŸ“š ê¸°ìˆ  ìŠ¤íƒ

### **Backend**

- FastAPI
- SQLModel
- PostgreSQL 18 + pgvector
- Celery + Redis

### **AI/ML**

- KURE-v1 (1024ì°¨ì› ì„ë² ë”©)
- LangChain (í…ìŠ¤íŠ¸ ì²­í‚¹)
- Sentence Transformers
- pdfplumber / PyPDF2

### **Infrastructure**

- Docker Compose
- NVIDIA GPU (ì„ íƒ)

---

## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### **Phase 1: ì„ë² ë”© ìƒì„±**

- [X] Resume í…Œì´ë¸” ì„¤ê³„
- [X] ResumeChunk í…Œì´ë¸” ì„¤ê³„ (RAG)
- [X] PDF ì—…ë¡œë“œ API
- [X] ìƒíƒœ ì¡°íšŒ API
- [X] Celery Task êµ¬í˜„
- [X] PDF í…ìŠ¤íŠ¸ ì¶”ì¶œ
- [X] LangChain ì²­í‚¹
- [X] KURE-v1 ì„ë² ë”© ìƒì„±
- [X] ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥
- [X] í†µí•© í…ŒìŠ¤íŠ¸ ì„±ê³µ

### **Phase 2: ë²¡í„° ê²€ìƒ‰ (ì˜ˆì •)**

- [ ] ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ API
- [ ] ì´ë ¥ì„œ ê¸°ë°˜ ì§ˆë¬¸ ìƒì„±
- [ ] ë‹µë³€ í‰ê°€ (RAG)
- [ ] ì‹¤ì‹œê°„ STT/TTS
- [ ] ê°ì • ë¶„ì„
- [ ] ìµœì¢… í‰ê°€ ë¦¬í¬íŠ¸

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

1. **ìë™í™”ëœ ì´ë ¥ì„œ ì²˜ë¦¬**

   - PDF ì—…ë¡œë“œë§Œìœ¼ë¡œ ìë™ íŒŒì‹± ë° ì„ë² ë”© ìƒì„±
   - ë¹„ë™ê¸° ì²˜ë¦¬ë¡œ ì‚¬ìš©ì ëŒ€ê¸° ì‹œê°„ ìµœì†Œí™”
2. **í•œêµ­ì–´ ìµœì í™”**

   - KURE-v1 ëª¨ë¸ë¡œ í•œêµ­ì–´ ê²€ìƒ‰ ì„±ëŠ¥ ê·¹ëŒ€í™”
   - 8192 í† í°ê¹Œì§€ ì§€ì›
3. **RAG ê¸°ë°˜ ì •ë°€ ê²€ìƒ‰**

   - ì²­í¬ ë‹¨ìœ„ ë¶„í• ë¡œ ì •í™•í•œ ê²€ìƒ‰
   - chunk_overlapìœ¼ë¡œ ë¬¸ë§¥ ìœ ì§€
4. **í™•ì¥ ê°€ëŠ¥í•œ êµ¬ì¡°**

   - ì´ë ¥ì„œ-ì§ˆë¬¸ ë§¤ì¹­
   - ì´ë ¥ì„œ-íšŒì‚¬ ì í•©ë„ ë¶„ì„
   - ìœ ì‚¬ ì§€ì›ì ê²€ìƒ‰

---

**ì‘ì„±ì**: AI Assistant
**ìµœì¢… ìˆ˜ì •**: 2026-02-04
**ìƒíƒœ**: âœ… Phase 1 ì™„ë£Œ
