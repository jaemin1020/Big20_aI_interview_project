# ğŸ” Phase 2: ë²¡í„° ê²€ìƒ‰ API êµ¬í˜„ ì„¤ê³„ì„œ

> **ì‘ì„±ì¼**: 2026-02-04
> **ìƒíƒœ**: ğŸ“‹ **ì„¤ê³„ ë‹¨ê³„**
> **ëª©ì **: pgvectorë¥¼ í™œìš©í•œ ì´ë ¥ì„œ ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ API êµ¬í˜„

---

## ğŸ“Š Phase 2 ê°œìš”

### âœ… **Phase 1 ì™„ë£Œ ì‚¬í•­ (ì „ì œ ì¡°ê±´)**

- âœ… PDF ì—…ë¡œë“œ ë° í…ìŠ¤íŠ¸ ì¶”ì¶œ
- âœ… LangChain ì²­í‚¹ (chunk_size=1500, overlap=300)
- âœ… KURE-v1 ì„ë² ë”© ìƒì„± (1024ì°¨ì›)
- âœ… ResumeChunk í…Œì´ë¸”ì— ì„ë² ë”© ì €ì¥

### ğŸ¯ **Phase 2 ëª©í‘œ**

1. **ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰ API** - ì¿¼ë¦¬ë¡œ ê´€ë ¨ ì´ë ¥ì„œ ì°¾ê¸°
2. **ì´ë ¥ì„œ ìƒì„¸ ê²€ìƒ‰** - íŠ¹ì • ì„¹ì…˜(ê²½ë ¥, í”„ë¡œì íŠ¸ ë“±) ê²€ìƒ‰
3. **ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ** - íŠ¹ì • ì´ë ¥ì„œì™€ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì´ë ¥ì„œ ì°¾ê¸°

---

## ğŸ—ï¸ ì•„í‚¤í…ì²˜ ì„¤ê³„

### **ê²€ìƒ‰ í”Œë¡œìš°**

```mermaid
graph TD
    A[ì‚¬ìš©ì ê²€ìƒ‰ ì¿¼ë¦¬] -->|POST /resumes/search| B[Backend API]
    B --> C[ì¿¼ë¦¬ ì„ë² ë”© ìƒì„±<br/>KURE-v1, 1024ì°¨ì›]
    C --> D[pgvector ìœ ì‚¬ë„ ê²€ìƒ‰<br/>ì½”ì‚¬ì¸ ê±°ë¦¬ ê³„ì‚°]
    D --> E[ìƒìœ„ Kê°œ ì²­í¬ ì¡°íšŒ<br/>ORDER BY distance]
    E --> F[Resume ì •ë³´ ì¡°ì¸<br/>ì¤‘ë³µ ì œê±°]
    F --> G[ê²°ê³¼ ë°˜í™˜<br/>ìœ ì‚¬ë„ ì ìˆ˜ í¬í•¨]
```

---

## ğŸ“ êµ¬í˜„ ìƒì„¸

### **1. ë²¡í„° ê²€ìƒ‰ API**

#### **1-1. ê¸°ë³¸ ê²€ìƒ‰ ì—”ë“œí¬ì¸íŠ¸**

**íŒŒì¼**: `backend-core/main.py`

**ìœ„ì¹˜**: ê¸°ì¡´ `/resumes` ì—”ë“œí¬ì¸íŠ¸ ë‹¤ìŒ (ì•½ 580ì¤„ ì´í›„)

```python
from sqlalchemy import text
from typing import List, Optional

@app.post("/resumes/search")
async def search_resumes(
    query: str,
    top_k: int = 10,
    min_score: float = 0.5,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    ë²¡í„° ìœ ì‚¬ë„ ê¸°ë°˜ ì´ë ¥ì„œ ê²€ìƒ‰
  
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬ (ì˜ˆ: "Python ë°±ì—”ë“œ ê°œë°œì")
        top_k: ë°˜í™˜í•  ìµœëŒ€ ê²°ê³¼ ìˆ˜ (ê¸°ë³¸: 10)
        min_score: ìµœì†Œ ìœ ì‚¬ë„ ì ìˆ˜ (0~1, ê¸°ë³¸: 0.5)
      
    Returns:
        ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ (ìœ ì‚¬ë„ ìˆœ ì •ë ¬)
    """
    logger.info(f"ğŸ” Resume search: query='{query}', top_k={top_k}, user={current_user.id}")
  
    # 1. ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
    # Celery taskë¡œ ì „ì†¡í•˜ê±°ë‚˜ ì§ì ‘ í˜¸ì¶œ
    # ì—¬ê¸°ì„œëŠ” ê°„ë‹¨íˆ ì§ì ‘ í˜¸ì¶œ (ë™ê¸°)
    from ai_worker.utils.vector_utils import get_embedding_generator
  
    generator = get_embedding_generator()
    query_embedding = generator.encode_query(query)  # 1024ì°¨ì› ë²¡í„°
  
    # 2. pgvectorë¡œ ìœ ì‚¬ë„ ê²€ìƒ‰
    # <=> ì—°ì‚°ì: ì½”ì‚¬ì¸ ê±°ë¦¬ (0ì— ê°€ê¹Œìš¸ìˆ˜ë¡ ìœ ì‚¬)
    # 1 - ì½”ì‚¬ì¸ ê±°ë¦¬ = ì½”ì‚¬ì¸ ìœ ì‚¬ë„
    sql_query = text("""
        SELECT 
            rc.id as chunk_id,
            rc.resume_id,
            rc.content,
            rc.chunk_index,
            1 - (rc.embedding <=> :query_embedding) as similarity_score,
            r.file_name,
            r.candidate_id,
            u.full_name as candidate_name,
            u.email as candidate_email
        FROM resume_chunks rc
        JOIN resumes r ON rc.resume_id = r.id
        JOIN users u ON r.candidate_id = u.id
        WHERE 
            r.processing_status = 'completed'
            AND rc.embedding IS NOT NULL
            AND 1 - (rc.embedding <=> :query_embedding) >= :min_score
        ORDER BY rc.embedding <=> :query_embedding
        LIMIT :top_k
    """)
  
    result = db.execute(
        sql_query,
        {
            "query_embedding": query_embedding,
            "min_score": min_score,
            "top_k": top_k
        }
    )
  
    # 3. ê²°ê³¼ í¬ë§·íŒ…
    chunks = result.fetchall()
  
    # 4. Resumeë³„ë¡œ ê·¸ë£¹í™” (ì¤‘ë³µ ì œê±°)
    resume_map = {}
    for chunk in chunks:
        resume_id = chunk.resume_id
      
        if resume_id not in resume_map:
            resume_map[resume_id] = {
                "resume_id": resume_id,
                "file_name": chunk.file_name,
                "candidate_name": chunk.candidate_name,
                "candidate_email": chunk.candidate_email,
                "max_similarity": chunk.similarity_score,
                "matched_chunks": []
            }
      
        resume_map[resume_id]["matched_chunks"].append({
            "chunk_index": chunk.chunk_index,
            "content": chunk.content[:200] + "..." if len(chunk.content) > 200 else chunk.content,
            "similarity_score": float(chunk.similarity_score)
        })
      
        # ìµœê³  ìœ ì‚¬ë„ ì—…ë°ì´íŠ¸
        if chunk.similarity_score > resume_map[resume_id]["max_similarity"]:
            resume_map[resume_id]["max_similarity"] = chunk.similarity_score
  
    # 5. ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    results = sorted(
        resume_map.values(),
        key=lambda x: x["max_similarity"],
        reverse=True
    )
  
    logger.info(f"âœ… Found {len(results)} resumes matching query")
  
    return {
        "query": query,
        "total_results": len(results),
        "results": results
    }
```

**ì‘ë‹µ ì˜ˆì‹œ**:

```json
{
  "query": "Python ë°±ì—”ë“œ ê°œë°œì",
  "total_results": 3,
  "results": [
    {
      "resume_id": 10,
      "file_name": "ì´ë ¥ì„œ.pdf",
      "candidate_name": "ê¹€ì§€ì›",
      "candidate_email": "no_reply@example.com",
      "max_similarity": 0.87,
      "matched_chunks": [
        {
          "chunk_index": 0,
          "content": "Python, FastAPI, PostgreSQLì„ ì‚¬ìš©í•œ ë°±ì—”ë“œ ê°œë°œ ê²½í—˜...",
          "similarity_score": 0.87
        }
      ]
    }
  ]
}
```

---

#### **1-2. ì„ë² ë”© ìƒì„± í—¬í¼ í•¨ìˆ˜**

**ë¬¸ì œ**: Backendì—ì„œ ì§ì ‘ ì„ë² ë”© ëª¨ë¸ì„ ë¡œë“œí•˜ë©´ ë©”ëª¨ë¦¬ ë‚­ë¹„

**í•´ê²°**: ë‘ ê°€ì§€ ì˜µì…˜

##### **ì˜µì…˜ A: Celery Task ì‚¬ìš© (ì¶”ì²œ)**

**íŒŒì¼**: `ai-worker/tasks/search_helper.py` (ì‹ ê·œ ìƒì„±)

```python
"""
ê²€ìƒ‰ í—¬í¼ Task
"""
from celery import shared_task
from utils.vector_utils import get_embedding_generator
import logging

logger = logging.getLogger("SearchHelper")

@shared_task(bind=True, name="generate_query_embedding")
def generate_query_embedding_task(self, query: str):
    """
    ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
  
    Args:
        query: ê²€ìƒ‰ ì¿¼ë¦¬
      
    Returns:
        list: 1024ì°¨ì› ì„ë² ë”© ë²¡í„°
    """
    logger.info(f"ğŸ” Generating embedding for query: {query}")
  
    generator = get_embedding_generator()
    embedding = generator.encode_query(query)
  
    return embedding.tolist()
```

**Backendì—ì„œ í˜¸ì¶œ**:

```python
# backend-core/main.py
@app.post("/resumes/search")
async def search_resumes(query: str, ...):
    # Celery taskë¡œ ì„ë² ë”© ìƒì„±
    task = celery_app.send_task(
        "generate_query_embedding",
        args=[query]
    )
  
    # ê²°ê³¼ ëŒ€ê¸° (ë™ê¸°)
    query_embedding = task.get(timeout=10)  # ìµœëŒ€ 10ì´ˆ ëŒ€ê¸°
  
    # ì´í›„ ê²€ìƒ‰ ë¡œì§...
```

##### **ì˜µì…˜ B: Backendì— ê²½ëŸ‰ ì„ë² ë”© ì„œë¹„ìŠ¤ ì¶”ê°€**

**íŒŒì¼**: `backend-core/utils/embedding_client.py` (ì‹ ê·œ ìƒì„±)

```python
"""
ì„ë² ë”© ìƒì„± í´ë¼ì´ì–¸íŠ¸ (ai-workerì™€ í†µì‹ )
"""
import httpx
import logging

logger = logging.getLogger("EmbeddingClient")

class EmbeddingClient:
    """ai-workerì˜ ì„ë² ë”© ì„œë¹„ìŠ¤ì™€ í†µì‹ """
  
    def __init__(self, worker_url: str = "http://ai-worker:8080"):
        self.worker_url = worker_url
        self.client = httpx.AsyncClient(timeout=30.0)
  
    async def encode_query(self, text: str) -> list:
        """
        ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
      
        Args:
            text: ê²€ìƒ‰ ì¿¼ë¦¬
          
        Returns:
            list: 1024ì°¨ì› ë²¡í„°
        """
        try:
            response = await self.client.post(
                f"{self.worker_url}/embed",
                json={"text": text, "type": "query"}
            )
            response.raise_for_status()
            return response.json()["embedding"]
        except Exception as e:
            logger.error(f"Failed to generate embedding: {e}")
            raise
```

**ai-workerì— HTTP ì„œë²„ ì¶”ê°€**:

```python
# ai-worker/embedding_server.py (ì‹ ê·œ ìƒì„±)
from flask import Flask, request, jsonify
from utils.vector_utils import get_embedding_generator

app = Flask(__name__)
generator = get_embedding_generator()

@app.post("/embed")
def embed_text():
    """í…ìŠ¤íŠ¸ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜"""
    data = request.json
    text = data.get("text")
    embed_type = data.get("type", "passage")  # query or passage
  
    if embed_type == "query":
        embedding = generator.encode_query(text)
    else:
        embedding = generator.encode_passage(text)
  
    return jsonify({"embedding": embedding.tolist()})

if __name__ == "__main__":
    app.run(host="0.0.0.0", port=8080)
```

---

### **2. ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ API**

**íŒŒì¼**: `backend-core/main.py`

```python
@app.get("/resumes/{resume_id}/similar")
async def find_similar_resumes(
    resume_id: int,
    top_k: int = 5,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    íŠ¹ì • ì´ë ¥ì„œì™€ ìœ ì‚¬í•œ ë‹¤ë¥¸ ì´ë ¥ì„œ ì°¾ê¸°
  
    Args:
        resume_id: ê¸°ì¤€ ì´ë ¥ì„œ ID
        top_k: ë°˜í™˜í•  ìœ ì‚¬ ì´ë ¥ì„œ ìˆ˜
      
    Returns:
        ìœ ì‚¬í•œ ì´ë ¥ì„œ ë¦¬ìŠ¤íŠ¸
    """
    # 1. ê¸°ì¤€ ì´ë ¥ì„œ ì¡°íšŒ
    resume = db.get(Resume, resume_id)
    if not resume:
        raise HTTPException(status_code=404, detail="Resume not found")
  
    # 2. ê¸°ì¤€ ì´ë ¥ì„œì˜ ì²« ë²ˆì§¸ ì²­í¬ ì„ë² ë”© ê°€ì ¸ì˜¤ê¸°
    stmt = select(ResumeChunk).where(
        ResumeChunk.resume_id == resume_id,
        ResumeChunk.chunk_index == 0
    )
    base_chunk = db.exec(stmt).first()
  
    if not base_chunk or base_chunk.embedding is None:
        raise HTTPException(
            status_code=400,
            detail="Resume embedding not available"
        )
  
    # 3. ìœ ì‚¬í•œ ì²­í¬ ê²€ìƒ‰ (ìê¸° ìì‹  ì œì™¸)
    sql_query = text("""
        SELECT DISTINCT
            r.id as resume_id,
            r.file_name,
            r.candidate_id,
            u.full_name as candidate_name,
            1 - (rc.embedding <=> :base_embedding) as similarity_score
        FROM resume_chunks rc
        JOIN resumes r ON rc.resume_id = r.id
        JOIN users u ON r.candidate_id = u.id
        WHERE 
            r.id != :resume_id
            AND r.processing_status = 'completed'
            AND rc.embedding IS NOT NULL
        ORDER BY rc.embedding <=> :base_embedding
        LIMIT :top_k
    """)
  
    result = db.execute(
        sql_query,
        {
            "base_embedding": base_chunk.embedding,
            "resume_id": resume_id,
            "top_k": top_k
        }
    )
  
    similar_resumes = [
        {
            "resume_id": row.resume_id,
            "file_name": row.file_name,
            "candidate_name": row.candidate_name,
            "similarity_score": float(row.similarity_score)
        }
        for row in result.fetchall()
    ]
  
    return {
        "base_resume_id": resume_id,
        "base_file_name": resume.file_name,
        "similar_resumes": similar_resumes
    }
```

---

### **3. ê³ ê¸‰ ê²€ìƒ‰ í•„í„°**

**íŒŒì¼**: `backend-core/main.py`

```python
from pydantic import BaseModel
from typing import Optional

class ResumeSearchRequest(BaseModel):
    """ì´ë ¥ì„œ ê²€ìƒ‰ ìš”ì²­"""
    query: str
    top_k: int = 10
    min_score: float = 0.5
  
    # í•„í„° ì˜µì…˜
    skills: Optional[List[str]] = None  # ì˜ˆ: ["Python", "FastAPI"]
    min_experience_years: Optional[int] = None
    education_level: Optional[str] = None  # ì˜ˆ: "í•™ì‚¬", "ì„ì‚¬"

@app.post("/resumes/search/advanced")
async def advanced_search_resumes(
    request: ResumeSearchRequest,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    ê³ ê¸‰ í•„í„°ë¥¼ í¬í•¨í•œ ì´ë ¥ì„œ ê²€ìƒ‰
  
    - ë²¡í„° ìœ ì‚¬ë„ ê²€ìƒ‰
    - structured_data ê¸°ë°˜ í•„í„°ë§
    """
    # 1. ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ (ìœ„ì™€ ë™ì¼)
    # ...
  
    # 2. structured_data í•„í„° ì ìš©
    if request.skills:
        # JSON í•„ë“œ ì¿¼ë¦¬
        sql_query += """
            AND r.structured_data->'skills'->'programming_languages' ?| :skills
        """
  
    # 3. ê²°ê³¼ ë°˜í™˜
    # ...
```

---

## ğŸ”§ í•„ìš”í•œ ìˆ˜ì • ì‚¬í•­

### **1. vector_utils.py ìˆ˜ì •**

**íŒŒì¼**: `ai-worker/utils/vector_utils.py`

**ì¶”ê°€ ë©”ì„œë“œ**:

```python
class EmbeddingGenerator:
    # ê¸°ì¡´ ì½”ë“œ...
  
    def encode_query(self, text: str) -> np.ndarray:
        """
        ê²€ìƒ‰ ì¿¼ë¦¬ë¥¼ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜
      
        Note: KURE-v1ì€ queryì™€ passageë¥¼ êµ¬ë¶„í•˜ì§€ ì•Šìœ¼ë¯€ë¡œ
              encode_passageì™€ ë™ì¼í•˜ê²Œ ì²˜ë¦¬
      
        Args:
            text: ê²€ìƒ‰ ì¿¼ë¦¬
          
        Returns:
            np.ndarray: 1024ì°¨ì› ë²¡í„°
        """
        return self.encode_passage(text)
```

---

### **2. main.pyì— Celery ì„¤ì • ì¶”ê°€**

**íŒŒì¼**: `ai-worker/main.py`

```python
# ê¸°ì¡´ includeì— ì¶”ê°€
app = Celery(
    "ai_worker",
    broker="redis://redis:6379/0",
    backend="redis://redis:6379/0",
    include=[
        'tasks.evaluator',
        'tasks.vision',
        'tasks.question_generator',
        'tasks.resume_parser',
        'tasks.answer_collector',
        'tasks.search_helper'  # âœ… ì¶”ê°€
    ]
)
```

---

### **3. PostgreSQL ì¸ë±ìŠ¤ ìƒì„±**

**íŒŒì¼**: `infra/postgres/init.sql`

**ì¶”ê°€ ë‚´ìš©**:

```sql
-- ë²¡í„° ê²€ìƒ‰ ì„±ëŠ¥ í–¥ìƒì„ ìœ„í•œ ì¸ë±ìŠ¤
-- HNSW (Hierarchical Navigable Small World) ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS idx_resume_chunks_embedding 
ON resume_chunks 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);

-- ì¼ë°˜ ì¸ë±ìŠ¤
CREATE INDEX IF NOT EXISTS idx_resumes_status 
ON resumes(processing_status);

CREATE INDEX IF NOT EXISTS idx_resume_chunks_resume_id 
ON resume_chunks(resume_id);
```

**ì¸ë±ìŠ¤ ì„¤ëª…**:

- `hnsw`: ê³ ì† ê·¼ì‚¬ ìµœê·¼ì ‘ ì´ì›ƒ ê²€ìƒ‰
- `m = 16`: ê·¸ë˜í”„ ì—°ê²° ìˆ˜ (ë†’ì„ìˆ˜ë¡ ì •í™•í•˜ì§€ë§Œ ëŠë¦¼)
- `ef_construction = 64`: ì¸ë±ìŠ¤ êµ¬ì¶• ì‹œ íƒìƒ‰ ê¹Šì´

---

## ğŸ“Š ì„±ëŠ¥ ìµœì í™”

### **1. ì¸ë±ìŠ¤ ì „ëµ**

```sql
-- ë²¡í„° ì¸ë±ìŠ¤ íƒ€ì… ë¹„êµ
-- IVFFlat: ë¹ ë¥´ì§€ë§Œ ëœ ì •í™•
CREATE INDEX idx_embedding_ivfflat 
ON resume_chunks 
USING ivfflat (embedding vector_cosine_ops)
WITH (lists = 100);

-- HNSW: ëŠë¦¬ì§€ë§Œ ë” ì •í™• (ì¶”ì²œ)
CREATE INDEX idx_embedding_hnsw 
ON resume_chunks 
USING hnsw (embedding vector_cosine_ops)
WITH (m = 16, ef_construction = 64);
```

### **2. ì¿¼ë¦¬ ìµœì í™”**

```python
# ìºì‹± ì „ëµ
from functools import lru_cache

@lru_cache(maxsize=100)
def get_cached_embedding(query: str) -> list:
    """ìì£¼ ì‚¬ìš©ë˜ëŠ” ì¿¼ë¦¬ëŠ” ìºì‹±"""
    generator = get_embedding_generator()
    return generator.encode_query(query).tolist()
```

### **3. ë°°ì¹˜ ê²€ìƒ‰**

```python
@app.post("/resumes/search/batch")
async def batch_search_resumes(
    queries: List[str],
    top_k: int = 10,
    db: Session = Depends(get_session)
):
    """
    ì—¬ëŸ¬ ì¿¼ë¦¬ë¥¼ í•œ ë²ˆì— ê²€ìƒ‰
    - ì„ë² ë”© ìƒì„±ì„ ë°°ì¹˜ë¡œ ì²˜ë¦¬
    - DB ì¿¼ë¦¬ ìµœì í™”
    """
    # ëª¨ë“  ì¿¼ë¦¬ë¥¼ í•œ ë²ˆì— ì„ë² ë”©
    generator = get_embedding_generator()
    embeddings = [generator.encode_query(q) for q in queries]
  
    # ë³‘ë ¬ ê²€ìƒ‰
    results = []
    for query, embedding in zip(queries, embeddings):
        # ê²€ìƒ‰ ë¡œì§...
        pass
  
    return results
```

---

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### **í…ŒìŠ¤íŠ¸ 1: ê¸°ë³¸ ê²€ìƒ‰**

```bash
curl -X POST "http://localhost:8000/resumes/search" \
  -H "Content-Type: application/json" \
  -H "Authorization: Bearer $TOKEN" \
  -d '{
    "query": "Python ë°±ì—”ë“œ ê°œë°œì",
    "top_k": 5,
    "min_score": 0.6
  }'
```

**ê¸°ëŒ€ ê²°ê³¼**:

- 200 OK
- Python ê´€ë ¨ ì´ë ¥ì„œ ë°˜í™˜
- ìœ ì‚¬ë„ ì ìˆ˜ 0.6 ì´ìƒ

---

### **í…ŒìŠ¤íŠ¸ 2: ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ**

```bash
curl -X GET "http://localhost:8000/resumes/10/similar?top_k=3" \
  -H "Authorization: Bearer $TOKEN"
```

**ê¸°ëŒ€ ê²°ê³¼**:

- 200 OK
- resume_id=10ê³¼ ìœ ì‚¬í•œ 3ê°œ ì´ë ¥ì„œ ë°˜í™˜

---

### **í…ŒìŠ¤íŠ¸ 3: ì„±ëŠ¥ í…ŒìŠ¤íŠ¸**

```python
import time

# 100ê°œ ì¿¼ë¦¬ ê²€ìƒ‰ ì‹œê°„ ì¸¡ì •
queries = [f"Python ê°œë°œì {i}" for i in range(100)]

start = time.time()
for query in queries:
    response = requests.post(
        "http://localhost:8000/resumes/search",
        json={"query": query, "top_k": 10}
    )
end = time.time()

print(f"í‰ê·  ê²€ìƒ‰ ì‹œê°„: {(end - start) / 100:.3f}ì´ˆ")
```

**ëª©í‘œ**:

- í‰ê·  ê²€ìƒ‰ ì‹œê°„ < 0.5ì´ˆ
- ì¸ë±ìŠ¤ ì‚¬ìš© ì‹œ < 0.1ì´ˆ

---

## ğŸ“¦ í•„ìš”í•œ íŒ¨í‚¤ì§€

### **backend-core/requirements.txt**

```txt
# ê¸°ì¡´ íŒ¨í‚¤ì§€...

# ë²¡í„° ê²€ìƒ‰ (ì´ë¯¸ í¬í•¨ë¨)
pgvector>=0.2.0
```

### **ai-worker/requirements.txt**

```txt
# ê¸°ì¡´ íŒ¨í‚¤ì§€...

# HTTP ì„œë²„ (ì˜µì…˜ B ì„ íƒ ì‹œ)
flask>=3.0.0
flask-cors>=4.0.0
```

---

## ğŸ”„ êµ¬í˜„ ìˆœì„œ

### **Step 1: ì¸ë±ìŠ¤ ìƒì„±**

1. `infra/postgres/init.sql` ìˆ˜ì •
2. PostgreSQL ì¬ì‹œì‘ ë˜ëŠ” ìˆ˜ë™ ì¸ë±ìŠ¤ ìƒì„±
3. ì¸ë±ìŠ¤ ìƒì„± í™•ì¸

### **Step 2: ê²€ìƒ‰ í—¬í¼ êµ¬í˜„**

4. `ai-worker/tasks/search_helper.py` ìƒì„±
5. `ai-worker/main.py`ì— task ë“±ë¡
6. Worker ì¬ì‹œì‘

### **Step 3: ê²€ìƒ‰ API êµ¬í˜„**

7. `backend-core/main.py`ì— `/resumes/search` ì¶”ê°€
8. Backend ì¬ì‹œì‘
9. Swagger UIì—ì„œ í…ŒìŠ¤íŠ¸

### **Step 4: ê³ ê¸‰ ê¸°ëŠ¥ ì¶”ê°€**

10. ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ API
11. ê³ ê¸‰ í•„í„° ê²€ìƒ‰ API
12. ë°°ì¹˜ ê²€ìƒ‰ API (ì„ íƒ)

### **Step 5: ì„±ëŠ¥ ìµœì í™”**

13. ì¿¼ë¦¬ ìºì‹± ì¶”ê°€
14. ì¸ë±ìŠ¤ íŠœë‹
15. ë¶€í•˜ í…ŒìŠ¤íŠ¸

---

## âœ… ì™„ë£Œ ì²´í¬ë¦¬ìŠ¤íŠ¸

### **í•„ìˆ˜ ê¸°ëŠ¥**

- [ ] PostgreSQL HNSW ì¸ë±ìŠ¤ ìƒì„±
- [ ] ì¿¼ë¦¬ ì„ë² ë”© ìƒì„± Task
- [ ] ê¸°ë³¸ ë²¡í„° ê²€ìƒ‰ API (`/resumes/search`)
- [ ] ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ API (`/resumes/{id}/similar`)
- [ ] ê²€ìƒ‰ ê²°ê³¼ í¬ë§·íŒ… (ì¤‘ë³µ ì œê±°, ì •ë ¬)

### **ì„ íƒ ê¸°ëŠ¥**

- [ ] ê³ ê¸‰ í•„í„° ê²€ìƒ‰
- [ ] ë°°ì¹˜ ê²€ìƒ‰
- [ ] ì¿¼ë¦¬ ìºì‹±
- [ ] ê²€ìƒ‰ íˆìŠ¤í† ë¦¬ ì €ì¥

### **í…ŒìŠ¤íŠ¸**

- [ ] ë‹¨ì¼ ì¿¼ë¦¬ ê²€ìƒ‰ í…ŒìŠ¤íŠ¸
- [ ] ìœ ì‚¬ ì´ë ¥ì„œ ì¶”ì²œ í…ŒìŠ¤íŠ¸
- [ ] ì„±ëŠ¥ í…ŒìŠ¤íŠ¸ (ì‘ë‹µ ì‹œê°„ < 0.5ì´ˆ)
- [ ] ì •í™•ë„ í…ŒìŠ¤íŠ¸ (ê´€ë ¨ ì´ë ¥ì„œ ë°˜í™˜)

---

## ğŸ¯ ê¸°ëŒ€ íš¨ê³¼

1. **ë¹ ë¥¸ ê²€ìƒ‰**

   - pgvector + HNSW ì¸ë±ìŠ¤ë¡œ ë°€ë¦¬ì´ˆ ë‹¨ìœ„ ê²€ìƒ‰
   - ìˆ˜ì²œ ê°œ ì´ë ¥ì„œì—ì„œë„ ì¦‰ì‹œ ê²°ê³¼ ë°˜í™˜
2. **ì •í™•í•œ ë§¤ì¹­**

   - KURE-v1 í•œêµ­ì–´ ì„ë² ë”©ìœ¼ë¡œ ì˜ë¯¸ ê¸°ë°˜ ê²€ìƒ‰
   - í‚¤ì›Œë“œ ë§¤ì¹­ë³´ë‹¤ í›¨ì”¬ ì •í™•
3. **í™•ì¥ ê°€ëŠ¥**

   - ì´ë ¥ì„œ-ì§ˆë¬¸ ë§¤ì¹­
   - ì´ë ¥ì„œ-JD ë§¤ì¹­
   - ìœ ì‚¬ ì§€ì›ì ê·¸ë£¹í™”
4. **ì‚¬ìš©ì ê²½í—˜**

   - ìì—°ì–´ ì¿¼ë¦¬ ì§€ì› ("3ë…„ ì´ìƒ Python ê²½í—˜")
   - ì‹¤ì‹œê°„ ê²€ìƒ‰ ê²°ê³¼
   - ê´€ë ¨ë„ ì ìˆ˜ ì œê³µ

---

## ğŸ“š ì°¸ê³  ìë£Œ

- [pgvector Documentation](https://github.com/pgvector/pgvector)
- [HNSW Algorithm](https://arxiv.org/abs/1603.09320)
- [KURE-v1 Model](https://huggingface.co/nlpai-lab/KURE-v1)
- [FastAPI Background Tasks](https://fastapi.tiangolo.com/tutorial/background-tasks/)

---

**ì‘ì„±ì**: AI Assistant
**ìµœì¢… ìˆ˜ì •**: 2026-02-04
**ìƒíƒœ**: ğŸ“‹ ì„¤ê³„ ì™„ë£Œ, êµ¬í˜„ ëŒ€ê¸°
