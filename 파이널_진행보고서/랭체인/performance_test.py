import time
import os
import gc
import statistics
import numpy as np
import pdfplumber
from sentence_transformers import SentenceTransformer
from langchain_huggingface import HuggingFaceEmbeddings
from langchain_community.document_loaders import PyPDFLoader
from langchain_text_splitters import RecursiveCharacterTextSplitter
from langchain_core.documents import Document

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
MODEL_NAME = "nlpai-lab/KURE-v1"
PDF_PATH = "ai-worker/resume.pdf"  # í”„ë¡œì íŠ¸ ë‚´ ì‹¤ì œ PDF ê²½ë¡œ
REPEAT = 5 # ì •ë°€ ì¸¡ì •ì„ ìœ„í•œ ë°˜ë³µ íšŸìˆ˜

# â”€â”€ ê²°ê³¼ ì €ì¥ â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
results = {
    "Loading & Chunking": {"Native": [], "LangChain": []},
    "Embedding (Batch)": {"Native": [], "LangChain": []},
    "Search (Similarity)": {"Native": [], "LangChain": []}
}

def run_benchmark():
    print(f"ğŸš€ [ë²¤ì¹˜ë§ˆí¬ ì‹œì‘] ì‹¤ì œ PDF ë°ì´í„° í™œìš©: {PDF_PATH}")
    print(f"   ì‚¬ìš© ëª¨ë¸: {MODEL_NAME}")
    
    if not os.path.exists(PDF_PATH):
        print(f"âŒ PDF íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {PDF_PATH}")
        return

    # 1. ëª¨ë¸ ì¤€ë¹„ (ê³µì •í•œ ë¹„êµë¥¼ ìœ„í•´ ë¯¸ë¦¬ ë¡œë“œ)
    print("\n[STEP 0] ëª¨ë¸ ë¡œë”© ì¤‘...")
    native_model = SentenceTransformer(MODEL_NAME, trust_remote_code=True)
    langchain_embedder = HuggingFaceEmbeddings(
        model_name=MODEL_NAME, 
        model_kwargs={'trust_remote_code': True}
    )

    for i in range(REPEAT):
        print(f"\n[ğŸ”„ {i+1}/{REPEAT}íšŒì°¨ í…ŒìŠ¤íŠ¸]")
        
        # -----------------------------------------------------------
        # A. Loading & Chunking (ë°ì´í„° ìˆ˜ê¸‰ ë° ì „ì²˜ë¦¬)
        # -----------------------------------------------------------
        # 1) LangChain ë°©ì‹: PyPDFLoader + RecursiveSplitter
        t0 = time.perf_counter()
        loader = PyPDFLoader(PDF_PATH)
        lc_docs = loader.load()
        text_splitter = RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=50)
        lc_chunks = text_splitter.split_documents(lc_docs)
        results["Loading & Chunking"]["LangChain"].append(time.perf_counter() - t0)

        # 2) Native ë°©ì‹: pdfplumber + Paragraph Split
        t0 = time.perf_counter()
        native_chunks = []
        with pdfplumber.open(PDF_PATH) as pdf:
            for page in pdf.pages:
                text = page.extract_text()
                if text:
                    # ê°„ë‹¨í•œ ë‹¨ë½ ê¸°ì¤€ ë¶„í•  (ì‹¤ì œ í”„ë¡œì íŠ¸ utils íŒ¨í„´ ëª¨ë°©)
                    paras = [p.strip() for p in text.split('\n\n') if p.strip()]
                    native_chunks.extend(paras)
        results["Loading & Chunking"]["Native"].append(time.perf_counter() - t0)

        # -----------------------------------------------------------
        # B. Embedding (ë²¡í„°í™”)
        # -----------------------------------------------------------
        native_texts = native_chunks
        lc_texts = [d.page_content for d in lc_chunks]

        # 1) LangChain ë°©ì‹
        t0 = time.perf_counter()
        lc_vectors = langchain_embedder.embed_documents(lc_texts)
        results["Embedding (Batch)"]["LangChain"].append(time.perf_counter() - t0)

        # 2) Native ë°©ì‹
        t0 = time.perf_counter()
        native_vectors = native_model.encode(native_texts, convert_to_tensor=False)
        results["Embedding (Batch)"]["Native"].append(time.perf_counter() - t0)

        # -----------------------------------------------------------
        # C. Search (ìœ ì‚¬ë„ ê²€ìƒ‰ - RAG ë™ì‘ ì‹œë®¬ë ˆì´ì…˜)
        # -----------------------------------------------------------
        query = "ì§€ì›ìì˜ AI í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•´ ì•Œë ¤ì¤˜"
        print(f"\nğŸ” [RAG ì‹œë®¬ë ˆì´ì…˜] ì§ˆì˜: '{query}'")
        
        # 1) LangChain ë°©ì‹ (ê°ì²´ ê¸°ë°˜ í•„í„°ë§ ë° ì •ë ¬)
        t0 = time.perf_counter()
        query_vec_lc = langchain_embedder.embed_query(query)
        # ë™ì‘ ë°©ì‹: ê° Document ê°ì²´ì™€ ë²¡í„°ë¥¼ ë§¤ì¹­í•˜ì—¬ ìœ ì‚¬ë„ ê³„ì‚° í›„ ê°ì²´ ë¦¬ìŠ¤íŠ¸ ì •ë ¬
        lc_search_results = []
        for j, doc in enumerate(lc_chunks):
            sim = np.dot(query_vec_lc, lc_vectors[j])
            lc_search_results.append(Document(page_content=doc.page_content, metadata={"sim": sim}))
        lc_search_results.sort(key=lambda x: x.metadata["sim"], reverse=True)
        results["Search (Similarity)"]["LangChain"].append(time.perf_counter() - t0)

        # 2) Native ë°©ì‹ (Raw Matrix NumPy ì—°ì‚°)
        t0 = time.perf_counter()
        query_vec_native = native_model.encode([query])[0]
        # ë™ì‘ ë°©ì‹: ë„˜íŒŒì´ í–‰ë ¬ ê³±(Dot Product)ì„ í†µí•´ ëª¨ë“  ì²­í¬ì˜ ìœ ì‚¬ë„ë¥¼ í•œ ë²ˆì— ê³ ì† ê³„ì‚°
        similarities = np.dot(native_vectors, query_vec_native)
        top_indices = np.argsort(similarities)[::-1][:3] # ìƒìœ„ 3ê°œ ì¶”ì¶œ
        native_search_results = [(native_chunks[idx], similarities[idx]) for idx in top_indices]
        results["Search (Similarity)"]["Native"].append(time.perf_counter() - t0)

        # 1íšŒì°¨ í…ŒìŠ¤íŠ¸ì—ì„œë§Œ ì‹¤ì œ ê°€ì ¸ì˜¨ ë°ì´í„°ë¥¼ ìƒì„¸ ì¶œë ¥í•˜ì—¬ í™•ì¸
        if i == 0:
            print("\n   ğŸ“„ [ì‹¤ì œ ê²€ìƒ‰ ë°ì´í„° í™•ì¸ - 1íšŒì°¨]")
            print(f"   {'='*80}")
            print(f"   {'[LangChain Result]':<40} | {'[Native Result]':<40}")
            print(f"   {'-'*80}")
            for k in range(min(3, len(lc_search_results), len(native_search_results))):
                lc_text = lc_search_results[k].page_content.replace('\n', ' ')[:35]
                lc_sim = lc_search_results[k].metadata['sim']
                nt_text = native_search_results[k][0].replace('\n', ' ')[:35]
                nt_sim = native_search_results[k][1]
                print(f"   {k+1}. {lc_text}... ({lc_sim:.4f}) | {nt_text}... ({nt_sim:.4f})")
            print(f"   {'='*80}")

        gc.collect()

    # ê²°ê³¼ ì¶œë ¥
    print_results()

def print_results():
    print("\n" + "="*70)
    print(f"{'Benchmarking Results (Avg of {REPEAT} runs)':^70}")
    print("="*70)
    print(f"{'Category':<25} | {'Native (Direct)':<15} | {'LangChain (Framework)':<15} | {'Winner':<10}")
    print("-"*70)
    
    comparisons = {}
    for cat, data in results.items():
        n_mean = statistics.mean(data["Native"])
        l_mean = statistics.mean(data["LangChain"])
        winner = "Native" if n_mean < l_mean else "LangChain"
        ratio = l_mean / n_mean if winner == "Native" else n_mean / l_mean
        
        print(f"{cat:<25} | {n_mean:>13.4f}s | {l_mean:>13.4f}s | {winner} ({ratio:.1f}x)")
        comparisons[cat] = {"n": n_mean, "l": l_mean, "winner": winner, "ratio": ratio}
    
    print("="*70)
    print("\nï¿½ [ë°ì´í„° ê¸°ë°˜ ì‹¤ì¸¡ ë¶„ì„]")
    
    # 1. Loading/Chunking ë¶„ì„
    c = comparisons["Loading & Chunking"]
    print(f"1. ë°ì´í„° ë¡œë“œ/ë¶„í• : {c['winner']} ë°©ì‹ì´ ì•½ {c['ratio']:.1f}ë°° ë” ê¸°ë¯¼í•©ë‹ˆë‹¤.")
    print(f"   - LangChainì€ RecursiveSplitterë¥¼ í†µí•œ ê³ í’ˆì§ˆ ì˜ë¯¸ ë‹¨ìœ„ ë¶„í• ì„ ì œê³µí•˜ëŠ” ëŒ€ì‹  ì—°ì‚°ëŸ‰ì´ ë§ìŠµë‹ˆë‹¤.")
    
    # 2. Embedding ë¶„ì„
    c = comparisons["Embedding (Batch)"]
    diff_percent = abs(c['n'] - c['l']) / max(c['n'], c['l']) * 100
    print(f"2. ì„ë² ë”© ì—°ì‚°: ë‘ ë°©ì‹ì˜ ì°¨ì´ëŠ” {diff_percent:.1f}% ë‚´ì™¸ë¡œ ë§¤ìš° ë¯¸ë¯¸í•©ë‹ˆë‹¤.")
    print(f"   - ë‚´ë¶€ ì—”ì§„(SentenceTransformer)ì´ ë™ì¼í•˜ì—¬ ì—°ì‚° íš¨ìœ¨ì€ ë„êµ¬ì— ì¢…ì†ë˜ì§€ ì•ŠìŒì„ ì¦ëª…í•©ë‹ˆë‹¤.")
    
    # 3. Search ë¶„ì„
    c = comparisons["Search (Similarity)"]
    print(f"3. í…ìŠ¤íŠ¸ ê²€ìƒ‰: {c['winner']} ë°©ì‹ì´ ì•½ {c['ratio']:.1f}ë°° ë” íš¨ìœ¨ì ì…ë‹ˆë‹¤.")
    if c['winner'] == "Native":
        print(f"   - Nativeì˜ NumPy í–‰ë ¬ ì—°ì‚°ì´ ë­ì²´ì¸ì˜ Document ê°ì²´ ìƒì„±/ì •ë ¬ ì˜¤ë²„í—¤ë“œë³´ë‹¤ ë¬¼ë¦¬ì ìœ¼ë¡œ ë¹ ë¦…ë‹ˆë‹¤.")
    
    print(f"\nâœ… ìµœì¢… ì‹œì‚¬ì : ì¸¡ì •ëœ ìˆ˜ì¹˜ì— ë”°ë¥´ë©´ {comparisons['Search (Similarity)']['winner']} ë°©ì‹ì´ ì‹¤ì‹œê°„ ê²€ìƒ‰ ì‘ë‹µì„± í™•ë³´ì— ìœ ë¦¬í•˜ë©°,")
    print(f"ê°œë°œ ìƒì‚°ì„±ê³¼ ì •êµí•œ ë¬¸ì„œ íŒŒì‹±ì´ ìµœìš°ì„ ì¼ ê²½ìš° LangChainì˜ ë˜í¼ ê¸°ëŠ¥ì„ í™œìš©í•˜ëŠ” ê²ƒì´ í•©ë¦¬ì ì¸ ì„ íƒì…ë‹ˆë‹¤.")

if __name__ == "__main__":
    run_benchmark()
