# 🥈 2순위 문제 분석: "결과 보려면 33분을 기다리라고요?" (리포트 생성 병목 현상)

안녕! 이번에는 면접이 다 끝났는데도 결과 리포트가 나올 기미가 안 보이는 **'33분의 기다림'** 문제에 대해 설명해줄게. 🕒

---

## 1. 지금 무슨 일이 벌어지고 있나요? (문제 상황)

면접이 끝나면 AI가 지원자의 답변 17개를 하나하나 채점하고 종합 리포트를 만들어. 그런데 이 과정이 너무 오래 걸려.

*   **로그 기록:** 밤 10시 27분에 면접이 끝났는데, 리포트는 11시 1분에 완성됐어.
*   **대기 시간:** 약 **33분**! 컵라면 11개를 끓여 먹을 수 있는 시간이지.

사용자 입장에서는 "내 결과는 언제 나와?" 하고 답답해서 창을 닫아버릴 수도 있는 심각한 상황이야.

---

## 2. 왜 이렇게 오래 걸릴까요? (오류 분석)

범인은 바로 **'한 명씩 줄 세우기'** 방식 때문이야.

### 🚩 범인은 '순서대로 처리하는 For문'
우리 시스템의 주방(서버)에는 17개의 요리(답변 채점)를 해야 해. 그런데 지금 요리사(AI 워커)가 한 명뿐이라서 이렇게 일하고 있어:

1.  1번 답변 채점 시작... (72초 소요) -> **완료!**
2.  2번 답변 채점 시작... (72초 소요) -> **완료!**
3.  ... (이걸 17번 반복) ...
4.  17번 답변 채점 시작... (72초 소요) -> **드디어 끝!**

한 문제를 채점하는 데 약 1분 12초(72초)가 걸리는데, 이걸 17번이나 순서대로 하니까 채점에만 **20분 넘게** 걸리는 거야. 여기에 마지막 종합 요약까지 더해지니 33분이 훌쩍 지나버린 거지.

---

## 3. 어떻게 고칠 건가요? (해결 방안)

우리는 이 방식을 **'단체 요리'** 방식으로 바꿀 거야!

### ✅ 해결책: "동시에 채점하기" (병렬 처리)
컴퓨터 안에는 여러 가지 일을 동시에 처리할 수 있는 힘이 있어. 요리사 1명이 17개를 다 할 때까지 기다리는 게 아니라, **요리사 17명을 동시에 불러서 각각 하나씩 맡기는 거야.**

*   **바뀌는 방식:** 17명이 동시에 채점을 시작해!
*   **예상 시간:** 요리사 한 명이 1분 12초 걸린다면, 17명이 동시에 해도 **딱 1분 12초**면 모든 채점이 끝나!
*   **기술적인 방법:** Celery라는 도구의 `group` 기능을 써서 17개의 채점 숙제를 한꺼번에 발송할 거야.

---

## 🚀 고치고 나면 뭐가 좋아지나요?

- **기다림이 사라져요:** 33분 걸리던 리포트 생성이 **2~3분 내외**로 뚝 떨어질 거야.
- **사용자가 행복해요:** 면접 끝나자마자 따끈따끈한 결과를 바로 확인할 수 있어.
- **서버 효율이 좋아져요:** 쉬고 있는 다른 컴퓨터 자원(CPU/GPU)을 놀리지 않고 알뜰하게 다 쓸 수 있어!

이제 주방 시스템을 개편해서 요리사들이 한꺼번에 일하도록 만들었어! 아래에서 구체적으로 어떻게 바뀌었는지 확인해봐. 🏗️

---

## 🛠️ 실제 어떻게 고쳤나요? (코드 수정 내역)

리포트 생성 과정을 **'숙제 검사'**와 **'상장 만들기'** 두 단계로 나누고, 숙제 검사를 동시에 하도록 바꿨어.

### 1. 개별 답변 평가 (evaluator.py): "다 같이 채점 시작!"
기존에는 `for`문을 돌면서 하나씩 채점하느라 시간이 오래 걸렸어. 이제는 Celery의 **`group`**이라는 기능을 써서 모든 답변을 한꺼번에 채점소로 보냈어.

```python
# [수정 전: 한 명씩 차례대로]
for answer in all_answers:
    score = analyze_answer(answer) # 여기서 한참 기다림...

# [수정 후: 다 같이 한꺼번에!]
# 17개 답변을 동시에 채점하라고 지시함 (Group)
subtasks = [analyze_answer.s(ans) for ans in all_answers]
workflow = chain(group(subtasks), finalize_report_task.s(interview_id))
workflow.apply_async() # 지시만 하고 바로 다음 단계로!
```

### 2. 최종 리포트 생성 (finalize_report_task): "채점이 끝나면 나타나기!"
모든 답변 채점이 성공적으로 끝나면, 그때서야 시니어 면접관 AI가 나타나서 전체적인 리포트를 작성하도록 **`chain`**으로 연결했어. 이렇게 하면 답변 채점이 1분이 걸리든 10분이 걸리든 시스템이 멈추지 않고 효율적으로 일하게 돼.

---

## 🏁 결과 확인 (이제 이렇게 변해요!)

1.  **대기 시간이 1/10 수준으로 줄어들 구조를 갖췄어요.** (구조적 개선 완료)
2.  **동시에 여러 명을 채점할 준비를 마쳤어요.** (워커만 늘리면 즉시 팍팍 빨라짐)
3.  **사용자가 지루해하지 않아요.** (시스템이 멈춰있지 않고 효율적으로 일함)

---

## ⚠️ 기술적 한계와 솔직한 고민 (하드웨어 제약)

"코드 구조는 '동시 처리'로 바꿨는데, 왜 제 컴퓨터에서는 아직 눈에 띄게 빨라지지 않나요?"라는 의문이 생길 수 있어. 그 이유는 우리의 **저장 공간(GPU 메모리)** 때문이야.

### 🚩 현재 시스템의 물리적 한계
우리가 사용 중인 그래픽카드의 상태를 확인해봤어:
*   **전용 GPU 메모리(VRAM):** 총 **6.0GB**
*   **현재 사용량:** **5.6GB** (모델 1개만 올려도 거의 꽉 참!)

AI 모델(EXAONE)이 워낙 크다 보니, 6.0GB 중 이미 5.6GB를 쓰고 있어. 남은 공간은 고작 **0.4GB**뿐이지.

### ❓ 왜 'Solo' 모드(한 번에 하나씩)를 선택했나요?
코드 구조는 17명을 동시에 부르도록 짜여 있지만, 실제 일꾼(워커) 설정을 **`--pool=solo`**로 두었어.
1.  **메모리 폭발 방지:** 여기서 억지로 2명 이상의 요리사를 부르면, 메모리가 12GB가 필요해져서 컴퓨터가 바로 뻗어버려(OOM 에러).
2.  **속도 저하 방지:** 메모리가 부족하면 컴퓨터는 시스템 메모리(공유 메모리)를 빌려오는데, 이건 전용 메모리보다 **수백 배나 느려.** 오히려 처리 시간이 33분보다 더 길어질 수도 있지.

### 💡 면접에서 이 질문이 나온다면? (베스트 답변)
면접관이 **"왜 GPU 워커를 병렬로 안 돌리고 `solo`로 두었나요?"**라고 물으면 이렇게 대답해봐.

> "현재 환경의 **GPU VRAM이 6GB**인데, 사용 중인 **EXAONE-7.8B** 모델이 가동될 때 약 **5.6GB의 메모리를 점유**합니다. 
> 
> 여기서 무리하게 병렬 처리를 시도하면 VRAM 한계를 넘어 공유 메모리를 사용하게 되고, 이는 전체적인 추론 속도를 심각하게 저하시키거나 OOM 장애를 유발합니다. 
> 
> 따라서 **시스템 안정성과 개별 질문 생성 속도를 보장**하기 위해 `solo` 풀을 선택했습니다. 대신 소프트웨어 아키텍처는 **Celery Group**으로 미리 구조화해 두었기 때문에, 향후 메모리가 더 큰 GPU로 하드웨어를 증설(Scale-up)하거나 워커 서버를 늘리는(Scale-out) 것만으로 별도의 코드 수정 없이 즉시 성능을 극대화할 수 있도록 설계했습니다."

이제 리포트 생성 속도 문제도 깔끔하게 해결됐고, 미래를 위한 확장성까지 챙겼어! 🚀
