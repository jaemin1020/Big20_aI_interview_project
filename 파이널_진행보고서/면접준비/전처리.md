# 👔 면접 대비: 데이터 전처리(Preprocessing) 기술 문서 (Q&A 형식)

본 문서는 실제 기술 면접 상황을 가정하여, 우리 프로젝트의 데이터 전처리 로직을 전문적인 답변 형태로 정리한 자료입니다.

---

### Q1. 이력서 데이터의 전처리 파이프라인은 어떻게 구성되어 있나요?
**A1.** 저희 프로젝트의 전처리는 크게 **추출(Extraction), 정제(Cleaning), 구조화(Parsing), 분할(Chunking)**의 4단계로 구성됩니다. 
먼저 `pdfplumber`를 활용해 PDF의 텍스트와 표 데이터를 보존하며 추출합니다. 이후 정규표현식을 통해 불필요한 공백과 특수문자를 제거하는 정제 과정을 거칩니다. 정제된 텍스트는 지원자의 인적 사항, 학력, 프로젝트 등으로 섹션을 나누어 JSON 형태로 구조화하며, 마지막으로 RAG 성능 최적화를 위해 `RecursiveCharacterTextSplitter`를 사용하여 적절한 크기의 조각(Chunk)으로 분할합니다.

---

### Q2. 비정형 PDF 데이터에서 텍스트를 추출할 때 어떤 기술적 라이브러리를 사용했고, 그 이유는 무엇인가요?
**A2.** `pdfplumber` 라이브러리를 사용했습니다. 
일반적인 `PyPDF2` 같은 라이브러리는 텍스트의 순서가 뒤섞이거나 특히 '표(Table)' 데이터를 무시하는 경향이 있습니다. 반면 `pdfplumber`는 문서 내의 레이아웃 좌표 정보를 기반으로 텍스트를 추출하며, 표의 행과 열을 리스트 구조로 정확하게 파싱할 수 있는 기능을 제공합니다. 이력서 데이터는 표 형식의 경력 및 학위 정보가 핵심이기 때문에, 데이터의 손실을 최소화하기 위해 해당 라이브러리를 선택했습니다.

---

### Q3. 저희 프로젝트의 파싱(Parsing) 로직에서 가장 핵심적인 기법은 무엇인가요?
**A3.** 이력서의 복잡한 구조를 해석하기 위해 **'표 기반 구조화'와 '텍스트 패턴 매칭'을 혼합한 하이브리드 방식**을 사용했습니다.
1.  **표(Table) 파싱:** `pdfplumber`를 통해 추출된 2차원 리스트 형태의 표 데이터에서 첫 번째 열(Key)의 키워드를 분석하여 학력, 경력, 자격증 등의 섹션을 식별합니다.
2.  **정규표현식(Regex) 폴백:** 표 형식이 아니거나 텍스트가 깨진 경우를 대비해, "이름: [가-힣]{2,4}"와 같은 정규식 패턴을 사용하여 핵심 인적 사항을 보조적으로 추출합니다.
3.  **자기소개서 자동 분리:** "[질문1]", "[질문2]" 등의 고유 패턴을 감지하여 질문과 답변을 쌍(Pair)으로 정교하게 분리해 처리하도록 구현했습니다.

---

### Q4. 텍스트 정제(Cleaning) 단계에서 구체적으로 어떤 처리를 수행했나요?
**A4.** 주로 **데이터 정규화(Normalization)**에 집중했습니다. 
PDF 추출 과정에서 발생하는 중복 공백, 불필요한 줄바꿈, 탭 문자 등을 Python의 `re` 모듈(정규표현식)을 사용해 제거했습니다. `re.sub(r'\s+', ' ', text)`와 같은 패턴을 활용해 모든 공백 문자를 단일 공백으로 통일함으로써, 임베딩 모델이 텍스트의 의미를 더 정확하게 파악할 수 있도록 노이즈를 제거했습니다. 또한 "이 름 : OOO"과 같이 공백이 섞인 고유 패턴들을 식별하여 일관된 형식으로 통합했습니다.

---

### Q5. 텍스트 분할(Chunking) 시 사용한 전략과 설정값(Parameter)의 근거는 무엇인가요?
**A5.** LangChain의 `RecursiveCharacterTextSplitter`를 사용했으며, **Chunk Size 600자, Chunk Overlap 100자**를 기본 전략으로 채택했습니다.
*   **Chunk Size (600):** 너무 작으면 문맥이 부족하고, 너무 크면 임베딩 벡터의 의미가 희석됩니다. EXAONE-3.5 모델의 Context Window와 RAG 검색의 정확도를 고려하여 정보의 밀도가 가장 높은 600자를 선택했습니다.
*   **Chunk Overlap (100):** 조각 간에 100자를 겹치게 설정하여, 문맥의 단절을 방지했습니다. 특히 자소서 질문과 답변이 연결되는 지점에서 정보가 잘려 검색 성능(Retrieval)이 저하되는 현상을 막기 위한 핵심적인 장치입니다.

---

### Q6. 이력서의 특정 섹션(예: 프로젝트, 학력)을 AI가 어떻게 정확히 인식하도록 구현했나요?
**A6.** **키워드 지향적 섹션 감지(Keyword-Based Section Detection)** 로직을 구현했습니다.
텍스트를 상단부터 읽어 내려가며 "학력", "Education", "Experience", "프로젝트" 등의 핵심 키워드를 트리거로 섹션을 전환합니다. 특히 표 데이터의 경우 첫 번째 열의 텍스트를 분석하여 현재 행이 어떤 카테고리에 속하는지 판별합니다. 이렇게 분류된 데이터에는 'category' 메타데이터를 부여하여, 추후 RAG 검색 시 지원자의 '프로젝트'만 필터링해서 검색하거나 '자격증' 유무를 즉시 확인할 수 있도록 검색 효율성을 극대화했습니다.

---

### 💡 [면접 팁] 전처리 관련 추가 예상 질문
*   **Q:** "전처리가 RAG 검색 성능에 어떤 영향을 주었나요?"
*   **A:** "무분별한 텍스트를 넣었을 때보다, 섹션을 나누고 메타데이터를 부여한 뒤 검색했을 때 정확도(Top-1 Hit Rate)가 약 30% 이상 향상되는 것을 확인했습니다."
*   **Q:** "특이한 폰트나 이미지가 섞여 있어 텍스트 추출이 안 되는 경우는 어떻게 대비했나요?"
*   **A:** "현재는 텍스트 기반 추출을 우선시하지만, 실패 시 OCR 엔진(Tesseract 등)을 도입하거나 사용자에게 텍스트 입력을 유도하는 폴백(Fallback) 프로세스를 고려하고 있습니다."
