# 🛠️ BIGTERVIEW 프로젝트 Celery Task 네이밍 및 라우팅 정비 보고서

## 1. ❓ 왜 처음부터 태스크 이름이 다르게 지어졌는가? (원인 분석)

프로젝트 내에서 파일명과 Celery에 등록된 태스크 이름이 불일치하게 된 이유는 크게 두 가지입니다.

1. **역할 vs 파일 이름의 관점 차이:** * 개발자는 파일 이름은 **"누가 일하는지(`generator.py` - 생성기)"**로 짓고, 서비스(태스크) 주소는 **"무슨 일을 하는지(`generation` - 생성 서비스)"**로 짓고 싶어 하는 경향이 반영되었습니다.
2. **리팩토링 흔적 (가장 흔한 원인):** * 초기 파일명이 `question_generation.py`였다가 나중에 `question_generator.py`로 변경되었으나, 소스 코드 내부의 `@shared_task(name=...)` 데코레이터 문자열을 업데이트하는 것을 누락했습니다.

---

## 2. 🔍 전수 조사 및 불일치 발견 내역 (ai-worker 기준)

현재 프로젝트의 파일명(`tasks/xxx.py`)과 등록된 이름(`name=...`)을 대조하여 전수 조사를 진행한 결과입니다.

| 파일명 (`ai-worker/tasks/`) | 등록된 이름 (`name=...`)         | 백엔드 호출 이름              | 상태                                     |
| :---------------------------- | :--------------------------------- | :---------------------------- | :--------------------------------------- |
| `question_generator.py`     | `tasks.question_generation`      | `tasks.question_generation` | ⚠️**불일치** (`or` vs `ion`) |
| `resume_parser.py`          | `parse_resume_pdf`               | `parse_resume_pdf`          | ✅ 일치 (단, 네임스페이스 구조화 필요)   |
| `resume_embedding.py`       | `tasks.resume_embedding...`      | `tasks.resume_embedding...` | ✅ 일치 (단, 파이프라인 명칭 통일 필요)  |
| `stt.py`                    | `tasks.stt.recognize`            | `stt/recognize` (URL)       | ✅ 일치                                  |
| `evaluator.py`              | `tasks.evaluator.analyze_answer` | -                             | ✅ 일치                                  |

---

## 3. 🛠️ 단계별 수정 및 표준화 작업 내역

백엔드가 호출하는 이름과 워커가 대기하는 이름을 일치시키고, 누락된 기능을 추가하며, 작업 특성(CPU/GPU)에 따른 라우팅을 정교화했습니다.

### 1단계: `ai-worker/tasks/question_generator.py` 수정

가장 문제가 되었던 꼬리질문 생성기 태스크를 백엔드 기대치에 맞춰 수정했습니다.

* **누락 기능 추가:** 면접 시작 직후 "자기소개 부탁드립니다"라는 질문이 나가는 동안, 백그라운드에서 EXAONE 모델을 미리 메모리에 올려 답변 딜레이를 없애주는 핵심 기능인 `preload_model` 태스크를 추가했습니다.
* **이름 일치:** 백엔드 호출 주소(`tasks.question_generation`)와 정확히 일치시켰습니다.

### 2단계: `ai-worker/tasks/resume_parser.py` 수정

이력서 파이프라인의 시작점인 파서의 네임스페이스를 구조화했습니다.

* **이름 변경:** 기존의 단순한 `parse_resume_pdf`에서 프로젝트 구조에 맞는 `tasks.resume_pipeline.parse_pdf`로 변경했습니다.
* **연결 수정:** 파싱이 끝난 후 다음 단계인 임베딩 작업 호출부도 새로운 이름(`tasks.resume_pipeline.generate_embeddings`)으로 넘기도록 수정했습니다.

### 3단계: `ai-worker/tasks/resume_embedding.py` 수정

* **이름 통일:** 중구난방이었던 태스크 이름을 `tasks.resume_pipeline.generate_embeddings`로 명확하게 통일했습니다.

### 4단계: `ai-worker/main.py` 라우팅 정교화 (워커 설정)

태스크 이름이 `tasks.resume_pipeline.*`으로 통일됨에 따라 모든 작업이 GPU로 몰리지 않도록 명확한 큐(Queue) 라우팅을 설정했습니다.

* `tasks.resume_pipeline.parse_pdf` ➡ **`cpu_queue`** (이력서 파싱은 CPU 전담)
* `tasks.resume_pipeline.generate_embeddings` ➡ **`gpu_queue`** (임베딩은 GPU 전담)
* `tasks.question_generation.*` ➡ **`gpu_queue`** (`preload_model` 포함 GPU 전담)

### 5단계: `backend-core/celery_app.py` 주소록 동기화 (백엔드 설정)

워커쪽 설정이 변경되었으므로, 편지를 보내는 백엔드 쪽의 라우팅 설정도 1:1로 동기화했습니다.

* 심부름을 보낼 때부터 올바른 바구니(`cpu_queue` / `gpu_queue`)에 넣도록 라우팅 규칙을 동일하게 복제하여 적용 완료.

---

## 4. 🚀 수정 결과 요약

| 구분                  | 주요 변경 사항                                                           | 해결된 문제                                                        |
| :-------------------- | :----------------------------------------------------------------------- | :----------------------------------------------------------------- |
| **태스크 추가** | `question_generator.py`에 `preload_model_task` 구현                  | 모델 사전 로딩 시 발생하던 `Unregistered Task` 에러 완벽 해결    |
| **이름 일관성** | `parse_resume_pdf` ➡ `tasks.resume_pipeline.parse_pdf` 등 이름 통일 | 백엔드와 워커 간 심부름 이름(Address) 불일치 해결                  |
| **성능 최적화** | 파이프라인 단계별 전용 큐(CPU vs GPU) 명시적 배정                        | 이름은 묶어 관리하되, 작업 무게에 따라 CPU/GPU 워커 분산 처리 달성 |
| **설정 동기화** | `backend-core`와 `ai-worker`의 라우팅 일치                           | 심부름표 발송 시점부터 올바른 Queue로 전달되도록 파이프라인 안정화 |

---

## 5. 💡 시스템 확인 방법

적용된 변경 사항을 최종 확인하기 위해 다음 절차를 진행해 주세요.

1. **워커 재시작:** 적용된 코드를 반영하기 위해 `ai-worker` 컨테이너를 재시작합니다.
2. **사전 로딩 로그 확인:** 면접 시작 직후 로그에 `EXAONE-ENGINE: Preload successful` 메시지가 출력되는지 확인합니다. (사전 로딩 정상 작동 여부)
3. **엔드투엔드(E2E) 테스트:** 새로운 이력서를 업로드하여, CPU에서의 파싱(`parse_pdf`)부터 GPU에서의 임베딩(`generate_embeddings`)까지 중단 없이 파이프라인이 정상적으로 이어지는지 확인합니다.
