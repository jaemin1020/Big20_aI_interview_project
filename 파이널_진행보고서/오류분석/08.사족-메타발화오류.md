# 오류 분석 보고서: AI 질문 생성 시 사족 및 메타 발화 발생 (08)

## 1. 개요 (Overview)
AI 면접관이 질문을 생성할 때, 지원자에게 직접 던지는 질문 외에 **"질문을 제시하겠습니다"**, **"지원자 답변 요약:"**, **"심층 질문:"** 등 자신의 추론 과정이나 의도를 설명하는 **메타 발화(Meta-speech)**가 포함되는 현상이 발생했습니다. 이는 면접의 몰입도를 방해하고 시스템의 전문성을 저하시키는 주요 오류 사례로 분석되었습니다.

---

## 2. 발생 현상 (Problem Description)
### [실제 발생 사례]
> "그렇다면 지원자의 답변에서 구체적인 내용이 부족한 부분을 파악하여, 그 부분을 심층적으로 탐구할 수 있는 질문을 제시하겠습니다. 지원자 답변 요약: '그냥 했습니다.'라는 답변은 구체적인 내용이나 적용 사례가 부족합니다. 심층 질문: SQLD 및 ADSP 자격증을 취득하면서 특정 프로젝트나 시나리오에서 복잡한 데이터베이스 최적화 기법이나 분산 처리 알고리즘을 어떻게 적용하셨는지 구체적인 사례와 함께 설명해 주실 수 있으신가요?"

### [문제점]
1. **서두 사족 (Introductory Filler)**: "질문을 제시하겠습니다"와 같은 불필요한 서술.
2. **레이블 노출 (Label Leakage)**: "지원자 답변 요약:", "심층 질문:" 등 시스템 내부용 레이블이 그대로 출력됨.
3. **불필요한 요약 (Redundant Summary)**: 질문만 하면 되는 단계에서 지원자의 답변을 굳이 요약하여 길어짐.

---

## 3. 원인 분석 (Root Cause Analysis)

### 3.1 AI 페르소나의 과잉 몰입 (Persona Over-fitting)
프롬프트에서 AI에게 "베테랑 면접관", "정밀 검증 전문가" 등 강력한 페르소나를 부여함에 따라, AI가 **자신의 전문성을 입증하기 위해** "나는 지금부터 이러한 의도로 질문을 할 것이다"라는 점을 사용자에게 친절하게 설명하려는 경향(Chain-of-Thought 성향)을 보였습니다.

### 3.2 모델의 지시사항 유출 (Instruction Leakage)
EXAONE-3.5와 같은 특정 LLM 혹은 4-bit 양자화 모델에서 발생할 수 있는 현상으로, 시스템 프롬프트(System Prompt)에 명시된 "답변을 분석하여 질문을 생성하라"는 **지시사항 자체를 출력의 일부로 오인**하여 그대로 뱉어내는 '가이드라인 유출' 현상입니다.

### 3.3 정제 로직(Cleaning Logic)의 패턴 미흡
기존의 `clean_ai_output` 함수에서는 "질문:", "요약:"과 같은 단순한 키워드만 제거하도록 정규식이 작성되어 있었습니다. 하지만 이번 사례처럼 **"~를 파악하여 ~를 제시하겠습니다"**와 같은 문장형 서두(Meta-commentary)는 정해진 패턴에 걸리지 않아 필터링되지 못했습니다.

### 3.4 꼬리질문(Follow-up)의 논리적 구조화 경향
꼬리질문 단계에서는 지원자의 이전 답변을 근거로 삼아야 하므로, 모델 내부적으로 **[근거 파악] -> [질문 생성]**의 단계를 거칩니다. 이때 모델이 이 두 단계를 분리하지 못하고 하나로 합쳐서 출력한 것이 원인입니다.

---

## 4. 해결 및 개선 방안 (Resolution & Improvements)

### 4.1 정제 로직(Cleaning Parser) 대폭 강화
단순 키워드 매칭을 넘어, 문장형 사족을 제거하기 위한 **다단계 정규식 필터**를 추가했습니다.
- "제시하겠습니다", "하겠습니다", "드리겠습니다"로 끝나는 서두 문장 전체 삭제.
- "지원자의 답변", "파악하여", "탐구할" 등 메타 키워드가 포함된 문장 강제 필터링.
- 최종적으로 '질문:' 혹은 '?' 뒤에 붙는 모든 부연 설명을 잘라내는 로직 보강.

### 4.2 프롬프트 전역 제약(Global Constraint) 강화
출력의 마지막 단계에서 명시적으로 다음과 같은 제약을 추가했습니다.
- "인사말, 부연 설명, 자기소개, 가설 제시를 절대 하지 마십시오."
- "오직 물음표(?)로 끝나는 단일 문장의 질문만 출력하십시오."

### 4.3 논리 분리 (Split & Extract)
만약 모델이 "요약: ~ 질문: ~" 형태로 답변을 생성하더라도, 시스템단에서 자동으로 **가장 마지막 질문 문구만 추출**하여 지원자에게 전달하도록 방어 코드를 적용했습니다.

---

## 5. 결론 (Conclusion)
메타 발화 오류는 모델의 '과한 친절'과 '지시사항 이해 오류'에서 비롯된 것으로, 이를 방지하기 위해서는 강력한 시스템 프롬프트뿐만 아니라 **출력 후처리(Post-processing)** 단계에서의 정교한 정제 로직이 필수적임을 확인했습니다. 이번 수정을 통해 사족 없는 깔끔하고 전문적인 면접 환경을 확보했습니다.
