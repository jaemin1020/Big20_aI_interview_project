# 시스템 성능 지연 및 안정성 심층 분석 보고서

## 1. 개요
최근 시스템 로그 분석 결과, 프론트엔드와 백엔드 간의 통신 병목, 비효율적인 태스크 처리, 그리고 인프라 환경(WSL2)의 불안정성으로 인해 전체 인터뷰 경험의 질이 저하되고 있음이 확인되었습니다. 본 보고서는 발견된 4대 핵심 문제를 분석하고 이에 대한 구체적인 기술적 해결 방안을 제시합니다.

---

## 2. 핵심 분석 결과 및 개선안

### [1단계] 통신 구조 개선 (완료 ✅)
- **문제점**: 프론트엔드가 1초 미만 단위로 `GET /interviews/{id}/questions` API를 무한 호출(Polling)함에 따라 서버 CPU와 DB 커넥션이 불필요하게 낭비됨.
- **관련 현상**:
    ```text
    interview_backend  | INFO: 172.18.0.1 - "GET /interviews/135/questions HTTP/1.1" 200 OK
    interview_backend  | [WARNING] Interview-Router: ⏳ [TTS Missing] ID: 14055
    ```
- **수정 사항 (2026-02-28)**:
    1. **Polling 주기 최적화**: 프론트엔드의 주요 폴링 주기(질문 상태 확인, 리포트 생성 확인 등)를 기존 1~3초에서 **5초**로 상향 조정하여 백엔드 호출 횟수를 60% 이상 절감.
    2. **AbortController 도입 (Request 중복 방지)**: 새로운 Polling 요청을 보내기 전, 아직 완료되지 않은 이전 요청이 있다면 즉시 `abort()` 시켜 데이터 레이스 컨디션 및 자원 낭비 원천 차단.
    3. **코드 변경 파일**:
        - `frontend/src/api/interview.js`: 모든 API 요청에 `signal` 옵션 추가.
        - `frontend/src/App.jsx`: `useRef`를 통한 `AbortController` 관리 및 `setInterval` 주기 연장 로직 적용.


### [2단계] 태스크 중복 실행 방지 (완료 ✅)
- **문제점**: 동일한 질문 ID에 대해 TTS 음성 합성 태스크가 큐에 중복 수신되어 CPU 자원을 심각하게 낭비함.
- **관련 현상**:
    ```text
    # 동일 ID(14055)에 대해 서로 다른 태스크 ID가 3번이나 중복 수신
    interview_worker_cpu | Task tasks.tts.synthesize[541f...] received
    interview_worker_cpu | ✅ 음성 합성 완료 (소요시간: 4.9s)
    ```
- **수정 사항 (2026-02-28)**:
    1. **Redis 기반 Idempotency (멱등성) 적용**: 백엔드 `_fire_tts_for_question` 함수에 Redis 분산 락 로직을 삽입하여, 동일 질문에 대해 60초 이내 중복 전송을 차단함.
    2. **통합 태스크 호출**: 모든 TTS 생성 지점(질문 생성, 리얼타임 인터뷰 등)을 `_fire_tts_for_question` 도우미 함수로 단일화함.
    3. **워커 검증 강화**: `tasks/tts.py`에서 작업 시작 직전 파일 존재 여부를 체크하고, 이미 존재하는 경우 연산을 수행하지 않고 즉시 스킵함.
    4. **모델 Preload 최적화**: `ai-worker/main.py`에 모델 사전 로딩(STT, Embedding, LLM) 로직을 추가하여, 첫 요청 시 발생하는 지연(최대 84초)을 사전에 제거함.


### [3단계] DB 세션 및 환경 안정화 (완료 ✅)
- **문제점**: DB 트랜잭션 충돌로 인한 잠금(Locking) 현상(이미 진행 중인 트랜잭션 오류)과 WSL2 도커의 시간 동기화(Drift) 에러로 인해 워커 하트비트 유실 및 비정상 중단 발생.
- **관련 현상**:
    ```text
    interview_db | WARNING: there is already a transaction in progress
    interview_worker_gpu | Substantial drift ... Current drift is 28 seconds.
    ```
- **수정 사항 (2026-02-28)**:
    1. **DB 연결 풀 관리 강화**: `ai-worker/db.py`에 `pool_pre_ping=True`를 적용하여 끊긴 연결을 자동 재시도하고, `pool_size`를 백엔드와 일치시켜 고부하 상황 대응.
    2. **커넥션 충돌 원천 차단**: Celery의 `worker_process_init` 시그널을 활용하여, 자식 프로세스 생성 시 부모로부터 상속받은 DB 연결 풀을 폐기(`engine.dispose()`)하고 새로 생성하도록 강제.
    3. **WSL2 시간 동기화 자동화**: `scripts/sync_wsl2_time.sh`를 배포하여 호스트 PC 절전 모드 복귀 후 발생하는 시간 오차를 한 번에 해결할 수 있도록 조치.


### [4단계] AI 파이프라인 성능 최적화 (완료 ✅)
- **문제점**: RAG 검색부터 질문 생성까지 지연이 발생하며, LLM의 컨텍스트 크기(16k)가 학습 기준(32k)보다 작아 긴 면접 시 기억력 저하 우려.
- **관련 현상**:
    ```text
    interview_worker_gpu | [18:24:52] [RAG 검색 시작] -> [18:26:17] 성공 (84.7s 소요)
    interview_worker_gpu | llama_context: n_ctx_per_seq (16384) < n_ctx_train (32768)
    ```
- **수정 사항 (2026-02-28)**:
    1. **LLM 컨텍스트 확장**: `ai-worker/utils/exaone_llm.py`에서 `n_ctx`를 **32,768**로 상향하여 모델의 원래 성능을 100% 발휘하도록 개선.
    2. **RAG 검색 싱글톤(Singleton) 고도화**: `tasks/rag_retrieval.py`에 `PGVector` 인스턴스 캐싱 로직(`get_vector_store`)을 추가하여, 검색 시마다 발생하는 객체 생성 오버헤드를 제거.
    3. **임베딩 모델 공유**: 검색(RAG)과 저장이 동일한 모델 인스턴스를 공유하도록 구조를 통일하여 GPU 메모리 점유율 최적화.


---

## 3. 우선순위 기반 실행 로드맵
위 분석 내용을 바탕으로 다음과 같은 순서대로 코드 수정을 진행할 것을 권고합니다.

1. **우선순위 1 (상)**: **TTS 중복 방지 로직** (`ai-worker/tasks/tts.py`) 및 **DB 세션 구조 개선**. (시스템 생존 직결)
2. **우선순위 2 (중)**: **프론트엔드 Polling 주기 완화** (`frontend/src/api/interview.js` 등). (서버 부하 경감)
3. **우선순위 3 (하)**: **임베딩 모델 로딩 최적화 및 컨텍스트 확장**. (응답 품질 향상)

---
**보고서 작성일**: 2026-02-28
**작성자**: Antigravity (AI Assistant)
