
# 📑 [기술 보고서] 벡터 데이터 저장 엔진: PGVector 기반 영구 저장 매커니즘

본 문서는 임베딩된 이력서 데이터를 PostgreSQL의 벡터 확장 기능(`pgvector`)을 활용하여 영구 저장하고, 멀티 테넌트(Multi-tenant) 검색을 위해 메타데이터를 관리하는 기술적 과정을 상세히 기술합니다.

---

## 1. 환경 유연성 확보: 동적 경로 설정 (Dynamic Pathing)

가장 먼저 코드는 실행 환경(Docker vs Local)에 상관없이 서버의 핵심 로직을 참조할 수 있도록 설계되었습니다.

```python
current_dir = os.path.dirname(os.path.abspath(__file__))
backend_core_docker = "/backend-core"
backend_core_local = os.path.join(current_dir, "backend-core")

if os.path.exists(backend_core_docker):
    sys.path.append(backend_core_docker)

```

### 🔍 깊이 있는 분석

* **존재 이유**: 개발자의 로컬 PC 폴더 구조와 Docker 컨테이너 내부의 구조는 완전히 다릅니다.
* **해결**: `sys.path.append`를 통해 파이썬의 모듈 탐색 경로에 동적으로 길을 터줌으로써, 어느 환경에서든 `db.py`나 `embedding.py` 같은 공통 모듈을 에러 없이 불러올 수 있는 **환경 독립성(Environmental Independence)**을 확보했습니다.

---

## 2. 데이터 표준화: `Document` 객체 생성

AI 도구(LangChain)가 DB와 소통하기 위해서는 텍스트를 전용 포장지인 **`Document`** 객체에 담아야 합니다.

```python
for item in embedded_chunks:
    metadata = item.get("metadata", {})
    metadata["resume_id"] = resume_id # 핵심 견출지
    metadata["chunk_type"] = item.get("type", "unknown")
  
    doc = Document(
        page_content=item["text"],
        metadata=metadata
    )

```

### 🔍 상세 로직 분석

* **`page_content`**: AI가 실제로 읽고 질문을 생성할 **원본 텍스트**입니다.
* **메타데이터(Metadata)의 전략적 활용**: 수만 명의 이력서 조각이 하나의 DB 테이블(`collection`)에 섞여 저장됩니다. 이때 `resume_id`를 메타데이터로 심어두지 않으면, 나중에 특정 사용자의 데이터만 골라내는 것이 불가능합니다. 이는 DB의 **인덱싱(Indexing)**과 **필터링** 속도를 결정짓는 결정적인 설계입니다.

---

## 3. 벡터 저장소의 핵심: `PGVector` 연동

이 코드는 단순한 DB 저장을 넘어, PostgreSQL을 **고차원 좌표 검색 엔진**으로 변환시킵니다.

```python
vector_store = PGVector.from_documents(
    embedding=embeddings,
    documents=documents,
    collection_name="resume_all_embeddings",
    connection_string=connection_string,
    pre_delete_collection=False,
)

```

### 🔍 기술적 메커니즘

1. **`from_documents`**: 이 함수는 내부적으로 **[텍스트 추출 → 임베딩 모델 실행 → 벡터 생성 → DB Insert]**라는 복잡한 과정을 단 한 번에 수행하는 고수준 API입니다.
2. **`collection_name`**: DB 내에서 논리적인 그룹을 나눕니다. "이력서 전용 창고"라고 이름을 붙여주는 것과 같습니다.
3. **보안 관리 (`os.getenv`)**: `DATABASE_URL`을 환경 변수에서 가져옴으로써, 코드 내에 비밀번호가 노출되는 보안 사고를 원천 차단합니다.

---

## 4. 전체 파이프라인에서의 역할 (Workflow)

이 코드가 완료됨으로써 사용자의 이력서는 다음과 같은 상태가 됩니다.

1. **텍스트**: 사람이 읽을 수 있는 형태 (`page_content`)
2. **벡터**: AI가 의미로 검색할 수 있는 수치 형태 (`vector`)
3. **식별자**: 누구의 데이터인지 알 수 있는 정보 (`metadata: resume_id`)

이 세 가지가 결합되어 DB에 저장되면, 이후 **EXAONE 3.5** 모델은 사용자의 질문이 들어왔을 때 DB에서 가장 유사한 조각을 **초고속으로 검색(Semantic Retrieval)**하여 답변을 생성하게 됩니다.

---

## 💡 요약 및 기술 총평

| 단계                  | 적용 기술                 | 목적                                               |
| --------------------- | ------------------------- | -------------------------------------------------- |
| **환경 적응**   | `sys.path` 동적 제어    | 로컬/도커 환경 구분 없는 코드 실행                 |
| **데이터 포장** | `LangChain Document`    | AI 프레임워크 표준 규격 준수                       |
| **검색 최적화** | `Metadata Injection`    | 수만 명 중 특정 지원자 데이터만 즉시 필터링        |
| **영구 저장**   | `PGVector (PostgreSQL)` | 고차원 벡터의 안정적 저장 및 유사도 검색 엔진 구축 |

**최종 결론:**
이 코드는 이력서 분석 시스템의 **'지식 창고'**를 구축하는 마지막 퍼즐 조각입니다. 단순히 데이터를 쌓는 것이 아니라, **나중에 AI 면접관이 가장 정확한 근거를 신속하게 찾을 수 있도록 최적화된 상태로 저장**하는 고도의 설계가 반영되어 있습니다.
