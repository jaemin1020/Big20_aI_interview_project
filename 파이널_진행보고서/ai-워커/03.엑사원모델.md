논문에서 그래프 및 도표 첨부해야함

### 컨텍스트 길이 확장 및 성능 유지 (5page)

- **단계적 컨텍스트 확장**: K-EXAONE은 기본적으로 8K 토큰까지 프리트레이닝된 후, 두 단계에 걸쳐 컨텍스트 길이를 32K, 256K로 확장함. 각 단계에서 데이터 샘플링 비율을 조정하여 장문맥 학습 신호와 안정성을 균형 있게 반영함.
- **Rehearsal Dataset**: 장문맥 특화 학습 시 단기(짧은 문맥) 성능 저하를 방지하기 위해, 프리트레이닝 분포 및 기타 단기 데이터에서 고품질 샘플을 재사용하는 Rehearsal Dataset을 도입. 이 데이터셋은 8K→32K, 32K→256K 확장 단계 모두에 포함되며, 각 단계별로 비율을 조정하여 장문맥 신호와 단기 신호가 모두 반영되도록 설계됨. 이를 통해 컨텍스트 확장 후에도 단기 벤치마크 및 내부 검증 지표에서 성능 저하가 없음을 확인함.
- **Synthetic Reasoning Dataset**: 수학, 과학, 경쟁 프로그래밍 등 고난도 문제와 중간 추론(Intermediate Reasoning)을 포함하는 합성 데이터셋을 추가로 학습. 이 데이터셋은 최종 답뿐 아니라 중간 추론 패턴까지 학습하도록 설계되어, 다단계 추론력과 일관성, 복잡한 문제 해결력을 강화함. 장문맥 학습 단계 전체에 걸쳐 이 데이터셋을 통합하여, 긴 입력에서도 추론 품질이 유지되도록 함.
- **Long-Document Dataset**: 장기 의존성 학습을 위해, 전체 문서 단위의 시퀀스를 한 번에 입력하는 Long-Document Dataset을 활용. 이 데이터셋은 문서 전체를 잘라내지 않고 통째로 입력하여, 모델이 장기적 토큰 간 관계를 학습하도록 유도함. 8K→32K 단계에서는 32K까지의 안정적 성능에 중점, 32K→256K 단계에서는 장문서 샘플 비중을 높여 256K까지의 장기 의존성 학습을 강화함.
- **Needle-In-A-Haystack(NIAH) 테스트**: 장문맥 정보 보존력 검증을 위해 NIAH 테스트를 반복적으로 실시. 이 테스트는 긴 입력 내에서 특정 정보를 얼마나 잘 기억하고 찾아내는지 평가하는 방식으로, 각 단계별로 모델이 목표 컨텍스트 길이에서 거의 완벽한 NIAH 성능을 달성할 때까지 학습을 반복함(그린라이트 기준).

### 포스트 트레이닝 및 정렬 (5~6page)

- **지도학습(SFT)**: 다양한 사용자 지시(instruction)에 따라 적절한 응답을 생성하도록 대규모 지도학습을 실시. 도메인별로 태스크를 분류하고, 각 도메인에 맞는 데이터 생성 방식 또는 전문가를 활용함. 한국어 특화 성능 강화를 위해 과기정통부, NIA, K-DATA 등에서 제공하는 공공 및 기관 데이터를 적극 활용함.
- **강화학습(RL)**: 수학, 코드, STEM, 지시이행 등 다양한 과제에 대해 verifiable reward(룰 기반+LLM 판정)를 활용해 RL을 수행. 오프폴리시 정책경사(truncated importance sampling), zero-variance filtering(동일 보상 샘플 제거), 그룹/글로벌 어드밴티지 정규화 등 최신 RL 기법을 적용. KL penalty는 제외하여 불필요한 계산을 줄이고 성능을 높임. RL 단계에서는 MoE 라우터를 고정(freeze)하여 안정성을 확보함.
- **Preference Learning**: RL 이후, 모델을 인간 선호에 더 잘 맞추기 위해 Preference Learning을 실시. GROUPER(Group-wise SimPER)라는 개선된 SimPER 변형을 도입, 그룹 단위로 여러 응답을 샘플링하고, 각 응답에 대해 다차원 평가 기준(룰 기반+루브릭 기반 생성 보상)을 결합하여 그룹 내 표준화 및 스케일링을 통해 선호도 정렬을 강화함.
- **실제 활용성 강화**: 에이전트 도구 사용, 웹서치, 요약/압축 서브에이전트 등 실제 환경에서의 활용성을 높이기 위한 다양한 기능을 도입. 예를 들어, 웹서치 시 요약 서브에이전트가 웹페이지를 요약해주고, 도구 호출 이력이 많아지면 트래젝토리 압축 서브에이전트가 전체 상호작용을 JSON 구조로 압축하여 맥락 효율성을 높임. 이 모든 서브에이전트는 K-EXAONE 기반으로 구현됨.

(모든 내용 출처: 5~6page)

### 평가 및 벤치마크 결과 (7~10, 18, 20page)

- **평가 카테고리 및 벤치마크**

  - K-EXAONE은 총 9개 카테고리(세계지식, 수학, 코딩, 에이전트 도구 사용, 지시이행, 장문맥 이해, 한국어, 다국어, 안전성)에서 다양한 공개 및 자체 벤치마크로 평가됨. (7page)
  - 주요 벤치마크: MMLU-PRO(세계지식), AIME/IMO/HMMT(수학), LIVECODEBENCH/TERMINAL-BENCH/SWE-BENCH(Coding), 2-BENCH/BROWSECOMP(Agentic Tool Use), IFBENCH/IFEVAL(Instruction Following), AA-LCR/OPENAI-MRCR(Long Context), KMMLU-PRO/KOBALT/CLICK/HRM8K/KO-LONGBENCH(한국어), MMMLU/WMT24(다국어), KGC-SAFETY/WILDJAILBREAK(안전성) 등. (7page)
- **Reasoning/Non-Reasoning 모드 성능**

  - Reasoning 모드에서 MMLU-PRO 83.8, AIME 92.8, LIVECODEBENCH V6 80.7, KOBALT 61.8, MMMLU 85.7, KGC-SAFETY 96.1 등 동급 오픈웨이트/상용 모델과 유사하거나 우수한 성적을 기록함. (8~10page)
  - Non-Reasoning 모드에서도 MMLU-PRO 81.0, LIVECODEBENCH V6 44.6, KOBALT 49.1, MMMLU 83.8, KGC-SAFETY 88.4 등 경쟁력 있는 결과를 보임. (9page)
  - Reasoning/Non-Reasoning 모드 모두에서 DeepSeek-V3.2, Qwen3-235B, gpt-oss-120b 등과 비교해 전반적으로 상위권 성능을 유지함. (8~10page)
- **한국어 및 다국어 성능**

  - 한국어 벤치마크(KMMLU-PRO, KOBALT, CLICK, HRM8K, KO-LONGBENCH)에서 Reasoning 모드 기준 KMMLU-PRO 67.3, KOBALT 61.8, CLICK 83.9, HRM8K 90.9, KO-LONGBENCH 86.8 등 고른 성적을 보임. (9page)
  - 다국어(MMMLU, WMT24)에서도 MMMLU 85.7, WMT24 90.5로, 언어별 편차 없이 균형 잡힌 성능을 달성함. (10, 20page)
  - 언어별 세부 성능(예: MMMLU KO 85.6, DE 85.1, ES 86.6, JA 85.5 등)도 고르게 나타남. (20page)
- **장문맥 이해 및 실용적 코딩**

  - 장문맥 벤치마크(AA-LCR, OPENAI-MRCR, KO-LONGBENCH)에서 Reasoning 모드 기준 AA-LCR 53.5, OPENAI-MRCR 52.3, KO-LONGBENCH 86.8 등 긴 입력에서도 정보 보존 및 추론력이 우수함을 입증함. (9page)
  - 실용적 코딩 평가(CODEUTILITYBENCH)에서 전작(EXAONE-4.0-32B) 대비 전체 점수 71.9→63.2로 향상, 특히 코드 이해/구현(Understanding/Implementation) 영역에서 큰 개선을 보임. (18page)
  - 다만, 코드 유지보수(Maintenance) 영역에서는 여전히 추가 개선 여지가 있음(66.0점). (18page)
- **안전성**

  - KGC-SAFETY(한국 민감성, 미래 위험 등 포함)에서 Safe Rate 96.1%로, 동급 모델 중 최고 수준의 안전성을 기록함. (22page)
- **요약**

  - K-EXAONE은 다양한 벤치마크에서 Reasoning/Non-Reasoning, 한국어/다국어, 장문맥/단문맥, 실용적 코딩, 안전성 등 모든 측면에서 동급 최고 수준의 성능과 균형 잡힌 결과를 보여줌.

(모든 내용 출처: 7~10, 18, 20, 22page)
