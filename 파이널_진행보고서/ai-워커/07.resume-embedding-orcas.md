
# 📄 [기술 보고서] AI 면접 시스템: RAG 기반 지능형 질문 생성 엔진

**일시:** 2026년 3월 1일
**대상:** AI 시스템 아키텍처 및 백엔드 개발 검토용
**주요 기술:** Python, LangChain, Celery, PostgreSQL(pgvector), EXAONE-3.5 LLM

---

# 1. 시스템 아키텍처 개요 (System Architecture)

본 시스템은 지원자의 이력서를 분석하여 벡터화하고, 이를 바탕으로 면접 단계에 맞는 최적의 질문을 실시간으로 생성하는 **오케스트레이션(Orchestration) 구조**를 가집니다.

## ✅ 핵심 구조

* **비동기 파이프라인**

  * Celery를 활용하여 무거운 GPU 연산(임베딩, LLM 추론)을 백그라운드에서 처리
  * API 응답 지연 최소화
* **RAG (Retrieval-Augmented Generation)**

  * 이력서 데이터를 의미 단위(Chunk)로 분할
  * 벡터 DB에 저장
  * 질문 생성 시 관련 정보를 즉시 검색하여 정확도 향상

---

# 2. 데이터 인입 파이프라인: 이력서 벡터화 (Resume Indexing)

이력서 데이터를 AI가 검색 가능한 형태로 변환하는 단계입니다.

---

## 2.1 주요 코드 분석 (`generate_resume_embeddings`)

```python
@shared_task(bind=True, name="tasks.resume_pipeline.generate_embeddings", queue='gpu_queue')
def generate_resume_embeddings(self, resume_id: int):
    # 1. 청킹(Chunking): 구조화된 데이터를 의미 단위로 분할
    chunks = chunk_resume(resume.structured_data)
  
    # 2. 임베딩(Embedding): 텍스트를 1024차원의 수치 벡터로 변환
    embedded_data = embed_chunks(chunks)
  
    # 3. 벡터 DB 저장: pgvector를 사용하여 검색 가능한 형태로 인덱싱
    store_embeddings(resume_id, embedded_data)
```

---

## 2.2 기술적 강점

### 🔹 리소스 최적화

* `gpu_queue` 전용 큐 사용
* CPU와 GPU 작업 분리
* 동시 처리량 증가 및 병목 현상 감소

### 🔹 데이터 정합성 관리

* `processing_status` 상태 추적

  * `processing → completed / failed`
* 실패 시 재처리 가능
* 시스템 안정성 확보

---

# 3. 지능형 질문 생성 엔진 (Question Generation)

면접의 흐름과 지원자의 특성(비전공자, 직무 전환자 등)을 고려하여 동적으로 질문을 생성합니다.

---

## 3.1 워크플로우 제어 로직

면접 단계는 `INTERVIEW_STAGES` 설정을 참조하여 동적으로 판별됩니다.

```python
# 비전공자/직무 전환자 여부에 따른 시나리오 분기
is_transition = check_if_transition(major, interview.position)
get_next_stage_func = get_next_stage_transition if is_transition else get_next_stage_normal
```

### ✔ 특징

* 지원자 특성 기반 분기 처리
* 면접 흐름의 유연성 확보
* 고정 질문 트리 구조 탈피

---

## 3.2 LangChain 기반 추론 체인 (LCEL)

단순 텍스트 생성이 아니라, 단계별 지침과 페르소나를 결합한 추론 체인을 구성했습니다.

```python
# LCEL(LangChain Expression Language) 문법 활용
prompt = PromptTemplate.from_template(PROMPT_TEMPLATE)
chain = prompt | llm | StrOutputParser()

# 실시간 지시사항 주입
final_content = chain.invoke({
    "context": context_text,
    "mode_instruction": "자기소개서 문장을 인용하여 질문을 시작하십시오.",
    "company_ideal": company_ideal
})
```

### ✔ 설계 포인트

* 실시간 Instruction Injection
* 회사 인재상 반영 가능
* 특정 단계(예: 가치관 질문)에서 자소서 인용 강제

---

## 3.3 응답 정제 및 가공 (Post-Processing)

LLM 출력의 불필요한 메타 문구 제거 및 UI 전달 포맷 정리

### 🔹 정규표현식 기반 패턴 제거

예:

* "질문은 다음과 같습니다"
* "아래와 같이 질문드립니다"

→ 자동 삭제

### 🔹 UI 전달 형식 구조화

```
[심층면접]
질문 내용
```

* 면접관 톤 유지
* 일관된 사용자 경험 제공

---

# 4. 안정성 및 성능 최적화 (Reliability & Performance)

---

## 4.1 메모리 관리 (Memory Management)

대규모 LLM 워커의 메모리 누수 방지를 위한 명시적 정리 수행

```python
gc.collect()  # 파이썬 가비지 컬렉션 강제 실행
if torch.cuda.is_available():
    torch.cuda.empty_cache()  # GPU 캐시 비우기
```

### ✔ 효과

* 장시간 실행 시 OOM 방지
* GPU 메모리 파편화 완화
* 워커 안정성 향상

---

## 4.2 장애 복구 로직 (Fallback Mechanism)

면접이 중단되지 않도록 설계된 이중 안전 장치

### 🔹 Retry 메커니즘

* 최대 3회 재시도 (`self.retry`)

### 🔹 Fallback 질문 자동 생성

* 모델 오류 발생 시
* 사전 정의된 시스템 공통 질문으로 대체

예:

```
"최근 수행한 프로젝트 중 가장 도전적이었던 경험을 말씀해 주세요."
```

→ 사용자 경험 단절 방지

---

# 5. 결론 및 향후 전망

본 시스템은 다음 기술을 결합하여 설계되었습니다.

* RAG 기반 정밀 검색
* 비동기 큐 시스템
* 동적 면접 시나리오 제어
* LLM 후처리 및 안정화 구조

## 🎯 현재 성과

* 비전공자 특화 질문 생성
* 자소서 기반 맞춤형 질문 생성
* 면접 단계별 동적 분기 구현 완료

## 🚀 향후 확장 가능성

* 실시간 감성 분석 레이어 추가

  * 답변 속도 분석
  * 음성 톤 분석
  * 감정 변화 감지
* 질문 난이도 및 압박 강도 조절
* 개인화된 피드백 자동 생성

---

# 📌 종합 평가

본 시스템은 단순 LLM 질의응답 구조를 넘어,

* **비동기 고성능 처리**
* **정교한 RAG 검색 구조**
* **면접 흐름 제어 오케스트레이션**
* **안정성 및 장애 복구 설계**

를 모두 포함한 **실서비스 수준의 AI 면접 플랫폼 백엔드 아키텍처**입니다.
