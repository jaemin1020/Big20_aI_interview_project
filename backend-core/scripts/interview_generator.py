"""
ì´ë ¥ì„œ ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸°
- BGE-M3 ëª¨ë¸ í™œìš©
- ê¸°ìˆ  ìŠ¤íƒ, ê²½ë ¥, í”„ë¡œì íŠ¸ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±
"""

from typing import List, Dict, Any, Optional
from sentence_transformers import SentenceTransformer
from sqlmodel import Session, select, text, and_
import sys
import os

# ìƒìœ„ ë””ë ‰í† ë¦¬ì˜ ëª¨ë“ˆ import
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

from database import engine
from models import Question, QuestionCategory, QuestionDifficulty
from scripts.resume_parser import ResumeParser


class InterviewQuestionGenerator:
    """ì´ë ¥ì„œ ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„±"""

    def __init__(self, model_name: str = 'BAAI/bge-m3'):
        """
        Args:
            model_name: ì‚¬ìš©í•  ì„ë² ë”© ëª¨ë¸ (ê¸°ë³¸: BGE-M3)
        """
        print(f"ğŸ”„ {model_name} ëª¨ë¸ ë¡œë”© ì¤‘...")
        self.model = SentenceTransformer(model_name)
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

    def generate_questions_from_resume(
        self,
        resume_data: Dict[str, Any],
        num_questions: int = 10,
        difficulty_distribution: Optional[Dict[str, int]] = None
    ) -> List[Dict[str, Any]]:
        """
        ì´ë ¥ì„œ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸ ìƒì„±

        Args:
            resume_data: íŒŒì‹±ëœ ì´ë ¥ì„œ ë°ì´í„°
            num_questions: ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜
            difficulty_distribution: ë‚œì´ë„ ë¶„í¬ (ì˜ˆ: {"easy": 2, "medium": 5, "hard": 3})

        Returns:
            ìƒì„±ëœ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        """

        # ê²½ë ¥ì— ë”°ë¥¸ ê¸°ë³¸ ë‚œì´ë„ ë¶„í¬ ì„¤ì •
        if difficulty_distribution is None:
            difficulty_distribution = self._get_default_difficulty_distribution(
                resume_data.get('experience_years', 0)
            )

        questions = []

        # 1. ê¸°ìˆ  ìŠ¤íƒ ê¸°ë°˜ ì§ˆë¬¸ (50%)
        tech_count = int(num_questions * 0.5)
        if resume_data.get('skills'):
            tech_questions = self._get_tech_based_questions(
                resume_data['skills'],
                tech_count,
                difficulty_distribution
            )
            questions.extend(tech_questions)

        # 2. í”„ë¡œì íŠ¸/ê²½í—˜ ê¸°ë°˜ ì§ˆë¬¸ (30%)
        exp_count = int(num_questions * 0.3)
        if resume_data.get('raw_text'):
            exp_questions = self._get_experience_based_questions(
                resume_data['raw_text'],
                exp_count
            )
            questions.extend(exp_questions)

        # 3. ì¼ë°˜ ì§ˆë¬¸ (20%)
        general_count = num_questions - len(questions)
        if general_count > 0:
            general_questions = self._get_general_questions(
                resume_data.get('experience_years', 0),
                general_count,
                difficulty_distribution
            )
            questions.extend(general_questions)

        # ì¤‘ë³µ ì œê±° ë° ê°œìˆ˜ ì¡°ì •
        unique_questions = self._remove_duplicates(questions)
        return unique_questions[:num_questions]

    def _get_default_difficulty_distribution(self, experience_years: int) -> Dict[str, int]:
        """ê²½ë ¥ì— ë”°ë¥¸ ê¸°ë³¸ ë‚œì´ë„ ë¶„í¬"""
        if experience_years == 0:
            # ì‹ ì…: ì‰¬ì›€ 60%, ë³´í†µ 30%, ì–´ë ¤ì›€ 10%
            return {"easy": 6, "medium": 3, "hard": 1}
        elif experience_years < 3:
            # ì£¼ë‹ˆì–´: ì‰¬ì›€ 30%, ë³´í†µ 50%, ì–´ë ¤ì›€ 20%
            return {"easy": 3, "medium": 5, "hard": 2}
        elif experience_years < 7:
            # ë¯¸ë“¤: ì‰¬ì›€ 20%, ë³´í†µ 50%, ì–´ë ¤ì›€ 30%
            return {"easy": 2, "medium": 5, "hard": 3}
        else:
            # ì‹œë‹ˆì–´: ì‰¬ì›€ 10%, ë³´í†µ 40%, ì–´ë ¤ì›€ 50%
            return {"easy": 1, "medium": 4, "hard": 5}

    def _get_tech_based_questions(
        self,
        skills: List[str],
        count: int,
        difficulty_dist: Dict[str, int]
    ) -> List[Dict[str, Any]]:
        """ê¸°ìˆ  ìŠ¤íƒ ê¸°ë°˜ ì§ˆë¬¸ ê²€ìƒ‰"""
        questions = []

        with Session(engine) as session:
            for skill in skills[:5]:  # ìƒìœ„ 5ê°œ ê¸°ìˆ ë§Œ
                # ê¸°ìˆ  ê´€ë ¨ ê²€ìƒ‰ ì¿¼ë¦¬
                query = f"{skill} ê¸°ìˆ  ë©´ì ‘ ì§ˆë¬¸ ê°œë… ì›ë¦¬"
                query_emb = self.model.encode(query, normalize_embeddings=True).tolist()

                # VectorDBì—ì„œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
                stmt = select(
                    Question,
                    text(f"embedding <=> '{query_emb}' AS distance")
                ).where(
                    and_(
                        Question.is_active == True,
                        Question.embedding.isnot(None)
                    )
                ).order_by(text("distance")).limit(2)

                results = session.exec(stmt).all()

                for result in results:
                    question = result[0]
                    similarity = 1 - result[1]

                    questions.append({
                        'id': question.id,
                        'content': question.content,
                        'category': question.category,
                        'difficulty': question.difficulty,
                        'similarity': similarity,
                        'source': f'ê¸°ìˆ : {skill}'
                    })

                if len(questions) >= count:
                    break

        return questions[:count]

    def _get_experience_based_questions(
        self,
        resume_text: str,
        count: int
    ) -> List[Dict[str, Any]]:
        """ê²½í—˜/í”„ë¡œì íŠ¸ ê¸°ë°˜ ì§ˆë¬¸ ê²€ìƒ‰"""
        questions = []

        # ì´ë ¥ì„œ ì „ì²´ í…ìŠ¤íŠ¸ë¡œ ìœ ì‚¬ ì§ˆë¬¸ ê²€ìƒ‰
        resume_emb = self.model.encode(resume_text, normalize_embeddings=True).tolist()

        with Session(engine) as session:
            stmt = select(
                Question,
                text(f"embedding <=> '{resume_emb}' AS distance")
            ).where(
                and_(
                    Question.is_active == True,
                    Question.embedding.isnot(None),
                    Question.category.in_([
                        QuestionCategory.EXPERIENCE,
                        QuestionCategory.PROJECT,
                        QuestionCategory.PROBLEM_SOLVING
                    ])
                )
            ).order_by(text("distance")).limit(count)

            results = session.exec(stmt).all()

            for result in results:
                question = result[0]
                similarity = 1 - result[1]

                questions.append({
                    'id': question.id,
                    'content': question.content,
                    'category': question.category,
                    'difficulty': question.difficulty,
                    'similarity': similarity,
                    'source': 'ê²½í—˜ ê¸°ë°˜'
                })

        return questions

    def _get_general_questions(
        self,
        experience_years: int,
        count: int,
        difficulty_dist: Dict[str, int]
    ) -> List[Dict[str, Any]]:
        """ì¼ë°˜ ì§ˆë¬¸ (ë‚œì´ë„ ê¸°ë°˜)"""
        questions = []

        # ë‚œì´ë„ ê²°ì •
        if experience_years < 2:
            target_difficulty = QuestionDifficulty.EASY
        elif experience_years < 5:
            target_difficulty = QuestionDifficulty.MEDIUM
        else:
            target_difficulty = QuestionDifficulty.HARD

        with Session(engine) as session:
            stmt = select(Question).where(
                and_(
                    Question.is_active == True,
                    Question.difficulty == target_difficulty
                )
            ).limit(count)

            results = session.exec(stmt).all()

            for question in results:
                questions.append({
                    'id': question.id,
                    'content': question.content,
                    'category': question.category,
                    'difficulty': question.difficulty,
                    'similarity': 0.0,
                    'source': f'ì¼ë°˜ ({target_difficulty})'
                })

        return questions

    def _remove_duplicates(self, questions: List[Dict[str, Any]]) -> List[Dict[str, Any]]:
        """ì¤‘ë³µ ì§ˆë¬¸ ì œê±°"""
        seen_ids = set()
        unique_questions = []

        for q in questions:
            if q['id'] not in seen_ids:
                seen_ids.add(q['id'])
                unique_questions.append(q)

        return unique_questions

    def generate_interview_report(
        self,
        resume_data: Dict[str, Any],
        questions: List[Dict[str, Any]]
    ) -> Dict[str, Any]:
        """ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„±"""

        # ì¹´í…Œê³ ë¦¬ë³„ ì§ˆë¬¸ ìˆ˜
        category_count = {}
        for q in questions:
            cat = q['category']
            category_count[cat] = category_count.get(cat, 0) + 1

        # ë‚œì´ë„ë³„ ì§ˆë¬¸ ìˆ˜
        difficulty_count = {}
        for q in questions:
            diff = q['difficulty']
            difficulty_count[diff] = difficulty_count.get(diff, 0) + 1

        return {
            'candidate_name': resume_data.get('name', 'Unknown'),
            'experience_years': resume_data.get('experience_years', 0),
            'skills': resume_data.get('skills', []),
            'total_questions': len(questions),
            'category_distribution': category_count,
            'difficulty_distribution': difficulty_count,
            'questions': questions
        }


# ==================== ì „ì²´ ì›Œí¬í”Œë¡œìš° ====================

def process_resume_and_generate_interview(
    resume_file_path: str,
    num_questions: int = 10
) -> Dict[str, Any]:
    """
    ì´ë ¥ì„œ ì²˜ë¦¬ ë° ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì „ì²´ ì›Œí¬í”Œë¡œìš°

    Args:
        resume_file_path: ì´ë ¥ì„œ íŒŒì¼ ê²½ë¡œ
        num_questions: ìƒì„±í•  ì§ˆë¬¸ ê°œìˆ˜

    Returns:
        ë©´ì ‘ ë¦¬í¬íŠ¸
    """

    print("=" * 60)
    print("ğŸ¯ ì´ë ¥ì„œ ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì‹œìŠ¤í…œ")
    print("=" * 60)

    # 1. ì´ë ¥ì„œ íŒŒì‹±
    print("\nğŸ“„ 1ë‹¨ê³„: ì´ë ¥ì„œ íŒŒì‹± ì¤‘...")
    parser = ResumeParser()
    resume_data = parser.parse_resume(resume_file_path)

    print(f"âœ… íŒŒì‹± ì™„ë£Œ!")
    print(f"   - ì´ë¦„: {resume_data.get('name', 'N/A')}")
    print(f"   - ê²½ë ¥: {resume_data.get('experience_years', 0)}ë…„")
    print(f"   - ê¸°ìˆ  ìŠ¤íƒ: {len(resume_data.get('skills', []))}ê°œ")

    # 2. ì§ˆë¬¸ ìƒì„±
    print("\nğŸ¯ 2ë‹¨ê³„: ë§ì¶¤í˜• ë©´ì ‘ ì§ˆë¬¸ ìƒì„± ì¤‘...")
    generator = InterviewQuestionGenerator()
    questions = generator.generate_questions_from_resume(
        resume_data,
        num_questions=num_questions
    )

    print(f"âœ… {len(questions)}ê°œ ì§ˆë¬¸ ìƒì„± ì™„ë£Œ!")

    # 3. ë¦¬í¬íŠ¸ ìƒì„±
    print("\nğŸ“Š 3ë‹¨ê³„: ë©´ì ‘ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘...")
    report = generator.generate_interview_report(resume_data, questions)

    print("âœ… ë¦¬í¬íŠ¸ ìƒì„± ì™„ë£Œ!")

    # 4. ê²°ê³¼ ì¶œë ¥
    print("\n" + "=" * 60)
    print("ğŸ“‹ ë©´ì ‘ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸")
    print("=" * 60)

    for i, q in enumerate(questions, 1):
        print(f"\n{i}. [{q['category']}] [{q['difficulty']}]")
        print(f"   {q['content'][:100]}...")
        print(f"   ì¶œì²˜: {q['source']} | ìœ ì‚¬ë„: {q['similarity']:.3f}")

    print("\n" + "=" * 60)
    print("ğŸ“Š í†µê³„")
    print("=" * 60)
    print(f"ì´ ì§ˆë¬¸ ìˆ˜: {report['total_questions']}")
    print(f"\nì¹´í…Œê³ ë¦¬ë³„:")
    for cat, count in report['category_distribution'].items():
        print(f"  - {cat}: {count}ê°œ")
    print(f"\në‚œì´ë„ë³„:")
    for diff, count in report['difficulty_distribution'].items():
        print(f"  - {diff}: {count}ê°œ")

    return report


# ==================== ì‚¬ìš© ì˜ˆì‹œ ====================

if __name__ == "__main__":
    import sys

    # ìƒ˜í”Œ ì´ë ¥ì„œ ìƒì„± ë° í…ŒìŠ¤íŠ¸
    print("ğŸš€ ì´ë ¥ì„œ ê¸°ë°˜ ë©´ì ‘ ì§ˆë¬¸ ìƒì„± í…ŒìŠ¤íŠ¸")

    # ìƒ˜í”Œ ì´ë ¥ì„œ ìƒì„±
    sample_text = """
ì´ë¦„: ê¹€ê°œë°œ
ì´ë©”ì¼: kim.dev@example.com
ì „í™”ë²ˆí˜¸: 010-1234-5678

[ê²½ë ¥]
ì´ ê²½ë ¥: 3ë…„

[ê¸°ìˆ  ìŠ¤íƒ]
- ë°±ì—”ë“œ: Python, FastAPI, Django, PostgreSQL
- í”„ë¡ íŠ¸ì—”ë“œ: React, TypeScript
- ì¸í”„ë¼: Docker, Kubernetes, AWS

[í”„ë¡œì íŠ¸ ê²½í—˜]
1. ì „ììƒê±°ë˜ í”Œë«í¼ ê°œë°œ
   - FastAPIë¥¼ ì‚¬ìš©í•œ REST API ì„œë²„ ê°œë°œ
   - PostgreSQL ë°ì´í„°ë² ì´ìŠ¤ ì„¤ê³„ ë° ìµœì í™”
"""

    sample_file = "test_resume.txt"
    with open(sample_file, 'w', encoding='utf-8') as f:
        f.write(sample_text)

    try:
        # ë©´ì ‘ ì§ˆë¬¸ ìƒì„±
        report = process_resume_and_generate_interview(
            sample_file,
            num_questions=10
        )

        print("\n" + "=" * 60)
        print("âœ… í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
        print("=" * 60)

    except Exception as e:
        print(f"\nâŒ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback
        traceback.print_exc()

    finally:
        # ìƒ˜í”Œ íŒŒì¼ ì‚­ì œ
        import os
        if os.path.exists(sample_file):
            os.remove(sample_file)
