import sys
import os
from sentence_transformers import SentenceTransformer
import numpy as np
import re
from typing import List, Dict, Any

# ìŠ¤í¬ë¦½íŠ¸ ì‹¤í–‰ ê²½ë¡œ ì„¤ì •
sys.path.append(os.path.dirname(os.path.dirname(os.path.abspath(__file__))))

class InterviewQuestionGenerator:
    """
    BGE-M3 ëª¨ë¸ì„ í™œìš©í•œ ë©´ì ‘ ì§ˆë¬¸ ë§¤ì¹­ ì‹œìŠ¤í…œ
    (ìƒì„±í˜• LLMì´ ì•„ë‹Œ, ê²€ìƒ‰ ê¸°ë°˜ì˜ ì§ˆë¬¸ ì¶”ì²œ ì‹œìŠ¤í…œ)
    """

    def __init__(self):
        print("ğŸ”„ ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìˆìŠµë‹ˆë‹¤... (BGE-M3)")
        self.model = SentenceTransformer('BAAI/bge-m3')
        print("âœ… ëª¨ë¸ ë¡œë“œ ì™„ë£Œ!")

        # ê°€ìƒì˜ ë©´ì ‘ ì§ˆë¬¸ ë°ì´í„°ë² ì´ìŠ¤ (ì‹¤ì œë¡œëŠ” DBì—ì„œ ê°€ì ¸ì™€ì•¼ í•¨)
        self.question_bank = [
            # Python
            "Pythonì˜ GIL(Global Interpreter Lock)ì— ëŒ€í•´ ì„¤ëª…í•˜ê³ , ì´ê²ƒì´ ë©€í‹°ìŠ¤ë ˆë”© ì„±ëŠ¥ì— ë¯¸ì¹˜ëŠ” ì˜í–¥ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "Pythonì˜ ë©”ëª¨ë¦¬ ê´€ë¦¬ ë©”ì»¤ë‹ˆì¦˜(GC, Reference Counting)ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "Decorator(ë°ì½”ë ˆì´í„°)ì˜ ë™ì‘ ì›ë¦¬ì™€ ì‚¬ìš© ì˜ˆì‹œë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "Generatorì™€ Iteratorì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "Pythonì˜ ë¹„ë™ê¸° í”„ë¡œê·¸ë˜ë°(asyncio)ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",

            # Web Framework (FastAPI/Django)
            "FastAPIì™€ Djangoì˜ ì£¼ìš” ì°¨ì´ì ì€ ë¬´ì—‡ì´ë©°, ì–´ë–¤ ìƒí™©ì—ì„œ FastAPIë¥¼ ì„ íƒí•˜ì‹œê² ìŠµë‹ˆê¹Œ?",
            "RESTful APIì˜ ë©±ë“±ì„±(Idempotency)ì— ëŒ€í•´ ì„¤ëª…í•˜ê³ , POSTì™€ PUTì˜ ì°¨ì´ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "Dependency Injection(ì˜ì¡´ì„± ì£¼ì…)ì´ FastAPIì—ì„œ ì–´ë–»ê²Œ í™œìš©ë˜ëŠ”ì§€ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "ORM(Object-Relational Mapping)ì˜ ì¥ë‹¨ì ê³¼ N+1 ë¬¸ì œ í•´ê²° ë°©ë²•ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "Middlewareì˜ ê°œë…ê³¼ ì›¹ í”„ë ˆì„ì›Œí¬ì—ì„œì˜ ì—­í• ì€ ë¬´ì—‡ì¸ê°€ìš”?",

            # Database (SQL/NoSQL)
            "RDBMSì™€ NoSQLì˜ ì°¨ì´ì ê³¼ ê°ê°ì˜ ì‚¬ìš© ì‚¬ë¡€ë¥¼ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "DB ì¸ë±ìŠ¤(Index)ì˜ ë™ì‘ ì›ë¦¬ì™€ ì¸ë±ìŠ¤ë¥¼ ì‚¬ìš©í–ˆì„ ë•Œì˜ ì¥ë‹¨ì ì„ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "íŠ¸ëœì­ì…˜ì˜ ACID ì†ì„±ì— ëŒ€í•´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "SQL Injection ê³µê²©ì´ë€ ë¬´ì—‡ì´ë©°, ì´ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ë°©ë²•ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì •ê·œí™”(Normalization)ì™€ ë¹„ì •ê·œí™”(Denormalization)ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",

            # CS / Infra
            "Dockerì™€ VM(Virtual Machine)ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "CI/CD íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ê²½í—˜ì´ ìˆë‹¤ë©´, ì–´ë–¤ ë„êµ¬ë¥¼ ì‚¬ìš©í–ˆê³  ì–´ë–¤ ê³¼ì •ì„ ìë™í™”í–ˆë‚˜ìš”?",
            "í”„ë¡œì„¸ìŠ¤(Process)ì™€ ìŠ¤ë ˆë“œ(Thread)ì˜ ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "TCPì™€ UDPì˜ ì°¨ì´ì ì„ ì‹ ë¢°ì„± ê´€ì ì—ì„œ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "CORS(Cross-Origin Resource Sharing) ì´ìŠˆë€ ë¬´ì—‡ì´ë©°, ì–´ë–»ê²Œ í•´ê²°í•˜ë‚˜ìš”?",

            # ì¸ì„±/í˜‘ì—…
            "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ ê·¸ ê³¼ì •ì—ì„œ ì–´ë–»ê²Œ ë¬¸ì œë¥¼ í•´ê²°í–ˆëŠ”ì§€ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "íŒ€ì›ê³¼ì˜ ê°ˆë“±ì´ ë°œìƒí–ˆì„ ë•Œ ì–´ë–»ê²Œ í•´ê²°í•˜ì‹œë‚˜ìš”?",
            "ìƒˆë¡œìš´ ê¸°ìˆ ì„ ìŠµë“í•˜ëŠ” ìì‹ ë§Œì˜ ë…¸í•˜ìš°ê°€ ìˆë‚˜ìš”?",
            "ì½”ë“œ ë¦¬ë·°ë¥¼ í•  ë•Œ ê°€ì¥ ì¤‘ìš”í•˜ê²Œ ìƒê°í•˜ëŠ” ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ì‹¤íŒ¨í–ˆë˜ ê²½í—˜ì´ ìˆë‹¤ë©´, ê·¸ë¡œë¶€í„° ë¬´ì—‡ì„ ë°°ì› ë‚˜ìš”?"
        ]

        # ì§ˆë¬¸ DB ë¯¸ë¦¬ ì„ë² ë”©
        print("ğŸ”„ ì§ˆë¬¸ ë°ì´í„°ë² ì´ìŠ¤ ì„ë² ë”© ì¤‘...")
        self.question_embeddings = self.model.encode(self.question_bank, normalize_embeddings=True)
        print(f"âœ… {len(self.question_bank)}ê°œì˜ ì§ˆë¬¸ ë°ì´í„°ë¥¼ ì¤€ë¹„í–ˆìŠµë‹ˆë‹¤.")

    def analyze_text(self, text: str) -> Dict[str, Any]:
        """ì…ë ¥ í…ìŠ¤íŠ¸(ì´ë ¥ì„œ/ìê¸°ì†Œê°œ) ë¶„ì„"""

        # ê°„ë‹¨í•œ í‚¤ì›Œë“œ ì¶”ì¶œ (ë¹„íš¨ìœ¨ì ì´ì§€ë§Œ ë°ëª¨ìš©)
        keywords = ['Python', 'Django', 'FastAPI', 'Java', 'Spring', 'Docker', 'AWS', 'SQL', 'React']
        found_keywords = [k for k in keywords if k.lower() in text.lower()]

        return {
            'length': len(text),
            'keywords': found_keywords,
            'summary': text[:50] + "..." if len(text) > 50 else text
        }

    def generate_questions(self, input_text: str, top_k: int = 3) -> List[Dict[str, Any]]:
        """ì…ë ¥ í…ìŠ¤íŠ¸ì™€ ê´€ë ¨ëœ ë©´ì ‘ ì§ˆë¬¸ ê²€ìƒ‰"""

        query_emb = self.model.encode([input_text], normalize_embeddings=True)[0]

        # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
        similarities = np.dot(self.question_embeddings, query_emb)

        # ìƒìœ„ top_kê°œ ì¶”ì¶œ
        top_indices = np.argsort(similarities)[::-1][:top_k]

        results = []
        for idx in top_indices:
            results.append({
                'question': self.question_bank[idx],
                'similarity': float(similarities[idx])
            })

        return results

def clear_screen():
    os.system('cls' if os.name == 'nt' else 'clear')

def main():
    clear_screen()
    print("=" * 60)
    print("ğŸ¤– ë©´ì ‘ ì§ˆë¬¸ ìƒì„±ê¸° (Interview Question Generator)")
    print("   Powered by BGE-M3 (Retrieval-based)")
    print("=" * 60)
    print("ì´ë ¥ì„œ ë‚´ìš©ì´ë‚˜ ìê¸°ì†Œê°œ, í˜¹ì€ ê¸°ìˆ  ìŠ¤íƒì„ ì…ë ¥í•˜ë©´")
    print("ì¤€ë¹„ëœ ì§ˆë¬¸ DBì—ì„œ ê°€ì¥ ì í•©í•œ ë©´ì ‘ ì§ˆë¬¸ì„ ì°¾ì•„ì¤ë‹ˆë‹¤.")
    print("-" * 60)

    generator = InterviewQuestionGenerator()

    while True:
        print("\n" + "=" * 60)
        print("í…ìŠ¤íŠ¸ë¥¼ ì…ë ¥í•˜ì„¸ìš” (ì¢…ë£Œí•˜ë ¤ë©´ 'q' ì…ë ¥):")
        print("ì˜ˆì‹œ: 'ì €ëŠ” íŒŒì´ì¬ê³¼ FastAPIë¥¼ ì£¼ë¡œ ì‚¬ìš©í–ˆê³  ë°±ì—”ë“œ ê°œë°œ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤.'")

        user_input = input("\nì…ë ¥ > ").strip()

        if user_input.lower() == 'q':
            print("ğŸ‘‹ í”„ë¡œê·¸ë¨ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
            break

        if not user_input:
            continue

        print("\nğŸ”„ ë¶„ì„ ë° ì§ˆë¬¸ ê²€ìƒ‰ ì¤‘...")

        # 1. í…ìŠ¤íŠ¸ ë¶„ì„
        analysis = generator.analyze_text(user_input)
        if analysis['keywords']:
            print(f"ğŸ’¡ ê°ì§€ëœ í‚¤ì›Œë“œ: {', '.join(analysis['keywords'])}")

        # 2. ì§ˆë¬¸ ë§¤ì¹­
        questions = generator.generate_questions(user_input, top_k=5)

        print(f"\nğŸ¯ '{analysis['summary']}'ì— ëŒ€í•œ ì¶”ì²œ ë©´ì ‘ ì§ˆë¬¸:")
        for i, item in enumerate(questions, 1):
            score = item['similarity']
            # ìœ ì‚¬ë„ê°€ ë„ˆë¬´ ë‚®ìœ¼ë©´ í‘œì‹œ ì•ˆ í•¨ (ì˜µì…˜)
            relevance = ""
            if score > 0.6: relevance = "(ë§¤ìš° ê´€ë ¨ë¨)"
            elif score > 0.4: relevance = "(ê´€ë ¨ë¨)"
            else: relevance = "(ì•½ê°„ ê´€ë ¨ë¨)"

            print(f"\n{i}. {item['question']}")
            print(f"   [ìœ ì‚¬ë„: {score:.4f} {relevance}]")

if __name__ == "__main__":
    main()
