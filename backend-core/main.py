from fastapi import FastAPI, Depends, HTTPException, status, UploadFile, File
from fastapi.security import OAuth2PasswordRequestForm
from fastapi.middleware.cors import CORSMiddleware
from sqlmodel import Session, select
from celery import Celery
from datetime import datetime, timedelta
from typing import List
import logging
import os
import shutil
from pathlib import Path

# DB ì„¤ì •
from database import init_db, get_session
# DB í…Œì´ë¸” ëª¨ë“ˆ ì„í¬íŠ¸
from models import (
    User, UserCreate, UserLogin, Company,
    Interview, InterviewCreate, InterviewResponse, InterviewStatus,
    Question, QuestionCategory, QuestionDifficulty,
    Transcript, TranscriptCreate, Speaker,
    EvaluationReport, EvaluationReportResponse,
    Resume
)
# ì¸ì¦ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
# ì¸ì¦ ê´€ë ¨ ëª¨ë“ˆ ì„í¬íŠ¸
from auth import get_password_hash, verify_password, create_access_token, get_current_user
from utils.common import validate_email, validate_username  # ìœ íš¨ì„± ê²€ì‚¬ ì¶”ê°€

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger("Backend-Core")

app = FastAPI(title="AI Interview Backend v2.0")

# DB ì´ˆê¸°í™”
@app.on_event("startup")
def on_startup():
    init_db()
    logger.info("âœ… Database initialized with new schema")

# CORS ì„¤ì •
ALLOWED_ORIGINS = os.getenv("ALLOWED_ORIGINS", "http://localhost:3000").split(",")
app.add_middleware(
    CORSMiddleware,
    allow_origins=ALLOWED_ORIGINS,
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# Company Router ë“±ë¡
from routes.companies import router as companies_router
app.include_router(companies_router)

# STT Router ë“±ë¡
from routes.stt import router as stt_router
app.include_router(stt_router)

# Celery ì„¤ì •
celery_app = Celery("ai_worker", broker="redis://redis:6379/0", backend="redis://redis:6379/0")

# ==================== Auth Endpoints ====================
# íšŒì›ê°€ì…
@app.post("/register")
async def register(user_data: UserCreate, db: Session = Depends(get_session)):
    # 1. ìœ íš¨ì„± ê²€ì‚¬ (ê¸¸ì´ ë° í¬ë§·)
    if not validate_username(user_data.username):
        raise HTTPException(
            status_code=400, 
            detail="ì•„ì´ë””ëŠ” 4~12ìì˜ ì˜ë¬¸ ì†Œë¬¸ì, ìˆ«ì, ë°‘ì¤„(_)ë§Œ ì‚¬ìš© ê°€ëŠ¥í•©ë‹ˆë‹¤."
        )
    
    if not validate_email(user_data.email):
        raise HTTPException(status_code=400, detail="ìœ íš¨í•˜ì§€ ì•Šì€ ì´ë©”ì¼ í˜•ì‹ì…ë‹ˆë‹¤.")

    # 2. ì¤‘ë³µ í™•ì¸
    stmt = select(User).where(
        (User.username == user_data.username) | (User.email == user_data.email)
    )
    existing_user = db.exec(stmt).first()
    if existing_user:
        raise HTTPException(status_code=400, detail="Username or email already exists")
    
    # ìƒˆ ì‚¬ìš©ì ìƒì„±
    new_user = User(
        email=user_data.email,
        username=user_data.username,
        role=user_data.role,
        password_hash=get_password_hash(user_data.password),
        full_name=user_data.full_name
    )
    db.add(new_user)
    db.commit()
    db.refresh(new_user)
    
    logger.info(f"New user registered: {new_user.username} ({new_user.role})")
    return {"id": new_user.id, "username": new_user.username, "email": new_user.email}

# ë¡œê·¸ì¸
@app.post("/token")
async def login(form_data: OAuth2PasswordRequestForm = Depends(), db: Session = Depends(get_session)):
    # ì‚¬ìš©ì ì¸ì¦
    stmt = select(User).where(User.username == form_data.username)
    user = db.exec(stmt).first()
    # ë¹„ë°€ë²ˆí˜¸ í™•ì¸
    if not user or not verify_password(form_data.password, user.password_hash):
        raise HTTPException(
            status_code=status.HTTP_401_UNAUTHORIZED,
            detail="Incorrect username or password"
        )
    # í† í° ìƒì„±
    access_token = create_access_token(data={"sub": user.username})
    logger.info(f"User logged in: {user.username}")
    return {"access_token": access_token, "token_type": "bearer"}

# ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ
@app.get("/users/me")
async def read_users_me(current_user: User = Depends(get_current_user)):
    return current_user

# ==================== Interview Endpoints ====================
# ë©´ì ‘ ìƒì„±
@app.post("/interviews", response_model=InterviewResponse)
async def create_interview(
    interview_data: InterviewCreate,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ë©´ì ‘ ì„¸ì…˜ ìƒì„± ë° ì§ˆë¬¸ ìƒì„±"""
    
    # 1. Interview ë ˆì½”ë“œ ìƒì„± (ìƒíƒœ: SCHEDULED)
    new_interview = Interview(
        candidate_id=current_user.id,
        position=interview_data.position,
        company_id=interview_data.company_id,
        status=InterviewStatus.SCHEDULED,
        scheduled_time=interview_data.scheduled_time,
        start_time=datetime.utcnow()
    )
    # DBì— ì €ì¥
    db.add(new_interview)
    db.commit()
    db.refresh(new_interview)
    
    logger.info(f"Interview created: ID={new_interview.id}, Position={new_interview.position}")
    
    # 2. AI ì§ˆë¬¸ ìƒì„±
    # Backendê°€ ì§ì ‘ LLMì„ ëŒë¦¬ì§€ ì•Šìœ¼ë¯€ë¡œ, Celery Taskë¥¼ í˜¸ì¶œí•©ë‹ˆë‹¤.
    generated_questions = []
    
    try:
        logger.info("Requesting question generation from AI-Worker...")
        # Celery íƒœìŠ¤í¬ í˜¸ì¶œ (ìµœëŒ€ 90ì´ˆ ëŒ€ê¸° - ëª¨ë¸ ë¡œë”© ì‹œê°„ ê³ ë ¤)
        task = celery_app.send_task(
            "tasks.question_generator.generate_questions",
            args=[interview_data.position, new_interview.id, 5]
        )
        # ë™ê¸°ì ìœ¼ë¡œ ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦¼ (UXìƒ ì§ˆë¬¸ì´ ë°”ë¡œ í•„ìš”í•¨)
        generated_questions = task.get(timeout=180)
        logger.info(f"Received {len(generated_questions)} questions from AI-Worker")
        
    except Exception as e:
        logger.warning(f"AI-Worker question generation failed ({e}). Using fallback questions.")
        # ì‹¤íŒ¨ ì‹œ í´ë°± ì§ˆë¬¸ ìƒì„±
        generated_questions = [
            f"{interview_data.position} ì§ë¬´ì— ì§€ì›í•˜ê²Œ ëœ ë™ê¸°ë¥¼ êµ¬ì²´ì ìœ¼ë¡œ ë§ì”€í•´ì£¼ì„¸ìš”.",
            "ê°€ì¥ ë„ì „ì ì´ì—ˆë˜ í”„ë¡œì íŠ¸ ê²½í—˜ê³¼ ê·¸ ê³¼ì •ì—ì„œ ì–»ì€ êµí›ˆì€ ë¬´ì—‡ì¸ê°€ìš”?",
            f"{interview_data.position}ë¡œì„œ ë³¸ì¸ì˜ ê°€ì¥ í° ê°•ì ê³¼ ë³´ì™„í•˜ê³  ì‹¶ì€ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?",
            "ê°ˆë“± ìƒí™©ì„ í•´ê²°í–ˆë˜ êµ¬ì²´ì ì¸ ì‚¬ë¡€ê°€ ìˆë‹¤ë©´ ì„¤ëª…í•´ì£¼ì„¸ìš”.",
            "í–¥í›„ 5ë…„ ë’¤ì˜ ì»¤ë¦¬ì–´ ëª©í‘œëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
        ]

    # 3. Questions ë° Transcript í…Œì´ë¸”ì— ì €ì¥
    try:
        for i, q_text in enumerate(generated_questions):
            # 3-1. ì§ˆë¬¸ ì€í–‰ì— ì €ì¥
            question = Question(
                content=q_text,
                category=QuestionCategory.TECHNICAL if i < 3 else QuestionCategory.BEHAVIORAL,
                difficulty=QuestionDifficulty.MEDIUM,
                rubric_json={
                    "criteria": ["êµ¬ì²´ì„±", "ì§ë¬´ ì í•©ì„±", "ë…¼ë¦¬ë ¥"], 
                    "weight": {"content": 0.5, "communication": 0.5}
                },
                position=interview_data.position
            )
            db.add(question)
            db.commit()
            db.refresh(question)
            
            # 3-2. Transcriptì— AI ë°œí™”ë¡œ ê¸°ë¡
            transcript = Transcript(
                interview_id=new_interview.id,
                speaker=Speaker.AI,
                text=q_text,
                question_id=question.id,
                order=i
            )
            db.add(transcript)
        
        # ë©´ì ‘ ìƒíƒœ ì—…ë°ì´íŠ¸: LIVE
        new_interview.status = InterviewStatus.LIVE
        db.add(new_interview)
        db.commit()
        db.refresh(new_interview)
        
    except Exception as e:
        logger.error(f"Failed to save questions: {e}")
        # ì—ëŸ¬ ë°œìƒ ì‹œì—ë„ ë©´ì ‘ ì„¸ì…˜ì€ ë°˜í™˜ (ë¹ˆ ì§ˆë¬¸ ëª©ë¡ì¼ ìˆ˜ ìˆìŒ)
    
    return InterviewResponse(
        id=new_interview.id,
        candidate_id=new_interview.candidate_id,
        position=new_interview.position,
        status=new_interview.status,
        start_time=new_interview.start_time,
        end_time=new_interview.end_time,
        overall_score=new_interview.overall_score
    )

# ==================== Question Endpoints ====================

# ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ
@app.get("/interviews/{interview_id}/questions")
async def get_interview_questions(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ë©´ì ‘ì˜ ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ (Transcriptì—ì„œ AI ë°œí™”ë§Œ í•„í„°ë§) - Redis ìºì‹± ì ìš©"""
    from utils.redis_cache import get_cached_interview_questions, cache_interview_questions
    
    # 1. ìºì‹œ ì¡°íšŒ
    cached_questions = get_cached_interview_questions(interview_id)
    if cached_questions is not None:
        logger.info(f"âœ… Returning cached questions for interview {interview_id}")
        return cached_questions
    
    # 2. ìºì‹œ ë¯¸ìŠ¤ - DB ì¡°íšŒ
    stmt = select(Transcript).where(
        Transcript.interview_id == interview_id,
        Transcript.speaker == Speaker.AI
    ).order_by(Transcript.order)
    
    transcripts = db.exec(stmt).all()
    
    questions = [
        {
            "id": t.question_id,
            "content": t.text,
            "order": t.order,
            "timestamp": t.timestamp.isoformat() if t.timestamp else None
        }
        for t in transcripts
    ]
    
    # 3. ìºì‹œ ì €ì¥
    cache_interview_questions(interview_id, questions)
    logger.info(f"ğŸ’¾ Cached {len(questions)} questions for interview {interview_id}")
    
    return questions

# ==================== Transcript Endpoints ====================

# ëŒ€í™” ê¸°ë¡ ì €ì¥
@app.post("/transcripts")
async def create_transcript(
    transcript_data: TranscriptCreate,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ì‹¤ì‹œê°„ ëŒ€í™” ê¸°ë¡ ì €ì¥ (STT ê²°ê³¼)"""
    
    transcript = Transcript(
        interview_id=transcript_data.interview_id,
        speaker=transcript_data.speaker,
        text=transcript_data.text,
        question_id=transcript_data.question_id
    )
    db.add(transcript)
    db.commit()
    db.refresh(transcript)
    
    logger.info(f"Transcript saved: Interview={transcript.interview_id}, Speaker={transcript.speaker}")
    
    # ì‚¬ìš©ì ë‹µë³€ì¸ ê²½ìš° AI í‰ê°€ ìš”ì²­
    if transcript.speaker == Speaker.USER:
        # í•´ë‹¹ ì§ˆë¬¸ ì¡°íšŒ
        question = db.get(Question, transcript.question_id)
        if question:
            celery_app.send_task(
                "tasks.evaluator.analyze_answer",
                args=[
                    transcript.id,
                    question.content,
                    transcript.text,
                    question.rubric_json,
                    question.id  # ì§ˆë¬¸ ID ì¶”ê°€ (í‰ê·  ì ìˆ˜ ì—…ë°ì´íŠ¸ìš©)
                ]
            )
            logger.info(f"Evaluation task sent for transcript {transcript.id}")
    
    return {"id": transcript.id, "status": "saved"}

# ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
@app.get("/interviews/{interview_id}/transcripts")
async def get_interview_transcripts(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ë©´ì ‘ì˜ ì „ì²´ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ"""
    stmt = select(Transcript).where(
        Transcript.interview_id == interview_id
    ).order_by(Transcript.timestamp)
    
    transcripts = db.exec(stmt).all()
    
    return [
        {
            "id": t.id,
            "speaker": t.speaker,
            "text": t.text,
            "timestamp": t.timestamp,
            "sentiment_score": t.sentiment_score,
            "emotion": t.emotion
        }
        for t in transcripts
    ]

# ==================== Evaluation Endpoints ====================

# ë©´ì ‘ ì™„ë£Œ ì²˜ë¦¬ ë° ìµœì¢… í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±
@app.post("/interviews/{interview_id}/complete")
async def complete_interview(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ë©´ì ‘ ì¢…ë£Œ ë° ìµœì¢… í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„±"""
    
    interview = db.get(Interview, interview_id)
    if not interview:
        raise HTTPException(status_code=404, detail="Interview not found")
    
    # ë©´ì ‘ ì¢…ë£Œ ì²˜ë¦¬
    interview.status = InterviewStatus.COMPLETED
    interview.end_time = datetime.utcnow()
    db.add(interview)
    db.commit()
    
    # í‰ê°€ ë¦¬í¬íŠ¸ ìƒì„± íƒœìŠ¤í¬ ì „ë‹¬
    celery_app.send_task(
        "tasks.evaluator.generate_final_report",
        args=[interview_id]
    )
    
    logger.info(f"Interview {interview_id} completed. Report generation started.")
    return {"status": "completed", "interview_id": interview_id}

@app.get("/interviews/{interview_id}/report", response_model=EvaluationReportResponse)
async def get_evaluation_report(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """í‰ê°€ ë¦¬í¬íŠ¸ ì¡°íšŒ"""
    stmt = select(EvaluationReport).where(
        EvaluationReport.interview_id == interview_id
    )
    report = db.exec(stmt).first()
    
    if not report:
        raise HTTPException(status_code=404, detail="Report not yet available")
    
    return report

# ==================== Resume Endpoints ====================

# ì—…ë¡œë“œ ë””ë ‰í† ë¦¬ ì„¤ì •
UPLOAD_DIR = Path("./uploads/resumes")
UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

@app.post("/resumes/upload")
async def upload_resume(
    file: UploadFile = File(...),
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ì´ë ¥ì„œ íŒŒì¼ ì—…ë¡œë“œ (PDF, DOC, DOCX)"""
    
    # íŒŒì¼ í™•ì¥ì ê²€ì¦
    allowed_extensions = [".pdf", ".doc", ".docx"]
    file_ext = Path(file.filename).suffix.lower()
    if file_ext not in allowed_extensions:
        raise HTTPException(
            status_code=400, 
            detail=f"Unsupported file type. Allowed: {', '.join(allowed_extensions)}"
        )
    
    # íŒŒì¼ ì €ì¥ ê²½ë¡œ ìƒì„± (candidate_id_timestamp_filename)
    timestamp = datetime.utcnow().strftime("%Y%m%d_%H%M%S")
    safe_filename = f"{current_user.id}_{timestamp}_{file.filename}"
    file_path = UPLOAD_DIR / safe_filename
    
    try:
        # íŒŒì¼ ì €ì¥
        with file_path.open("wb") as buffer:
            shutil.copyfileobj(file.file, buffer)
        
        # Resume ë ˆì½”ë“œ ìƒì„±
        new_resume = Resume(
            candidate_id=current_user.id,
            file_name=file.filename,
            file_path=str(file_path),
            file_size=file_path.stat().st_size,
            processing_status="pending"
        )
        db.add(new_resume)
        db.commit()
        db.refresh(new_resume)
        
        logger.info(f"Resume uploaded: ID={new_resume.id}, User={current_user.username}, File={file.filename}")
        
        # Celery íƒœìŠ¤í¬ë¡œ ì´ë ¥ì„œ íŒŒì‹± ë° êµ¬ì¡°í™” ì‘ì—… ì „ë‹¬
        celery_app.send_task(
            "parse_resume_pdf",
            args=[new_resume.id, str(file_path)]
        )
        logger.info(f"Resume parsing task sent for ID={new_resume.id}")
        
        return {
            "id": new_resume.id,
            "file_name": new_resume.file_name,
            "file_size": new_resume.file_size,
            "status": "uploaded",
            "message": "Resume uploaded successfully. Processing will begin shortly."
        }
        
    except Exception as e:
        logger.error(f"Resume upload failed: {e}")
        # ì‹¤íŒ¨ ì‹œ íŒŒì¼ ì‚­ì œ
        if file_path.exists():
            file_path.unlink()
        raise HTTPException(status_code=500, detail="File upload failed")

# ==================== Recruiter Endpoints ====================

# ì „ì²´ ì¸í„°ë·° ëª©ë¡ ì¡°íšŒ
@app.get("/interviews")
async def get_all_interviews(
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """ì „ì²´ ì¸í„°ë·° ëª©ë¡ ì¡°íšŒ (ë¦¬í¬ë£¨í„°ìš©)"""
    
    # ê¶Œí•œ ì²´í¬: recruiter ë˜ëŠ” adminë§Œ ì ‘ê·¼ ê°€ëŠ¥
    if current_user.role not in ["recruiter", "admin"]:
        # candidateëŠ” ìì‹ ì˜ ì¸í„°ë·°ë§Œ ì¡°íšŒ ê°€ëŠ¥
        stmt = select(Interview).where(
            Interview.candidate_id == current_user.id
        ).order_by(Interview.created_at.desc())
    else:
        # recruiter/adminì€ ì „ì²´ ì¡°íšŒ
        stmt = select(Interview).order_by(Interview.created_at.desc())
    
    interviews = db.exec(stmt).all()
    
    # ì‘ë‹µ ë°ì´í„° êµ¬ì„± (candidate ì •ë³´ í¬í•¨)
    result = []
    for interview in interviews:
        candidate = db.get(User, interview.candidate_id)
        result.append({
            "id": interview.id,
            "candidate_id": interview.candidate_id,
            "candidate_name": candidate.full_name if candidate else "Unknown",
            "position": interview.position,
            "status": interview.status,
            "created_at": interview.created_at,
            "start_time": interview.start_time,
            "end_time": interview.end_time,
            "overall_score": interview.overall_score
        })
    
    logger.info(f"Interviews list requested by {current_user.username} ({current_user.role}): {len(result)} records")
    return result

# ==================== Health Check ====================

# ì„œë²„ ìƒíƒœ í™•ì¸
@app.get("/")
async def root():
    return {
        "service": "AI Interview Backend v2.0",
        "status": "running",
        "database": "PostgreSQL with pgvector",
        "features": ["real-time STT", "emotion analysis", "AI evaluation"]
    }

if __name__ == "__main__":
    import uvicorn
    uvicorn.run("main:app", host="0.0.0.0", port=8000, reload=True)