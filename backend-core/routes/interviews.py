from fastapi import APIRouter, Depends, HTTPException, status
from sqlmodel import Session, select, text
from datetime import datetime, timezone, timedelta

# KST (Korea Standard Time) ì„¤ì •
KST = timezone(timedelta(hours=9))

def get_kst_now():
    return datetime.now(KST).replace(tzinfo=None)

from typing import List
import logging
import os
import base64
import json
from pathlib import Path

from database import get_session
from db_models import (
    User, Interview, InterviewCreate, InterviewResponse, InterviewStatus,
    Question, QuestionCategory, QuestionDifficulty,
    Transcript, TranscriptCreate, Speaker,
    EvaluationReport, EvaluationReportResponse
)
from utils.auth_utils import get_current_user
from utils.redis_cache import redis_client

router = APIRouter(prefix="/interviews", tags=["interviews"])
logger = logging.getLogger("Interview-Router")
logger.setLevel(logging.INFO)

# Celery
from celery_app import celery_app

# TTS ì˜¤ë””ì˜¤ ì €ì¥ ë””ë ‰í† ë¦¬ (ë°±ì—”ë“œì™€ ai-worker ê³µìœ  ë³¼ë¥¨)
TTS_UPLOAD_DIR = Path("/app/uploads/tts")
TTS_UPLOAD_DIR.mkdir(parents=True, exist_ok=True)

# ë°±ì—”ë“œ ì™¸ë¶€ URL (VITE_API_URL í™˜ê²½ë³€ìˆ˜ ì‚¬ìš© ë¶ˆê°€ ì‹œ ê¸°ë³¸ê°’)
BACKEND_PUBLIC_URL = os.getenv("BACKEND_PUBLIC_URL", "http://localhost:8000")

def _fire_tts_for_question(question_id: int, question_text: str) -> None:
    """ì„¤ëª…:
        ì§ˆë¬¸ì— ëŒ€í•œ TTS íƒœìŠ¤í¬ë¥¼ ì‹¤í–‰í•˜ê³  ìƒì„±ëœ WAV íŒŒì¼ì„ ê³µìœ  ë³¼ë¥¨(uploads/tts/)ì— ì €ì¥í•©ë‹ˆë‹¤.
        ë¬¸ì¥ ë‚´ì˜ [ë‹¨ê³„] íƒœê·¸ë¥¼ ìë™ìœ¼ë¡œ ì œê±°í•˜ì—¬ í•©ì„±í•˜ë©°, ì´ë¯¸ íŒŒì¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš° ì¤‘ë³µ ìƒì„±ì„ ë°©ì§€í•©ë‹ˆë‹¤.
    """
    filename = f"q_{question_id}.wav"
    filepath = TTS_UPLOAD_DIR / filename

    # ì´ë¯¸ ìƒì„±ëœ íŒŒì¼ì´ë©´ ìŠ¤í‚µ
    if filepath.exists():
        return

    # [Idempotency] Redis ë¶„ì‚° ë½ ì²´í¬ (ì¤‘ë³µ ìš”ì²­ ë°©ì§€)
    if redis_client:
        lock_key = f"lock:tts:{question_id}"
        if redis_client.get(lock_key):
            logger.debug(f"ğŸ›‘ [TTS] ìš”ì²­ ìŠ¤í‚µ (ì´ë¯¸ ì²˜ë¦¬ ì¤‘): {filename}")
            return
        # 60ì´ˆ ë™ì•ˆ ë½ ì„¤ì • (íƒœìŠ¤í¬ê°€ íì— ë¨¸ë¬´ëŠ” ì‹œê°„ ê³ ë ¤)
        redis_client.setex(lock_key, 60, "in_progress")

    # [...] ë¯¸ë¦¬ë³´ê¸° íƒœê·¸ ì œê±° (TTSê°€ ì½ëŠ” í´ë¦° í…ìŠ¤íŠ¸)
    clean_text = question_text
    if question_text.startswith('[') and ']' in question_text:
        parts = question_text.split(']', 1)
        if len(parts) > 1:
            clean_text = parts[1].strip()

    try:
        # [fire-and-forget] TTS íƒœìŠ¤í¬ëŠ” íŒŒì¼ì„ ì§ì ‘ ì €ì¥í•˜ë¯€ë¡œ ê²°ê³¼ë¥¼ ê¸°ë‹¤ë¦´ í•„ìš” ì—†ìŒ
        celery_app.send_task(
            "tasks.tts.synthesize",
            args=[clean_text],
            kwargs={"language": "ko", "question_id": question_id},
            queue="cpu_queue"
        )
        logger.info(f"ğŸ”Š [TTS] ë¹„ë™ê¸° ìŒì„± ìƒì„± ìš”ì²­ ì™„ë£Œ: {filename} (ë°±ê·¸ë¼ìš´ë“œ ì²˜ë¦¬ ì¤‘)")
    except Exception as e:
        logger.warning(f"[TTS] question_id={question_id} ìƒì„± ìš”ì²­ ì‹¤íŒ¨: {e}")

# ë©´ì ‘ ìƒì„±
@router.post("", response_model=InterviewResponse)
async def create_interview(
    interview_data: InterviewCreate,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    ë©´ì ‘ ì„¸ì…˜ ìƒì„± ë° ì§ˆë¬¸ ìƒì„±
    """
    logger.info(f"ğŸ†• Creating interview session for user {current_user.id} using Resume ID: {interview_data.resume_id}")

    # ì´ë ¥ì„œì—ì„œ ì§€ì› ì§ë¬´(target_role) ë° íšŒì‚¬ëª… ê°€ì ¸ì˜¤ê¸°
    from db_models import Resume, Company
    import json
    resume = db.get(Resume, interview_data.resume_id)
    target_role = "ì¼ë°˜"
    extracted_company_id = interview_data.company_id

    if resume and resume.structured_data:
        s_data = resume.structured_data
        if isinstance(s_data, str):
            try:
                s_data = json.loads(s_data)
                if isinstance(s_data, str): 
                    s_data = json.loads(s_data)
            except Exception as e:
                logger.error(f"Failed to parse structured_data for auto-match: {e}")
                s_data = {}

        header = s_data.get("header", {}) if isinstance(s_data, dict) else {}
        target_role = header.get("target_role") or "ì¼ë°˜"

        if not extracted_company_id:
            target_company_name = header.get("target_company")
            logger.info(f"ğŸ” Extracted company name from resume: '{target_company_name}'")

            if target_company_name:
                stripped_name = str(target_company_name).strip()
                from sqlalchemy import func
                stmt = select(Company).where(func.lower(Company.company_name) == func.lower(stripped_name))
                found_company = db.exec(stmt).first()
                if found_company:
                    extracted_company_id = found_company.id
                    logger.info(f"ğŸ¢ Company auto-matched: '{stripped_name}' -> ID: {extracted_company_id}")
                else:
                    logger.warning(f"âš ï¸ No company found matching name: '{stripped_name}'")

    logger.info(f"ğŸ’¾ Final company_id to be saved: '{extracted_company_id}'")

    # 1. Interview ë ˆì½”ë“œ ìƒì„±
    new_interview = Interview(
        candidate_id=current_user.id,
        position=target_role, 
        company_id=extracted_company_id, 
        resume_id=interview_data.resume_id,
        status=InterviewStatus.SCHEDULED,
        scheduled_time=interview_data.scheduled_time,
        start_time=get_kst_now(),
        created_at=get_kst_now()
    )
    db.add(new_interview)
    db.commit()
    db.refresh(new_interview)

    interview_id = new_interview.id
    logger.info(f"Interview record created: ID={interview_id} (Target Role: {target_role})")

    # 2. í…œí”Œë¦¿ ì§ˆë¬¸ ì¦‰ì‹œ ìƒì„±
    try:
        from utils.interview_helpers import get_candidate_info, generate_template_question, check_if_transition
        candidate_info = get_candidate_info(db, interview_data.resume_id)
        is_transition = check_if_transition(candidate_info.get("major", ""), target_role)

        if is_transition:
            from config.interview_scenario_transition import get_initial_stages
            logger.info(f"âœ¨ [TRANSITION] Career change detected ({candidate_info.get('major')} -> {target_role}). Using transition scenario.")
        else:
            from config.interview_scenario import get_initial_stages
            logger.info("âœ… [STANDARD] Regular career path detected. Using standard scenario.")

        initial_stages = get_initial_stages()

        for stage_config in initial_stages:
            question_text = generate_template_question(stage_config["template"], candidate_info)
            display_name = stage_config.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
            intro_msg = stage_config.get("intro_sentence", "")
            question_text = f"{intro_msg} {question_text}" if intro_msg else question_text

            # 2-1. Question ê°ì²´ ìƒì„±
            question = Question(
                content=question_text,
                category=QuestionCategory.BEHAVIORAL,
                difficulty=QuestionDifficulty.EASY,
                question_type=stage_config["stage"],
                rubric_json={"criteria": ["ëª…í™•ì„±"]},
                position=target_role,
                created_at=get_kst_now()
            )
            db.add(question)
            db.flush() 

            # 2-1. Question ê°ì²´ ìƒì„± (TTS ë¹„ë™ê¸° ìš”ì²­ í¬í•¨)
            _fire_tts_for_question(question.id, question_text)

            # 2-2. Transcript ê°ì²´ ìƒì„±
            transcript = Transcript(
                interview_id=new_interview.id,
                speaker="AI",
                text=question_text,
                question_id=question.id,
                order=stage_config.get("order", 0),
                timestamp=get_kst_now()
            )
            db.add(transcript)
            logger.info(f"âœ¨ [PRE-GENERATE] Stage '{stage_config['stage']}' (Order {stage_config['order']}) created at backend.")

        new_interview.status = InterviewStatus.LIVE
        db.add(new_interview)
        db.commit() 

        logger.info(f"âœ… Interview setup SUCCESS for ID={interview_id}")

        try:
            celery_app.send_task(
                "tasks.question_generation.preload_model",
                queue="gpu_queue"
            )
            logger.info("ğŸ”¥ [Preload] EXAONE ëª¨ë¸ ì‚¬ì „ ë¡œë”© íƒœìŠ¤í¬ ë°œì‚¬ ì™„ë£Œ (ë¹„ë™ê¸°)")
        except Exception as e:
            logger.warning(f"[Preload] ëª¨ë¸ ì‚¬ì „ ë¡œë”© íƒœìŠ¤í¬ ì „ì†¡ ì‹¤íŒ¨ (ë¬´ì‹œ): {e}")

    except Exception as e:
        logger.error(f"âŒ Interview setup CRITICAL FAILURE: {e}")
        db.rollback()
        raise HTTPException(status_code=500, detail=f"ì§ˆë¬¸ ìƒì„± ì¤‘ ì„œë²„ ì˜¤ë¥˜: {str(e)}")

    return InterviewResponse(
        id=new_interview.id,
        candidate_id=new_interview.candidate_id,
        position=new_interview.position,
        status=new_interview.status,
        start_time=new_interview.start_time,
        end_time=new_interview.end_time,
        overall_score=new_interview.overall_score
    )

# ì „ì²´ ì¸í„°ë·° ëª©ë¡ ì¡°íšŒ 
@router.get("")
async def get_all_interviews(
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    if current_user.role not in ["recruiter", "admin"]:
        stmt = select(Interview).where(
            Interview.candidate_id == current_user.id
        ).order_by(Interview.created_at.desc())
    else:
        stmt = select(Interview).order_by(Interview.created_at.desc())

    interviews = db.exec(stmt).all()
    result = []
    from db_models import Company, Resume
    for interview in interviews:
        candidate = db.get(User, interview.candidate_id)
        resume = db.get(Resume, interview.resume_id) if interview.resume_id else None
        company = db.get(Company, interview.company_id) if interview.company_id else None

        actual_company = "ì§€ì› ê¸°ì—…"
        if resume and resume.structured_data:
            actual_company = resume.structured_data.get("header", {}).get("target_company") or actual_company

        if (not actual_company or actual_company == "ì§€ì› ê¸°ì—…") and company:
            actual_company = company.company_name

        result.append({
            "id": interview.id,
            "candidate_id": interview.candidate_id,
            "candidate_name": candidate.full_name if candidate else "Unknown",
            "position": interview.position,
            "company_name": actual_company, 
            "status": interview.status,
            "created_at": interview.created_at,
            "start_time": interview.start_time,
            "end_time": interview.end_time,
            "overall_score": interview.overall_score,
            "resume_id": interview.resume_id
        })
    return result

# ë©´ì ‘ ì§ˆë¬¸ ì¡°íšŒ (â˜… í”„ë¡ íŠ¸ì—”ë“œê°€ í´ë§í•  í•µì‹¬ API)
@router.get("/{interview_id}/questions")
async def get_interview_questions(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    """
    ë©´ì ‘ì˜ ì§ˆë¬¸ ëª©ë¡ ì¡°íšŒ
    í”„ë¡ íŠ¸ì—”ë“œì—ì„œ ì£¼ê¸°ì ìœ¼ë¡œ í˜¸ì¶œ(Polling)í•˜ì—¬ ìƒˆ ì§ˆë¬¸ê³¼ TTS ìŒì„± íŒŒì¼ ìƒíƒœë¥¼ í™•ì¸í•©ë‹ˆë‹¤.
    """
    stmt = select(Transcript).where(
        Transcript.interview_id == interview_id,
        Transcript.speaker == "AI"
    ).order_by(Transcript.id)

    results = db.exec(stmt).all()
    interview = db.get(Interview, interview_id)

    def get_audio_url(question_id: int, question_text: str) -> str | None:
        """TTS íŒŒì¼ ì¡´ì¬ ì‹œ URL ë°˜í™˜, ì—†ìœ¼ë©´ TTS íŠ¸ë¦¬ê±° í›„ None ë°˜í™˜"""
        if question_id is None:
            return None
        filepath = TTS_UPLOAD_DIR / f"q_{question_id}.wav"
        if filepath.exists():
            timestamp = int(get_kst_now().timestamp())
            url = f"{BACKEND_PUBLIC_URL}/uploads/tts/q_{question_id}.wav?t={timestamp}"
            return url
        
        logger.warning(f"â³ [TTS Missing] ID: {question_id}, Path: {filepath}")
        import threading
        threading.Thread(
            target=_fire_tts_for_question,
            args=(question_id, question_text),
            daemon=True
        ).start()
        return None

    return {
        "status": interview.status if interview else "UNKNOWN",
        "questions": [
            {
                "id": t.question_id,
                "content": t.text,
                "order": t.order,
                "timestamp": t.timestamp,
                "audio_url": get_audio_url(t.question_id, t.text)
            }
            for t in results
        ]
    }

# ë©´ì ‘ì˜ ì „ì²´ ëŒ€í™” ê¸°ë¡ ì¡°íšŒ
@router.get("/{interview_id}/transcripts")
async def get_interview_transcripts(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    stmt = select(Transcript).where(
        Transcript.interview_id == interview_id
    ).order_by(Transcript.timestamp)

    transcripts = db.exec(stmt).all()

    return [
        {
            "id": t.id,
            "speaker": t.speaker,
            "text": t.text,
            "timestamp": t.timestamp,
            "sentiment_score": t.sentiment_score,
            "emotion": t.emotion
        }
        for t in transcripts
    ]

# ë©´ì ‘ ì™„ë£Œ ì²˜ë¦¬
@router.post("/{interview_id}/complete")
async def complete_interview(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    interview = db.get(Interview, interview_id)
    if not interview:
        raise HTTPException(status_code=404, detail="Interview not found")

    interview.status = InterviewStatus.COMPLETED
    interview.end_time = get_kst_now()
    db.add(interview)
    db.commit()

    celery_app.send_task(
        "tasks.evaluator.generate_final_report",
        args=[interview_id],
        queue='gpu_queue'
    )
    return {"status": "completed", "interview_id": interview_id}

# í–‰ë™ ë¶„ì„ ì ìˆ˜ ì €ì¥
@router.patch("/{interview_id}/behavior-scores")
async def save_behavior_scores(
    interview_id: int,
    request: dict,
    db: Session = Depends(get_session),
):
    import json as json_lib

    interview = db.get(Interview, interview_id)
    if not interview:
        raise HTTPException(status_code=404, detail="Interview not found")

    averages = request.get("averages", {})
    interview.emotion_summary = {
        "averages": averages,
        "interview_duration_sec": request.get("interview_duration_sec"),
        "total_questions": request.get("total_questions")
    }
    interview.overall_score = averages.get("total")
    db.add(interview)

    per_question = request.get("per_question", [])
    if per_question:
        user_transcripts = db.exec(
            select(Transcript).where(
                Transcript.interview_id == interview_id,
                Transcript.speaker == SpeakerEnum.USER
            ).order_by(Transcript.id)
        ).all()

        for i, q_score in enumerate(per_question):
            if i < len(user_transcripts):
                user_transcripts[i].emotion = json_lib.dumps(q_score, ensure_ascii=False)
                user_transcripts[i].sentiment_score = q_score.get("total")
                db.add(user_transcripts[i])
                logger.info(f"  ğŸ“ Q{q_score['q_idx']} â†’ transcript[{user_transcripts[i].id}].emotion ì €ì¥")

    db.commit()
    logger.info(f"âœ… [behavior-scores] Interview {interview_id} í–‰ë™ ë¶„ì„ ì ìˆ˜ ì €ì¥ ì™„ë£Œ")
    return {"status": "saved", "interview_id": interview_id}

# í‰ê°€ ë¦¬í¬íŠ¸ ì¡°íšŒ
@router.get("/{interview_id}/report", response_model=EvaluationReportResponse)
async def get_evaluation_report(
    interview_id: int,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    stmt = select(EvaluationReport).where(
        EvaluationReport.interview_id == interview_id
    )
    report = db.exec(stmt).first()

    from db_models import Company, Resume
    interview = db.get(Interview, interview_id)

    if not interview:
        raise HTTPException(status_code=404, detail="Interview not found")

    resume = db.get(Resume, interview.resume_id) if interview.resume_id else None
    company = db.get(Company, interview.company_id) if interview.company_id else None
    candidate = db.get(User, interview.candidate_id) if interview.candidate_id else None

    res_data = {}
    if resume and resume.structured_data:
        if isinstance(resume.structured_data, str):
            import json
            try: res_data = json.loads(resume.structured_data)
            except: res_data = {}
        else:
            res_data = resume.structured_data

    res_header = res_data.get("header", {})

    cand_name = res_header.get("name") or (candidate.full_name if candidate else "ì§€ì›ì")
    actual_position = res_header.get("target_role") or (interview.position if interview.position != "ì¼ë°˜" else None) or "ì „ë¬¸ ì§ë¬´"

    actual_company = res_header.get("target_company")
    if not actual_company or str(actual_company).strip() == "":
        actual_company = company.company_name if (company and company.company_name) else "ì§€ì› ê¸°ì—…"

    if not report:
        now = get_kst_now()
        return {
            "id": 0,
            "interview_id": interview_id,
            "technical_score": 0, "communication_score": 0, "cultural_fit_score": 0,
            "summary_text": "AIê°€ í˜„ì¬ ë©´ì ‘ ë‚´ìš©ì„ ìƒì„¸ ë¶„ì„í•˜ê³  ìˆìŠµë‹ˆë‹¤. ì ì‹œë§Œ ê¸°ë‹¤ë ¤ ì£¼ì„¸ìš”.",
            "details_json": {},          
            "created_at": now,           
            "position": actual_position,
            "company_name": actual_company,
            "candidate_name": cand_name,
            "interview_date": interview.start_time or now,
            "technical_feedback": "ë¶„ì„ì´ ì™„ë£Œë˜ë©´ ì—¬ê¸°ì— í‘œì‹œë©ë‹ˆë‹¤.",
            "experience_feedback": "ë°ì´í„° ë¶„ì„ ì¤‘...",
            "problem_solving_feedback": "ë°ì´í„° ë¶„ì„ ì¤‘...",
            "communication_feedback": "ì˜ì‚¬ì†Œí†µ ì—­ëŸ‰ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "responsibility_feedback": "ì±…ì„ê° ë° ì¡°ì§ ì í•©ì„±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "growth_feedback": "ì„±ì¥ ê°€ëŠ¥ì„±ì„ ë¶„ì„ ì¤‘ì…ë‹ˆë‹¤.",
            "strengths": ["ë¶„ì„ ì§„í–‰ ì¤‘"],
            "improvements": ["ë¶„ì„ ì§„í–‰ ì¤‘"]
        }

    try:
        report_dict = report.model_dump()
    except AttributeError:
        report_dict = report.dict()
        
    report_dict["position"] = actual_position
    report_dict["company_name"] = actual_company
    report_dict["candidate_name"] = cand_name
    report_dict["interview_date"] = interview.start_time if interview else report.created_at

    details = report.details_json or {}

    report_dict["responsibility_score"] = details.get("responsibility_score", 0)
    report_dict["growth_score"] = details.get("growth_score", 0)
    report_dict["experience_score"] = details.get("experience_score", 0)
    report_dict["problem_solving_score"] = details.get("problem_solving_score", 0)

    report_dict["technical_feedback"] = details.get("technical_feedback") or report.summary_text or "ê¸°ìˆ  ì—­ëŸ‰ ë¶„ì„ ê²°ê³¼ê°€ ìƒì„± ì¤‘ì…ë‹ˆë‹¤."
    report_dict["experience_feedback"] = details.get("experience_feedback") or "í”„ë¡œì íŠ¸ ê²½í—˜ì— ëŒ€í•œ AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
    report_dict["problem_solving_feedback"] = details.get("problem_solving_feedback") or "ë¬¸ì œ í•´ê²° ëŠ¥ë ¥ì— ëŒ€í•œ AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
    report_dict["communication_feedback"] = details.get("communication_feedback") or "ì˜ì‚¬ì†Œí†µ ìŠ¤íƒ€ì¼ì— ëŒ€í•œ AI ë¶„ì„ ê²°ê³¼ì…ë‹ˆë‹¤."
    report_dict["responsibility_feedback"] = details.get("responsibility_feedback") or "ì§€ì›ìì˜ ì§ì—… ìœ¤ë¦¬ ë° ì±…ì„ê°ì— ëŒ€í•œ ìƒì„¸ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤."
    report_dict["growth_feedback"] = details.get("growth_feedback") or "í–¥í›„ ë°œì „ ê°€ëŠ¥ì„± ë° ì¸ì¬ìƒ ë¶€í•©ë„ì— ëŒ€í•œ ë¶„ì„ ë‚´ìš©ì…ë‹ˆë‹¤."

    report_dict["strengths"] = details.get("strengths") or ["ì„±ì‹¤í•œ ë‹µë³€ íƒœë„", "ì§ë¬´ ê¸°ì´ˆ ì—­ëŸ‰ ë³´ìœ "]
    report_dict["improvements"] = details.get("improvements") or ["êµ¬ì²´ì ì¸ ì‚¬ë¡€ ë³´ê°• í•„ìš”", "ê¸°ìˆ ì  ê·¼ê±° ë³´ì™„"]

    return report_dict

# ì‹¤ì‹œê°„ ëŒ€í™”í˜• ë©´ì ‘ API
@router.post("/realtime", response_model=InterviewResponse)
async def create_realtime_interview(
    interview_data: InterviewCreate,
    db: Session = Depends(get_session),
    current_user: User = Depends(get_current_user)
):
    logger.info(f"ğŸ†• Creating REALTIME interview session for user {current_user.id} using Resume ID: {interview_data.resume_id}")

    from utils.interview_helpers import get_candidate_info
    candidate_info = get_candidate_info(db, interview_data.resume_id)
    target_role = candidate_info.get("target_role", "ì¼ë°˜")
    candidate_name = candidate_info.get("candidate_name", "ì§€ì›ì")

    new_interview = Interview(
        candidate_id=current_user.id,
        position=target_role,
        company_id=interview_data.company_id,
        resume_id=interview_data.resume_id,
        status=InterviewStatus.IN_PROGRESS,
        scheduled_time=interview_data.scheduled_time,
        start_time=get_kst_now(),
        created_at=get_kst_now()
    )
    db.add(new_interview)
    db.commit()
    db.refresh(new_interview)
    db.flush() 

    logger.info(f"Realtime Interview created: ID={new_interview.id}, Candidate={candidate_name}, Target Role={target_role}")

    try:
        from utils.interview_helpers import generate_template_question, check_if_transition
        is_transition = check_if_transition(candidate_info.get("major", ""), target_role)

        try:
            if is_transition:
                from config.interview_scenario_transition import get_initial_stages
            else:
                from config.interview_scenario import get_initial_stages
            initial_stages = get_initial_stages()
        except ImportError:
            logger.warning("âš ï¸ Could not import interview_scenario, using hardcoded fallback questions.")
            initial_stages = [
                {"stage": "intro", "display_name": "ê¸°ë³¸ ì§ˆë¬¸", "intro_sentence": "ë°˜ê°‘ìŠµë‹ˆë‹¤. ë©´ì ‘ì„ ì‹œì‘í•˜ê¸° ìœ„í•´ ë¨¼ì € ê°„ë‹¨íˆ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.", "template": "{candidate_name} ì§€ì›ìë‹˜, ê°„ë‹¨íˆ ìê¸°ì†Œê°œ ë¶€íƒë“œë¦½ë‹ˆë‹¤.", "order": 1},
                {"stage": "motivation", "display_name": "ê¸°ë³¸ ì§ˆë¬¸", "intro_sentence": "ê°ì‚¬í•©ë‹ˆë‹¤. ì´ì–´ì„œ ì§€ì›í•˜ì‹  ë™ê¸°ì— ëŒ€í•´ ë“¤ì–´ë³´ê³  ì‹¶ìŠµë‹ˆë‹¤.", "template": "{candidate_name} ì§€ì›ìë‹˜, ì§€ì›ë™ê¸° ë§ì”€í•´ì£¼ì„¸ìš”.", "order": 2}
            ]

        for stage_config in initial_stages:
            question_text = generate_template_question(
                stage_config.get("template", "{candidate_name}ë‹˜ ì‹œì‘í•´ì£¼ì„¸ìš”."),
                candidate_info
            )
            display_name = stage_config.get("display_name", "ë©´ì ‘ì§ˆë¬¸")
            intro_msg = stage_config.get("intro_sentence", "")
            question_text = f"{intro_msg} {question_text}" if intro_msg else question_text

            question = Question(
                content=question_text,
                category=QuestionCategory.BEHAVIORAL,
                difficulty=QuestionDifficulty.EASY,
                question_type=stage_config.get("stage", "general"),
                rubric_json={"criteria": ["ëª…í™•ì„±"]},
                position=target_role,
                created_at=get_kst_now()
            )
            db.add(question)
            db.flush()

            # Question ê°ì²´ ìƒì„± (TTS ë¹„ë™ê¸° ìš”ì²­ í¬í•¨)
            _fire_tts_for_question(question.id, question_text)

            transcript = Transcript(
                interview_id=new_interview.id,
                speaker="AI",
                text=question_text,
                question_id=question.id,
                order=stage_config.get("order", 0),
                timestamp=get_kst_now()
            )
            db.add(transcript)

        db.commit()
        logger.info(f"âœ… Realtime interview setup SUCCESS for ID={new_interview.id}")

    except Exception as e:
        logger.error(f"âŒ Realtime interview setup FAILED: {e}")
        db.rollback()
        raise HTTPException(
            status_code=status.HTTP_500_INTERNAL_SERVER_ERROR,
            detail=f"ì§ˆë¬¸ ìƒì„± ì‹¤íŒ¨: {str(e)}"
        )

    return InterviewResponse(
        id=new_interview.id,
        candidate_id=new_interview.candidate_id,
        position=new_interview.position,
        status=new_interview.status,
        start_time=new_interview.start_time,
        end_time=new_interview.end_time,
        overall_score=new_interview.overall_score
    )